<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>WonderLand</title>
  
  <subtitle>Somnium &amp; Somniator</subtitle>
  <link href="/blog/atom.xml" rel="self"/>
  
  <link href="https://www.cmwonderland.com/blog/"/>
  <updated>2019-04-23T14:45:54.003Z</updated>
  <id>https://www.cmwonderland.com/blog/</id>
  
  <author>
    <name>James Chen</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Daily Random Thoughts</title>
    <link href="https://www.cmwonderland.com/blog/2019/04/23/26_dailythoughts/"/>
    <id>https://www.cmwonderland.com/blog/2019/04/23/26_dailythoughts/</id>
    <published>2019-04-23T11:47:25.000Z</published>
    <updated>2019-04-23T14:45:54.003Z</updated>
    
    <content type="html"><![CDATA[<h2 id="碎碎念-amp-will-update-daily"><a href="#碎碎念-amp-will-update-daily" class="headerlink" title="碎碎念&amp; will update daily"></a>碎碎念&amp; will update daily</h2><blockquote><p>基本来自于过去的各处的碎碎念，比如记录在朋友圈的，便签里的，笔记里的。和孟孟微信聊天的太不好找了，以及很多时候口头聊的时候觉得自己充满哲理与逻辑的很好的话都没有记录下来，总会有种可惜的感觉，不过也许很多东西都已经内化为大脑结构的一部分了吧。OK，让我们先从中二热血的开始。</p></blockquote><p>“整理这些碎碎念让我更好的感觉到我还活着”——2019.4.23<br><a id="more"></a></p><hr><p>深度学习只是效率更高的曲线拟合？陷入概率模型的陷阱？贝叶斯模型才是未来？因果推断是AI的途径？THE BOOK OF WHY值得读一读<br><a href="https://mp.weixin.qq.com/s/e4dhCPRbTr-amPbKWpiFwQ" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/e4dhCPRbTr-amPbKWpiFwQ</a></p><hr><p>最爱的龙珠超就这么完结啦，追了两年多，每周日一集，最忙的时候（美赛）都在凌晨补看了，考完托福出来也要先看了龙珠超再吃饭。总有人说龙珠超画面崩坏缺乏诚意，但是真的很好看呀，对于一个上大学了还把龙珠漫画重温了很多遍的人来说，龙珠系列二十多年后还有最爱的漫画的新篇章可以看真的太幸福了，记得去年十月八号109，110两集联播的大战的震撼，让我很多个晚上一遍遍地重温，龙珠总是能在这么多年后还点燃全世界粉丝的热情，龙珠这么赚钱的ip，明年剧场版搞完肯定还会接着画，悟空会更强，故事会继续~<a href="https://bbs.hupu.com/21773153.html" target="_blank" rel="noopener">https://bbs.hupu.com/21773153.html</a> </p><blockquote><p>记于龙珠超完结。</p></blockquote><iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width="330" height="86" src="//music.163.com/outchain/player?type=2&id=536623434&auto=1&height=66"></iframe><hr><p>这么多年了，江南想起来他还有龙族这本书要写了，人已经变成中年大叔了，还能热血得起来么。龙族勾起了我很多美好的回忆，和好哥们一起讨论每一个细节是非常愉快的经历，现在又可以在江南扣扣索索地每次更新两页纸之后吐槽了。</p><blockquote><p>记于龙五开始连载</p></blockquote><hr><p>校庆期间读到最好看的故事，把各个时代的知名人物给串起来了，很多感触：<br>最重要的故事总是被少数几个人推动着，如果没有张钹院士四十年来持续不断对人工智能的大力推进，新一代马少平这样的教师，还有周枫这样的天才，恐怕清华和人工智能未必会有多少缘分；真的很羡慕96年左右的黄金时代，在最早通互联网的地方那批人受到那么好的滋润，实习工资一万一个月，那时候北京房价才两千多吧，到现在也都成了一方互联网大佬，生逢其时很重要；计算机系真的是收纳聪明人，而且课程导向不断把人培养的更聪明有趣的地方，好像唐文斌在文章里说：“我们当时想办法把多门课的大作业凑成一个作业，努力编出一个很合理的题目，既可以交这边又能交那边，就可以用两倍时间把一个大作业做的非常之nb”，上学期用这个方法一个项目用了三遍，可惜没舍得花三倍的时间做好，可见投机取巧容易，有挑战心很难，而编程真的是很容易让人有挑战心的事情；<br>前辈们铺路，这个时代真好。</p><p><a href="https://mp.weixin.qq.com/s/cClINXB242XLmZ6AhE8e_w" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/cClINXB242XLmZ6AhE8e_w</a></p><blockquote><p>记于校庆</p></blockquote><hr><p>太酷炫了，而且看起来更贴近医疗应用，如果设备再小型化商业化的话，是不是可以说细胞尺度的医疗大数据时代就来了，也许有一天真的可以对活体生物做细胞尺度的建模？也许有一天可以对大脑做活体建模呢</p><p><a href="https://mp.weixin.qq.com/s/vn4SL0672OPytqET_4F1Hw" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/vn4SL0672OPytqET_4F1Hw</a></p><hr><p>施boss实在是太了不起了，人生为一件大事来。<br>看校董会俨然是清华系把持的了，说不定几十年后中国教育史”私立大学的曙光”一章会这么写：在当时最好的大学，几位治学与育人都具有超人眼光和手段的学界领袖杨振宁，施一公，钱颖一做出了一步大胆的尝试，从而孕育出了一所世界顶级的中国的私立大学。</p><p><a href="https://mp.weixin.qq.com/s/KiZpIVvtfVHEh-so4szbUQ" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/KiZpIVvtfVHEh-so4szbUQ</a></p><hr><p>强无敌，说好的一年，这才几个月就完成了第一步，我觉得这项目就是杰出科学家和基金会结合的典范，真女神级科学家Regev致力推动的人类细胞图谱，本来也是个上帝工程，需要Regev一遍遍强调一步步慢慢合作就好，不一定要有一个目标，完成一部分也行，结果扎克伯格的资金进来，全球顶级科学家积极申请，提前完成测序，以后数据要是都公开的话计算生物学家要幸福晕了<br>看来下一步忽悠几个富人给连接组学多捐点钱，什么研究大脑结构说不定可以变得更聪明、不得老年痴呆，长生不老什么的，说不定没几年就真把大脑连接全测出来了，要乐观，我看21世纪真还就是生命科学的世纪</p><p><a href="https://mp.weixin.qq.com/s/W2ItMP-LK5qPnAozxgsORg" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/W2ItMP-LK5qPnAozxgsORg</a></p><hr><p>这个真的好啊，快赶上以前mini款嗯价格了，太实惠了，而且支持pencil！ipad pro得五千往上了吧，再加上刚和罗技推出的300的pencil，两千多一点用最新款ipad而且是支持pencil款，ipad真是款越来越没对手的产品，，，</p><p><a href="https://wap.ithome.com/html/352915.htm" target="_blank" rel="noopener">https://wap.ithome.com/html/352915.htm</a></p><hr><p>拿到连接组的电镜数据的时候玩了个无聊的游戏，把空间的一百多层切片按时间顺序展开，发现神经元逐层的伸展在时间尺度上竟然像细胞的无规则运动，感觉这种时空的转换好有趣，如果时间尺度的游动在空间上展开又会是什么有趣的样子呢</p><blockquote><p>记于把空间图像动画呈现后的感想</p></blockquote><hr><p>百度云总裁的程序员表达风格，斯隆管理评论的主席这数据是用matplotlib画的吧，随随便便写个评论发Nature好爽，李稻葵随时装逼：和硅谷风险投资人Peter Thiel吃早餐聊起来人工智能，，，李稻葵是真帅真聪明真有趣，谦虚且学习能力极快，不愧是给boss上课的顶级智囊，李珍老师真幸福，，，疯狂夸工科比MIT强，自黑经管研究很弱，狂黑特朗普，然后自夸政府高科技领域政策宽松，狂赞美国的天才制度，狂黑中国的中庸培养扼杀个性。然后讨论一波不停骂特朗普，估计中美贸易战快被烦死了<br>另外说什么2030还不知道美国总统在哪儿呢，应该搞个AI xian fa，中国想得远，两个一百年，美国整天就在竞选，总感觉在黑，，，</p><blockquote><p>记于中美人工智能前沿论坛</p></blockquote><hr><p>这样做大概就默认了连接组学真的可以从结构还原记忆了，虽然差的太远太远，保存大脑并没有用，还得切成极其薄的切片，亚细胞尺度地成像再重构出来才行，以及如果是致死性的，那就是哲学上的命题了，这个人就不是自己了，应该只有忒休斯之船那样在活着的时候一部分一部分替换才可以，做不影响生命但是存储记忆部位的材料替换。看人类的技术进展，几十年内也没什么戏，这个初创公司的简单的把戏，也就是给个最后一刻的安慰罢了</p><p><a href="https://mp.weixin.qq.com/s/Rq_uUmdllhFvpr_JmNmv3g" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/Rq_uUmdllhFvpr_JmNmv3g</a></p><hr><p>有意思有深度，量子位这位编辑总结的好。之前我还专门总结过<a href="https://www.cmwonderland.com/2018/04/10/Deep-Learning-Practice/">Deep Learning Practice | WonderLand</a></p><p><a href="https://mp.weixin.qq.com/s/R-29UGMvHyBp8OkWk7zdpw" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/R-29UGMvHyBp8OkWk7zdpw</a></p><hr><p>这篇文章读了五遍，体会越来越深。初中的时候从宋老师那里借来犹太名人传科学家册读，活脱脱一部量子力学史，读Hinton的故事则是在读一部深度学习史，让人迫不及待地想知道个究竟，为什么事情这么发生了。Hinton是鼻祖，是如今万人崇敬的精神领袖，还对神经和意识无比痴迷，是个真正的科学家，且家学渊源深厚，“做学者，或者做个失败者”，从这种故事中获得历史上的大师们的精神传承非常有意义。我觉得Hinton有一种真正的科学家的魅力，不够入世，拥有庞大“虚幻”的梦想，  在寒冬和热潮中竟然能够不动摇，这种传世的科学精神非常非常的了不起。</p><p><a href="https://mp.weixin.qq.com/s/vNYMHFhXeEzz6Ny0p1pbNA" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/vNYMHFhXeEzz6Ny0p1pbNA</a></p><hr><p>太厉害了！马斯克原版roadster的神秘力量，太了不起了，并联发动机还可以回收，有人总是想找借口说马斯克没什么了不起，就是一个使用NASA技术的商人，NASA养多少亲儿子了怎么没见到成功的，马斯克想搞火箭的时候还得跑到俄罗斯买的时候又怎么说呢。我总觉得用凡人和投资人的角度去揣度马斯克是现实却狭隘庸俗的，当你被自我眼界所拘束的时候，他在用他的方式追寻星辰大海</p><p><a href="https://wap.ithome.com/html/346687.htm" target="_blank" rel="noopener">https://wap.ithome.com/html/346687.htm</a></p><hr><p>上午的讲座是听过的最佳之一，付向东太了不起了，RNA world的领军人物，人生经历颇为传奇，培养的学生也极其传奇，谈起人生经验科研经验培养经验，不知道台下一堆PI们有没有脸红耳赤的感觉，而且总能抓住重大科学问题，领域的切换也非常顺滑，还滑到了那么有趣的神经领域，最后落到疾病的治疗，实在是很了不起。现在愈发想以后去读个postdoc了，就是不知道六七年后付老师还搞不搞得动啦。午餐的时候听付老师继续谈笑风生，实在是太了不起了了，CNS和子刊发了七十多篇了，，大谈科研经验培养经验人生经验，感觉比施一公还强啊，，，博后做PI成功率80%，简直高的可怕，越来越想去读个postdoc了，，</p><blockquote><p>记于付向东讲座后</p></blockquote><hr><p>哇，从来没有看过这么特别且震撼的电影，今天和朋友去偏僻的海淀工人电影院看一部上映很久的梵高的电影，六万多帧，要么是彩色的油画，要么是黑白的胶片，抽象的影像把让细节和故事本身特别抓人，故事竟然有了点罗生门式的悬疑的味道，却没有走偏，原来观众想寻找的害死梵高的凶手并不存在，谁都没有错，每个人都不是坏人，只剩对天才的崇敬和对天才带来的性格与命运的诅咒的旁观式的叹惋，感觉现在越来越能理解这种事情了，那些让未来的世界变得美好的却承受着来自这个世界的痛苦的人，努力地付出却得痛苦地承认自己得不到回报，这种天赋让人羡慕也让人心疼。</p><blockquote><p>记观影《至爱梵高》</p></blockquote><hr><p>哇很美很美，顺便夹带点私货，学细胞的时候就在想，这么枯燥无味的讲述方式和背书方式简直是毫无用处的折磨，如果有人做了一个3D可视化或者VR的细胞全景，整个学期大家可以真的在细胞里遨游畅览，效果会好太多。只可惜有能力做出来的人大多没时间做。施一公几年前就想做Science is cool的让更多人爱上自然科学的工作了，看起来也没空做，而广大PI们工作繁重，而且恐怕也不舍得让实验室博士生们花很久做这个，我见过的最开明的就是张强锋老师让学生玩了几个月VR看结构了。最后还有一个很重要的问题，对于生物和化学这样公认的大坑来说，爱和理想能不能解决问题。我的很多同学在一门门地背生物课的时候都深受其苦，新雅的学生们和外系混住，意识到自己数学计算机和各种专业课学的太简单太水的也分分修辅修额外选课，让我觉得这么学科和它的解决方法太不匹配了，生物是最美丽动人的学科，但是仿佛在蛮荒时期的不定量，不系统，有大量难解之谜的研究方法让人失落，好像生物应该是四十二世纪的科学，我们都生的太早了一样。<br>而且最好玩的事情在于，生物学细碎却庞大，不需要多么费劲就总能发出来文章，而且往往数据和意义可以帮忙保驾护航，让一堆数学家物理学家嫉妒经费，这些更加美丽理性的学科更难推进，LHC烧了多少经费也验证不出来几个美妙的理论，有的数理出身的还会转生物来抢饭碗，这些人往往都聪明强大，包括在就业工作的时候，这些学了无数门复杂可怕的专业课的学生的综合水平也大大高于生物系的学生，我见识过电子系物理系计算机系这些专业的学生，课程设置上生物系一学期的课程带来的智力挑战未必比得上这些院系一门课程，院系间的差距大的可怕，最终带来了人的巨大差距。<br>所以结论就是，生物学太美丽而宏大，这么复杂的系统让我们丧失了定量化的工具，丧失了运用大脑更复杂的数理逻辑体系化解决的能力，于是我们选择了一条很卑微的道路，把精彩的专业课变成了专业内常识与名词介绍与记忆课程。其实一条复杂的信号通路，一个蛋白的互作网络，都需要大量的数学模型去描述，但是这样没法讲，没法做，投入太多，大家压力太大，研究看起来用不着这么难也能发文章，那就索性不要了好了。我去听过北大开的生物数学物理的课，讲如何在生物学问题里建模，课是数学系老师开的，课是数学物理专业学生选的。<br>从就业角度，大家当然愿意学金融，同样一片混沌模糊的专业，但是能赚钱，选计算机电子，累，动脑子但是赚钱，选数学物理，累动脑子，回头转行赚钱。选生物的话，似乎陷入了一个低门槛的陷阱，前两天一个PI问我，觉不觉得生物是一个大坑，每个人都知道它的问题，但是看起来这不是生物学的错，也不是大家的错，也许是生的早了的错，也许也有点想的不够多不够努力的错，所以对于广大社会群体来讲，同样不思考那么多，大学直接去计算机电子数学物理这些专业跟着被虐，都能学到很多能力，所以也怪大家主观能动性不强，还要怪生物学现象太多太多了，等二十五世纪一切尘埃落定，所有的一切发现都摆在生物学家眼前等待解释的时候，我相信那个时代的生物会是门槛最高最需要思维与理性的专业。希望这两代科学家解决好疾病衰老和神经的问题，让我们都有机会看到那一天吧。</p><p><a href="https://mp.weixin.qq.com/s/enkZra8kLqnV2gEi3ThTMA" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/enkZra8kLqnV2gEi3ThTMA</a></p><hr><p>学校终于批复了嘛。中国最好的大学损失了一位未来的杰出校长，但是中国教育史上可能因此留下一个更加传奇的名字，这是件功德无量的大事，施一公说他要把西湖大学建成中国的Berkeley，一定可以的</p><p>前几任校领导，陈希是今上化工系的老同学，如今已经是中组部长，书记处书记，胡和平水利系出来，已经是陕西书记，陈吉宁卸任不过两年多，已经是北京市长，施boss本来就深得今上厚爱，政治上也是前途无量的，但是我感觉他仔细考虑过这些，作为一个更加纯粹的科学家和教育家，他找到了一种我们这些书生看起来更棒的青史留名的机会，他衡量过什么才是他后半生的人生大事，所以这份事业在他心中真的拥有无比厚重的分量</p><blockquote><p>记于施一公辞任清华副校长，全职执掌西湖大学</p></blockquote><hr><p>最后一节体育课，一同学突然凑过来说，同学你以前是不是法学院的，看着好熟悉，我以为是法学院一同学，交谈几句发现是五字班的，生物竞赛生，开学就转了物理。高三的时候第一届生物预科班提前来了清华。三年前的春天，我当时还没转生物，看到了一个去NIBS罗敏敏老师实验室参观的通知，就跟着几个人一起跑过去了，想想真的神奇，在那里看了光遗传学的技术，还有透明脑的技术，罗敏敏老师一直是个非常fancy的人，然后认识了这个同学，我还感慨着我还没有转到生物系，这边高三的学生就被施一公拉过来提前上课了。我记得罗老师请吃饭的时候，我还问他，老师您觉得有没有可能我们可以把大脑里的所有结构研究清楚，这样人就可以永生了，我就是为这个梦想转系的。两年后上了钟毅和罗敏敏老师的神经课，知道王立元学长在钟老师那里也在做透明脑的成像，还认识了林祖迪学长做深度学习，但是暑研去了Harvard的Litchman那里用深度学习重构三维的大脑连接组学图像。而这位转物理的同学依然做着生物相关的研究，我一问，果然在宋森老师那里，做类脑计算的东西，宋森老师现在想用深度学习建模模拟出海马体的功能，感觉会非常有趣。钟老师本来也对我说想做类脑计算方面的工作，只可惜我本事太差，于是还是决定先踏踏实实学好深度学习的东西，心理先继续惦记着更加有趣但是飘渺的事物。没想到三年后遇到，大家围着的还是差不多的东西，大脑与意识真是古往今来最吸引人的事物，世界真小，但是有意思的人真多呀。</p><blockquote><p>记大三上网球课</p></blockquote><hr><p>2017年是我人生中真正感到满意的一年，难以想象这一年发生了多少事情，我热爱牵挂的人们依然幸福，最爱的人常在身边，发现了更多更大的世界，过去很多做不到的事情竟然一点点做到，遇到了很棒很了不起的人，感觉到人生的幸运和幸福，这半年做了很多不敢想象的事情，为自己喜爱的事情而奋斗是最佳的幸福条件，这一年感到自己多年来希冀的渺茫的梦想也许依然有为之奋斗一生的意义，这一年心想事成，感觉人类和科学的未来也光明可爱。<br>希望接下来的每一年，都能满意如今年，要倍加珍惜眼前美好的一切，要做更多真正了不起的事，要多想想真正的梦想，2018会更美好~</p><blockquote><p>2017年终</p></blockquote><hr><p>“在AI领域，我真的非常期待实现一个“没有AI就无法实现的”大的科学突破。我想这可能会在2018年发生在一个领域类似生物或化学领域。”<br>我们需要一个生物学领域的alpha go给老头子们带来点激荡了</p><p><a href="https://mp.weixin.qq.com/s/TyfT9bYq7tOkwuw7m0_SKg" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/TyfT9bYq7tOkwuw7m0_SKg</a></p><hr><p>Amazing，真的听不出来，那么不久电话客服就可以被淘汰了吗？既然他们大多数本身就在做信息检索，按照一套标准流程回应，现在有很自然的声音的话人们好接受多了。以及Google assistant 配上这样的声音能把siri甩开几个身位了，观感上差太多</p><p><a href="https://wap.ithome.com/html/340735.htm" target="_blank" rel="noopener">https://wap.ithome.com/html/340735.htm</a></p><hr><p>我看以后可以这样做三语教学：从胎教开始，播放中英文儿歌童谣，再加上把python代码转成语音？我看可以把github加星前一百的python项目的文档转成语音，培养孩子的语感，还可以把python常用package以及Sklearm,TensorFlow以及PyTorch的官方文档转成音频，还可以实时监测胎儿心动数据，搞一个机器学习算法，听的比较迷惑的地方多重复几遍。三岁开始教数值计算，五岁开始教基本数理逻辑，不能让孩子输在起跑线上，，<br>欢迎各位探讨新时代育儿经验</p><p><a href="https://mp.weixin.qq.com/s/WnH42-PLYDokJWpOPumurQ" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/WnH42-PLYDokJWpOPumurQ</a></p><hr><p>这家公司有趣了，暑假参加的比赛，SRT题和ANN大作业都在做胸片的识别，模式识别又做了CT的识别。感觉了感觉这家公司的创业成本和难度，CT的肺部识别因为kaggle和阿里两个大赛成熟方案很多，胸片的也有一些方案，吴恩达也在做，也好解决一些。鉴于代码开源好找到，难度基本就在于和医院合作拿到数据资源了。所以我猜最后还是腾讯来终结医疗图像市场，毕竟国家战略给BAT分山头的时候把AI医疗图像分给企鹅家了</p><p><a href="http://www.infervision.com/Infer/product?from=timeline&amp;isappinstalled=0" target="_blank" rel="noopener">http://www.infervision.com/Infer/product?from=timeline&amp;isappinstalled=0</a></p><hr><p>等老了是不是可以吹牛：年轻的时候看着比特币从几美元涨到了几十万美元一枚，，一天感慨一回，这种不知道顶点和终点的东西，和股市一样让人着迷，，比特币太贵了，要不买挖矿设备提供商英伟达好了</p><p><a href="https://wap.ithome.com/html/336543.htm" target="_blank" rel="noopener">https://wap.ithome.com/html/336543.htm</a></p><hr><p>真是愚蠢到令人瞠目结舌，核心的威力真是强，自己喜欢中医所以就这么搞？这是药，有可能会吃死人的东西，你为了推广中医临床都不用做了？以及中医不用参加医学考试，开诊所登记一下就行，我随意揣测一下：国家社保资金有巨大的缺口，医保承受不住，你们干脆就吃中药别吃那么贵的西药了，反正我们自己研发不出来有专利有仿制不了。我看以后谁敢看中医。</p><p><a href="https://mp.weixin.qq.com/s/6xQOUk3vgUe5mIWjhnPDKQ" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/6xQOUk3vgUe5mIWjhnPDKQ</a></p><hr><p>马斯克不是最完美的那个，却永远是最有魅力的那个，但是魅力这个词又这么单薄，这个人活得就像救世主一样，如果未来有什么决定命运的关头被挽救，那一定有他的功劳</p><p><a href="https://mp.weixin.qq.com/s/8tVLtErD7FvJ6jf7W45yLg" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/8tVLtErD7FvJ6jf7W45yLg</a></p><hr><p>没看成直播，十年后roadster2终于来了，百公里1.9，续航一千公里，史上速度最快的，在我看来也是最美的跑车，，但是另一款产品其实更伟大，这个拥有SpaceX公司的男人一定经常畅想着未来的模样，这个梦幻的卡车是为一个非常干净高效梦幻的未来而生的</p><p><a href="https://36kr.com/p/5103430.html?from=timeline&amp;isappinstalled=0" target="_blank" rel="noopener">https://36kr.com/p/5103430.html?from=timeline&amp;isappinstalled=0</a></p><hr><p>Oh my god！中国人的壮举！好想合作一波不过人家也说了合作的人太多了，，这实在太了不起了，有的事真的得有钱任性的社会主义大国才能干得了，你哈佛的每年上千万经费依然比不上我五十台设备并行成像，，遥远的梦想只要砸钱总是能实现的，大胆预测二十年后连接组学就能带来第一个完整的大脑三维重构图谱，那将是怎样壮观的景象，这个领域值得几代人奋斗终生</p><p><a href="https://mp.weixin.qq.com/s/oEaCUkM59tnNUPKIRZwekA" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/oEaCUkM59tnNUPKIRZwekA</a></p><hr><p>更幸运的是英伟达，，不到两年股价涨了六倍多，明知道AI火的要死矿主们还挖币挖的飞起，这笔这么好赚的买卖怎么就没想到呢，，</p><p><a href="https://mp.weixin.qq.com/s/EocGKMcs3tzY3O_dxbCVZQ" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/EocGKMcs3tzY3O_dxbCVZQ</a></p><hr><p>刚刚上市的搜狗和科大讯飞都是这波AI浪潮的超级幸运儿，浪潮一来发现自己这么多年的技术积累全都用得上，，</p><p><a href="https://mp.weixin.qq.com/s/ik3FKrwzhx_rrUEkKzyeqg" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/ik3FKrwzhx_rrUEkKzyeqg</a></p><hr><p>杰夫花了几天时间，最终想出“要弄清这个问题的最佳方式是把我的生活向前推进到80岁”，并做出“最小化遗憾”的决定。<br>杰夫说，你并不想最后记录下来的都是自己的遗憾。虽然你可能会对自己做错的事情感到懊悔，但更多的遗憾来自于“没有采取任何行动”</p><p>这个时代和马斯克一样强悍聪慧，并且有很终极的梦想的人。</p><p><a href="https://wap.ithome.com/html/333336.htm" target="_blank" rel="noopener">https://wap.ithome.com/html/333336.htm</a></p><hr><p>最后一场报告，生物物理所的副所长许老师真是好厉害，物理学出身，博士老板跟他发了第一篇文章后要转神经了，后来还当了院士，还是宋森的老板，然后许老师两轮博后跟着温伯格和杨振宁两位巨匠[可怜]，然后去冷泉港之前竟然没听过这地方，以为沃森早就死了，后来第一篇生物文章沃森还当了通讯作者，后来一路砍瓜切菜到现在，脑子聪明干啥都行</p><blockquote><p>记于博士生论坛 2017</p></blockquote><hr><p>搜狗就要IPO了，读到这篇旧文，很有感慨，王小川学长大概是这两代互联网巨头们最有情怀的了，不仅有科技情怀，而且有科学情怀，去年来讲AI是我听过的对AI最好的最有境界的思考之一，当年先是低谷，然后在巨头的庇护下找到生存之路，后来保护者弱了下来，自己倒是一步步变强，如今拆开独立上市，中间的博弈肯定也很不轻松，真的很厉害~</p><p><a href="https://mp.weixin.qq.com/s/MdA0w5ebce569XoCqA2rMg" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/MdA0w5ebce569XoCqA2rMg</a></p><hr><p>“我和爸爸通过一段程序对苏轼的3458首词进行了分词处理”，下面不用看了，改天施清华也可以”我和爸爸通过一台冷冻电镜解了个结构”，玩素质教育普通人怎么玩的过北上学生嘛，学学苏轼就能请到康震去讲，普通人被忽悠了那么多年素质教育，兜兜转转最后发现，应试教育才是公平的最好的出路，，</p><p>当然这样培训出来的学生确实可以很精英，高一去清华附中夏令营，发现附中的学生虽然数学题做的不如，但是数学建模很厉害，大多数地方的同学几乎是第一次接触这个概念，这种对普通人不公平的精英训练确实有效</p><p><a href="http://app.myzaker.com/news/article.php?pk=59dc08069490cbb27b00001f&amp;from=timeline&amp;isappinstalled=0" target="_blank" rel="noopener">http://app.myzaker.com/news/article.php?pk=59dc08069490cbb27b00001f&amp;from=timeline&amp;isappinstalled=0</a></p><hr><p>乍一看相当激动人心的样子，不过发现是去年的论文，似乎研究者也是耕耘在材料领域的，看到芯片真的长成神经元性状还是蛮震撼的，临界自组织还有幂率分布倒也很契合一派人对智能的看法。不过就像文中说的，这种芯片本身就有点不可解释了，人虽然不能解释人脑的具体机制依然可以使用人脑，不知道这种芯片的编码解码如何做下去呢，说不定机理上黑箱芯片不比普通芯片加黑箱算法容易解释，但是依然是类脑计算的一个有趣的也许有用的好研究~</p><p><a href="https://mp.weixin.qq.com/s/LqR4KLBkOWtu4UiElsQvIA" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/LqR4KLBkOWtu4UiElsQvIA</a></p><hr><p><strong>TO BE CONTINUED，上面的只是从朋友圈整理过来的。不得不说苹果的生态做的很好，靠着在手机上复制及时粘贴到电脑的功能，整理着还是非常快的。</strong></p><hr><p>提问：我有两个关于车的问题。第一，如果特斯拉与其他的厂商合作做了自动驾驶芯片，你还买不买特斯拉？<br>黄仁勋：我当然还会买他们的车。<br>已经不仅是英雄的惺惺相惜了，还有一丝我不会负他的感情在其中，马斯克和特斯拉的魅力呀，对科技界杀伤太大了，实验室附近常年停着那么两三辆特斯拉，每次都能眼睛看直了，太美<br><a href="https://mp.weixin.qq.com/s/i4-iEAqEJNA8DcKfifFKhQ" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/i4-iEAqEJNA8DcKfifFKhQ</a></p><hr><p>秋天的荷塘清爽明亮，比夏日更胜，水更是前所未有的清澈，池鱼游在厚厚的水草上，未近冬天的初秋真美</p><hr><p>说的真好啊，，学术和人才培养上真比施一公还强，就是嗅觉人脉和表达上差了施boss点，很好奇施一公七十一岁的时候成就和荣誉能积累到什么程度<br><a href="https://mp.weixin.qq.com/s/WptoqHlRb3FIF549dOGm4A" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/WptoqHlRb3FIF549dOGm4A</a></p><hr><p>THU树洞: 经管本科生无论从个人综合能力还是毕业后对社会的贡献（以薪资粗略衡量）都要比理工科院系的平均水平高很多，自然在学校读书的待遇就要比你们强。工科生在成为教授\研究员之前对社会的贡献几乎为负，凭什么和经管的人争？<br>忍不住笑了，就这一段话就可以开一个全校命题作文大赛了，好想看一看当年的论战盛况，只可惜如今言论产生地都被切割到以院系，年级甚至班级为单位，大家倒也相安无事了<br><a href="https://mp.weixin.qq.com/s/21ciHqN79G2xJ8BoscQCzA" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/21ciHqN79G2xJ8BoscQCzA</a></p><hr><p>大一普生课专门选择做期末展示，选的就是果蝇生物节律，当时觉得这反馈环路还有微分方程很高级，没想到是诺奖级的成果啊<br><a href="https://mp.weixin.qq.com/s/TlR2X4_GBb6_QrqItThxlA" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/TlR2X4_GBb6_QrqItThxlA</a></p><hr><p>生物必修一似乎有个短文，题目大概是为什么最近一些年诺贝尔化学奖频频颁给生物学家？一种霸道得意的情绪蕴含其中，万万没想到连冷冻电镜都可以拿化学奖，化学奖是真的没啥可评的了吗，，施一公也要哭了，委员会觉得做工具的比用工具的了不起呀，”不就是解俩结构嘛，给我两台我也能解”<br><a href="https://mp.weixin.qq.com/s/kKLiFH-vLbAkltP3i-a8Cw" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/kKLiFH-vLbAkltP3i-a8Cw</a></p><hr><p>饶老师的文字真是读起来酣畅淋漓啊，当然讲起来老本行确实更得心应手<br><a href="https://mp.weixin.qq.com/s/33lqGxZuwtYhLXYwsJrMqQ" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/33lqGxZuwtYhLXYwsJrMqQ</a></p><hr><p>把施一公在科学网的早年博客又读了一遍，感觉全身又充满了力量，孟孟学校的饭也能给人力量😊</p><hr><p>一直觉得园子里才是人与人差距最大的地方，能让人一直感觉到”原来还有这么强的人啊”的振奋感<br><a href="https://mp.weixin.qq.com/s/Zx2xoDc4qHJB_9hpD_jGIw" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/Zx2xoDc4qHJB_9hpD_jGIw</a></p><hr><p>深夜睡不着有感，修数双的室友被统计推断作业和申请季折磨得怀疑人生和自我价值，让我想起了晚上斌斌给我看的这个苦逼的做了七年的博士的毕业论文的致谢，我读了好多遍，写的真的很好啊，，</p><hr><p>细胞上完啦，本科最后一门生物课了，又看了从高一开始看了无数遍的视频，第一遍是邹等老师边看边配音，这一遍吴畏老师配音。你永远都想象不到，想象不够，一个小小的细胞有多么的神奇和伟大，细胞和生命就是这么神奇至极，令人神往</p><hr><p>有关大脑的一切都好浪漫，终于拿到了本来用来做意念训教和意念控制用的仪器，用大佬的程序可以把自己的脑电波实时呈现实在太酷了，接下来等着大佬帮忙改硬件，二十四小时记录数据，研究自己的大脑好酷啊~</p><hr><p>要开心的睡不着觉啦，因为各种原因一直拖着没有决定好暑研，把学堂班的项目都放弃了要自己找，读了很久的论文和文档，发好信之后的周末简直度日如年，随时算着波士顿的时间为什么还不回复。终于还是得到了梦想中的完美的暑研啦，要好好准备，去了要多干活呀~</p><hr><p>这种直男热血风真是完美契合，，西洋学长现在已经是学校御用导演了嘛，昨晚还回顾了一遍四五年前的作邻友舍系列<br><a href="https://mp.weixin.qq.com/s/pG1apcEPK8B_fyuTHW1jpQ" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/pG1apcEPK8B_fyuTHW1jpQ</a></p><hr><p>而我因为实验室不放假错过了一切，不过晚上在一年最空荡的三教和孟孟讨论学术，回寝路上听到李健在综体唱传奇，也是美好的一天，生日快乐~<br><a href="https://mp.weixin.qq.com/s/NUZHxuIaGrNNsouOYCgWMw" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/NUZHxuIaGrNNsouOYCgWMw</a></p><hr><p>清华大学真正的东门马上开通？看了通知兴冲冲跑过去，再仔细看通知发现明天开通，，从今以后和孟孟的距离缩短为直线距离</p><hr><p>天才的同学们总是思维活跃，人生的选择比战战兢兢走在固定轨道上的我们勇敢多了。<br>维特根斯坦还去奥地利山区给小学生教了六年书，采访的人恐怕不是蠢就是坏。”竞赛大牛就要继续搞研究，搞研究就要为国奉献清贫一生感人至深”，感觉坏的可能性大点吧<br><a href="https://zhuanlan.zhihu.com/p/36397449?utm_medium=social&amp;utm_member=MGFlN2IyZTVkOTUyYjEwNTI4NWRiZThlNjhjZjlhYzU%3D&amp;utm_source=wechat_timeline&amp;wechatShare=2&amp;from=timeline&amp;isappinstalled=0" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/36397449?utm_medium=social&amp;utm_member=MGFlN2IyZTVkOTUyYjEwNTI4NWRiZThlNjhjZjlhYzU%3D&amp;utm_source=wechat_timeline&amp;wechatShare=2&amp;from=timeline&amp;isappinstalled=0</a></p><hr><p>全国二太坑了，这是高考作文还是生存性分析大作业，，样本偏差情况下模型鲁棒性研究？看到了一篇The Legend of Abraham Wald的文章，看起来wald在国外的传奇度和国内的某些神奇理工科传说差不多，而且他确实推出来一堆公式来分析飞机的vulnerability 另外这篇作文是真的难举例子，生物里倒是很多例子但不容易出彩，而且立论的点很不好琢磨，最近几年最难作文题之一了吧<br><a href="https://mp.weixin.qq.com/s/LKGJi621BeQ3Zr3SWAdRqQ" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/LKGJi621BeQ3Zr3SWAdRqQ</a></p><hr><p>数学家说话就是这么真诚自在，被说服了，，<br><a href="https://mp.weixin.qq.com/s/CQx5VM_P0mOyYGvqpPNpHw" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/CQx5VM_P0mOyYGvqpPNpHw</a></p><hr><p>“我私下里总觉得，计算机专业可算是平民专业，它不需要你家庭有背景有资源有人脉，不需要你能说会道。能不能行，全靠自己。只要你肯下苦功夫，练就真本事，市场就买你的账，企业就愿意出高薪聘任你。正因为大学里学习计算机专业要下真功夫，没有花架子，有背景的子弟也较少选这个专业。可以说，这种专业可以说是平民家庭实现阶层跃迁的最佳通道。”<br><a href="https://mp.weixin.qq.com/s/mUugqcI-6BRCJI27C7drYg" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/mUugqcI-6BRCJI27C7drYg</a></p><hr><p>吃的最好的一顿，正好赶上一年一度的夏季家庭烧烤，老板的花园好漂亮，据说有Cambridge 附近最大的树，院子里各种鸟儿乱飞，有松鼠和花栗鼠跑来跑去，还有蜂鸟吃专门为它们准备的食物，师母的大餐很好吃，尤其是烤肋排，竟然从一点边吃边聊到了五点诶</p><hr><p>去MIT听了一场seminar，MIT的建筑有种上世纪八十年代的土潮感，三分之二听众都是中国人，感觉机器学习被国人占领，提供的食物非常黑暗，顺便发现了麦戈文的总部，以及纪念品店很棒~</p><hr><p>被学长拉去华人教会参加国庆日BBQ，给介绍的各种人竟然清一色清华毕业的，一个北大的都没见到，可能波士顿地区主要都是理工科学生？然后发现一个和善有趣的九十年代五字班学长竟然是当年清华数学建模主力队选手，现在在Google和MIT 做深度学习相当厉害~</p><hr><p>最近读到的最好的演讲，钱颖一去生院讲潘建伟去经管讲，还都讲的非常好诶</p><p><a href="https://mp.weixin.qq.com/s/L5cIrh5vYrkyE5fKEvjoJA" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/L5cIrh5vYrkyE5fKEvjoJA</a></p><hr><p>法律领域是NLP最佳应用领域了吧？说不定能减少很多法律人认为年轻人理所应当干的dirty work~<br><a href="https://mp.weixin.qq.com/s/lr-qMN13LGS8ONYzLzlMKA" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/lr-qMN13LGS8ONYzLzlMKA</a></p><hr><p>每天坐的橙线，，波士顿地铁破烂程度绝对对得起最早地铁的称号，比北京一号线还老旧几十年的水平，日常停运检修，随时减速停车，虽然没几条线但是地下修的跟迷宫一样，其实就是有轨电车的绿线甚至还可以随意穿过铁轨去平行的另三条支线站台，，<br><a href="https://mp.weixin.qq.com/s/8wtOGRlxiBsgZS0UKVw_6Q" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/8wtOGRlxiBsgZS0UKVw_6Q</a></p><hr><p>非常谦虚且很有想法的学姐，伯克利全奖毕业两年就找到CMU教职了还那么淡定低调，感觉脑子都用来思考了，，这种学科交叉的思维习惯，还有觉得需要理论就去拿了个数学学位的行动力，了不起，好强<br><a href="https://mp.weixin.qq.com/s/vwSoICyaScawKQsC26Tm_g" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/vwSoICyaScawKQsC26Tm_g</a></p><hr><p>突然就更新了，保密做的真好，无touchbar款直接砍了，不过看了一下CPU用上八代了键盘也换代了但是和上一代同内存一个起售价，挺良心了，前两天刚买17款的要哭了，，好像试试新款键盘的手感，，<br><a href="https://m.ithome.com/html/370171.htm" target="_blank" rel="noopener">https://m.ithome.com/html/370171.htm</a></p><hr><p>硅谷钢铁侠真的无所不能，马上中国工厂工人再让你体会上天堂的感觉。<br>“但这样的变化也让整个团队倍感自豪，他们认为自己在创造不同，甚至这些工程师是带着骄傲回家跟老婆说：我接下来半年都要997了。” 论洗脑就服马斯克，让员工每周工作七天只歇两个小时一起玩游戏还得心甘情愿输给自己的boss<br><a href="https://mp.weixin.qq.com/s/epZZ_0ne5BQZYh18CIGLHA" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/epZZ_0ne5BQZYh18CIGLHA</a></p><hr><p>终于习惯了楼下食堂的口味，被学长拉去法学院的学生中心吃了一顿，好像村里人进城了，法学院真有钱，，</p><hr><p>终于习惯了楼下食堂的口味，被学长拉去法学院的学生中心吃了一顿，好像村里人进城了，法学院真有钱，，</p><hr><p>计算机系一个实验室有六块儿闲置gpu的机器死板的只能在校内用一个奇葩的代理连接于是自己也没法在校外连，绝望之际网络技术专家帮我搞定了绕圈圈的了解方案，先做一个黑苹果，ssh到黑苹果再ssh到集群上，顺便解决了两层连接的jupyter和tensorboard的端口问题，于是现在我也是坐拥八块儿gpu的人了😀</p><hr><p>最搞笑的是这些干部还义正辞严地指责别人不懂他们的苦衷：”我们不把级别分的清清楚楚期末怎么综测比你们这些庶民高？”，跟真正的boss们学学闷声发财不好吗</p><hr><p>“像三鹿那样的深查”是说国外政府关切才不得不查同时把报道记者搞得家破人亡那种吗。很想知道中国人吃苦和忍耐的极限究竟在哪里<br><a href="https://mp.weixin.qq.com/s/9nQGQKavKJhh4_RrVmW4zg" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/9nQGQKavKJhh4_RrVmW4zg</a></p><hr><p>来Lichtman lab快一个月了，下午六点以后和周末就没见过一个外国人，，</p><hr><p>估计是得益于横向联合也格外害怕同类型人的横向联合，而只保留或者去中心化的微信，或者有中心的但是很容易加以诱导，用娱乐新闻转移视线的平台，我们特色化在治理人的水平上领先世界至少五十年</p><p><a href="https://www.zhihu.com/question/286761342/answer/451266877?utm_medium=social&amp;utm_oi=551878549213081600&amp;utm_source=wechat_timeline&amp;from=timeline&amp;isappinstalled=0" target="_blank" rel="noopener">https://www.zhihu.com/question/286761342/answer/451266877?utm_medium=social&amp;utm_oi=551878549213081600&amp;utm_source=wechat_timeline&amp;from=timeline&amp;isappinstalled=0</a></p><hr><p>哇，两校在争做世界一流大学的进程中频出奇招实在是精彩纷呈。<br>这两天看me too运动，女生们纷纷讲出自己受到的性骚扰，想起来陆陆续续听到的一些故事，有一些很不正常的事情正在悄悄发生，当年一地鸡毛的磁遗传学之争的两位清北主角，一位最近刚被人举报性骚扰，一位公然和女研究生成双入对，一位德高望重物质财富丰厚的教授因为只招漂亮女学生和学生谈恋爱，被全国闻名的妻子带人把生科楼的门给砸了，另有风流倜傥的年轻PI每晚十一点不回家待在实验室做点什么事，还有一位一直被学生觉得是被学院迫害的学术新星其实是搞大了学生肚子被学校清理，推广到全校全国得有多少事，我想努力压下去装作事情不发生，不把这种不应发生的事情写到法律里，以及无形中把一些群体的权力扩得这么大，只顾着纵容社会对女方进行slut shaming，这个社会有点不正常<br><a href="https://mp.weixin.qq.com/s/px4ZsYdDesyJ6guTDoq6jQ" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/px4ZsYdDesyJ6guTDoq6jQ</a></p><hr><p>突然发现两千天的时候正好是孟孟生日，佩服自己挑纪念日的水平😊</p><hr><p>天才和天才的差距可能比天才和普通人的差距都大，我看Peter Scholze可以算是天才中的天才了，人类的大脑结构怎么可以差异这么大呢</p><p><a href="https://mp.weixin.qq.com/s/tJ0556e3I5xdBICjuT8tPA" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/tJ0556e3I5xdBICjuT8tPA</a></p><hr><p>吴军的浪潮之巅里写了好几个互联网巨头被华尔街的短视玩死的例子，虽然不乏甩锅之嫌但是言语间泛滥着硅谷对华尔街的痛恨，我觉得对于真正的天才来说，制度的约束是无意义的，对于短暂的公司，王朝，人类历史来说，制度本来就依存于一个个创立它的人，而不应该约束天才本身，就像凯撒应该抛开元老院的烦扰发挥自己的天才，马斯克也不需要一群只是脑子聪明的家伙指手画脚，这些根本不愿意理解马斯克，总想着用自己熟悉的套路玩别人，活生生把自己演成了反派<br><a href="https://mp.weixin.qq.com/s/TbF_F3BEQzcJ2OsNj9ZZ-g" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/TbF_F3BEQzcJ2OsNj9ZZ-g</a></p><hr><p>终于吃到了一桌中国菜，由老板亲自当导游带着大家参观cajal的杰作，cajal真是个绝世的天才，科学与艺术的完美交织</p><hr><p>走之前赶上了老板的课，在美国神经的课好火呀</p><hr><p>马上就要走了我才发现实验室的其中一个存储中心的容量是4PB，，大数据时代在向我们招手</p><hr><p>今天上神经建模与数据分析课，洪波老师上来就来一句，我们这个课就是讲机器学习和深度学习，这已经是我选过的第五门花式起课名其实又讲了一遍机器学习/深度学习入门的课了，估计全校大概有二十门类似的课，堪称新一代万金油课程</p><hr><p>太满足了，没想到那么快就在北大又听到了暑研老板的讲座，感谢北大挑战班年会，正好邀请到jeff来做演讲。可能是听到的最精彩的一场演讲了，jeff的演讲从来没有重样，永远把最新的东西和最原始的思考加进去，感觉大家都被震住了，穿西装的jeff真的太帅了。</p><hr><p>突然发现这位姑娘的父亲是CV领域的超级超级超级超级大牛，羡慕坏了，，精英阶层对普通人头脑和身体的遗传连续压制？<br><a href="https://mp.weixin.qq.com/s/jRnKUj5er7FrmUC91qYzqA" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/jRnKUj5er7FrmUC91qYzqA</a></p><hr><p>新版macOS Mojave简直酷到没朋友，系统级的暗夜模式实在是太炫了而且细节很足。从酷炫的角度来说macos才是苹果三大系统今年最棒的升级</p><hr><p>日本提出过二十一世纪上半页拿三十个诺奖的口号，如今不到二十年已经完成一半多的目标了，，，前两天还正好调查了一下PD-L1药在中国的情况，进口的上了两款而且基本是全球最低的价格，国产的也有好几款要上了，虽然还是很贵而且不知道印度一时半会儿能不能仿的出来，不过感觉接下来几年此类药会非常火<br><a href="https://mp.weixin.qq.com/s/sQdJvEcE_6YBTO7IACdwPw" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/sQdJvEcE_6YBTO7IACdwPw</a></p><hr><p>花了两整天把生信课的大作业出好了，突然感觉对很多零基础的同学有点残忍，，不过去年老板的讲座版生信课退课率很高，今年全面加大难度后反而选满了还有很多人排队，可见大家还是喜欢课程虐一点的课吧[偷笑]</p><hr><p>虽然好多package都宣称自己把tensorflow封装的非常简单，几行就调了一个模型，但是这个真的是我见过的最简单的了，，拖动组件然后生成网络代码，如果功能稍微搞得复杂一点，，</p><hr><p>最近的事总是让我想到三体，尤其是第三部里面的很多事情，如果地球下一秒就会突然爆炸，或者外星人突然入侵毁灭一切的时候，人类会突然意识到究竟什么应该更早做吗<br>如果外星人四百年后会来呢？人类又会做哪些夸张的不可思议的过去觉得疯狂的事情，这么一件小小的事情已经给人类造成如此大的冲击，人太安逸和松散了，而且作为一个整体充满了愚蠢</p><hr><p>一个持续不断的感慨：学术的世袭垄断更容易和自然，遗传和环境的双重加成，而且不会受到其他类型的垄断受到的嫉妒和不满。</p><hr><p>被感动了一下，办签证办晚了还因为专业敏感被check一下子打乱了所有的计划，不但可能耽误了面试订的机票也只能退了，之前committee 已经专门批了一次允许提前去又给我改签了一次，在重新给安排了面试之后我满怀歉意地给订票的工作人员说取消机票就好了，结果被抄送给committee 之后告诉我说又给我申请了一下让我自己根据时间订机票而且报销一千刀，感觉如果只是去打个酱油都对不起那边的人情味，，</p><hr><p>上午组会开一半老板主动要我们去听Jessica Li的讲座，因为大师兄待过给我推荐我还专门套磁过清华生院毕业的李老师，感觉人很好说话，然后正好听到她在台上”斤斤计较”其他几篇文章说超过她的方法是有问题的，不过公正的说scRNA领域scImpute应该是最好的方法了，如果不考虑scVI的话</p><hr><p>CheXpert非常酷！两年前我们在比赛的时候还苦苦收集数据但是真的很不好找，当时知道斯坦福影像中心有很多数据但是不公开，现在吴恩达把他的二十多万张图像公开了，胸片领域的里程碑事件<br><a href="https://mp.weixin.qq.com/s/jfDoh2h-YJM89fcmKPoFWw" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/jfDoh2h-YJM89fcmKPoFWw</a></p><hr><p>不知道对灰度图像插值效果怎么样？突然发现哈利波特里魁地奇世界杯上的全景望远镜这几年算是基本被深度学习实现了，随时慢速播放加实时战术分析<br><a href="https://mp.weixin.qq.com/s/ZX2Je2gfzvu5sKbLIWIwVA" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/ZX2Je2gfzvu5sKbLIWIwVA</a></p><hr><p>超级震撼，特效爆炸，年轻演员演技在线，虽然有些逻辑漏洞但是无伤大雅，整部电影在原著的设定下有种狂放到极致的浪漫，看好流浪地球逆袭票房冠军<br><a href="https://mp.weixin.qq.com/s/Y1rgtSHc_SiJ5r_CZ5IMXg" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/Y1rgtSHc_SiJ5r_CZ5IMXg</a></p><hr><p>这是宣传猪队友吧，，直接立意降了一个格局，明明是人类命运共同体的大格局，饱和式救援，面对灾难无比缜密地尝试所有可能得反套路格局，被一下子降格了，真的夸不到点子上，，还不如多夸夸中国人瑰丽浪漫的带着地球经历百代流浪的想象力和生命力呢。<br><a href="https://mp.weixin.qq.com/s/VEbfdA2pgxzHq-wVTozomA" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/VEbfdA2pgxzHq-wVTozomA</a></p><hr><p>在纽约待了一周，超级感谢表哥无比热情细心的款待，感觉比春节在家还舒服，好吃的好玩的，中间只受了不到两天面试的折磨，还暂时远离了实验室的活😄<br>纽约真是座非常了不起的大都市，细密的街道切割出来的却是摩肩接踵的高楼大厦，据说一百年前的曼哈顿已经有那么多高耸的大楼了，而且晚上十点的时候大街上比国内的人还要多，给人一种热闹的安全感，纽约是个好地方</p><hr><p>推送刚出来就先备了个份，因为深谙学校的无耻之道。一个当年大肆宣扬的gpa改革已经肉眼可见坑了一届学生了，清新时报的推送出来不到一个小时就被勒令删除了，然后发现大家好像都用各种方式备份了这个推送，和当年的双培生，文素歧视，自行车铺等等事情一样，做错事推诿不管，出了事删帖了事，最搞笑的是大家除了备份一下推送好像毛用没有，很多人没有机会看到一些领导们惧怕被人看到的东西，而且未来能看到的东西会越来越少。constitutional law的教授当年说过，人和人之间的最基本关系就是控制关系，有了微信和知乎等渠道随意删帖权力的大小机构，可以更加随心所欲地营造着歌舞升平的繁荣局面了呀。<br><a href="https://github.com/whoTouchedMyGPA/Who-touched-my-GPA/blob/master/README.md?from=timeline&amp;isappinstalled=0" target="_blank" rel="noopener">https://github.com/whoTouchedMyGPA/Who-touched-my-GPA/blob/master/README.md?from=timeline&amp;isappinstalled=0</a></p><hr><p>小五爷园被招安已久，当然这号创号之处就是一些园子内的红专分子参与的，现在成了学校的官方传声筒，问题是这种唬人民群众的风格也唬不住学生啊，五字班学生整体学分绩下滑巨大就是不争的事实，发这么一篇文章被当做靶子被人们进一步攻击积累怨气，实在是naive，9102年了还不会做群众工作<br><a href="https://mp.weixin.qq.com/s/lv6FbLFCrJAmxf23sZf-0w" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/lv6FbLFCrJAmxf23sZf-0w</a></p><hr><p>这学期做的最有意思的事就是安排了每周五晚上到周六上午的空闲时间，和大家一起看各种有意思的课程。另外吴恩达新搞得课程讲的不错，虽然非常入门，一个小时就把四周的视频看完了，但是比fastai一通长篇大论胡讲有点意思</p><hr><p>人一辈子能听到几次震撼心灵的讲话呢，接下来的很多年可能都没法在现场听到了<br>记于学堂班成立十周年施一公演讲</p><hr><p>2019.4.23</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;碎碎念-amp-will-update-daily&quot;&gt;&lt;a href=&quot;#碎碎念-amp-will-update-daily&quot; class=&quot;headerlink&quot; title=&quot;碎碎念&amp;amp; will update daily&quot;&gt;&lt;/a&gt;碎碎念&amp;amp; will update daily&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;基本来自于过去的各处的碎碎念，比如记录在朋友圈的，便签里的，笔记里的。和孟孟微信聊天的太不好找了，以及很多时候口头聊的时候觉得自己充满哲理与逻辑的很好的话都没有记录下来，总会有种可惜的感觉，不过也许很多东西都已经内化为大脑结构的一部分了吧。OK，让我们先从中二热血的开始。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;“整理这些碎碎念让我更好的感觉到我还活着”——2019.4.23&lt;br&gt;
    
    </summary>
    
      <category term="thoughts" scheme="https://www.cmwonderland.com/blog/categories/thoughts/"/>
    
    
      <category term="life" scheme="https://www.cmwonderland.com/blog/tags/life/"/>
    
      <category term="thoughts" scheme="https://www.cmwonderland.com/blog/tags/thoughts/"/>
    
      <category term="brain" scheme="https://www.cmwonderland.com/blog/tags/brain/"/>
    
  </entry>
  
  <entry>
    <title>DIP assignment 1 image fusion and morphing</title>
    <link href="https://www.cmwonderland.com/blog/2019/04/23/52_DIP/"/>
    <id>https://www.cmwonderland.com/blog/2019/04/23/52_DIP/</id>
    <published>2019-04-23T04:59:19.000Z</published>
    <updated>2019-04-23T14:59:43.422Z</updated>
    
    <content type="html"><![CDATA[<p>The first assignment of Digital Image Processing course (2019 spring in Tsinghua)</p><a id="more"></a>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;The first assignment of Digital Image Processing course (2019 spring in Tsinghua)&lt;/p&gt;
    
    </summary>
    
      <category term="school work" scheme="https://www.cmwonderland.com/blog/categories/school-work/"/>
    
    
      <category term="deep learning" scheme="https://www.cmwonderland.com/blog/tags/deep-learning/"/>
    
      <category term="codes" scheme="https://www.cmwonderland.com/blog/tags/codes/"/>
    
      <category term="python" scheme="https://www.cmwonderland.com/blog/tags/python/"/>
    
      <category term="opencv" scheme="https://www.cmwonderland.com/blog/tags/opencv/"/>
    
      <category term="image processing" scheme="https://www.cmwonderland.com/blog/tags/image-processing/"/>
    
      <category term="poisson image editing" scheme="https://www.cmwonderland.com/blog/tags/poisson-image-editing/"/>
    
      <category term="face morphing" scheme="https://www.cmwonderland.com/blog/tags/face-morphing/"/>
    
  </entry>
  
  <entry>
    <title>我的申请故事</title>
    <link href="https://www.cmwonderland.com/blog/2019/04/23/my_application_story/"/>
    <id>https://www.cmwonderland.com/blog/2019/04/23/my_application_story/</id>
    <published>2019-04-22T16:30:44.000Z</published>
    <updated>2019-04-23T14:37:38.195Z</updated>
    
    <content type="html"><![CDATA[<p>可以说我的申请季过得相当充实而有意义，在这个忙乱的申请季，通过种种的思索和抉择，让我慢慢找寻到了未来的方向。<br><a id="more"></a></p><iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width="330" height="86" src="//music.163.com/outchain/player?type=2&id=28700552&auto=1&height=66"></iframe><p>说起来出国留学的念头，似乎对我所在的学院和专业是非常普遍流行的，出国读博是很多同学尤其是有志于继续科研的同学的首选。对我来说，思考出国留学这个念头的时候却总是会产生更多的疑问，对未来的专业，方向，人生的种种犹豫和疑问让我迟迟难以行动起来，加上平时花在辅修和实验室科研的时间和精力过多，也总喜欢自己捣鼓一些东西，导致我在很多事情上总是慢半拍，比如找暑研的时候不紧不慢，对托福和GRE也没什么计划性，套磁更是存在于脑海里一闪而过的念头。我想对于申请的事情我的被动和抗拒的另一个重要原因是感觉到自己的GPA不高，科研虽然做了很多但是没有什么发表的论文，心中有一些悲观的情绪，因此也迟迟不愿意行动。</p><p>就这样到了八月份，暑研过了一半，心中开始着急慌乱的时候知道了再来人的奖学金计划，于是报名，顺利地入选，回国后去再来人总部见到了自己的班主任，才发现自己对申请的了解如此之少，因为不愿意在留学申请论坛花费大量时间整理资料，导致自己对留学信息的了解非常的零碎，更重要的是对未来究竟要去哪个学校，学什么专业一无所知。班主任，还有再来人的创始人的内部讲座让我开始了解申请的整体架构和细节的注意点，更重要的是让我有一个积极准备的心态，我觉得在申请的过程中心态是非常重要的，在整个申请季中，心态很容易随着套磁、材料递交、面试等环节的细节的一些小问题波动，一开始的积极的心态——积极的行动毫无疑问是一个很好的正反馈的开始。</p><p>当我第一次和学术导师交流之后，我就感觉到自己找对人了，因为他解决了我的几个非常重要的疑惑，一个是选校，他对计算生物学、生物信息学的适合我的学校的评价，包括招收人数，偏好，委员会的情况以及一些他认识的套磁过的老师都做了细致的介绍，让屏幕另一边的我满足地记了大量的笔记。而且他非常非常推荐我认真套磁，告诉我套磁比我想象中更重要，在此之前我听过很多截然相反的观点，有的学长学姐认为套磁有用，并且举了一些自己的例子，有的学长学姐认为套磁几乎没用，我当时想了一下，认为我要申请的都是比较小的项目，而且既然有很多套磁有用的例子，证明这确实是一个大有学问的值得花功夫的地方。导师告诉我说他大概在申请半年前就开始套磁了，我虽然只剩下两个月就申请截止了，但是套磁依然不晚。可以说在12.1申请截止前的两个月，我花在套磁相关上的时间比CV,PS和各种材料填写加起来都多，而且确实取得了很好的效果。我的陶瓷工作是从我的个人博客的整理开始的，之前陆陆续续地写过几十篇各色文章，我又重新整理了我的各个课题的结果，暑研的成果，CV等，各种我能想到的东西都放了上去，又重新做了一个网站入口。所以陶瓷的时候我就没有附上pdf版本的CV，只用放上一个链接就可以了。在具体的套磁过程中，我心仪的学校平均都套了四五个老师，基本每个项目都收到了一些积极的回复，在套磁的过程中，我还进一步调整和思考了我的选校方案，从最开始的只有计算生物学和生物信息学，到生物医学、神经生物学和电子工程相关的项目我都有申请。因为我觉得读博是很强的导师导向的，从自己的相关工作中发掘和教授的潜在的匹配方向很重要，因为自己的研究经历比较杂，生物背景，辅修统计，除了生物信息学的课题本身和机器学习，深度学习相关，还有图像处理的相关研究和暑研，所以就这样跨了几个学科在申请。</p><p>我感觉在前期进行大量的套磁对于写PS和填写网申也是很有用的，可以及时调整策略。在网申结束前，我已经接到了一些积极的回应，包括几个网上面试，还有正好回国交流的教授的线下面试。在网申结束后我给套磁过的教授们都发了邮件提醒，一些教授也就开始越skype聊天了。我当时就花了一天的时候做了几页PPT，以一页一个课题的方式展示了一下自己的工作，然后发现整个申请季的面试套路差异并不是很大，除了少许个性化的问题需要准备，大多数的面试并不需要额外准备很多东西。我在套磁的时候套了不少中国的教授，他们往往有着更高的回复率，而且在帮助中国学生上更加积极，另外年轻的教授往往也会更加热情一点。我申请到的佐治亚理工的生物医学工程，以及拿到杜克大学的生物医学工程面试，都是遇到了非常热情的中国教授/年轻教授。在通过提前的面试后，他们可能会帮助自己过了简历关，避免自己的简历因为硬件不够直接被扔掉，我觉得这两所生物医学工程排名很高的项目对我比较友好，套磁是非常关键的，杜克的校园面试因为时间太晚我已经决定了去向没有参加，帮了我很多忙的教授还非常遗憾，又找我skype问我的心路历程和对他们招生的建议。我遇到的另外的套磁很有用的例子是哥大和UCLA的生信项目，我的导师告诉我说这两个项目都非常难进，所以要试试在套磁上突破，我当时都幸运到套到了几个committe里的成员，尤其是都有一些中国人，在我参加校园面试的时候甚至直接告诉我：我们现在面试不是要考验你的，你可以想想我还能在什么地方帮助你。后续也主动给我发邮件告诉我他们在努力地帮我争取机会，让我保持联系。包括CMU的计算生物学项目，也是我套磁到的老师在面试完之后帮我又写了推荐信，帮我拿到面试资格，以及录取。</p><p>我觉得我的套磁最成功的应该是NYU的EE的Ph.D.项目，当时听说了一位很厉害的校友教授做的图像和视频处理相关的研究我很感兴趣，虽然专业背景差距挺大，但是由于相信重要的是研究经历的匹配，我还是决定试着套一下磁。于是通过了一次比较煎熬的面试和后续多次邮件沟通，最后得以拿到offer。</p><p>回看我的申请过程，我感觉到最重要的是心态和行动的那个起始点，一个好的引爆点，对于注重感觉的我来说，一个好的开始非常重要。我现在依然对学术导师和班主任总结的选校表格印象深刻，一下子就梳理清楚了我的思路，给了我一个坚实的基础，而且让我有进一步发挥的余地。在申请的过程中我还有各种各样的小问题，后来看看我的学术导师和班主任总能给出对的建议和提示，对于喜欢纠结于细节的我来说也非常重要。而他们又给了我充分的空间，让我有机会处理一小段时间内的问题，让我得以以一种比较舒适的心态度过了申请季，并且最终选择了自己喜欢的方向。最后我还是想说，套磁对于博士申请来说，是一项非常重要的，需要付出很多时间和精力的大项目，在套磁的过程中体会和教授交流的技巧，发掘自己的优势，提前适应和教授们讨论科研和专业问题也非常有意义，对很多人数少的项目来说，好的套磁是一个非常好的翻盘的机会。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;可以说我的申请季过得相当充实而有意义，在这个忙乱的申请季，通过种种的思索和抉择，让我慢慢找寻到了未来的方向。&lt;br&gt;
    
    </summary>
    
      <category term="life" scheme="https://www.cmwonderland.com/blog/categories/life/"/>
    
    
      <category term="deep learning" scheme="https://www.cmwonderland.com/blog/tags/deep-learning/"/>
    
      <category term="life" scheme="https://www.cmwonderland.com/blog/tags/life/"/>
    
      <category term="bioinformatics" scheme="https://www.cmwonderland.com/blog/tags/bioinformatics/"/>
    
      <category term="medical image" scheme="https://www.cmwonderland.com/blog/tags/medical-image/"/>
    
      <category term="school" scheme="https://www.cmwonderland.com/blog/tags/school/"/>
    
      <category term="EE" scheme="https://www.cmwonderland.com/blog/tags/EE/"/>
    
  </entry>
  
  <entry>
    <title>LaTeX to MathML tool</title>
    <link href="https://www.cmwonderland.com/blog/2019/03/26/latex2mathml/"/>
    <id>https://www.cmwonderland.com/blog/2019/03/26/latex2mathml/</id>
    <published>2019-03-26T00:30:44.000Z</published>
    <updated>2019-04-23T13:07:13.952Z</updated>
    
    <content type="html"><![CDATA[<p>It is a small tool converting LaTeX style code to MathML which can be used in places like word.</p><p><a href="https://www.cmwonderland.com/blog/latex_to_mathml.html">https://www.cmwonderland.com/blog/latex_to_mathml.html</a></p><p><img src="http://i1.fuimg.com/640680/ed21032fb30bef6b.png" alt="Markdown"></p><p><a href="https://github.com/ltbyshi/misc_progs/blob/master/html/latex_to_mathml.html" target="_blank" rel="noopener">Credit to Shi binbin</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;It is a small tool converting LaTeX style code to MathML which can be used in places like word.&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.cmwonderland.
      
    
    </summary>
    
      <category term="techniques" scheme="https://www.cmwonderland.com/blog/categories/techniques/"/>
    
    
      <category term="techniques" scheme="https://www.cmwonderland.com/blog/tags/techniques/"/>
    
      <category term="tools" scheme="https://www.cmwonderland.com/blog/tags/tools/"/>
    
  </entry>
  
  <entry>
    <title>Undergraduate Research Summary</title>
    <link href="https://www.cmwonderland.com/blog/2018/12/20/research_summary/"/>
    <id>https://www.cmwonderland.com/blog/2018/12/20/research_summary/</id>
    <published>2018-12-19T16:30:44.000Z</published>
    <updated>2019-04-23T13:07:13.883Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Brief-Summary"><a href="#Brief-Summary" class="headerlink" title="Brief Summary"></a>Brief Summary</h2><div class="row"><iframe src="https://drive.google.com/file/d/1pc8W1kvm_4NikBGnBUjFKlv_ROJyXLQT/preview" style="width:100%; height:550px"></iframe></div><h2 id="Codes"><a href="#Codes" class="headerlink" title="Codes:"></a>Codes:</h2><p><a href="https://github.com/james20141606/" target="_blank" rel="noopener">GitHub</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Brief-Summary&quot;&gt;&lt;a href=&quot;#Brief-Summary&quot; class=&quot;headerlink&quot; title=&quot;Brief Summary&quot;&gt;&lt;/a&gt;Brief Summary&lt;/h2&gt;

	&lt;div class=&quot;row&quot;&gt;
		&lt;ifram
      
    
    </summary>
    
      <category term="projects" scheme="https://www.cmwonderland.com/blog/categories/projects/"/>
    
    
      <category term="project" scheme="https://www.cmwonderland.com/blog/tags/project/"/>
    
      <category term="connectomics" scheme="https://www.cmwonderland.com/blog/tags/connectomics/"/>
    
      <category term="deep learning" scheme="https://www.cmwonderland.com/blog/tags/deep-learning/"/>
    
      <category term="machine learning" scheme="https://www.cmwonderland.com/blog/tags/machine-learning/"/>
    
      <category term="precision medicine" scheme="https://www.cmwonderland.com/blog/tags/precision-medicine/"/>
    
      <category term="bioinformatics" scheme="https://www.cmwonderland.com/blog/tags/bioinformatics/"/>
    
      <category term="medical image" scheme="https://www.cmwonderland.com/blog/tags/medical-image/"/>
    
  </entry>
  
  <entry>
    <title>Book Summary</title>
    <link href="https://www.cmwonderland.com/blog/2018/10/11/93_book_summary/"/>
    <id>https://www.cmwonderland.com/blog/2018/10/11/93_book_summary/</id>
    <published>2018-10-11T11:57:25.000Z</published>
    <updated>2019-04-23T13:07:13.964Z</updated>
    
    <content type="html"><![CDATA[<p>I have been responsible for several (part of the ) books. </p><h2 id="Teaching-Book"><a href="#Teaching-Book" class="headerlink" title="Teaching Book"></a>Teaching Book</h2><p>As a TA for Bioinformatics Basic course, I am responsible for writing several chapters in two teaching books.</p><p><a href="https://www.cmwonderland.com/blog/2018/09/28/93_gitbook_teaching_book/"><strong>Link</strong></a></p><h2 id="High-School-knowledge-and-experience-sharing-book"><a href="#High-School-knowledge-and-experience-sharing-book" class="headerlink" title="High School knowledge and experience sharing book"></a>High School knowledge and experience sharing book</h2><p><a href="https://www.cmwonderland.com/blog/2018/09/29/93_book_high_school/"><strong>Link</strong></a></p><ul><li>I have invited around 100 elite students writing a book about high school life and their choices and dreams. I managed to publish them and they have been reprinted several times.</li><li>I also organized 6 booklets, purely experience sharing about college entrance exam and high school olympic games.</li></ul><h2 id="Grandpa-Autobiography"><a href="#Grandpa-Autobiography" class="headerlink" title="Grandpa Autobiography"></a>Grandpa Autobiography</h2><p>I typed and organized a small auto-biography of grandpa.</p><p><a href="https://www.cmwonderland.com/blog/2018/05/08/23_autobio/"><strong>Link</strong></a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;I have been responsible for several (part of the ) books. &lt;/p&gt;
&lt;h2 id=&quot;Teaching-Book&quot;&gt;&lt;a href=&quot;#Teaching-Book&quot; class=&quot;headerlink&quot; title=&quot;
      
    
    </summary>
    
      <category term="book" scheme="https://www.cmwonderland.com/blog/categories/book/"/>
    
    
      <category term="life" scheme="https://www.cmwonderland.com/blog/tags/life/"/>
    
      <category term="book" scheme="https://www.cmwonderland.com/blog/tags/book/"/>
    
      <category term="techniques" scheme="https://www.cmwonderland.com/blog/tags/techniques/"/>
    
      <category term="teaching" scheme="https://www.cmwonderland.com/blog/tags/teaching/"/>
    
  </entry>
  
  <entry>
    <title>exSeek extracellular RNA analysis tool for noninvasive biomarker</title>
    <link href="https://www.cmwonderland.com/blog/2018/10/11/101-exrna-project/"/>
    <id>https://www.cmwonderland.com/blog/2018/10/11/101-exrna-project/</id>
    <published>2018-10-10T16:30:44.000Z</published>
    <updated>2019-04-23T13:07:13.870Z</updated>
    
    <content type="html"><![CDATA[<p><strong>exSeek: extracellular RNA analysis tool for noninvasive biomarker</strong></p><p>The aim of this project is to combine <strong>small cell free RNA sequencing techniques</strong> with <strong>machine learning</strong> to identify promising candidate biomarker for cancers. We establish the pipeline from mapping to feature selection and propose a <strong>robust feature selection method</strong> to identify potential biomarkers.</p><p>Parts of this works difficulty is its steps and precision it requires. Since our exRNA-seq is different (it has less RNA reads), we have to explore the mapping sequence. We determine sequential mapping order, using peak calling because most long RNAs are fragments in blood. We also did matrix processing and robust feature selection for biomarker identification.</p><a id="more"></a><h2 id="Work-Summary"><a href="#Work-Summary" class="headerlink" title="Work Summary"></a>Work Summary</h2><ul><li>work summary on 12.8:</li></ul><div class="row"><iframe src="https://drive.google.com/file/d/1zFu8gvrLcgaJdVv3qAhotT2198VaxXvz/preview" style="width:100%; height:550px"></iframe></div><ul><li>work summary on 10.10<div class="row"><iframe src="https://drive.google.com/file/d/1-o090Cv-_cMOGITgzlC2FrVrlLdA9zva/preview" style="width:100%; height:550px"></iframe></div></li></ul><p>We use our own data: HCC exRNA and two other data: exoRBase and GSE71008 to establish our robust feature selection methods.</p><h2 id="Codes"><a href="#Codes" class="headerlink" title="Codes:"></a>Codes:</h2><p><a href="https://github.com/james20141606/exSeek" target="_blank" rel="noopener">exSeek GitHub</a></p><h2 id="Related"><a href="#Related" class="headerlink" title="Related"></a>Related</h2><p>As teaching assistant of <a href="https://lulab2.gitbook.io/" target="_blank" rel="noopener">Bioinformatics Basics</a>. I use part of our work to assign the <a href="https://lulab2.gitbook.io/teaching/part-iv.-quiz/quiz_exrna_tutorial" target="_blank" rel="noopener">final project</a> of this semester’s course.  </p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;strong&gt;exSeek: extracellular RNA analysis tool for noninvasive biomarker&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The aim of this project is to combine &lt;strong&gt;small cell free RNA sequencing techniques&lt;/strong&gt; with &lt;strong&gt;machine learning&lt;/strong&gt; to identify promising candidate biomarker for cancers. We establish the pipeline from mapping to feature selection and propose a &lt;strong&gt;robust feature selection method&lt;/strong&gt; to identify potential biomarkers.&lt;/p&gt;
&lt;p&gt;Parts of this works difficulty is its steps and precision it requires. Since our exRNA-seq is different (it has less RNA reads), we have to explore the mapping sequence. We determine sequential mapping order, using peak calling because most long RNAs are fragments in blood. We also did matrix processing and robust feature selection for biomarker identification.&lt;/p&gt;
    
    </summary>
    
      <category term="projects" scheme="https://www.cmwonderland.com/blog/categories/projects/"/>
    
    
      <category term="project" scheme="https://www.cmwonderland.com/blog/tags/project/"/>
    
      <category term="machine learning" scheme="https://www.cmwonderland.com/blog/tags/machine-learning/"/>
    
      <category term="precision medicine" scheme="https://www.cmwonderland.com/blog/tags/precision-medicine/"/>
    
  </entry>
  
  <entry>
    <title>RNA Structural Motif Finding using Deep Learning</title>
    <link href="https://www.cmwonderland.com/blog/2018/10/11/102-deepshape-project/"/>
    <id>https://www.cmwonderland.com/blog/2018/10/11/102-deepshape-project/</id>
    <published>2018-10-10T16:30:36.000Z</published>
    <updated>2019-04-23T13:07:13.880Z</updated>
    
    <content type="html"><![CDATA[<p><strong>DeepShape: RNA Structural Motif Finding</strong></p><p><strong>DeepShape</strong> is the project I like the most and devote the most during my undergraduate research time. It originates the interests of applying deep learning to predict RNA structure and structure probing data. During a lot of trying we realized current convolutional and recurrent neural network are not suitable to <strong>really understand RNA structure</strong>. We can get a “pseudo” good result yet learn little about the real structure information.</p><p>We then turn to predict RNA motif (especially RNA-protein interaction related motif). It is another harder problem compared with “simply” applying deep neural network to 1D and 2D structure data. We develop the mixture model for PWM optimization. We explore the possibility to use VAE for unsupervised learning. What’s more, I strongly believe a relatively new model: <strong>graph convolutional neural network</strong> has a great potential to really utilize and discover the structural information in motif finding problem. </p><a id="more"></a><h2 id="abstract"><a href="#abstract" class="headerlink" title="abstract"></a>abstract</h2><p>RNAs play key roles in cells through the structural specificity and interactions with proteins known as the RNA-binding proteins(RBP). The binding motifs enable crucial understanding of the regulation of RNAs. Many automatic tools have been developed to predict the RNA-protein binding sites from the rapidly growing multi-resource data, e.g. sequence, structure, their domain specific features. MEME, RNApromo and GraphProt can utilize sequence and structural feature using algorithms like expectation maximization (EM) or support vector machine (SVM). </p><p>However, there are several limitations in existing methods. For example, the SCFG-based model has a very high computational complexity and the position-weight matrix (PWM) model does not learn structural information. Machine learning model like GraphProt and DeepBind relies on class labels and can’t handle unsupervised motif finding task. Deep learning-based algorithms are believed  to be capable of capturing features in structural data, e.g. image and sequence data.  However, current models didn’t incorporate structure probing data like icSHAPE. What’s more, convolutional neural network cannot accept secondary structure data as input.</p><p>We propose to use Variational Auto-Encoder (VAE) as motif model and incorporate it into EM algorithm to predict motif existence and locate motif position.  VAE can encode sequence data and decode it as probability in PWM. It can be optimized by optimizing the combination of KL loss and reconstruction loss. VAE-based mixture model achieves good performance in sequence data (JASPAR). We also propose to use Graph Convolutional Neural Network (GCN) to capture RNA secondary structure feature for structural related motif finding. We first represent RNA structure as graph, encoding nucleotides and base pairs as nodes and edges. We also encode higher level graph features like hairpin, helix and bulge. GCN can incorporate and utilize both sequence and structural features to predict motif existence and location. It achieves good performance compared with other methods considering accuracy and computational efficiency.</p><h2 id="Poster"><a href="#Poster" class="headerlink" title="Poster"></a>Poster</h2><p><img src="http://i1.fuimg.com/640680/c5d74bc8ee9e44d9.jpg" alt="Markdown"></p><h2 id="Work-report"><a href="#Work-report" class="headerlink" title="Work report"></a>Work report</h2><p>We are still making progress in DeepShape project, using Graph Convolutional Neural Network to discover structural motif.</p><p>The Project introduction can be divided into two parts: predicting RNA secondary structure probing data and discover motif.</p><h3 id="Predicting-icSHAPE-secondary-structure-probing-data"><a href="#Predicting-icSHAPE-secondary-structure-probing-data" class="headerlink" title="Predicting icSHAPE: secondary structure probing data"></a>Predicting icSHAPE: secondary structure probing data</h3><div class="row"><iframe src="https://drive.google.com/file/d/1Iv1r7LUNpYxNrXm450GGUzT67M61qf4E/preview" style="width:100%; height:550px"></iframe></div><h3 id="methods"><a href="#methods" class="headerlink" title="methods:"></a>methods:</h3><p>We use window to convert RNA sequence into uniform slices for 1D deep learning model. We also try something <strong>new and fun</strong>: we convert one sequence to a 2D map and use <strong>specialized designed 2D U-net</strong> to predict it. (<em>Later we find that google use the similar idea to predict SNP as images</em>).</p><ul><li>1D<ul><li>CNN</li><li>RNN</li><li>ResNet</li><li>Seq2Seq</li><li>Attention</li></ul></li><li>2D<ul><li>U-net</li></ul></li></ul><h3 id="Discover-MOTIF-predict-existence-and-location-of-motif"><a href="#Discover-MOTIF-predict-existence-and-location-of-motif" class="headerlink" title="Discover MOTIF: predict existence and location of motif"></a>Discover MOTIF: predict existence and location of motif</h3><div class="row"><iframe src="https://drive.google.com/file/d/11XfyNguAXpVCcWGKQhgyspLA7w5M2fYa/preview" style="width:100%; height:550px"></iframe></div><h3 id="methods-1"><a href="#methods-1" class="headerlink" title="methods:"></a>methods:</h3><p>We revise and improve MEME’s EM algorithm to Mixture-PWM to make the model more robust to noises.</p><p>We also replace the PWM matrix with a Variational Auto-Encoder (<strong>VAE</strong>).</p><p>We then use Graph Convolutional Neural Network (<strong>GCN</strong>) to explore the possibility to predict <strong>Structural related motif</strong>. During our long time exploration, we find GCN may be the best method (in deep learning) to truly understand the structural information in RNA sequence.</p><h2 id="Codes"><a href="#Codes" class="headerlink" title="Codes:"></a>Codes:</h2><p><a href="https://github.com/james20141606/Deepshape/" target="_blank" rel="noopener">DeepShape GitHub</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;strong&gt;DeepShape: RNA Structural Motif Finding&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;DeepShape&lt;/strong&gt; is the project I like the most and devote the most during my undergraduate research time. It originates the interests of applying deep learning to predict RNA structure and structure probing data. During a lot of trying we realized current convolutional and recurrent neural network are not suitable to &lt;strong&gt;really understand RNA structure&lt;/strong&gt;. We can get a “pseudo” good result yet learn little about the real structure information.&lt;/p&gt;
&lt;p&gt;We then turn to predict RNA motif (especially RNA-protein interaction related motif). It is another harder problem compared with “simply” applying deep neural network to 1D and 2D structure data. We develop the mixture model for PWM optimization. We explore the possibility to use VAE for unsupervised learning. What’s more, I strongly believe a relatively new model: &lt;strong&gt;graph convolutional neural network&lt;/strong&gt; has a great potential to really utilize and discover the structural information in motif finding problem. &lt;/p&gt;
    
    </summary>
    
      <category term="projects" scheme="https://www.cmwonderland.com/blog/categories/projects/"/>
    
    
      <category term="project" scheme="https://www.cmwonderland.com/blog/tags/project/"/>
    
      <category term="deep learning" scheme="https://www.cmwonderland.com/blog/tags/deep-learning/"/>
    
      <category term="RNA structure" scheme="https://www.cmwonderland.com/blog/tags/RNA-structure/"/>
    
      <category term="VAE" scheme="https://www.cmwonderland.com/blog/tags/VAE/"/>
    
      <category term="GCN" scheme="https://www.cmwonderland.com/blog/tags/GCN/"/>
    
  </entry>
  
  <entry>
    <title>Summer Intern Project Summary</title>
    <link href="https://www.cmwonderland.com/blog/2018/10/10/100_summer_intern/"/>
    <id>https://www.cmwonderland.com/blog/2018/10/10/100_summer_intern/</id>
    <published>2018-10-10T14:05:19.000Z</published>
    <updated>2019-04-23T13:07:13.978Z</updated>
    
    <content type="html"><![CDATA[<p>This page summarize my summer intern work, includes final report, weekly report, codes, presentation.</p><p>To sum up, I mainly do two projects in this summer, which can be divided again into four works:</p><ul><li><p><a href="https://lichtmanlab.fas.harvard.edu/" target="_blank" rel="noopener">Lichtman Lab</a>:</p><ul><li>NMJ tracing and segmenting with statistical work</li><li>NMJ automatic segmentation pipeline</li></ul></li><li><p><a href="https://vcg.seas.harvard.edu/people" target="_blank" rel="noopener">Hanspiter Lab</a>:</p><ul><li>Synapse prediction</li><li>Synaptic polarity prediction</li></ul></li></ul><p>For NMJ tracing, segmenting and automatic prediction work, we push forward the project with the generous daily help of our mentor Jeff. </p><p>For Synapse project, I work with Zudi and Donglai, we now rank No.1 in the <a href="https://cremi.org" target="_blank" rel="noopener">CREMI contest</a>. And we will submit a paper to CVPR this November.</p><a id="more"></a><h1 id="final-report"><a href="#final-report" class="headerlink" title="final report"></a>final report</h1><ul><li>online pdf</li></ul><div class="row"><iframe src="https://drive.google.com/file/d/1XyEPj9r7p8VNk5nLlLIPNhZjuDHu2KTY/preview" style="width:100%; height:550px"></iframe></div><ul><li>pdf in github</li></ul><p>You may also find the <a href="https://github.com/james20141606/Summer_Intern/blob/master/summer_intern_report_xupeng.pdf" target="_blank" rel="noopener"><strong>PDF Version</strong></a> of this report from github.</p><h1 id="presentation"><a href="#presentation" class="headerlink" title="presentation"></a>presentation</h1><h2 id="in-Lichtman-lab"><a href="#in-Lichtman-lab" class="headerlink" title="in Lichtman lab"></a>in Lichtman lab</h2><ul><li>online pdf</li></ul><div class="row"><iframe src="https://drive.google.com/file/d/1pLtw2eLJl9kMVj1pGSCqehcBfjVdBZ4c/preview" style="width:100%; height:550px"></iframe></div><h2 id="in-Tsinghua"><a href="#in-Tsinghua" class="headerlink" title="in Tsinghua"></a>in Tsinghua</h2><ul><li>online pdf</li></ul><div class="row"><iframe src="https://drive.google.com/file/d/1mVOPchbWZ9nsODPklNjw_OGwl2vehKdF/preview" style="width:100%; height:550px"></iframe></div><h1 id="codes"><a href="#codes" class="headerlink" title="codes"></a>codes</h1><p><a href="https://github.com/james20141606/Summer_Intern" target="_blank" rel="noopener">Main codes</a><br><a href="https://github.com/james20141606/NMJ_automatic_pipeline" target="_blank" rel="noopener">Automatic pipeline</a><br><a href="https://github.com/james20141606/EM-network" target="_blank" rel="noopener">Synapse polarity</a></p><h1 id="detailed-progress"><a href="#detailed-progress" class="headerlink" title="detailed progress"></a>detailed progress</h1><p>I summarized my daily progress about the following project during my summer intern, please visit the related web pages:</p><p><a href="https://www.cmwonderland.com/2018/07/14/summerintern_NMJ/">NMJ project</a><br><a href="https://www.cmwonderland.com/2018/07/14/summerintern_Synapse_Prediction/">Synapse Prediction</a><br><a href="https://www.cmwonderland.com/2018/07/14/summerintern_Synaptic_Partner_and_Cluster_Project/">Synaptic Partner and Cluster Project</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;This page summarize my summer intern work, includes final report, weekly report, codes, presentation.&lt;/p&gt;
&lt;p&gt;To sum up, I mainly do two projects in this summer, which can be divided again into four works:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&quot;https://lichtmanlab.fas.harvard.edu/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Lichtman Lab&lt;/a&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;NMJ tracing and segmenting with statistical work&lt;/li&gt;
&lt;li&gt;NMJ automatic segmentation pipeline&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&quot;https://vcg.seas.harvard.edu/people&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Hanspiter Lab&lt;/a&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Synapse prediction&lt;/li&gt;
&lt;li&gt;Synaptic polarity prediction&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For NMJ tracing, segmenting and automatic prediction work, we push forward the project with the generous daily help of our mentor Jeff. &lt;/p&gt;
&lt;p&gt;For Synapse project, I work with Zudi and Donglai, we now rank No.1 in the &lt;a href=&quot;https://cremi.org&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;CREMI contest&lt;/a&gt;. And we will submit a paper to CVPR this November.&lt;/p&gt;
    
    </summary>
    
      <category term="projects" scheme="https://www.cmwonderland.com/blog/categories/projects/"/>
    
    
      <category term="project" scheme="https://www.cmwonderland.com/blog/tags/project/"/>
    
      <category term="neural science" scheme="https://www.cmwonderland.com/blog/tags/neural-science/"/>
    
      <category term="summer intern" scheme="https://www.cmwonderland.com/blog/tags/summer-intern/"/>
    
      <category term="connectomics" scheme="https://www.cmwonderland.com/blog/tags/connectomics/"/>
    
      <category term="computational neural science" scheme="https://www.cmwonderland.com/blog/tags/computational-neural-science/"/>
    
      <category term="deep learning" scheme="https://www.cmwonderland.com/blog/tags/deep-learning/"/>
    
      <category term="computer vision" scheme="https://www.cmwonderland.com/blog/tags/computer-vision/"/>
    
      <category term="Jeff Lichtman" scheme="https://www.cmwonderland.com/blog/tags/Jeff-Lichtman/"/>
    
  </entry>
  
  <entry>
    <title>Machine Learning for Traits Prediction</title>
    <link href="https://www.cmwonderland.com/blog/2018/10/10/96-emaize-project/"/>
    <id>https://www.cmwonderland.com/blog/2018/10/10/96-emaize-project/</id>
    <published>2018-10-10T12:30:51.000Z</published>
    <updated>2019-04-23T13:07:13.953Z</updated>
    
    <content type="html"><![CDATA[<p><strong>eMaize: Machine Learning for Traits Prediction</strong></p><p>Heterosis is the improved or increased function of any biological quality in a hybrid offspring. We have studied yet the largest maize SNP dataset for traits prediction.</p><p>We develop linear and non-linear models which consider relationships between different hybrids as well as other effect. Specially designed model proved to be efficient and robust in prediction maize’s traits.</p><p>We proposed a new mixed linear model <strong>Mixed Ridge</strong> with Fast cross validation to pick parameters. We also propose <strong>Metric Regressor</strong> for few shot learning.</p><a id="more"></a><h2 id="Preprint-paper"><a href="#Preprint-paper" class="headerlink" title="Preprint paper:"></a>Preprint paper:</h2><div class="row">    <embed src="https://arxiv.org/pdf/1808.06275.pdf" width="100%" height="550" type="application/pdf"></div><h2 id="Codes"><a href="#Codes" class="headerlink" title="Codes:"></a>Codes:</h2><p><a href="https://github.com/james20141606/eMaize/" target="_blank" rel="noopener">eMaize GitHub</a></p><h2 id="Presentation"><a href="#Presentation" class="headerlink" title="Presentation"></a>Presentation</h2><div class="row"><iframe src="https://drive.google.com/file/d/1m3fLr_DUkF2NB_DU_YRfAAMV-vkU09AA/preview" style="width:100%; height:550px"></iframe></div><h2 id="Related"><a href="#Related" class="headerlink" title="Related"></a>Related</h2><h3 id="proposal"><a href="#proposal" class="headerlink" title="proposal"></a>proposal</h3><div class="row"><iframe src="https://drive.google.com/file/d/1uD61pNPaNcpAn_MPE9jSjk25qIwhdFAm/preview" style="width:100%; height:550px"></iframe></div>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;strong&gt;eMaize: Machine Learning for Traits Prediction&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Heterosis is the improved or increased function of any biological quality in a hybrid offspring. We have studied yet the largest maize SNP dataset for traits prediction.&lt;/p&gt;
&lt;p&gt;We develop linear and non-linear models which consider relationships between different hybrids as well as other effect. Specially designed model proved to be efficient and robust in prediction maize’s traits.&lt;/p&gt;
&lt;p&gt;We proposed a new mixed linear model &lt;strong&gt;Mixed Ridge&lt;/strong&gt; with Fast cross validation to pick parameters. We also propose &lt;strong&gt;Metric Regressor&lt;/strong&gt; for few shot learning.&lt;/p&gt;
    
    </summary>
    
      <category term="projects" scheme="https://www.cmwonderland.com/blog/categories/projects/"/>
    
    
      <category term="project" scheme="https://www.cmwonderland.com/blog/tags/project/"/>
    
      <category term="machine learning" scheme="https://www.cmwonderland.com/blog/tags/machine-learning/"/>
    
      <category term="breeding" scheme="https://www.cmwonderland.com/blog/tags/breeding/"/>
    
      <category term="linear mixed model" scheme="https://www.cmwonderland.com/blog/tags/linear-mixed-model/"/>
    
  </entry>
  
  <entry>
    <title>MDN for Signal Position Prediction</title>
    <link href="https://www.cmwonderland.com/blog/2018/10/09/94-signal-project/"/>
    <id>https://www.cmwonderland.com/blog/2018/10/09/94-signal-project/</id>
    <published>2018-10-08T16:50:56.000Z</published>
    <updated>2019-04-23T13:07:13.945Z</updated>
    
    <content type="html"><![CDATA[<p>This page summarize our work on using mixture density network to jointly predict position coordinates.</p><p>We collaborate with Jun Li in New York University. </p><h2 id="presentation-of-current-work"><a href="#presentation-of-current-work" class="headerlink" title="presentation of current work"></a>presentation of current work</h2><div class="row"><iframe src="https://drive.google.com/file/d/12kdQZKUrz-z_4k-eSW83ogKvTRwPjn3o/preview" style="width:100%; height:550px"></iframe></div><a id="more"></a><h2 id="methods"><a href="#methods" class="headerlink" title="methods"></a>methods</h2><h3 id="model"><a href="#model" class="headerlink" title="model"></a>model</h3><p>We use pytorch and tensorflow to develop our mixture density network. </p><ul><li>A MLP is used to generate pi, mu and sigma for 2D isotropic gaussian distribution.</li><li>Several 2D gaussian distribution is mixed to form a mixed gaussian distribution.<br><img src="http://i2.tiimg.com/640680/4d39615fdca66f67.png" alt="Markdown"></li><li>We use Maximum Likelihood Estimation, choose negetive log likelihood as our loss function for optimization</li><li><img src="http://i2.tiimg.com/640680/abf549073048f5f9.png" alt="Markdown"></li></ul><p>Several tricks:</p><ul><li>deal with loss nan: we use log transform of signa, mu and pi, also a cutoff of sigma and pseudo counts of pi is used to prevend loss explosion of vanishing</li><li>z score normalization to optimize the model easier.</li><li>we use mean shift to find modes in gaussian mixture</li></ul><p><img src="http://i2.tiimg.com/640680/0ef0ba152c39f99f.png" alt="Markdown"></p><h3 id="result"><a href="#result" class="headerlink" title="result"></a>result</h3><p><img src="http://i2.tiimg.com/640680/e7e107d4d04e6849.png" alt="Markdown"></p><h3 id="data"><a href="#data" class="headerlink" title="data"></a>data</h3><h4 id="mountain-data"><a href="#mountain-data" class="headerlink" title="mountain data"></a>mountain data</h4><ul><li>data position<br><img src="http://i2.tiimg.com/640680/1668bdf4741445b1.png" alt="Markdown"></li><li>t-SNE to cluster data<br><img src="http://i2.tiimg.com/640680/c06e0baac3381bc4.png" alt="Markdown"></li><li>feature distribution<br><img src="http://i2.tiimg.com/640680/258900a437c4a544.png" alt="Markdown"></li></ul><h4 id="city-data"><a href="#city-data" class="headerlink" title="city data"></a>city data</h4><ul><li>data position<br><img src="http://i2.tiimg.com/640680/c84923de5dd7b62a.png" alt="Markdown"></li><li>receriver position<br><img src="http://i2.tiimg.com/640680/37d804dc03e44805.png" alt="Markdown"></li><li>transmitter position<br><img src="http://i2.tiimg.com/640680/ed56538e48c4a54f.png" alt="Markdown"></li></ul><h4 id="explore-useful-features"><a href="#explore-useful-features" class="headerlink" title="explore useful features"></a>explore useful features</h4><p>We use PCC to quantify the PCC between samples’ features and distance. We use dynamic weight to pick features having higher relation with distance. It seems TOA has the significant higher weight<br><img src="http://i2.tiimg.com/640680/1533405e66d3b4c4.gif" alt="Markdown"></p><p>We plan to use some <strong>imputation method</strong>, including some methods from single cell analysis. We also aim to use <strong>RNN</strong> for changeable size feature and <strong>attention model</strong> to pick more related features.</p><h2 id="codes"><a href="#codes" class="headerlink" title="codes"></a>codes</h2><p><a href="https://github.com/james20141606/Signal" target="_blank" rel="noopener">https://github.com/james20141606/Signal</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;This page summarize our work on using mixture density network to jointly predict position coordinates.&lt;/p&gt;
&lt;p&gt;We collaborate with Jun Li in New York University. &lt;/p&gt;
&lt;h2 id=&quot;presentation-of-current-work&quot;&gt;&lt;a href=&quot;#presentation-of-current-work&quot; class=&quot;headerlink&quot; title=&quot;presentation of current work&quot;&gt;&lt;/a&gt;presentation of current work&lt;/h2&gt;

	&lt;div class=&quot;row&quot;&gt;
		&lt;iframe src=&quot;https://drive.google.com/file/d/12kdQZKUrz-z_4k-eSW83ogKvTRwPjn3o/preview&quot; style=&quot;width:100%; height:550px&quot;&gt;&lt;/iframe&gt;
	&lt;/div&gt;
    
    </summary>
    
      <category term="projects" scheme="https://www.cmwonderland.com/blog/categories/projects/"/>
    
    
      <category term="project" scheme="https://www.cmwonderland.com/blog/tags/project/"/>
    
      <category term="machine learning" scheme="https://www.cmwonderland.com/blog/tags/machine-learning/"/>
    
      <category term="signal" scheme="https://www.cmwonderland.com/blog/tags/signal/"/>
    
      <category term="MLP" scheme="https://www.cmwonderland.com/blog/tags/MLP/"/>
    
      <category term="Mixture model" scheme="https://www.cmwonderland.com/blog/tags/Mixture-model/"/>
    
      <category term="MDN" scheme="https://www.cmwonderland.com/blog/tags/MDN/"/>
    
      <category term="attention mechanism" scheme="https://www.cmwonderland.com/blog/tags/attention-mechanism/"/>
    
  </entry>
  
  <entry>
    <title>QUIZ Predicting maize traits using SNP data</title>
    <link href="https://www.cmwonderland.com/blog/2018/10/06/31_quiz_emaize_tutorial/"/>
    <id>https://www.cmwonderland.com/blog/2018/10/06/31_quiz_emaize_tutorial/</id>
    <published>2018-10-06T12:03:19.000Z</published>
    <updated>2019-04-23T13:07:13.933Z</updated>
    
    <content type="html"><![CDATA[<p>This is one of the two course quizzes instruction of <a href="https://lulab.gitbooks.io/teaching/content/" target="_blank" rel="noopener">Bioinformatics basic course in Tsinghua University</a>. You may also find it <a href="https://lulab.gitbooks.io/teaching/content/quiz/quiz_exrna/quiz_emaize_tutorial.html" target="_blank" rel="noopener">here</a>.</p><p>The related <a href="https://github.com/lulab/teaching_book/blob/master/quiz/quiz_emaize/quiz_emaize_tutorial.ipynb" target="_blank" rel="noopener">jupyter file</a></p><a id="more"></a><h1 id="eMaize玉米育种挑战赛"><a href="#eMaize玉米育种挑战赛" class="headerlink" title="eMaize玉米育种挑战赛"></a>eMaize玉米育种挑战赛</h1><p>请在<a href="https://cloud.tsinghua.edu.cn/f/3f4fc999720d45f198ca/" target="_blank" rel="noopener">quiz_emaize_tutorial_shared</a>下载相关数据，并下载该<a href="https://cloud.tsinghua.edu.cn/f/def95f1d1beb4031bf2f/" target="_blank" rel="noopener">文件夹</a>下的内容，打开<code>quiz_emaize_tutorial.ipynb</code>文件阅读详细的<strong>Quiz指南</strong>。</p><h2 id="eMaize背景简介"><a href="#eMaize背景简介" class="headerlink" title="eMaize背景简介"></a>eMaize背景简介</h2><p>eMaize挑战赛是<a href="http://emaize.imaze.org/emaize/emaize_cn.php" target="_blank" rel="noopener">一个通过机器学习方法预测玉米性状的比赛</a>，要求我们以SNP作为特征，通过训练一个模型，<strong>对玉米的三个性状进行预测</strong>。</p><p>本教程将会包括：</p><ul><li>介绍数据的情况，使用方式</li><li>具体任务要求</li><li>一些机器学习的概念方法以及工具使用</li></ul><h2 id="编程工具介绍"><a href="#编程工具介绍" class="headerlink" title="编程工具介绍"></a>编程工具介绍</h2><p>大作业需要使用python完成，推荐读者使用python3。我们需要一些python的工具包来实现部分功能。推荐使用包管理软件Anaconda来预装一些必需的包以及安装其他需要的包。另外强烈建议使用jupyter notebook进行代码编辑、运行和调试。具体使用方法请参考教程<a href="https://lulab.gitbooks.io/teaching/content/part-iii.-machine-learning-basics/python_tutorial.html" target="_blank" rel="noopener">Anaconda 和 jupyter</a>相关指南。<br>如果本地缺少下列可能需要的包，请使用<code>pip</code>或者<code>conda</code>进行安装。如:</p><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pip <span class="keyword">install</span> tqdm</span><br><span class="line">conda <span class="keyword">install</span> sklearn</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#导入必需的库</span></span><br><span class="line">%pylab inline</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.random_projection <span class="keyword">import</span> SparseRandomProjection</span><br><span class="line"><span class="keyword">import</span> scipy.stats</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> sklearn</span><br><span class="line"><span class="keyword">import</span> h5py</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> r2_score</span><br><span class="line"><span class="keyword">from</span> scipy.stats.stats <span class="keyword">import</span> pearsonr</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line"><span class="keyword">import</span> xgboost</span><br><span class="line"><span class="keyword">from</span> xgboost.sklearn <span class="keyword">import</span> XGBRegressor</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> Ridge</span><br><span class="line"><span class="keyword">from</span> sklearn.kernel_ridge <span class="keyword">import</span> KernelRidge</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> neighbors</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestRegressor</span><br><span class="line"><span class="keyword">from</span> sklearn.gaussian_process <span class="keyword">import</span> GaussianProcessRegressor</span><br><span class="line"><span class="keyword">from</span> sklearn.gaussian_process.kernels <span class="keyword">import</span> DotProduct</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm_notebook <span class="keyword">as</span> tqdm</span><br><span class="line"><span class="keyword">from</span> IPython.display <span class="keyword">import</span> display, Image</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line">warnings.filterwarnings(<span class="string">'ignore'</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">styles = [<span class="string">"white"</span>,<span class="string">"dark"</span>,<span class="string">'whitegrid'</span>,<span class="string">"darkgrid"</span>]</span><br><span class="line">contexts = [<span class="string">'paper'</span>,<span class="string">'talk'</span>,<span class="string">'poster'</span>,<span class="string">'notebook'</span>]</span><br><span class="line">sns.set_context(contexts[<span class="number">1</span>])</span><br><span class="line">sns.set_style(styles[<span class="number">2</span>])</span><br></pre></td></tr></table></figure><h2 id="数据介绍"><a href="#数据介绍" class="headerlink" title="数据介绍"></a>数据介绍</h2><p>原始数据中有6210个样本，其中4754个样本作为训练集，1456个样本作为测试集 <br></p><ul><li><strong>genotype</strong>：SNP (Single-nucleotide polymorphism) 数据<br>  每个位点可能有三种情况，如AA，AT，TT，每个样本SNP位点约为190万个，数据位置<code>data/genotype_2bit/</code>，包含十个染色体各自的SNP，使用时需要整合在一起。 <br></li><li><strong>trait</strong>：<br>  共三种，trait1开花期，trait2株高，trait3产量，为连续值，只提供训练集样本的性状数据。<code>data/pheno_emaize.txt</code> <br><br><br><br>作为示例仅仅使用每个样本的5000个SNP，在做大作业的过程中请使用全部的SNP。<br></li></ul><h3 id="Genotype数据"><a href="#Genotype数据" class="headerlink" title="Genotype数据"></a>Genotype数据</h3><h4 id="SNP数据存储格式"><a href="#SNP数据存储格式" class="headerlink" title="SNP数据存储格式"></a>SNP数据存储格式</h4><p>txt存储格式不适合大数据读取的问题，对内存的占用过多 <br><br>对于结构化的、能够存储为矩阵的数据，可以使用HDF5格式存取，内存占用小，读取速度快。</p><blockquote><p>tips: 在命令行查看数据shape的方法为：<br>cd至文件路径下，输入：h5ls filename</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#使用h5py读取5000个SNP，此时数据为原始的碱基信息</span></span><br><span class="line"><span class="keyword">with</span> h5py.File(<span class="string">'data/snp_5000'</span>,<span class="string">'r'</span>) <span class="keyword">as</span> f:</span><br><span class="line">    <span class="keyword">print</span> (list(f.keys()))</span><br><span class="line">    snps = f[<span class="string">'snp'</span>][:]</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#使用h5py读取5000个SNP，此时为原始的碱基信息转化为数值信息后的数据</span></span><br><span class="line"><span class="keyword">with</span> h5py.File(<span class="string">'data/2bit_geno'</span>,<span class="string">'r'</span>) <span class="keyword">as</span> f:</span><br><span class="line">    <span class="keyword">print</span> (list(f.keys()))</span><br><span class="line">    snps_2bit = f[<span class="string">'data'</span>][:]</span><br><span class="line">snps_2bit.shape</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#使用h5py读取一个染色体的SNP示例，此时文件内为我们处理好的数值化数据，注意需要先解压文件：</span></span><br><span class="line"><span class="keyword">with</span> h5py.File(<span class="string">'data/genotype_2bit/chr1.h5'</span>,<span class="string">'r'</span>) <span class="keyword">as</span> f:</span><br><span class="line">    <span class="keyword">print</span> (list(f.keys()))</span><br><span class="line">    chr1_snps = f[<span class="string">'data'</span>][:]</span><br><span class="line">chr1_snps.shape, chr1_snps.dtype</span><br></pre></td></tr></table></figure><h4 id="性状数据"><a href="#性状数据" class="headerlink" title="性状数据"></a>性状数据</h4><p>使用numpy/pandas均可读取性状数据，计算时一般使用numpy.array的形式</p><p>前4764个样本的性状是已知的，后1454个样本性状待预测</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">traits = pd.read_csv(<span class="string">'data/pheno_emaize.txt'</span>,<span class="string">'\t'</span>)</span><br><span class="line">display(traits.head())</span><br><span class="line">display(traits.tail())</span><br></pre></td></tr></table></figure><h5 id="查看性状的分布情况"><a href="#查看性状的分布情况" class="headerlink" title="查看性状的分布情况"></a>查看性状的分布情况</h5><p>注意，对性状数据已经做过了normalization</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">trait1 = np.array(traits[<span class="string">'trait1'</span>])[:<span class="number">4754</span>]</span><br><span class="line">trait2 = np.array(traits[<span class="string">'trait2'</span>])[:<span class="number">4754</span>]</span><br><span class="line">trait3 = np.array(traits[<span class="string">'trait3'</span>])[:<span class="number">4754</span>]</span><br><span class="line">fig, ax = plt.subplots(<span class="number">1</span>,<span class="number">3</span>, figsize=(<span class="number">15</span>,<span class="number">4</span>))</span><br><span class="line">ax[<span class="number">0</span>].hist(trait1,bins = <span class="number">20</span>,color=<span class="string">'b'</span>,alpha=<span class="number">0.6</span>)</span><br><span class="line">ax[<span class="number">0</span>].set_title(<span class="string">'Normalized Trait1: Flowering Time'</span>,fontsize=<span class="number">14</span>)</span><br><span class="line">ax[<span class="number">1</span>].hist(trait2,bins = <span class="number">20</span>,color=<span class="string">'g'</span>,alpha=<span class="number">0.6</span>)</span><br><span class="line">ax[<span class="number">1</span>].set_title(<span class="string">'Normalized Trait2: Height'</span>,fontsize=<span class="number">14</span>)               </span><br><span class="line">ax[<span class="number">2</span>].hist(trait3,bins = <span class="number">20</span>,color=<span class="string">'r'</span>,alpha=<span class="number">0.6</span>)</span><br><span class="line">ax[<span class="number">2</span>].set_title(<span class="string">'Normalized Trait3: Yield'</span>,fontsize=<span class="number">14</span>)</span><br></pre></td></tr></table></figure><p><img src="http://i1.fuimg.com/640680/4d02e8859cdfd53f.png" alt="Markdown"></p><h2 id="Quiz具体要求"><a href="#Quiz具体要求" class="headerlink" title="Quiz具体要求"></a>Quiz具体要求</h2><p>之前的部分我们介绍了基本的背景知识，接下来我们会提出解答本题目的具体要求：</p><ul><li>完成<strong>特征选择和特征筛除工作</strong>。</li><li>完成<strong>对三种性状的预测</strong>并提交预测结果，允许多次提交预测结果以获得更好的结果。</li><li>提交一份<strong>工作报告</strong>，中英文不限，同时提交<strong>源代码</strong>。</li><li>选择性完成加分项内容。</li></ul><h3 id="特征选择和冗余特征筛除"><a href="#特征选择和冗余特征筛除" class="headerlink" title="特征选择和冗余特征筛除"></a>特征选择和冗余特征筛除</h3><p>本挑战原始特征数量接近2,000,000，超过大多数机器学习模型的输入限制，特征间相关性很强，冗余特征很多，且过多的特征数量导致计算开销非常大，这都需要完成特征选择和去除冗余的步骤。</p><p>鉴于本问题原始特征数量过于巨大，并不是每种特征选择和降维方法都适合，请读者思考和选择合适的特征选择与降维方法，在这里仅提供几个方法参考：</p><ul><li>特征选择：<ul><li>ANOVA（方差分析）</li><li>基于模型权重排序（如线性模型）</li></ul></li><li>降维：<ul><li>PCA</li><li>SVD</li><li>Random Projection</li></ul></li></ul><blockquote><p>tips: 请思考是否需要针对特征选择或者降维后的数据做scale</p></blockquote><h3 id="完成对测试集三种性状的预测，尝试得到尽可能好的预测结果"><a href="#完成对测试集三种性状的预测，尝试得到尽可能好的预测结果" class="headerlink" title="完成对测试集三种性状的预测，尝试得到尽可能好的预测结果"></a>完成对测试集三种性状的预测，尝试得到尽可能好的预测结果</h3><ul><li>请思考和探索使用何种回归模型，读者可以尝试多种模型并比较其结果，在<em>编程工具介绍</em>部分读者可以看到一些机器学习模型的方法，也推荐读者思考和使用其他模型。</li><li>思考和探索是否对每个性状使用不同的模型</li><li>根据训练集与测试集的特殊划分方式（见<em>查看训练集与测试集的划分</em>部分）思考可以使用的策略。</li></ul><h3 id="加分内容"><a href="#加分内容" class="headerlink" title="加分内容"></a>加分内容</h3><p>为了更完整地展示emaize挑战的困难与有趣之处，我们为有余力的读者设置了更多的挑战。</p><h4 id="对模型进行鲁棒性测试-10’"><a href="#对模型进行鲁棒性测试-10’" class="headerlink" title="对模型进行鲁棒性测试 (10’)"></a>对模型进行鲁棒性测试 (10’)</h4><p>这是一个并不非常困难的但是对于本问题比较重要的工作，该工作可以细分为以下几项内容：</p><ul><li>在读者已有的数据（训练集数据）上进行多轮（如100、1000轮）交叉验证，测试模型的鲁棒性</li><li>设计不同的数据集划分方式，除了随机划分训练集与验证集，还可以有其他特殊的设计方法</li><li>统计测试结果，以多种形式展现，包括统计数据和图示。</li></ul><p>为了帮助读者完成测试，我们会给读者提供部分代码和一些相关的统计图，供读者使用和仿照设计，详见<em>补充知识</em>的<em>模型鲁棒性测试</em>部分。</p><h4 id="使用ANOVA进行特征选择的加速算法-5’"><a href="#使用ANOVA进行特征选择的加速算法-5’" class="headerlink" title="使用ANOVA进行特征选择的加速算法 (5’)"></a>使用ANOVA进行特征选择的加速算法 (5’)</h4><p>方差分析方法可以利用p值挑选feature <br><br>调用scipy.stats.f_oneway,利用SNPs和性状可以很容易地计算出p-value，进而挑选特征，但是对于大量数据来说速度较慢 <br><br>我们可以设计一种加速ANOVA计算的方法完成计算，相比于scipy.stats的方法可以提升计算速度数百倍。为了帮助读者实现这一功能，我们提供给读者设计的基本思路，请参考<a href="#fastanova"><em>ANOVA加速算法部分</em></a>，有能力的读者可以根据基本思路实现ANOVA的加速算法。</p><h4 id="混合线性模型-20’"><a href="#混合线性模型-20’" class="headerlink" title="混合线性模型 (20’)"></a>混合线性模型 (20’)</h4><p>育种领域的一个经典模型是混合线性模型(linear mixed model)，请尝试设计一个混合线性模型来解决本问题。</p><ul><li><p>可以研究并调用<a href="https://github.com/MicrosoftGenomics/FaST-LMM" target="_blank" rel="noopener">FaST-LMM package</a>，研究其原理并应用于我们的数据中，试图在测试集上获得好的预测结果(5’)</p></li><li><p>根据其思路进行改进，设计一个类似的混合线性模型，并且可以通过快速的交叉验证挑选超参数，最终在测试集上获得好的效果。详细内容可以参考<a href="assets/Mixed_ridge&amp;Fast_cv.pdf">这篇文档</a>。(15’)</p></li></ul><h2 id="补充知识（选读）"><a href="#补充知识（选读）" class="headerlink" title="补充知识（选读）"></a>补充知识（选读）</h2><h3 id="测试预测结果"><a href="#测试预测结果" class="headerlink" title="测试预测结果"></a>测试预测结果</h3><h5 id="查看训练集与测试集的划分"><a href="#查看训练集与测试集的划分" class="headerlink" title="查看训练集与测试集的划分"></a>查看训练集与测试集的划分</h5><p>请读者特别关注这个信息，训练集与测试集特殊的划分方式是本问题的一个特点与难点，也是想解决好本问题的关键。</p><p>下图中彩色部分为训练集性状，白色部分为待预测性状 <br><br>可以发现其划分方式并不随机，这会导致常规的机器学习方法出现一些问题，常规的机器学习问题中，每个样本彼此独立，但是对于育种问题，很多样本可能有同一个父本或者母本，比如图中的每一行样本都来自同一个父本，每一列样本都来自同一个母本。读者需要自己思考待预测样本和已有样本的关系，结合机器学习的特点“通过学习已有数据的特征对未知数据进行预测”，思考并观察预测结果的好坏。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">generate_parent_table</span><span class="params">(phenotype_file)</span>:</span></span><br><span class="line">    phenotypes = pd.read_table(phenotype_file)</span><br><span class="line">    pedigree = phenotypes[<span class="string">'pedigree'</span>].str.split(<span class="string">'_'</span>, expand=<span class="keyword">True</span>)</span><br><span class="line">    pedigree.columns = [<span class="string">'f'</span>, <span class="string">'X'</span>, <span class="string">'m'</span>]</span><br><span class="line">    phenotypes = pd.concat([phenotypes, pedigree], axis=<span class="number">1</span>)</span><br><span class="line">    phenotypes[<span class="string">'number'</span>] = np.arange(phenotypes.shape[<span class="number">0</span>])</span><br><span class="line">    parent_table = phenotypes.pivot_table(values=<span class="string">'number'</span></span><br><span class="line">                                          , index=[<span class="string">'m'</span>], columns=[<span class="string">'f'</span>], dropna=<span class="keyword">False</span>)</span><br><span class="line">    male_ids = [<span class="string">'m%d'</span> % i <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, parent_table.shape[<span class="number">0</span>] + <span class="number">1</span>)]</span><br><span class="line">    female_ids = [<span class="string">'f%d'</span> % i <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, parent_table.shape[<span class="number">1</span>] + <span class="number">1</span>)]</span><br><span class="line">    parent_table = parent_table.loc[male_ids, female_ids]</span><br><span class="line">    <span class="keyword">return</span> parent_table</span><br><span class="line">phenotype_file = <span class="string">'data/pheno_emaize.txt'</span></span><br><span class="line">parent_table = generate_parent_table(phenotype_file)</span><br><span class="line">phenotypes = pd.read_table(<span class="string">'data/pheno_emaize.txt'</span>)</span><br><span class="line">fig, ax = subplots(<span class="number">3</span>,<span class="number">1</span>, figsize=(<span class="number">15</span>, <span class="number">10</span>))</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">3</span>):</span><br><span class="line">    trait = [<span class="string">'trait1'</span>,<span class="string">'trait2'</span>,<span class="string">'trait3'</span>][i]</span><br><span class="line">    ax[i].imshow(np.take(np.ravel(phenotypes[trait].values), parent_table), cmap=cm.RdBu)</span><br><span class="line">    ax[i].set_title(<span class="string">'Phenotypes of training data (%s)'</span>%trait)</span><br><span class="line">    ax[i].set_ylabel(<span class="string">'male'</span>)</span><br><span class="line">    ax[i].set_xlabel(<span class="string">'female'</span>)</span><br><span class="line">plt.tight_layout()</span><br></pre></td></tr></table></figure><p><img src="http://i1.fuimg.com/640680/d2f0f8536f919855.png" alt="Markdown"></p><h5 id="测试集具体划分"><a href="#测试集具体划分" class="headerlink" title="测试集具体划分"></a>测试集具体划分</h5><p>我们会把测试区域分为三个部分，来测试提交的结果，三个区域分别为下图的淡蓝色，黄色和红色区域，请读者思考它们各自的特征。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">fig,ax=plt.subplots(figsize=(<span class="number">20</span>,<span class="number">5</span>))</span><br><span class="line">testexample = np.zeros([<span class="number">30</span>,<span class="number">207</span>])</span><br><span class="line">testexample[<span class="number">25</span>:,:<span class="number">202</span>] = <span class="number">100</span></span><br><span class="line">testexample[:<span class="number">25</span>,<span class="number">202</span>:] = <span class="number">200</span></span><br><span class="line">testexample[<span class="number">25</span>:,<span class="number">202</span>:] = <span class="number">300</span></span><br><span class="line">ax.imshow(testexample,cmap=<span class="string">'jet'</span>)</span><br></pre></td></tr></table></figure><p><img src="http://i1.fuimg.com/640680/8ad266b66785548e.png" alt="Markdown"></p><h5 id="评价指标"><a href="#评价指标" class="headerlink" title="评价指标"></a>评价指标</h5><p>对于回归问题，我们一般使用<script type="math/tex">r^2</script>和pearson correlation coefficient(PCC)衡量，其定义如下：</p><p><script type="math/tex">r^2 = 1-\frac{SS_{res}}{SS_{tot}}</script><br></p><p><script type="math/tex">PCC = \frac{cov(X,Y)}{\sigma_X \sigma_Y} = \frac{E[(X-\mu_X)(Y-\mu_Y)]}{\sigma_X \sigma_Y}</script><br></p><h3 id="将SNP数据编码为向量"><a href="#将SNP数据编码为向量" class="headerlink" title="将SNP数据编码为向量"></a>将SNP数据编码为向量</h3><p>每个位点的碱基只有三种情况，不会出现更多碱基组合的可能，比如某位点仅有AA，AT，TT三种可能的情况<br><br>我们可以采取三种方式对其编码：</p><ul><li>转化为0、1、2。找到minor allele frequency（MAF），即两种碱基（如A、T）中出现频率低的那个，以A作为MAF为例，则TT为0，AT为1，AA为2，这样可以突出MAF</li><li>转化为3-bit one hot vector,<script type="math/tex">[1,0,0]^T,[0,1,0]^T,[0,0,1]^T</script>这样可以保持三种向量在空间距离的一致</li><li>转化为2-bit vector,则AA，AT，TT分别编为<script type="math/tex">[1,0]^T,[1,1]^T,[0,1]^T</script>,不需要考虑MAF<br>我们采取第三种方式处理了数据并提供给读者</li></ul><h4 id="具体处理过程"><a href="#具体处理过程" class="headerlink" title="具体处理过程"></a>具体处理过程</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">convert_2bit</span><span class="params">(seq)</span>:</span></span><br><span class="line">    genotypes = np.zeros([<span class="number">6210</span>,<span class="number">2</span>])</span><br><span class="line">    a = seq[<span class="number">1</span>].split(<span class="string">'/'</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">6210</span>):</span><br><span class="line">        <span class="keyword">if</span> seq[<span class="number">4</span>:][i] == a[<span class="number">0</span>] + a[<span class="number">0</span>]:</span><br><span class="line">            genotypes[i] = np.array([<span class="number">0</span>,<span class="number">1</span>])</span><br><span class="line">        <span class="keyword">if</span> seq[<span class="number">4</span>:][i] == a[<span class="number">0</span>] + a[<span class="number">1</span>]:</span><br><span class="line">            genotypes[i] = np.array([<span class="number">1</span>,<span class="number">0</span>])</span><br><span class="line">        <span class="keyword">if</span> seq[<span class="number">4</span>:][i] == a[<span class="number">1</span>] + a[<span class="number">1</span>]:</span><br><span class="line">            genotypes[i] = np.array([<span class="number">1</span>,<span class="number">1</span>])</span><br><span class="line">    genotypes = genotypes.astype(<span class="string">'int'</span>).T</span><br><span class="line">    <span class="keyword">return</span> genotypes</span><br></pre></td></tr></table></figure><p>真实转换时python的转换速度较慢，这里为了展示基本的原理使用了python来演示。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">snps = snps.astype(<span class="string">'str'</span>)</span><br><span class="line">snps.shape</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">convert_2bit(snps[<span class="number">2</span>].astype(<span class="string">'str'</span>))</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">geno_conv = np.ndarray([<span class="number">10000</span>,<span class="number">6210</span>])</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> tqdm(range(<span class="number">5000</span>)):</span><br><span class="line">    geno_conv[i*<span class="number">2</span>:(i+<span class="number">1</span>)*<span class="number">2</span>] = convert_2bit(snps[i+<span class="number">1</span>])</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#查看SNP的大致情况，取前100行（50个位点），前50个样本，</span></span><br><span class="line">fig, ax = plt.subplots(figsize=(<span class="number">20</span>,<span class="number">10</span>))</span><br><span class="line">ax.matshow(geno_conv[:<span class="number">100</span>,:<span class="number">50</span>],cmap = cm.binary_r)</span><br></pre></td></tr></table></figure><p><img src="http://i1.fuimg.com/640680/870c6a096a867529.png" alt="Markdown"></p><h3 id="模型鲁棒性测试"><a href="#模型鲁棒性测试" class="headerlink" title="模型鲁棒性测试"></a>模型鲁棒性测试</h3><h4 id="设计特殊的交叉验证方式"><a href="#设计特殊的交叉验证方式" class="headerlink" title="设计特殊的交叉验证方式"></a>设计特殊的交叉验证方式</h4><p>不同的样本具有关联性，有的样本可能来自同一亲本，而训练集和测试集的划分并不是随机的<br>因此我们可以专门设计交叉验证时数据集的划分方式：</p><ul><li>random</li><li>by female</li><li>by male</li><li>cross sampling</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> method <span class="keyword">in</span> (<span class="string">'random'</span>, <span class="string">'by_female'</span>, <span class="string">'by_male'</span>, <span class="string">'cross'</span>):</span><br><span class="line">    <span class="keyword">with</span> h5py.File(<span class="string">'data/cv_index.%s'</span>%method, <span class="string">'r'</span>) <span class="keyword">as</span> f:</span><br><span class="line">        index_train = f[<span class="string">'0/train'</span>][:]</span><br><span class="line">        index_test = f[<span class="string">'0/test'</span>][:]</span><br><span class="line">    fig, ax = subplots(<span class="number">2</span>, <span class="number">1</span>, figsize=(<span class="number">16</span>, <span class="number">6</span>))</span><br><span class="line">    sampling_table = np.zeros(np.prod(parent_table.shape))</span><br><span class="line">    sampling_table[index_train] = <span class="number">1</span></span><br><span class="line">    sampling_table = np.take(sampling_table, parent_table)</span><br><span class="line">    ax[<span class="number">0</span>].imshow(sampling_table, cmap=cm.Greys)</span><br><span class="line">    ax[<span class="number">0</span>].set_title(<span class="string">'Training samples (%s)'</span>%method)</span><br><span class="line"></span><br><span class="line">    sampling_table = np.zeros(np.prod(parent_table.shape))</span><br><span class="line">    sampling_table[index_test] = <span class="number">1</span></span><br><span class="line">    sampling_table = np.take(sampling_table, parent_table)</span><br><span class="line">    ax[<span class="number">1</span>].imshow(sampling_table, cmap=cm.Greys)</span><br><span class="line">    ax[<span class="number">1</span>].set_title(<span class="string">'Test samples (%s)'</span>%method)</span><br><span class="line">    plt.tight_layout()</span><br></pre></td></tr></table></figure><p>请在jupyter文件中查看相关图片。</p><h3 id="ANOVA加速算法"><a href="#ANOVA加速算法" class="headerlink" title="ANOVA加速算法"></a>ANOVA加速算法</h3><p>思路简要提示：</p><p><img src="http://i1.fuimg.com/640680/ef4e5c183a271656.png" alt="Markdown"></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;This is one of the two course quizzes instruction of &lt;a href=&quot;https://lulab.gitbooks.io/teaching/content/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Bioinformatics basic course in Tsinghua University&lt;/a&gt;. You may also find it &lt;a href=&quot;https://lulab.gitbooks.io/teaching/content/quiz/quiz_exrna/quiz_emaize_tutorial.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The related &lt;a href=&quot;https://github.com/lulab/teaching_book/blob/master/quiz/quiz_emaize/quiz_emaize_tutorial.ipynb&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;jupyter file&lt;/a&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="school work" scheme="https://www.cmwonderland.com/blog/categories/school-work/"/>
    
    
      <category term="machine learning" scheme="https://www.cmwonderland.com/blog/tags/machine-learning/"/>
    
      <category term="python" scheme="https://www.cmwonderland.com/blog/tags/python/"/>
    
      <category term="bioinformatics" scheme="https://www.cmwonderland.com/blog/tags/bioinformatics/"/>
    
      <category term="teaching" scheme="https://www.cmwonderland.com/blog/tags/teaching/"/>
    
      <category term="TA" scheme="https://www.cmwonderland.com/blog/tags/TA/"/>
    
  </entry>
  
  <entry>
    <title>Python Tutorial</title>
    <link href="https://www.cmwonderland.com/blog/2018/10/06/55_python_basics/"/>
    <id>https://www.cmwonderland.com/blog/2018/10/06/55_python_basics/</id>
    <published>2018-10-06T12:03:19.000Z</published>
    <updated>2019-04-23T13:07:13.968Z</updated>
    
    <content type="html"><![CDATA[<p>This is one of the chapter in <a href="https://lulab.gitbooks.io/teaching/content/" target="_blank" rel="noopener">Bioinformatics basic course in Tsinghua University</a>. You may also find it <a href="https://lulab.gitbooks.io/teaching/content/appendix/python_tutorial.html" target="_blank" rel="noopener">here</a></p><p>The related <a href="https://github.com/lulab/teaching_book/blob/master/appendix/python_tutorial.ipynb" target="_blank" rel="noopener">jupyter file</a></p><a id="more"></a><h2 id="Python-Tutorial"><a href="#Python-Tutorial" class="headerlink" title="Python Tutorial"></a>Python Tutorial</h2><p><img src="http://i2.tiimg.com/640680/bd9bf324c62838ea.png" alt="Markdown"></p><h2 id="Install-Anaconda-Python"><a href="#Install-Anaconda-Python" class="headerlink" title="Install Anaconda Python"></a>Install Anaconda Python</h2><p>URL: (<a href="https://www.anaconda.com/download/" target="_blank" rel="noopener">https://www.anaconda.com/download/</a>)</p><ul><li>Easy install of data science packages (binary distribution)</li><li>Package management with </li></ul><p><code>conda</code></p><p><img src="http://i2.tiimg.com/640680/6c673d3d2a99eb69.png" alt="Markdown"></p><p>Install Python packages using conda:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda install h5py</span><br></pre></td></tr></table></figure><p>Update a package to the latest version:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda update h5py</span><br></pre></td></tr></table></figure><p>Install Python packages using pip:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install h5py</span><br></pre></td></tr></table></figure><p>Update a package using pip:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install --upgrade h5py</span><br></pre></td></tr></table></figure><h2 id="Python-language-tips"><a href="#Python-language-tips" class="headerlink" title="Python language tips"></a>Python language tips</h2><h3 id="Compatibility-between-Python-3-x-and-Python-2-x"><a href="#Compatibility-between-Python-3-x-and-Python-2-x" class="headerlink" title="Compatibility between Python 3.x and Python 2.x"></a>Compatibility between Python 3.x and Python 2.x</h3><p><strong>Biggest difference</strong>: print is a function rather than statement in Python 3</p><p>This does not work in Python 3</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">print</span> <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span></span><br></pre></td></tr></table></figure><p><strong>Solution</strong>: use the <code>__future__</code> module</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"><span class="comment"># this works both in Python 2 and Python 3</span></span><br><span class="line">print(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>)</span><br></pre></td></tr></table></figure><p><strong>Second biggest difference</strong>: some package/function names in the standard library are changed</p><p><strong>Python 2</strong> =&gt; <strong>Python 3</strong></p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">cStringIO =&gt; io.StringIO</span><br><span class="line">Queue =&gt; queue</span><br><span class="line">cPickle =&gt; pickle</span><br><span class="line">ConfigParser =&gt; configparser</span><br><span class="line">HTMLParser =&gt; html.parser</span><br><span class="line">SocketServer =&gt; socketserver</span><br><span class="line">SimpleHTTPServer =&gt; http.server</span><br></pre></td></tr></table></figure><p><strong>Solution</strong>: use the <code>six</code> module</p><ul><li>Refer to (<a href="https://docs.python.org/3/library/__future__.html" target="_blank" rel="noopener">https://docs.python.org/3/library/__future__.html</a>) for usage of the <code>__future__</code> module.</li><li>Refer to (<a href="https://pythonhosted.org/six/" target="_blank" rel="noopener">https://pythonhosted.org/six/</a>) for usage of the <code>six</code> module.</li></ul><h3 id="Get-away-from-IndentationError"><a href="#Get-away-from-IndentationError" class="headerlink" title="Get away from IndentationError"></a>Get away from IndentationError</h3><p>Python forces usage of tabs/spaces to indent code</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># use a tab</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">3</span>):</span><br><span class="line">    print(i)</span><br><span class="line"><span class="comment"># use 2 spaces</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">3</span>):</span><br><span class="line">  print(i)</span><br><span class="line"><span class="comment"># use 4 spaces</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">3</span>):</span><br><span class="line">    print(i)</span><br></pre></td></tr></table></figure><p><strong>Best practice</strong>: always use 4 spaces. You can set whether to use spaces(soft tabs) or tabs for indentation.</p><p>In vim editor, use <code>:set list</code> to inspect incorrect number of spaces/tabs.</p><h3 id="Add-Shebang-and-encoding-at-the-beginning-of-executable-scripts"><a href="#Add-Shebang-and-encoding-at-the-beginning-of-executable-scripts" class="headerlink" title="Add Shebang and encoding at the beginning of executable scripts"></a>Add Shebang and encoding at the beginning of executable scripts</h3><p>Create a file named <code>welcome.py</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#! /usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*- coding: UTF-8 -*-</span></span><br><span class="line">print(<span class="string">'welcome to python!'</span>)</span><br></pre></td></tr></table></figure><p>Then set the python script as executable:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">chmod +x welcome.py</span><br></pre></td></tr></table></figure><p>Now you can run the script without specifying the Python interpreter:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./welcome.py</span><br></pre></td></tr></table></figure></p><h3 id="All-variables-functions-classes-are-dynamic-objects"><a href="#All-variables-functions-classes-are-dynamic-objects" class="headerlink" title="All variables, functions, classes are dynamic objects"></a>All variables, functions, classes are dynamic objects</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyClass</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, name)</span>:</span></span><br><span class="line">        self.name = name</span><br><span class="line"><span class="comment"># assign an integer to a</span></span><br><span class="line">a = <span class="number">1</span></span><br><span class="line">print(type(a))</span><br><span class="line"><span class="comment"># assign a string to a</span></span><br><span class="line">a = <span class="string">'abc'</span></span><br><span class="line">print(type(a))</span><br><span class="line"><span class="comment"># assign a function to a</span></span><br><span class="line">a = range</span><br><span class="line">print(type(a))</span><br><span class="line">print(a(<span class="number">10</span>))</span><br><span class="line"><span class="comment"># assign a class to a</span></span><br><span class="line">a = MyClass</span><br><span class="line">print(type(a))</span><br><span class="line">b = a(<span class="string">'myclass'</span>)</span><br><span class="line">print(b.name)</span><br><span class="line"><span class="comment"># assign an instance of a class to a</span></span><br><span class="line">a = MyClass(<span class="string">'myclass'</span>)</span><br><span class="line">print(b.name)</span><br><span class="line"><span class="comment"># get type of a</span></span><br><span class="line">print(type(a))</span><br></pre></td></tr></table></figure><h3 id="All-python-variables-are-pointers-references"><a href="#All-python-variables-are-pointers-references" class="headerlink" title="All python variables are pointers/references"></a>All python variables are pointers/references</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">a = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]</span><br><span class="line">print(<span class="string">'a = '</span>, a)</span><br><span class="line"><span class="comment"># this add another refrence to the list</span></span><br><span class="line">b = a</span><br><span class="line">print(<span class="string">'b = '</span>, b)</span><br><span class="line"><span class="comment"># this will change contents of both a and b</span></span><br><span class="line">b[<span class="number">2</span>] = <span class="number">4</span></span><br><span class="line">print(<span class="string">'a = '</span>, a)</span><br><span class="line">print(<span class="string">'b = '</span>, b)</span><br></pre></td></tr></table></figure><h3 id="Use-deepcopy-if-you-really-want-to-COPY-a-variable"><a href="#Use-deepcopy-if-you-really-want-to-COPY-a-variable" class="headerlink" title="Use deepcopy if you really want to COPY a variable"></a>Use <code>deepcopy</code> if you really want to COPY a variable</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> copy <span class="keyword">import</span> deepcopy</span><br><span class="line">a = &#123;<span class="string">'A'</span>: [<span class="number">1</span>], <span class="string">'B'</span>: [<span class="number">2</span>], <span class="string">'C'</span>: [<span class="number">3</span>]&#125;</span><br><span class="line">print(a)</span><br><span class="line"><span class="comment"># shallow copy</span></span><br><span class="line">b = dict(a)</span><br><span class="line"><span class="comment"># modify elements of b will change contents of a</span></span><br><span class="line">b[<span class="string">'A'</span>].append(<span class="number">2</span>)</span><br><span class="line">print(<span class="string">'a = '</span>, a)</span><br><span class="line">print(<span class="string">'b = '</span>, b)</span><br><span class="line"><span class="comment"># this also does not work</span></span><br><span class="line">c = &#123;k:v <span class="keyword">for</span> k, v <span class="keyword">in</span> a&#125;</span><br><span class="line">c[<span class="string">'A'</span>].append(<span class="number">3</span>)</span><br><span class="line">print(<span class="string">'a = '</span>, a)</span><br><span class="line">print(<span class="string">'c = '</span>, c)</span><br><span class="line"><span class="comment"># recurrently copy every object of a</span></span><br><span class="line">d = deepcopy(a)</span><br><span class="line"><span class="comment"># modify elements of c will not change contents of a</span></span><br><span class="line">d[<span class="string">'A'</span>].append(<span class="number">2</span>)</span><br><span class="line">print(<span class="string">'a = '</span>, a)</span><br><span class="line">print(<span class="string">'d = '</span>, d)</span><br></pre></td></tr></table></figure><h3 id="What-if-I-accidentally-overwrite-my-builtin-functions"><a href="#What-if-I-accidentally-overwrite-my-builtin-functions" class="headerlink" title="What if I accidentally overwrite my builtin functions?"></a>What if I accidentally overwrite my builtin functions?</h3><p>You can refer to (<a href="https://docs.python.org/2/library/functions.html" target="_blank" rel="noopener">https://docs.python.org/2/library/functions.html</a>) for builtin functions in the standard library.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">A = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>]</span><br><span class="line"><span class="comment"># Ops! the builtin function sum is overwritten by a number</span></span><br><span class="line">sum = sum(A)</span><br><span class="line"><span class="comment"># this will raise an error because sum is not a function now</span></span><br><span class="line">print(sum(A))</span><br><span class="line"><span class="comment"># recover the builtin function into the current environment</span></span><br><span class="line"><span class="keyword">from</span> __builtin__ <span class="keyword">import</span> sum</span><br><span class="line"><span class="comment"># this works because sum is a function</span></span><br><span class="line">print(sum(A))</span><br></pre></td></tr></table></figure><p><strong>Note</strong>: in Python 3, you should import from <code>builtins</code> rather than <code>__builtin__</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> builtins <span class="keyword">import</span> sum</span><br></pre></td></tr></table></figure><h3 id="int-is-of-arbitrary-precision-in-Python"><a href="#int-is-of-arbitrary-precision-in-Python" class="headerlink" title="int is of arbitrary precision in Python!"></a><code>int</code> is of arbitrary precision in Python!</h3><p>In Pyhton:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="number">2</span>**<span class="number">10000</span>)</span><br></pre></td></tr></table></figure><p>In R:</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="number">2</span>^<span class="number">10000</span>)</span><br></pre></td></tr></table></figure><h3 id="Easiest-way-to-swap-values-of-two-variables"><a href="#Easiest-way-to-swap-values-of-two-variables" class="headerlink" title="Easiest way to swap values of two variables"></a>Easiest way to swap values of two variables</h3><p>In C/C++:</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> a = <span class="number">1</span>, b = <span class="number">2</span>, t;</span><br><span class="line">t = a;</span><br><span class="line">a = b;</span><br><span class="line">b = t;</span><br></pre></td></tr></table></figure><p>In Python:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">a = <span class="number">1</span></span><br><span class="line">b = <span class="number">2</span></span><br><span class="line">b, a = a, b</span><br><span class="line">print(a, b)</span><br></pre></td></tr></table></figure><h3 id="List-comprehension"><a href="#List-comprehension" class="headerlink" title="List comprehension"></a>List comprehension</h3><p>Use for-loops:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">a = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>):</span><br><span class="line">    a.append(i + <span class="number">10</span>)</span><br><span class="line">print(a)</span><br></pre></td></tr></table></figure><p>Use list comprehension</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">a = [i + <span class="number">10</span> <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>)]</span><br><span class="line">print(a)</span><br></pre></td></tr></table></figure><h3 id="Dict-comprehension"><a href="#Dict-comprehension" class="headerlink" title="Dict comprehension"></a>Dict comprehension</h3><p>Use for-loops:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">a = &#123;&#125;</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>):</span><br><span class="line">    a[i] = chr(ord(<span class="string">'A'</span>) + i) </span><br><span class="line">print(a)</span><br></pre></td></tr></table></figure><p>Use dict comprehension:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">a = &#123;i:chr(ord(<span class="string">'A'</span>) + i) <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>)&#125;</span><br><span class="line">print(a)</span><br></pre></td></tr></table></figure></p><h3 id="For-the-one-liners"><a href="#For-the-one-liners" class="headerlink" title="For the one-liners"></a>For the one-liners</h3><p>Use ‘;’ instead of ‘\n’:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># print the first column of each line</span></span><br><span class="line">python -c <span class="string">'import sys; print("\n".join(line.split("\t")[0] for line in sys.stdin))'</span></span><br></pre></td></tr></table></figure><p>For more examples of one-liners, please refer to (<a href="https://wiki.python.org/moin/Powerful%20Python%20One-Liners" target="_blank" rel="noopener">https://wiki.python.org/moin/Powerful%20Python%20One-Liners</a>).</p><h3 id="Read-from-standard-input"><a href="#Read-from-standard-input" class="headerlink" title="Read from standard input"></a>Read from standard input</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="comment"># read line by line</span></span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</span><br><span class="line">    print(line)</span><br></pre></td></tr></table></figure><h3 id="Order-of-dict-keys-are-NOT-as-you-expected"><a href="#Order-of-dict-keys-are-NOT-as-you-expected" class="headerlink" title="Order of dict keys are NOT as you expected"></a>Order of dict keys are NOT as you expected</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">a = &#123;<span class="string">'A'</span>: <span class="number">1</span>, <span class="string">'B'</span>: <span class="number">2</span>, <span class="string">'C'</span>: <span class="number">3</span>, <span class="string">'D'</span>: <span class="number">4</span>, <span class="string">'E'</span>: <span class="number">5</span>, <span class="string">'F'</span>: <span class="number">6</span>&#125;</span><br><span class="line"><span class="comment"># not in lexicographical order</span></span><br><span class="line">print([key <span class="keyword">for</span> key <span class="keyword">in</span> a])</span><br><span class="line"><span class="comment"># now in lexicographical order</span></span><br><span class="line">print([key <span class="keyword">for</span> key <span class="keyword">in</span> sorted(a)])</span><br></pre></td></tr></table></figure><h3 id="Use-enumerate-to-add-a-number-during-iteration"><a href="#Use-enumerate-to-add-a-number-during-iteration" class="headerlink" title="Use enumerate() to add a number during iteration"></a>Use enumerate() to add a number during iteration</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">A = [<span class="string">'a'</span>, <span class="string">'b'</span>, <span class="string">'c'</span>, <span class="string">'d'</span>]</span><br><span class="line"><span class="keyword">for</span> i, a <span class="keyword">in</span> enumerate(A):</span><br><span class="line">    print(i, a)</span><br></pre></td></tr></table></figure><h3 id="Reverse-a-list"><a href="#Reverse-a-list" class="headerlink" title="Reverse a list"></a>Reverse a list</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># a = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]</span></span><br><span class="line">a = range(<span class="number">10</span>)</span><br><span class="line">print(a)</span><br><span class="line">print(a[::<span class="number">-1</span>])</span><br></pre></td></tr></table></figure><h3 id="Strings-are-immutable-in-Python"><a href="#Strings-are-immutable-in-Python" class="headerlink" title="Strings are immutable in Python"></a>Strings are immutable in Python</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">a = <span class="string">'ABCDF'</span></span><br><span class="line"><span class="comment"># will raise an Error</span></span><br><span class="line">a[<span class="number">4</span>] = <span class="string">'E'</span></span><br><span class="line"><span class="comment"># convert str to bytearray</span></span><br><span class="line">b = bytearray(a)</span><br><span class="line"><span class="comment"># bytearray are mutable</span></span><br><span class="line">b[<span class="number">4</span>] = <span class="string">'E'</span></span><br><span class="line"><span class="comment"># convert bytearray to str</span></span><br><span class="line">print(str(b))</span><br></pre></td></tr></table></figure><h3 id="tuples-are-hashable-while-lists-are-not-hashable"><a href="#tuples-are-hashable-while-lists-are-not-hashable" class="headerlink" title="tuples are hashable while lists are not hashable"></a>tuples are hashable while lists are not hashable</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># create dict using tuples as keys</span></span><br><span class="line">d = &#123;</span><br><span class="line">    (<span class="string">'chr1'</span>, <span class="number">1000</span>, <span class="number">2000</span>): <span class="string">'featureA'</span>,</span><br><span class="line">    (<span class="string">'chr1'</span>, <span class="number">2000</span>, <span class="number">3000</span>): <span class="string">'featureB'</span>,</span><br><span class="line">    (<span class="string">'chr1'</span>, <span class="number">3000</span>, <span class="number">4000</span>): <span class="string">'featureC'</span>,</span><br><span class="line">    (<span class="string">'chr1'</span>, <span class="number">4000</span>, <span class="number">5000</span>): <span class="string">'featureD'</span>,</span><br><span class="line">    (<span class="string">'chr1'</span>, <span class="number">5000</span>, <span class="number">6000</span>): <span class="string">'featureE'</span>,</span><br><span class="line">    (<span class="string">'chr1'</span>, <span class="number">6000</span>, <span class="number">7000</span>): <span class="string">'featureF'</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment"># query the dict using tuples</span></span><br><span class="line">print(d[(<span class="string">'chr1'</span>, <span class="number">3000</span>, <span class="number">4000</span>)])</span><br><span class="line">print(d[(<span class="string">'chr1'</span>, <span class="number">6000</span>, <span class="number">7000</span>)])</span><br><span class="line"><span class="comment"># will raise an error</span></span><br><span class="line">d = &#123;[<span class="string">'chr1'</span>, <span class="number">1000</span>, <span class="number">2000</span>]: <span class="string">'featureA'</span>&#125;</span><br></pre></td></tr></table></figure><h3 id="Use-itertools"><a href="#Use-itertools" class="headerlink" title="Use itertools"></a>Use itertools</h3><p>Nested loops in a more concise way:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">A = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]</span><br><span class="line">B = [<span class="string">'a'</span>, <span class="string">'b'</span>, <span class="string">'c'</span>]</span><br><span class="line">C = [<span class="string">'i'</span>, <span class="string">'j'</span>, <span class="string">'k'</span>]</span><br><span class="line">D = [<span class="string">'x'</span>, <span class="string">'y'</span>, <span class="string">'z'</span>]</span><br><span class="line"><span class="comment"># Use nested for-loops</span></span><br><span class="line"><span class="keyword">for</span> a <span class="keyword">in</span> A:</span><br><span class="line">    <span class="keyword">for</span> b <span class="keyword">in</span> B:</span><br><span class="line">        <span class="keyword">for</span> c <span class="keyword">in</span> C:</span><br><span class="line">            <span class="keyword">for</span> d <span class="keyword">in</span> D:</span><br><span class="line">                print(a, b, c, d)</span><br><span class="line"><span class="comment"># Use itertools.product</span></span><br><span class="line"><span class="keyword">import</span> itertools</span><br><span class="line"><span class="keyword">for</span> a, b, c, d <span class="keyword">in</span> itertools.product(A, B, C, D):</span><br><span class="line">    print(a, b, c, d)</span><br></pre></td></tr></table></figure><p>Get all combinations of a list:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">A = [<span class="string">'A'</span>, <span class="string">'B'</span>, <span class="string">'C'</span>, <span class="string">'D'</span>]</span><br><span class="line"><span class="comment"># Use itertools.combinations</span></span><br><span class="line"><span class="keyword">import</span> itertools</span><br><span class="line"><span class="keyword">for</span> a, b, c <span class="keyword">in</span> itertools.combinations(A, <span class="number">3</span>):</span><br><span class="line">    print(a, b, c)</span><br></pre></td></tr></table></figure><h3 id="Convert-iterables-to-lists"><a href="#Convert-iterables-to-lists" class="headerlink" title="Convert iterables to lists"></a>Convert iterables to lists</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> itertools</span><br><span class="line">A = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]</span><br><span class="line">B = [<span class="string">'a'</span>, <span class="string">'b'</span>, <span class="string">'c'</span>]</span><br><span class="line">a = itertools.product(A, B)</span><br><span class="line"><span class="comment"># a is a iterable rather than a list</span></span><br><span class="line">print(a)</span><br><span class="line"><span class="comment"># a is a list now</span></span><br><span class="line">a = list(a)</span><br><span class="line">print(a)</span><br></pre></td></tr></table></figure><h3 id="Use-the-zip-function-to-transpose-nested-lists-tuples-iterables"><a href="#Use-the-zip-function-to-transpose-nested-lists-tuples-iterables" class="headerlink" title="Use the zip() function to transpose nested lists/tuples/iterables"></a>Use the zip() function to transpose nested lists/tuples/iterables</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">records = [</span><br><span class="line">    (<span class="string">'chr1'</span>, <span class="number">1000</span>, <span class="number">2000</span>),</span><br><span class="line">    (<span class="string">'chr1'</span>, <span class="number">2000</span>, <span class="number">3000</span>),</span><br><span class="line">    (<span class="string">'chr1'</span>, <span class="number">3000</span>, <span class="number">4000</span>),</span><br><span class="line">    (<span class="string">'chr1'</span>, <span class="number">4000</span>, <span class="number">5000</span>),</span><br><span class="line">    (<span class="string">'chr1'</span>, <span class="number">5000</span>, <span class="number">6000</span>),</span><br><span class="line">    (<span class="string">'chr1'</span>, <span class="number">6000</span>, <span class="number">7000</span>)</span><br><span class="line">]</span><br><span class="line"><span class="comment"># iterate by rows</span></span><br><span class="line"><span class="keyword">for</span> chrom, start, end <span class="keyword">in</span> records:</span><br><span class="line">    print(chrom, start, end)</span><br><span class="line"><span class="comment"># extract columns</span></span><br><span class="line">chroms, starts, ends = zip(*records)</span><br><span class="line"><span class="comment"># build records from columns</span></span><br><span class="line"><span class="comment"># now records2 is the same as records</span></span><br><span class="line">records2 = zip(chroms, starts, ends)</span><br><span class="line">print(records)</span><br></pre></td></tr></table></figure><h3 id="Global-and-local-variables"><a href="#Global-and-local-variables" class="headerlink" title="Global and local variables"></a>Global and local variables</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># a is global</span></span><br><span class="line">a = <span class="number">1</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">print_local</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="comment"># a is local</span></span><br><span class="line">    a = <span class="number">2</span></span><br><span class="line">    print(a)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">print_global</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="comment"># a is global</span></span><br><span class="line">    <span class="keyword">global</span> a</span><br><span class="line">    a = <span class="number">2</span></span><br><span class="line">    print(a)</span><br><span class="line"></span><br><span class="line"><span class="comment"># print global variable</span></span><br><span class="line">print(a)</span><br><span class="line"><span class="comment"># print local variable from function</span></span><br><span class="line">print_local()</span><br><span class="line"><span class="comment"># a is unchanged</span></span><br><span class="line">print(a)</span><br><span class="line"><span class="comment"># change and print global from function</span></span><br><span class="line">print_global()</span><br><span class="line"><span class="comment"># a is changed</span></span><br><span class="line">print(a)</span><br></pre></td></tr></table></figure><h3 id="Use-defaultdict"><a href="#Use-defaultdict" class="headerlink" title="Use defaultdict"></a>Use defaultdict</h3><p>Use <code>dict</code>:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">d = &#123;&#125;</span><br><span class="line">d[<span class="string">'a'</span>] = []</span><br><span class="line">d[<span class="string">'b'</span>] = []</span><br><span class="line">d[<span class="string">'c'</span>] = []</span><br><span class="line"><span class="comment"># extend list with new elements</span></span><br><span class="line">d[<span class="string">'a'</span>] += [<span class="number">1</span>, <span class="number">2</span>]</span><br><span class="line">d[<span class="string">'b'</span>] += [<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>]</span><br><span class="line">d[<span class="string">'c'</span>] += [<span class="number">6</span>]</span><br><span class="line"><span class="keyword">for</span> key, val <span class="keyword">in</span> d.items():</span><br><span class="line">    print(key, val)</span><br></pre></td></tr></table></figure><p>Use <code>defaultdict</code>:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> defaultdict</span><br><span class="line"><span class="comment"># a new list is created automatically when new elements are added</span></span><br><span class="line">d = defaultdict(list)</span><br><span class="line"><span class="comment"># extend list with new elements</span></span><br><span class="line">d[<span class="string">'a'</span>] += [<span class="number">1</span>, <span class="number">2</span>]</span><br><span class="line">d[<span class="string">'b'</span>] += [<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>]</span><br><span class="line">d[<span class="string">'c'</span>] += [<span class="number">6</span>]</span><br><span class="line"><span class="keyword">for</span> key, val <span class="keyword">in</span> d.items():</span><br><span class="line">    print(key, val)</span><br></pre></td></tr></table></figure><h3 id="Use-generators"><a href="#Use-generators" class="headerlink" title="Use generators"></a>Use generators</h3><p>Example: read a large FASTA file</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">append_extra_line</span><span class="params">(f)</span>:</span></span><br><span class="line">    <span class="string">"""Yield an empty line after the last line in the file</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> f:</span><br><span class="line">        <span class="keyword">yield</span> line</span><br><span class="line">    <span class="keyword">yield</span> <span class="string">''</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">read_fasta</span><span class="params">(filename)</span>:</span></span><br><span class="line">    <span class="keyword">with</span> open(filename, <span class="string">'r'</span>) <span class="keyword">as</span> f:</span><br><span class="line">        name = <span class="keyword">None</span></span><br><span class="line">        seq = <span class="string">''</span></span><br><span class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> append_extra_line(f):</span><br><span class="line">            <span class="keyword">if</span> line.startswith(<span class="string">'&gt;'</span>) <span class="keyword">or</span> (len(line) == <span class="number">0</span>):</span><br><span class="line">                <span class="keyword">if</span> (len(seq) &gt; <span class="number">0</span>) <span class="keyword">and</span> (name <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>):</span><br><span class="line">                    <span class="keyword">yield</span> (name, seq)</span><br><span class="line">                <span class="keyword">if</span> line.startswith(<span class="string">'&gt;'</span>):</span><br><span class="line">                    name = line.strip()[<span class="number">1</span>:].split()[<span class="number">0</span>]</span><br><span class="line">                    seq = <span class="string">''</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">if</span> name <span class="keyword">is</span> <span class="keyword">None</span>:</span><br><span class="line">                    <span class="keyword">raise</span> ValueError(<span class="string">'the first line does not start with "&gt;"'</span>)</span><br><span class="line">                seq += line.strip()</span><br><span class="line"><span class="comment"># print sequence name and length of each </span></span><br><span class="line"><span class="keyword">for</span> name, seq <span class="keyword">in</span> read_fasta(<span class="string">'test.fa'</span>):</span><br><span class="line">    print(name, len(seq))</span><br></pre></td></tr></table></figure><h3 id="Turn-off-annoying-KeyboardInterrupt-and-BrokenPipe-Error"><a href="#Turn-off-annoying-KeyboardInterrupt-and-BrokenPipe-Error" class="headerlink" title="Turn off annoying KeyboardInterrupt and BrokenPipe Error"></a>Turn off annoying KeyboardInterrupt and BrokenPipe Error</h3><p>Without exception handling (press Ctrl+C):</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line">time.sleep(<span class="number">300</span>)</span><br></pre></td></tr></table></figure><p>With exception handling (press Ctrl+C):</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> errno</span><br><span class="line"></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    time.sleep(<span class="number">300</span>)</span><br><span class="line"><span class="keyword">except</span> KeyboardInterrupt:</span><br><span class="line">    sys.exit(<span class="number">1</span>)</span><br><span class="line"><span class="keyword">except</span> OSError <span class="keyword">as</span> e:</span><br><span class="line">    <span class="keyword">if</span> e.errno == errno.EPIPE:</span><br><span class="line">        sys.exit(-e.errno)</span><br></pre></td></tr></table></figure><h3 id="Class-and-instance-variables"><a href="#Class-and-instance-variables" class="headerlink" title="Class and instance variables"></a>Class and instance variables</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyClass</span><span class="params">()</span>:</span></span><br><span class="line">    name = <span class="string">'class_name'</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, name)</span>:</span></span><br><span class="line">        self.name = name</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">change_name</span><span class="params">(self, name)</span>:</span></span><br><span class="line">        self.name = name</span><br><span class="line"></span><br><span class="line"><span class="comment"># print class variable</span></span><br><span class="line">print(MyClass.name)</span><br><span class="line"><span class="comment"># create an instance from MyClass</span></span><br><span class="line">a = MyClass(<span class="string">'instance_name'</span>)</span><br><span class="line"><span class="comment"># print instance name</span></span><br><span class="line">print(a.name)</span><br><span class="line"><span class="comment"># change instance name</span></span><br><span class="line">a.change_name(<span class="string">'instance_new_name'</span>)</span><br><span class="line">print(a.name)</span><br><span class="line">print(MyClass.name)</span><br><span class="line"><span class="comment"># change class name</span></span><br><span class="line">MyClass.name = <span class="string">'class_new_name'</span></span><br><span class="line">print(a.name)</span><br><span class="line">print(MyClass.name)</span><br></pre></td></tr></table></figure><h2 id="Useful-Python-packages-for-data-analysis"><a href="#Useful-Python-packages-for-data-analysis" class="headerlink" title="Useful Python packages for data analysis"></a>Useful Python packages for data analysis</h2><h3 id="Browser-based-interactive-programming-in-Python-jupyter"><a href="#Browser-based-interactive-programming-in-Python-jupyter" class="headerlink" title="Browser-based interactive programming in Python: jupyter"></a>Browser-based interactive programming in Python: jupyter</h3><p>URL: (<a href="http://jupyter.org/" target="_blank" rel="noopener">http://jupyter.org/</a>)</p><p><strong>Start jupyter notebook</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jupyter notebook --no-browser</span><br></pre></td></tr></table></figure><p><strong>Jupyter notebooks manager</strong></p><p><img src="http://i2.tiimg.com/640680/883fecd2e4eb8e5b.png" alt="Markdown"></p><p><strong>Jupyter process manager</strong></p><p><img src="http://i2.tiimg.com/640680/118f51c0d90051c8.png" alt="Markdown"></p><p><strong>Jupyter notebook</strong></p><p><img src="http://i2.tiimg.com/640680/98f28eb528ec01b8.png" alt="Markdown"></p><p><strong>Integrate with matplotlib</strong></p><p><img src="http://i2.tiimg.com/640680/88d0bef8d04a30c6.png" alt="Markdown"></p><p><strong>Browser-based text editor</strong></p><p><img src="http://i2.tiimg.com/640680/3ff9089547169bd3.png" alt="Markdown"></p><p><strong>Browser-based terminal</strong></p><p><img src="http://i2.tiimg.com/640680/782990d4fc31ded7.png" alt="Markdown"></p><p><strong>Display image</strong></p><p><img src="http://i2.tiimg.com/640680/0bb4e663938fe506.png" alt="Markdown"></p><p><strong>Display dataframe</strong></p><p><img src="http://i2.tiimg.com/640680/f3d01d72d42e8579.png" alt="Markdown"></p><p><strong>Display audio</strong></p><p><img src="http://i2.tiimg.com/640680/56c5bcb9364c6462.png" alt="Markdown"></p><p><strong>Embedded markdown</strong></p><p><img src="http://i2.tiimg.com/640680/e917186572eb56a1.png" alt="Markdown"></p><h3 id="Python-packages-for-scientific-computing"><a href="#Python-packages-for-scientific-computing" class="headerlink" title="Python packages for scientific computing"></a>Python packages for scientific computing</h3><p><img src="http://i2.tiimg.com/640680/6a9c55b2916eea12.jpg" alt="Markdown"></p><h3 id="Vector-arithmetics-numpy"><a href="#Vector-arithmetics-numpy" class="headerlink" title="Vector arithmetics: numpy"></a>Vector arithmetics: numpy</h3><p>URL: (<a href="http://www.numpy.org/" target="_blank" rel="noopener">http://www.numpy.org/</a>)</p><p>Example:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="comment"># create an empty matrix of shape (5, 4)</span></span><br><span class="line">X = np.zeros((<span class="number">5</span>, <span class="number">4</span>), dtype=np.int32)</span><br><span class="line"><span class="comment"># create an array of length 5: [0, 1, 2, 3, 4]</span></span><br><span class="line">y = np.arange(<span class="number">5</span>)</span><br><span class="line"><span class="comment"># create an array of length 4: [0, 1, 2, 3]</span></span><br><span class="line">z = np.arange(<span class="number">4</span>)</span><br><span class="line"><span class="comment"># set Row 1 to [0, 1, 2, 3]</span></span><br><span class="line">X[<span class="number">0</span>] = np.arange(<span class="number">4</span>)</span><br><span class="line"><span class="comment"># set Row 2 to [1, 1, 1, 1]</span></span><br><span class="line">X[<span class="number">1</span>] = <span class="number">1</span></span><br><span class="line"><span class="comment"># add 1 to all elements</span></span><br><span class="line">X += <span class="number">1</span></span><br><span class="line"><span class="comment"># add y to each row of X</span></span><br><span class="line">X += y.reshape((<span class="number">-1</span>, <span class="number">1</span>))</span><br><span class="line"><span class="comment"># add z to each column of X</span></span><br><span class="line">X += z.reshape((<span class="number">1</span>, <span class="number">-1</span>))</span><br><span class="line"><span class="comment"># get row sums =&gt; </span></span><br><span class="line">row_sums = X.sum(axis=<span class="number">1</span>)</span><br><span class="line"><span class="comment"># get column sums</span></span><br><span class="line">col_sums = X.sum(axis=<span class="number">0</span>)</span><br><span class="line"><span class="comment"># matrix multiplication</span></span><br><span class="line">A = X.dot(X.T)</span><br><span class="line"><span class="comment"># save matrix to text file</span></span><br><span class="line">np.savetxt(<span class="string">'data.txt'</span>, A)</span><br></pre></td></tr></table></figure><h3 id="Numerical-analysis-probability-distribution-signal-processing-etc-scipy"><a href="#Numerical-analysis-probability-distribution-signal-processing-etc-scipy" class="headerlink" title="Numerical analysis (probability distribution, signal processing, etc.): scipy"></a>Numerical analysis (probability distribution, signal processing, etc.): scipy</h3><p>URL: (<a href="https://www.scipy.org/" target="_blank" rel="noopener">https://www.scipy.org/</a>)</p><p>scipy.stats contains a large number probability distributions:<br><img src="http://i2.tiimg.com/640680/7f5bc15337bf554a.png" alt="Markdown"></p><p>Unified interface for all probability distributions:<br><img src="http://i2.tiimg.com/640680/b2b4f50de382d817.png" alt="Markdown"></p><h3 id="Just-in-time-JIT-compiler-for-vector-arithmetics"><a href="#Just-in-time-JIT-compiler-for-vector-arithmetics" class="headerlink" title="Just-in-time (JIT) compiler for vector arithmetics"></a>Just-in-time (JIT) compiler for vector arithmetics</h3><p>URL: (<a href="https://numba.pydata.org/" target="_blank" rel="noopener">https://numba.pydata.org/</a>)</p><p>Compile python for-loops to native code to achive similar performance to C/C++ code.<br>Example:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> numba <span class="keyword">import</span> jit</span><br><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> arange</span><br><span class="line"></span><br><span class="line"><span class="comment"># jit decorator tells Numba to compile this function.</span></span><br><span class="line"><span class="comment"># The argument types will be inferred by Numba when function is called.</span></span><br><span class="line"><span class="meta">@jit</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sum2d</span><span class="params">(arr)</span>:</span></span><br><span class="line">    M, N = arr.shape</span><br><span class="line">    result = <span class="number">0.0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(M):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(N):</span><br><span class="line">            result += arr[i,j]</span><br><span class="line">    <span class="keyword">return</span> result</span><br><span class="line"></span><br><span class="line">a = arange(<span class="number">9</span>).reshape(<span class="number">3</span>,<span class="number">3</span>)</span><br><span class="line">print(sum2d(a))</span><br></pre></td></tr></table></figure><h3 id="Library-for-symbolic-computation-sympy"><a href="#Library-for-symbolic-computation-sympy" class="headerlink" title="Library for symbolic computation: sympy"></a>Library for symbolic computation: sympy</h3><p>URL: (<a href="http://www.sympy.org/en/index.html" target="_blank" rel="noopener">http://www.sympy.org/en/index.html</a>)</p><p><img src="http://i2.tiimg.com/640680/0533f1359890e8ed.png" alt="Markdown"></p><h3 id="Operation-on-data-frames-pandas"><a href="#Operation-on-data-frames-pandas" class="headerlink" title="Operation on data frames: pandas"></a>Operation on data frames: pandas</h3><p>URL: (<a href="http://pandas.pydata.org/pandas-docs/stable/" target="_blank" rel="noopener">http://pandas.pydata.org/pandas-docs/stable/</a>)</p><p>Example:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="comment"># read a bed file</span></span><br><span class="line">genes = pd.read_table(<span class="string">'gene.bed'</span>, header=<span class="keyword">None</span>, sep=<span class="string">'\t'</span>,</span><br><span class="line">                     names=(<span class="string">'chrom'</span>, <span class="string">'start'</span>, <span class="string">'end'</span>, <span class="string">'gene_id'</span>, <span class="string">'score'</span>, <span class="string">'strand'</span>, <span class="string">'biotype'</span>))</span><br><span class="line"><span class="comment"># get all gene IDs</span></span><br><span class="line">gene_ids = genes[<span class="string">'gene_id'</span>]</span><br><span class="line"><span class="comment"># set gene_id as index</span></span><br><span class="line">genes.index = genes[<span class="string">'gene_id'</span>]</span><br><span class="line"><span class="comment"># get row with given gene_id</span></span><br><span class="line">gene = genes.loc[<span class="string">'ENSG00000212325.1'</span>]</span><br><span class="line"><span class="comment"># get rows with biotype = 'protein_coding'</span></span><br><span class="line">genes_selected = genes[genes[<span class="string">'biotype'</span>] == <span class="string">'protein_coding'</span>]]</span><br><span class="line"><span class="comment"># get protein coding genes in chr1</span></span><br><span class="line">genes_selected = genes.query(<span class="string">'(biotype == "protein_coding") and (chrom == "chr1")'</span>)</span><br><span class="line"><span class="comment"># count genes for each biotype</span></span><br><span class="line">biotype_counts = genes.groupby(<span class="string">'biotype'</span>)[<span class="string">'gene_id'</span>].count()</span><br><span class="line"><span class="comment"># add a column for gene length</span></span><br><span class="line">genes[<span class="string">'length'</span>] = genes[<span class="string">'end'</span>] - genes[<span class="string">'start'</span>]</span><br><span class="line"><span class="comment"># calculate average gene length for each chromosome and biotype</span></span><br><span class="line">length_table = genes.pivot_table(values=<span class="string">'length'</span>, index=<span class="string">'biotype'</span>, columns=<span class="string">'chrom'</span>)</span><br><span class="line"><span class="comment"># save DataFrame to Excel file</span></span><br><span class="line">length_table.to_excel(<span class="string">'length_table.xlsx'</span>)</span><br></pre></td></tr></table></figure><h3 id="Basic-graphics-and-plotting-matplotlib"><a href="#Basic-graphics-and-plotting-matplotlib" class="headerlink" title="Basic graphics and plotting: matplotlib"></a>Basic graphics and plotting: matplotlib</h3><p>URL: (<a href="https://matplotlib.org/contents.html" target="_blank" rel="noopener">https://matplotlib.org/contents.html</a>)</p><p><img src="http://i2.tiimg.com/640680/73c9ac2564d70838.png" alt="Markdown"></p><h3 id="Statistical-data-visualization-seaborn"><a href="#Statistical-data-visualization-seaborn" class="headerlink" title="Statistical data visualization: seaborn"></a>Statistical data visualization: seaborn</h3><p>URL: (<a href="https://seaborn.pydata.org/" target="_blank" rel="noopener">https://seaborn.pydata.org/</a>)</p><p><img src="http://i2.tiimg.com/640680/39a71f7469439ab1.png" alt="Markdown"></p><h3 id="Interactive-programming-in-Python-ipython"><a href="#Interactive-programming-in-Python-ipython" class="headerlink" title="Interactive programming in Python: ipython"></a>Interactive programming in Python: ipython</h3><p>URL: (<a href="http://ipython.org/ipython-doc/stable/index.html" target="_blank" rel="noopener">http://ipython.org/ipython-doc/stable/index.html</a>)</p><p><img src="http://i2.tiimg.com/640680/0bec0a9639a5c1e2.png" alt="Markdown"></p><h3 id="Statistical-tests-statsmodels"><a href="#Statistical-tests-statsmodels" class="headerlink" title="Statistical tests: statsmodels"></a>Statistical tests: statsmodels</h3><p>URL: (<a href="https://www.statsmodels.org/stable/index.html" target="_blank" rel="noopener">https://www.statsmodels.org/stable/index.html</a>)</p><p><img src="http://i2.tiimg.com/640680/68736b715f5d433b.png" alt="Markdown"></p><h3 id="Machine-learning-algorithms-scikit-learn"><a href="#Machine-learning-algorithms-scikit-learn" class="headerlink" title="Machine learning algorithms: scikit-learn"></a>Machine learning algorithms: scikit-learn</h3><p>URL: (<a href="http://scikit-learn.org/" target="_blank" rel="noopener">http://scikit-learn.org/</a>)</p><p><img src="http://i2.tiimg.com/640680/bc36e9b169826b32.png" alt="Markdown"></p><p>Example:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> make_classification</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> roc_auc_score, accuracy_score</span><br><span class="line"></span><br><span class="line"><span class="comment"># generate ramdom data</span></span><br><span class="line">X, y = make_classification(n_samples=<span class="number">1000</span>, n_classes=<span class="number">2</span>, n_features=<span class="number">10</span>)</span><br><span class="line"><span class="comment"># split dataset into training and test dataset</span></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.2</span>)</span><br><span class="line"><span class="comment"># create an classifier object</span></span><br><span class="line">model = LogisticRegression()</span><br><span class="line"><span class="comment"># training the classifier</span></span><br><span class="line">model.fit(X_train, y_train)</span><br><span class="line"><span class="comment"># predict outcomes on the test dataset</span></span><br><span class="line">y_pred = model.predict(X_test)</span><br><span class="line"><span class="comment"># evalualte the classification performance</span></span><br><span class="line">print(<span class="string">'roc_auc_score = %f'</span>%roc_auc_score(y_test, y_pred))</span><br><span class="line">print(<span class="string">'accuracy_score = %f'</span>%accuracy_score(y_test, y_pred))</span><br></pre></td></tr></table></figure><h3 id="Natural-language-analysis-gensim"><a href="#Natural-language-analysis-gensim" class="headerlink" title="Natural language analysis: gensim"></a>Natural language analysis: gensim</h3><p>URL: (<a href="https://radimrehurek.com/gensim/" target="_blank" rel="noopener">https://radimrehurek.com/gensim/</a>)</p><h3 id="HTTP-library-requests"><a href="#HTTP-library-requests" class="headerlink" title="HTTP library: requests"></a>HTTP library: requests</h3><p>URL: (<a href="http://docs.python-requests.org/en/master/" target="_blank" rel="noopener">http://docs.python-requests.org/en/master/</a>)</p><p><img src="http://i2.tiimg.com/640680/2360c5310673162a.png" alt="Markdown"></p><h3 id="Lightweight-Web-framework-flask"><a href="#Lightweight-Web-framework-flask" class="headerlink" title="Lightweight Web framework: flask"></a>Lightweight Web framework: flask</h3><p>URL: (<a href="http://flask.pocoo.org/" target="_blank" rel="noopener">http://flask.pocoo.org/</a>)</p><p><img src="http://i2.tiimg.com/640680/186cb62c6e00df0e.png" alt="Markdown"></p><h3 id="Deep-learning-framework-tensorflow"><a href="#Deep-learning-framework-tensorflow" class="headerlink" title="Deep learning framework: tensorflow"></a>Deep learning framework: tensorflow</h3><p>URL: (<a href="http://tensorflow.org/" target="_blank" rel="noopener">http://tensorflow.org/</a>)</p><h3 id="High-level-deep-learning-framework-keras"><a href="#High-level-deep-learning-framework-keras" class="headerlink" title="High-level deep learning framework: keras"></a>High-level deep learning framework: keras</h3><p>URL: (<a href="https://keras.io/" target="_blank" rel="noopener">https://keras.io/</a>)</p><h3 id="Operation-on-sequence-and-alignment-formats-biopython"><a href="#Operation-on-sequence-and-alignment-formats-biopython" class="headerlink" title="Operation on sequence and alignment formats: biopython"></a>Operation on sequence and alignment formats: biopython</h3><p>URL: (<a href="http://biopython.org/" target="_blank" rel="noopener">http://biopython.org/</a>)</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> Bio <span class="keyword">import</span> SeqIO</span><br><span class="line"><span class="keyword">for</span> record <span class="keyword">in</span> SeqIO.parse(<span class="string">'test.fa'</span>, <span class="string">'fasta'</span>):</span><br><span class="line">    print(record.id, len(record.seq))</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> Bio <span class="keyword">import</span> SeqIO</span><br><span class="line"><span class="keyword">from</span> Bio.Seq <span class="keyword">import</span> Seq</span><br><span class="line"><span class="keyword">from</span> Bio.SeqRecord <span class="keyword">import</span> SeqRecord</span><br><span class="line">sequences = [</span><br><span class="line">    SeqRecord(Seq(<span class="string">'ACCGGTATCTATATCCCCGAGAGGAATGGGTCAGACATGGACCTAC'</span>), id=<span class="string">'A'</span>, description=<span class="string">''</span>),</span><br><span class="line">    SeqRecord(Seq(<span class="string">'TTACAATGTGGCAGTGAACGCGTGACAATCCTCCCCGTTGGACAT'</span>), id=<span class="string">'B'</span>, description=<span class="string">''</span>),</span><br><span class="line">    SeqRecord(Seq(<span class="string">'CAAAGCTGCATCGAATTGTCGAGACAACACTAGATTTAAGCGCA'</span>), id=<span class="string">'C'</span>, description=<span class="string">''</span>),</span><br><span class="line">    SeqRecord(Seq(<span class="string">'CGCCCGCGAGGGCAATCAGGACGGATTTACGGAT'</span>), id=<span class="string">'D'</span>, description=<span class="string">''</span>),</span><br><span class="line">    SeqRecord(Seq(<span class="string">'CCGCCCACGCTCCCGTTTTCTTCCATACCTGTCC'</span>), id=<span class="string">'E'</span>, description=<span class="string">''</span>)</span><br><span class="line">]</span><br><span class="line"><span class="keyword">with</span> open(<span class="string">'test_out.fa'</span>, <span class="string">'w'</span>) <span class="keyword">as</span> f:</span><br><span class="line">    SeqIO.write(sequences, f, <span class="string">'fasta'</span>)</span><br></pre></td></tr></table></figure><h3 id="Operation-on-genomic-formats-BigWig-etc-bx-python"><a href="#Operation-on-genomic-formats-BigWig-etc-bx-python" class="headerlink" title="Operation on genomic formats (BigWig,etc.): bx-python"></a>Operation on genomic formats (BigWig,etc.): bx-python</h3><h3 id="Operation-on-HDF5-files-h5py"><a href="#Operation-on-HDF5-files-h5py" class="headerlink" title="Operation on HDF5 files: h5py"></a>Operation on HDF5 files: h5py</h3><p>URL: (<a href="https://www.h5py.org/" target="_blank" rel="noopener">https://www.h5py.org/</a>)</p><p>Save data to an HDF5 file</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> h5py</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="comment"># generate data</span></span><br><span class="line">chroms = [<span class="string">'chr1'</span>, <span class="string">'chr2'</span>, <span class="string">'chr3'</span>]</span><br><span class="line">chrom_sizes = &#123;</span><br><span class="line">    <span class="string">'chr1'</span>: <span class="number">15000</span>,</span><br><span class="line">    <span class="string">'chr2'</span>: <span class="number">12000</span>,</span><br><span class="line">    <span class="string">'chr3'</span>: <span class="number">11000</span></span><br><span class="line">&#125;</span><br><span class="line">coverage = &#123;&#125;</span><br><span class="line">counts = &#123;&#125;</span><br><span class="line"><span class="keyword">for</span> chrom, size <span class="keyword">in</span> chrom_sizes.items():</span><br><span class="line">    coverage[chrom] = np.random.randint(<span class="number">10</span>, <span class="number">1000</span>, size=size)</span><br><span class="line">    counts[chrom] = np.random.randint(<span class="number">1000</span>, size=size)%coverage[chrom]</span><br><span class="line"><span class="comment"># save data to an HDF5 file</span></span><br><span class="line"><span class="keyword">with</span> h5py.File(<span class="string">'dataset.h5'</span>, <span class="string">'w'</span>) <span class="keyword">as</span> f:</span><br><span class="line">    <span class="keyword">for</span> chrom <span class="keyword">in</span> chrom_sizes:</span><br><span class="line">        g = f.create_group(chrom)</span><br><span class="line">        g.create_dataset(<span class="string">'coverage'</span>, data=coverage[chrom])</span><br><span class="line">        g.create_dataset(<span class="string">'counts'</span>, data=counts[chrom])</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">h5ls -r dataset.h5</span><br></pre></td></tr></table></figure><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">/                        Group</span><br><span class="line">/chr1                    Group</span><br><span class="line">/chr1/counts             Dataset &#123;15000&#125;</span><br><span class="line">/chr1/coverage           Dataset &#123;15000&#125;</span><br><span class="line">/chr2                    Group</span><br><span class="line">/chr2/counts             Dataset &#123;12000&#125;</span><br><span class="line">/chr2/coverage           Dataset &#123;12000&#125;</span><br><span class="line">/chr3                    Group</span><br><span class="line">/chr3/counts             Dataset &#123;11000&#125;</span><br><span class="line">/chr3/coverage           Dataset &#123;11000&#125;</span><br></pre></td></tr></table></figure><p>Read data from an HDF file:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> h5py</span><br><span class="line"><span class="comment"># read data from an HDF5 file</span></span><br><span class="line"><span class="keyword">with</span> h5py.File(<span class="string">'dataset.h5'</span>, <span class="string">'r'</span>) <span class="keyword">as</span> f:</span><br><span class="line">    coverage = &#123;&#125;</span><br><span class="line">    counts = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> chrom <span class="keyword">in</span> f.keys():</span><br><span class="line">        coverage[chrom] = f[chrom + <span class="string">'/coverage'</span>][:]</span><br><span class="line">        counts[chrom] = f[chrom + <span class="string">'/counts'</span>][:]</span><br></pre></td></tr></table></figure><h3 id="Mixed-C-C-and-python-programming-cython"><a href="#Mixed-C-C-and-python-programming-cython" class="headerlink" title="Mixed C/C++ and python programming: cython"></a>Mixed C/C++ and python programming: cython</h3><p>URL: (<a href="http://cython.org/" target="_blank" rel="noopener">http://cython.org/</a>)</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">cimport numpy <span class="keyword">as</span> np</span><br><span class="line">cimport cython</span><br><span class="line"><span class="keyword">from</span> cython.parallel <span class="keyword">import</span> prange</span><br><span class="line"><span class="keyword">from</span> cython.parallel cimport parallel</span><br><span class="line">cimport openmp</span><br><span class="line"></span><br><span class="line"><span class="meta">@cython.boundscheck(False) # turn off bounds-checking for entire function</span></span><br><span class="line"><span class="meta">@cython.wraparound(False)  # turn off negative index wrapping for entire function</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">compute_mse_grad_linear_ard</span><span class="params">(np.ndarray[np.float64_t, ndim=<span class="number">1</span>] w,</span></span></span><br><span class="line"><span class="function"><span class="params">        np.ndarray[np.float64_t, ndim=<span class="number">2</span>] X1,</span></span></span><br><span class="line"><span class="function"><span class="params">        np.ndarray[np.float64_t, ndim=<span class="number">2</span>] X2,</span></span></span><br><span class="line"><span class="function"><span class="params">        np.ndarray[np.float64_t, ndim=<span class="number">2</span>] Kinv1,</span></span></span><br><span class="line"><span class="function"><span class="params">        np.ndarray[np.float64_t, ndim=<span class="number">2</span>] K2,</span></span></span><br><span class="line"><span class="function"><span class="params">        np.ndarray[np.float64_t, ndim=<span class="number">2</span>] a,</span></span></span><br><span class="line"><span class="function"><span class="params">        np.ndarray[np.float64_t, ndim=<span class="number">2</span>] err,</span></span></span><br><span class="line"><span class="function"><span class="params">        np.ndarray[np.float64_t, ndim=<span class="number">2</span>] mask=None)</span>:</span></span><br><span class="line">    <span class="string">'''Compute the gradients of MSE on the test samples with respect to relevance vector w.</span></span><br><span class="line"><span class="string">    :param w: 1D array of shape [n_features]</span></span><br><span class="line"><span class="string">    :return: gradients of MSE wrt. 2, 1D array of shape [n_features]</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    cdef np.int64_t N1, N2, p</span><br><span class="line">    cdef np.int64_t k, i, j, m</span><br><span class="line">    N1 = X1.shape[<span class="number">0</span>]</span><br><span class="line">    N2 = X2.shape[<span class="number">0</span>]</span><br><span class="line">    p = X2.shape[<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">    cdef np.ndarray[np.float64_t, ndim=<span class="number">2</span>] K2Kinv1 = K2.dot(Kinv1)</span><br><span class="line">    cdef np.ndarray[np.float64_t, ndim=<span class="number">1</span>] mse_grad = np.zeros_like(w)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#cdef np.ndarray[np.float64_t, ndim=3] K1_grad = np.zeros((p, N1, N1), dtype=np.float64)</span></span><br><span class="line">    <span class="comment">#cdef np.ndarray[np.float64_t, ndim=3] K2_grad = np.zeros((p, N2, N1), dtype=np.float64)</span></span><br><span class="line">    <span class="comment">#cdef np.ndarray[np.float64_t, ndim=3] K_grad =  np.zeros((p, N2, N1), dtype=np.float64)</span></span><br><span class="line">    cdef np.int64_t max_n_threads = openmp.omp_get_max_threads()</span><br><span class="line">    cdef np.ndarray[np.float64_t, ndim=<span class="number">3</span>] K1_grad = np.zeros((max_n_threads, N1, N1), dtype=np.float64)</span><br><span class="line">    cdef np.ndarray[np.float64_t, ndim=<span class="number">3</span>] K2_grad = np.zeros((max_n_threads, N2, N1), dtype=np.float64)</span><br><span class="line">    cdef np.ndarray[np.float64_t, ndim=<span class="number">3</span>] K_grad  = np.zeros((max_n_threads, N1, N1), dtype=np.float64)</span><br><span class="line"></span><br><span class="line">    cdef np.int64_t thread_id</span><br><span class="line">    <span class="keyword">with</span> nogil, parallel():</span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> prange(p):</span><br><span class="line">            thread_id = openmp.omp_get_thread_num()</span><br><span class="line">            <span class="comment"># compute K1_grad</span></span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> range(N1):</span><br><span class="line">                <span class="keyword">for</span> j <span class="keyword">in</span> range(N1):</span><br><span class="line">                    K1_grad[thread_id, i, j] = <span class="number">2.0</span>*w[k]*X1[i, k]*X1[j, k]</span><br><span class="line">            <span class="comment"># compute K2_grad</span></span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> range(N2):</span><br><span class="line">                <span class="keyword">for</span> j <span class="keyword">in</span> range(N1):</span><br><span class="line">                    K2_grad[thread_id, i, j] = <span class="number">2.0</span>*w[k]*X2[i, k]*X1[j, k]</span><br><span class="line">            <span class="comment"># compute K_grad</span></span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> range(N2):</span><br><span class="line">                <span class="keyword">for</span> j <span class="keyword">in</span> range(N1):</span><br><span class="line">                    K_grad[thread_id, i, j] = K2_grad[thread_id, i, j]</span><br><span class="line">                    <span class="keyword">for</span> m <span class="keyword">in</span> range(N1):</span><br><span class="line">                        K_grad[thread_id, i, j] += K2Kinv1[i, m]*K1_grad[thread_id, m, j]</span><br><span class="line">            <span class="comment"># compute mse_grad</span></span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> range(N2):</span><br><span class="line">                <span class="keyword">for</span> j <span class="keyword">in</span> range(N1):</span><br><span class="line">                    mse_grad[k] += err[i, <span class="number">0</span>]*K_grad[thread_id, i, j]*a[j, <span class="number">0</span>]</span><br><span class="line">    <span class="keyword">return</span> mse_grad, K_grad</span><br></pre></td></tr></table></figure><h3 id="Progress-bar-tqdm"><a href="#Progress-bar-tqdm" class="headerlink" title="Progress bar: tqdm"></a>Progress bar: tqdm</h3><p>URL: (<a href="https://pypi.python.org/pypi/tqdm" target="_blank" rel="noopener">https://pypi.python.org/pypi/tqdm</a>)</p><p><img src="http://i2.tiimg.com/640680/010f81392dd7104a.png" alt="Markdown"></p><p><img src="http://i2.tiimg.com/640680/70da70ed24b4932f.png" alt="Markdown"></p><h2 id="Example-Python-scripts"><a href="#Example-Python-scripts" class="headerlink" title="Example Python scripts"></a>Example Python scripts</h2><h3 id="View-a-table-in-a-pretty-way"><a href="#View-a-table-in-a-pretty-way" class="headerlink" title="View a table in a pretty way"></a>View a table in a pretty way</h3><p>The original table is ugly:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">head -n 15 metadata.tsv</span><br></pre></td></tr></table></figure><p>Output:</p><figure class="highlight nimrod"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">File</span> accession<span class="type">File</span> format<span class="type">Output</span> <span class="keyword">type</span><span class="type">Experiment</span> accession<span class="type">Assay</span><span class="type">Biosample</span> term id</span><br><span class="line"><span class="type">ENCFF983DFB</span>fastqreads<span class="type">ENCSR429XTR</span><span class="type">ChIP</span>-<span class="built_in">seq</span><span class="type">EFO</span>:<span class="number">0002067</span></span><br><span class="line"><span class="type">ENCFF590TBW</span>fastqreads<span class="type">ENCSR429XTR</span><span class="type">ChIP</span>-<span class="built_in">seq</span><span class="type">EFO</span>:<span class="number">0002067</span></span><br><span class="line"><span class="type">ENCFF258RWG</span>bamunfiltered alignments<span class="type">ENCSR429XTR</span><span class="type">ChIP</span>-<span class="built_in">seq</span><span class="type">EFO</span>:<span class="number">0002067</span></span><br><span class="line"><span class="type">ENCFF468LRV</span>bamunfiltered alignments<span class="type">ENCSR429XTR</span><span class="type">ChIP</span>-<span class="built_in">seq</span><span class="type">EFO</span>:<span class="number">0002067</span></span><br><span class="line"><span class="type">ENCFF216EBS</span>bamalignments<span class="type">ENCSR429XTR</span><span class="type">ChIP</span>-<span class="built_in">seq</span><span class="type">EFO</span>:<span class="number">0002067</span></span><br><span class="line"><span class="type">ENCFF232QFN</span>bamunfiltered alignments<span class="type">ENCSR429XTR</span><span class="type">ChIP</span>-<span class="built_in">seq</span><span class="type">EFO</span>:<span class="number">0002067</span></span><br><span class="line"><span class="type">ENCFF682NGE</span>bamalignments<span class="type">ENCSR429XTR</span><span class="type">ChIP</span>-<span class="built_in">seq</span><span class="type">EFO</span>:<span class="number">0002067</span></span><br><span class="line"><span class="type">ENCFF328UKA</span>bamunfiltered alignments<span class="type">ENCSR429XTR</span><span class="type">ChIP</span>-<span class="built_in">seq</span><span class="type">EFO</span>:<span class="number">0002067</span></span><br><span class="line"><span class="type">ENCFF165COO</span>bamalignments<span class="type">ENCSR429XTR</span><span class="type">ChIP</span>-<span class="built_in">seq</span><span class="type">EFO</span>:<span class="number">0002067</span></span><br><span class="line"><span class="type">ENCFF466OLG</span>bamalignments<span class="type">ENCSR429XTR</span><span class="type">ChIP</span>-<span class="built_in">seq</span><span class="type">EFO</span>:<span class="number">0002067</span></span><br><span class="line"><span class="type">ENCFF595HIY</span>bigBed narrowPeakpeaks<span class="type">ENCSR429XTR</span><span class="type">ChIP</span>-<span class="built_in">seq</span><span class="type">EFO</span>:<span class="number">0002067</span></span><br><span class="line"><span class="type">ENCFF494CKB</span>bigWigfold change over control<span class="type">ENCSR429XTR</span><span class="type">ChIP</span>-<span class="built_in">seq</span><span class="type">EFO</span>:<span class="number">0002067</span></span><br><span class="line"><span class="type">ENCFF308BXW</span>bigWigfold change over control<span class="type">ENCSR429XTR</span><span class="type">ChIP</span>-<span class="built_in">seq</span><span class="type">EFO</span>:<span class="number">0002067</span></span><br><span class="line"><span class="type">ENCFF368IHM</span>bed narrowPeakpeaks<span class="type">ENCSR429XTR</span><span class="type">ChIP</span>-<span class="built_in">seq</span><span class="type">EFO</span>:<span class="number">0002067</span></span><br></pre></td></tr></table></figure><p>Now display the table more clearly:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">head -n 15 metadata.tsv | tvi -d $<span class="string">'\t'</span> -j center</span><br></pre></td></tr></table></figure><p>Output:</p><figure class="highlight nimrod"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">File</span> accession    <span class="type">File</span> format          <span class="type">Output</span> <span class="keyword">type</span>        <span class="type">Experiment</span> accession  <span class="type">Assay</span>   <span class="type">Biosample</span> term id</span><br><span class="line"> <span class="type">ENCFF983DFB</span>         fastq                reads               <span class="type">ENCSR429XTR</span>      <span class="type">ChIP</span>-<span class="built_in">seq</span>    <span class="type">EFO</span>:<span class="number">0002067</span></span><br><span class="line"> <span class="type">ENCFF590TBW</span>         fastq                reads               <span class="type">ENCSR429XTR</span>      <span class="type">ChIP</span>-<span class="built_in">seq</span>    <span class="type">EFO</span>:<span class="number">0002067</span></span><br><span class="line"> <span class="type">ENCFF258RWG</span>          bam         unfiltered alignments       <span class="type">ENCSR429XTR</span>      <span class="type">ChIP</span>-<span class="built_in">seq</span>    <span class="type">EFO</span>:<span class="number">0002067</span></span><br><span class="line"> <span class="type">ENCFF468LRV</span>          bam         unfiltered alignments       <span class="type">ENCSR429XTR</span>      <span class="type">ChIP</span>-<span class="built_in">seq</span>    <span class="type">EFO</span>:<span class="number">0002067</span></span><br><span class="line"> <span class="type">ENCFF216EBS</span>          bam               alignments            <span class="type">ENCSR429XTR</span>      <span class="type">ChIP</span>-<span class="built_in">seq</span>    <span class="type">EFO</span>:<span class="number">0002067</span></span><br><span class="line"> <span class="type">ENCFF232QFN</span>          bam         unfiltered alignments       <span class="type">ENCSR429XTR</span>      <span class="type">ChIP</span>-<span class="built_in">seq</span>    <span class="type">EFO</span>:<span class="number">0002067</span></span><br><span class="line"> <span class="type">ENCFF682NGE</span>          bam               alignments            <span class="type">ENCSR429XTR</span>      <span class="type">ChIP</span>-<span class="built_in">seq</span>    <span class="type">EFO</span>:<span class="number">0002067</span></span><br><span class="line"> <span class="type">ENCFF328UKA</span>          bam         unfiltered alignments       <span class="type">ENCSR429XTR</span>      <span class="type">ChIP</span>-<span class="built_in">seq</span>    <span class="type">EFO</span>:<span class="number">0002067</span></span><br><span class="line"> <span class="type">ENCFF165COO</span>          bam               alignments            <span class="type">ENCSR429XTR</span>      <span class="type">ChIP</span>-<span class="built_in">seq</span>    <span class="type">EFO</span>:<span class="number">0002067</span></span><br><span class="line"> <span class="type">ENCFF466OLG</span>          bam               alignments            <span class="type">ENCSR429XTR</span>      <span class="type">ChIP</span>-<span class="built_in">seq</span>    <span class="type">EFO</span>:<span class="number">0002067</span></span><br><span class="line"> <span class="type">ENCFF595HIY</span>   bigBed narrowPeak          peaks               <span class="type">ENCSR429XTR</span>      <span class="type">ChIP</span>-<span class="built_in">seq</span>    <span class="type">EFO</span>:<span class="number">0002067</span></span><br><span class="line"> <span class="type">ENCFF494CKB</span>        bigWig       fold change over control     <span class="type">ENCSR429XTR</span>      <span class="type">ChIP</span>-<span class="built_in">seq</span>    <span class="type">EFO</span>:<span class="number">0002067</span></span><br><span class="line"> <span class="type">ENCFF308BXW</span>        bigWig       fold change over control     <span class="type">ENCSR429XTR</span>      <span class="type">ChIP</span>-<span class="built_in">seq</span>    <span class="type">EFO</span>:<span class="number">0002067</span></span><br><span class="line"> <span class="type">ENCFF368IHM</span>    bed narrowPeak            peaks               <span class="type">ENCSR429XTR</span>      <span class="type">ChIP</span>-<span class="built_in">seq</span>    <span class="type">EFO</span>:<span class="number">0002067</span></span><br></pre></td></tr></table></figure><p>You can also get some help by typing <code>tvi -h</code>:</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">usage: tvi [-h] [-d DELIMITER] [-j &#123;left,right,center&#125;] [-s SEPARATOR]</span><br><span class="line">           [infile]</span><br><span class="line"></span><br><span class="line"><span class="builtin-name">Print</span> tables pretty</span><br><span class="line"></span><br><span class="line">positional arguments:</span><br><span class="line">  infile                input file,<span class="built_in"> default </span>is stdin</span><br><span class="line"></span><br><span class="line">optional arguments:</span><br><span class="line">  -h, --help            show this help message <span class="keyword">and</span> exit</span><br><span class="line">  -d DELIMITER          delimiter of fields of input.<span class="built_in"> Default </span>is white space.</span><br><span class="line">  -j &#123;left,right,center&#125;</span><br><span class="line">                        justification, either left, right <span class="keyword">or</span> center. Default</span><br><span class="line">                        is left</span><br><span class="line">  -s SEPARATOR          separator of fields <span class="keyword">in</span> output</span><br></pre></td></tr></table></figure><p><code>tvi.py</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#! /usr/bin/env python</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> cStringIO <span class="keyword">import</span> StringIO</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></span><br><span class="line">parser = argparse.ArgumentParser(description=<span class="string">'Print tables pretty'</span>)</span><br><span class="line">parser.add_argument(<span class="string">'infile'</span>, type=str, nargs=<span class="string">'?'</span>,</span><br><span class="line"> help=<span class="string">'input file, default is stdin'</span>)</span><br><span class="line">parser.add_argument(<span class="string">'-d'</span>, dest=<span class="string">'delimiter'</span>, type=str,</span><br><span class="line"> required=<span class="keyword">False</span>,</span><br><span class="line"> help=<span class="string">'delimiter of fields of input. Default is white space.'</span>)</span><br><span class="line">parser.add_argument(<span class="string">'-j'</span>, dest=<span class="string">'justify'</span>, type=str,</span><br><span class="line"> required=<span class="keyword">False</span>, default=<span class="string">'left'</span>,</span><br><span class="line"> choices=[<span class="string">'left'</span>, <span class="string">'right'</span>, <span class="string">'center'</span>],</span><br><span class="line"> help=<span class="string">'justification, either left, right or center. Default is left'</span>)</span><br><span class="line">parser.add_argument(<span class="string">'-s'</span>, dest=<span class="string">'separator'</span>, type=str,</span><br><span class="line"> required=<span class="keyword">False</span>, default=<span class="string">' '</span>,</span><br><span class="line"> help=<span class="string">'separator of fields in output'</span>)</span><br><span class="line">args = parser.parse_args()</span><br><span class="line"></span><br><span class="line">table = []</span><br><span class="line">maxwidth = []</span><br><span class="line"></span><br><span class="line"><span class="comment"># default is to read from stdin</span></span><br><span class="line">fin = sys.stdin</span><br><span class="line"><span class="keyword">if</span> args.infile:</span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">fin = open(args.infile, <span class="string">'rt'</span>)</span><br><span class="line"><span class="keyword">except</span> IOError <span class="keyword">as</span> e:</span><br><span class="line">sys.stderr.write(<span class="string">'Error: %s: %s\n'</span>%(e.strerror, args.infile))</span><br><span class="line">sys.exit(e.errno)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> fin:</span><br><span class="line">fields = <span class="keyword">None</span></span><br><span class="line"><span class="comment"># split line by delimiter</span></span><br><span class="line"><span class="keyword">if</span> args.delimiter:</span><br><span class="line">fields = line.strip().split(args.delimiter)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">fields = line.strip().split()</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> xrange(len(fields)):</span><br><span class="line">width = len(fields[i])</span><br><span class="line"><span class="keyword">if</span> (i+<span class="number">1</span>) &gt; len(maxwidth):</span><br><span class="line">maxwidth.append(width)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line"><span class="keyword">if</span> width &gt; maxwidth[i]:</span><br><span class="line">maxwidth[i] = width</span><br><span class="line">table.append(fields)</span><br><span class="line">fin.close()</span><br><span class="line"></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line"><span class="keyword">for</span> fields <span class="keyword">in</span> table:</span><br><span class="line">line = StringIO()</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> xrange(len(fields)):</span><br><span class="line"><span class="comment"># format field with different justification</span></span><br><span class="line">nSpace = maxwidth[i] - len(fields[i])</span><br><span class="line"><span class="keyword">if</span> args.justify == <span class="string">'left'</span>:</span><br><span class="line">line.write(fields[i])</span><br><span class="line"><span class="keyword">for</span> j <span class="keyword">in</span> xrange(nSpace):</span><br><span class="line">line.write(<span class="string">' '</span>)</span><br><span class="line"><span class="keyword">elif</span> args.justify == <span class="string">'right'</span>:</span><br><span class="line"><span class="keyword">for</span> j <span class="keyword">in</span> xrange(nSpace):</span><br><span class="line">line.write(<span class="string">' '</span>)</span><br><span class="line">line.write(fields[i])</span><br><span class="line"><span class="keyword">elif</span> args.justify == <span class="string">'center'</span>:</span><br><span class="line"><span class="keyword">for</span> j <span class="keyword">in</span> xrange(nSpace/<span class="number">2</span>):</span><br><span class="line">line.write(<span class="string">' '</span>)</span><br><span class="line">line.write(fields[i])</span><br><span class="line"><span class="keyword">for</span> j <span class="keyword">in</span> xrange(nSpace - nSpace/<span class="number">2</span>):</span><br><span class="line">line.write(<span class="string">' '</span>)</span><br><span class="line"></span><br><span class="line">line.write(args.separator)</span><br><span class="line"><span class="keyword">print</span> line.getvalue()</span><br><span class="line">line.close()</span><br><span class="line"><span class="keyword">except</span> IOError:</span><br><span class="line">sys.exit(<span class="number">-1</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">main()</span><br></pre></td></tr></table></figure><h3 id="Generate-a-random-FASTA-file"><a href="#Generate-a-random-FASTA-file" class="headerlink" title="Generate a random FASTA file"></a>Generate a random FASTA file</h3><p><code>seqgen.py</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#! /usr/bin/env python</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"><span class="keyword">import</span> textwrap</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">write_fasta</span><span class="params">(fout, seq, name=<span class="string">'seq'</span>, description=None)</span>:</span></span><br><span class="line"><span class="keyword">if</span> description:</span><br><span class="line">fout.write(<span class="string">'&gt;'</span> + name + <span class="string">' '</span> + description + <span class="string">'\n'</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">fout.write(<span class="string">'&gt;'</span> + name + <span class="string">'\n'</span>)</span><br><span class="line">fout.write(textwrap.fill(seq) + <span class="string">'\n'</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></span><br><span class="line">parser = argparse.ArgumentParser(description=<span class="string">'Generate sequences and output in various formats'</span>)</span><br><span class="line">parser.add_argument(<span class="string">'-n'</span>, <span class="string">'--number'</span>, dest=<span class="string">'number'</span>, type=int, required=<span class="keyword">False</span>,</span><br><span class="line"> default=<span class="number">10</span>, help=<span class="string">'Number of sequences to generate'</span>)</span><br><span class="line">parser.add_argument(<span class="string">'--min-length'</span>, dest=<span class="string">'min_length'</span>, type=int, required=<span class="keyword">False</span>,</span><br><span class="line"> default=<span class="number">30</span>, help=<span class="string">'Minimal length'</span>)</span><br><span class="line">parser.add_argument(<span class="string">'--max-length'</span>, dest=<span class="string">'max_length'</span>, type=int, required=<span class="keyword">False</span>,</span><br><span class="line"> default=<span class="number">50</span>, help=<span class="string">'Maximal length'</span>)</span><br><span class="line">parser.add_argument(<span class="string">'-l'</span>, <span class="string">'--length'</span>, type=int, required=<span class="keyword">False</span>,</span><br><span class="line"> help=<span class="string">'Fixed length. If specified, --min-length and --max-length will be ignored.'</span>)</span><br><span class="line">parser.add_argument(<span class="string">'-a'</span>, <span class="string">'--alphabet'</span>, type=str, required=<span class="keyword">False</span>,</span><br><span class="line"> default=<span class="string">'ATGC'</span>, help=<span class="string">'Letters to used in the sequences'</span>)</span><br><span class="line">parser.add_argument(<span class="string">'-f'</span>, <span class="string">'--format'</span>, type=str, required=<span class="keyword">False</span>,</span><br><span class="line"> choices=[<span class="string">'fasta'</span>, <span class="string">'text'</span>], default=<span class="string">'fasta'</span>, help=<span class="string">'Output formats'</span>)</span><br><span class="line">parser.add_argument(<span class="string">'-o'</span>, <span class="string">'--outfile'</span>, type=argparse.FileType(<span class="string">'w'</span>), required=<span class="keyword">False</span>,</span><br><span class="line"> default=sys.stdout, help=<span class="string">'Output file name'</span>)</span><br><span class="line">parser.add_argument(<span class="string">'-p'</span>, <span class="string">'--prefix'</span>, type=str, required=<span class="keyword">False</span>,</span><br><span class="line"> default=<span class="string">'RN_'</span>, help=<span class="string">'Prefix of sequence names for fasta format'</span>)</span><br><span class="line">args = parser.parse_args()</span><br><span class="line"></span><br><span class="line">rand = random.Random()</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> xrange(args.number):</span><br><span class="line"><span class="keyword">if</span> args.length:</span><br><span class="line">length = args.length</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">length = rand.randint(args.min_length, args.max_length)</span><br><span class="line">seq = bytearray(length)</span><br><span class="line"><span class="keyword">for</span> j <span class="keyword">in</span> xrange(length):</span><br><span class="line">seq[j] = rand.choice(args.alphabet)</span><br><span class="line"><span class="keyword">if</span> args.format == <span class="string">'fasta'</span>:</span><br><span class="line">write_fasta(args.outfile, str(seq), args.prefix + <span class="string">'%08d'</span>%i)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">args.outfile.write(seq + <span class="string">'\n'</span>)</span><br><span class="line">args.outfile.close()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">main()</span><br></pre></td></tr></table></figure><h2 id="Weekly-tasks"><a href="#Weekly-tasks" class="headerlink" title="Weekly tasks"></a>Weekly tasks</h2><p>All files you need for completing the tasks can be found at: <a href="assets/weekly_tasks.zip">weekly_tasks.zip</a></p><p><strong>Task 1: run examples (Python tips, numpy, pandas) in this tutorial</strong></p><p>Install Anaconda on your PC. Try to understand example code and run in Jupyter or IPython.</p><p><strong>Task 2: write a Python program to convert a GTF file to BED12 format</strong> </p><ul><li>Please refer to (<a href="https://genome.ucsc.edu/FAQ/FAQformat.html#format1" target="_blank" rel="noopener">https://genome.ucsc.edu/FAQ/FAQformat.html#format1</a>) for BED12 format and refer to (<a href="https://www.ensembl.org/info/website/upload/gff.html" target="_blank" rel="noopener">https://www.ensembl.org/info/website/upload/gff.html</a>) for GTF format.<br>GTF example:</li></ul><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">chr1</span>HAVANAgene<span class="number">29554</span><span class="number">31109</span>.+.gene_id <span class="string">"ENSG00000243485.5"</span>; <span class="attribute">gene_type</span> <span class="string">"lincRNA"</span>; <span class="attribute">gene_name</span> <span class="string">"MIR1302-2HG"</span>; <span class="attribute">level</span> <span class="number">2</span>; <span class="attribute">tag</span> <span class="string">"ncRNA_host"</span>; <span class="attribute">havana_gene</span> <span class="string">"OTTHUMG00000000959.2"</span>;</span><br><span class="line"><span class="attribute">chr1</span>HAVANAtranscript<span class="number">29554</span><span class="number">31097</span>.+.gene_id <span class="string">"ENSG00000243485.5"</span>; <span class="attribute">transcript_id</span> <span class="string">"ENST00000473358.1"</span>; <span class="attribute">gene_type</span> <span class="string">"lincRNA"</span>; <span class="attribute">gene_name</span> <span class="string">"MIR1302-2HG"</span>; <span class="attribute">transcript_type</span> <span class="string">"lincRNA"</span>; <span class="attribute">transcript_name</span> <span class="string">"MIR1302-2HG-202"</span>; <span class="attribute">level</span> <span class="number">2</span>; <span class="attribute">transcript_support_level</span> <span class="string">"5"</span>; <span class="attribute">tag</span> <span class="string">"not_best_in_genome_evidence"</span>; <span class="attribute">tag</span> <span class="string">"dotter_confirmed"</span>; <span class="attribute">tag</span> <span class="string">"basic"</span>; <span class="attribute">havana_gene</span> <span class="string">"OTTHUMG00000000959.2"</span>; <span class="attribute">havana_transcript</span> <span class="string">"OTTHUMT00000002840.1"</span>;</span><br><span class="line"><span class="attribute">chr1</span>HAVANAexon<span class="number">29554</span><span class="number">30039</span>.+.gene_id <span class="string">"ENSG00000243485.5"</span>; <span class="attribute">transcript_id</span> <span class="string">"ENST00000473358.1"</span>; <span class="attribute">gene_type</span> <span class="string">"lincRNA"</span>; <span class="attribute">gene_name</span> <span class="string">"MIR1302-2HG"</span>; <span class="attribute">transcript_type</span> <span class="string">"lincRNA"</span>; <span class="attribute">transcript_name</span> <span class="string">"MIR1302-2HG-202"</span>; <span class="attribute">exon_number</span> <span class="number">1</span>; <span class="attribute">exon_id</span> <span class="string">"ENSE00001947070.1"</span>; <span class="attribute">level</span> <span class="number">2</span>; <span class="attribute">transcript_support_level</span> <span class="string">"5"</span>; <span class="attribute">tag</span> <span class="string">"not_best_in_genome_evidence"</span>; <span class="attribute">tag</span> <span class="string">"dotter_confirmed"</span>; <span class="attribute">tag</span> <span class="string">"basic"</span>; <span class="attribute">havana_gene</span> <span class="string">"OTTHUMG00000000959.2"</span>; <span class="attribute">havana_transcript</span> <span class="string">"OTTHUMT00000002840.1"</span>;</span><br></pre></td></tr></table></figure><p>BED12 example:</p><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">chr1<span class="number">67522353</span><span class="number">67532326</span>ENST00000230113<span class="number">0</span>+<span class="number">0</span><span class="number">0</span><span class="number">0</span><span class="number">5</span><span class="number">45</span>,<span class="number">60</span>,<span class="number">97</span>,<span class="number">64</span>,<span class="number">221</span>,<span class="number">0</span>,<span class="number">5024</span>,<span class="number">7299</span>,<span class="number">7961</span>,<span class="number">9752</span>,</span><br><span class="line">chr1<span class="number">39249837</span><span class="number">39257649</span>ENST00000289890<span class="number">0</span>-<span class="number">0</span><span class="number">0</span><span class="number">0</span><span class="number">3</span><span class="number">365</span>,<span class="number">78</span>,<span class="number">115</span>,<span class="number">0</span>,<span class="number">4304</span>,<span class="number">7697</span>,</span><br><span class="line">chr1<span class="number">144245237</span><span class="number">144250279</span>ENST00000294715<span class="number">0</span>-<span class="number">0</span><span class="number">0</span><span class="number">0</span><span class="number">3</span><span class="number">78</span>,<span class="number">135</span>,<span class="number">55</span>,<span class="number">0</span>,<span class="number">448</span>,<span class="number">4987</span>,</span><br><span class="line">chr1<span class="number">15111814</span><span class="number">15152464</span>ENST00000310916<span class="number">0</span>-<span class="number">0</span><span class="number">0</span><span class="number">0</span><span class="number">6</span><span class="number">5993</span>,<span class="number">578</span>,<span class="number">121</span>,<span class="number">88</span>,<span class="number">146</span>,<span class="number">174</span>,<span class="number">0</span>,<span class="number">6512</span>,<span class="number">8762</span>,<span class="number">9157</span>,<span class="number">12413</span>,<span class="number">40476</span>,</span><br><span class="line">chr1<span class="number">34975698</span><span class="number">34978706</span>ENST00000311990<span class="number">0</span>-<span class="number">0</span><span class="number">0</span><span class="number">0</span><span class="number">3</span><span class="number">1704</span>,<span class="number">154</span>,<span class="number">29</span>,<span class="number">0</span>,<span class="number">2232</span>,<span class="number">2979</span>,</span><br></pre></td></tr></table></figure><ul><li>The GTF file is <code>weekly_tasks/gencode.v27.long_noncoding_RNAs.gtf</code>.</li><li>Each line in the output file is a transcript with the 4th columns as transcript ID</li><li>The version number of the transcript ID should be stripped (e.g. ENST00000473358.1 =&gt; ENST00000473358). </li><li>The output file is sorted <strong>first by transcript IDs</strong> and <strong>then by chromosome</strong> in lexicographical order. </li><li>Column 5, 7, 8, 9 in the BED12 file should be set to 0.</li><li>Please do NOT use any external tools (e.g. <code>sort</code>, <code>awk</code>, etc.) in your program other than Python.</li><li>An example output can be found in <code>weekly_tasks/transcripts.bed</code>.</li></ul><p><strong>Hint:</strong> use <code>dict</code>, <code>list</code>, <code>tuple</code>, <code>str.split</code>, <code>re.match</code>, <code>sorted</code>.</p><p><strong>Task 3: write a Python program to add a prefix to all directories</strong></p><ul><li>Each prefix is a two-digit number starting from 00 and ‘-‘. If the number is less than 10, a single ‘0’ letter should be filled.</li><li>The files/directories should be numbered according to the <strong>lexicographical</strong> order.<br>For example, if the original directory structure is:</li></ul><figure class="highlight dns"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">.</span><br><span class="line">├── <span class="keyword">A</span></span><br><span class="line">│   ├── <span class="keyword">A</span></span><br><span class="line">│   │   ├── <span class="keyword">A</span></span><br><span class="line">│   │   ├── B</span><br><span class="line">│   │   └── C</span><br><span class="line">│   ├── B</span><br><span class="line">│   │   └── <span class="keyword">A</span></span><br><span class="line">│   └── C</span><br><span class="line">│       └── <span class="keyword">A</span></span><br><span class="line">├── B</span><br><span class="line">│   ├── <span class="keyword">A</span></span><br><span class="line">│   └── B</span><br><span class="line">└── C</span><br><span class="line">    ├── <span class="keyword">A</span></span><br><span class="line">    └── B</span><br><span class="line">        └── <span class="keyword">A</span></span><br></pre></td></tr></table></figure><p>then you should get the following directory structure after renaming:</p><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">.</span><br><span class="line">├── <span class="number">00</span>-A</span><br><span class="line">│   ├── <span class="number">00</span>-A</span><br><span class="line">│   │   ├── <span class="number">00</span>-A</span><br><span class="line">│   │   ├── <span class="number">01</span>-B</span><br><span class="line">│   │   └── <span class="number">02</span>-C</span><br><span class="line">│   ├── <span class="number">01</span>-B</span><br><span class="line">│   │   └── <span class="number">00</span>-A</span><br><span class="line">│   └── <span class="number">02</span>-C</span><br><span class="line">│       └── <span class="number">00</span>-A</span><br><span class="line">├── <span class="number">01</span>-B</span><br><span class="line">│   ├── <span class="number">00</span>-A</span><br><span class="line">│   └── <span class="number">01</span>-B</span><br><span class="line">└── <span class="number">02</span>-C</span><br><span class="line">    ├── <span class="number">00</span>-A</span><br><span class="line">    └── <span class="number">01</span>-B</span><br><span class="line">        └── <span class="number">00</span>-A</span><br></pre></td></tr></table></figure><ul><li>The original directories can be found in <code>weekly_tasks/original_dirs</code>.</li><li>The root directory (i.e. <code>original_dirs</code>) should not be renamed.</li><li>You can use <code>tree</code> command to display the directory structure as shown above.</li><li>An example result can be found in <code>weekly_tasks/renamed_dirs</code>.<br><strong>Hint:</strong> use <code>os.listdir</code>, <code>os.rename</code>, <code>str.format</code>, <code>sorted</code>, <code>yield</code>.</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;This is one of the chapter in &lt;a href=&quot;https://lulab.gitbooks.io/teaching/content/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Bioinformatics basic course in Tsinghua University&lt;/a&gt;. You may also find it &lt;a href=&quot;https://lulab.gitbooks.io/teaching/content/appendix/python_tutorial.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The related &lt;a href=&quot;https://github.com/lulab/teaching_book/blob/master/appendix/python_tutorial.ipynb&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;jupyter file&lt;/a&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="teaching" scheme="https://www.cmwonderland.com/blog/categories/teaching/"/>
    
    
      <category term="machine learning" scheme="https://www.cmwonderland.com/blog/tags/machine-learning/"/>
    
      <category term="python" scheme="https://www.cmwonderland.com/blog/tags/python/"/>
    
      <category term="bioinformatics" scheme="https://www.cmwonderland.com/blog/tags/bioinformatics/"/>
    
      <category term="teaching" scheme="https://www.cmwonderland.com/blog/tags/teaching/"/>
    
      <category term="TA" scheme="https://www.cmwonderland.com/blog/tags/TA/"/>
    
  </entry>
  
  <entry>
    <title>QUIZ identification of cancer biomarker from exRNA-seq data</title>
    <link href="https://www.cmwonderland.com/blog/2018/10/06/32_quiz_exrna_tutorial/"/>
    <id>https://www.cmwonderland.com/blog/2018/10/06/32_quiz_exrna_tutorial/</id>
    <published>2018-10-06T11:01:19.000Z</published>
    <updated>2019-04-23T13:07:13.925Z</updated>
    
    <content type="html"><![CDATA[<p>This is one of the two course quizzes instruction of <a href="https://lulab.gitbooks.io/teaching/content/" target="_blank" rel="noopener">Bioinformatics basic course in Tsinghua University</a>. You may also find it <a href="https://lulab.gitbooks.io/teaching/content/quiz/quiz_exrna/quiz_exrna_tutorial.html" target="_blank" rel="noopener">here</a></p><p>The related <a href="https://github.com/lulab/teaching_book/blob/master/quiz/quiz_exrna/quiz_exrna_tutorial.ipynb" target="_blank" rel="noopener">jupyter file</a></p><a id="more"></a><p>请在<a href="https://cloud.tsinghua.edu.cn/f/3f4fc999720d45f198ca/" target="_blank" rel="noopener">quiz_exrna_tutorial_shared</a>下载相关文件，并下载该<a href="https://cloud.tsinghua.edu.cn/f/ae9a9d63d1db435ab6e2/" target="_blank" rel="noopener">文件夹</a>下的内容，打开<code>quiz_exrna_tutorial.ipynb</code>文件阅读详细的<strong>Quiz指南</strong>。</p><h2 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a>背景介绍</h2><p>（adapt from Young Lee）</p><p>在多种体液中，如血清、唾液以及尿液等，可以检测到一类非侵入性细胞外 RNA (extracellular RNA, exRNA)。诸如环状RNA (circular RNA)等这类具有空间结构的 RNA 分子，能够在血浆中稳定存在。这些从细胞分泌出的 exRNA 通常由微囊泡 (microvesicles)、外泌体(exosome) 包裹，或者与 RBP 密切结合形成 RNP 复合体。因为这些分子由于具备类细胞膜结构和蛋白质的保护，加上某些 RNA 具有特定的结构，exRNA 在多种体液 (血清、唾液、尿液等) 中可以抵抗体液中 RNase 的降解，从而稳定存在。exRNA 包括的类型很多，例如 miRNA，Y RNA, circRNA，lncRNA 等，每种又有不同的加工、剪切和修饰产物，这种多样性为更 好的临床检验带来了新的期望。这些 exRNA 可以成为一类有效的生物标志物，服务于人体健康状况检测和疾病的诊断，如癌症的早期诊断、肿瘤生长状况监测、以及预后辅助诊断。</p><p>本Quiz依托于Lulab现有的一些研究结果，希望读者通过生物信息学方法，尝试使用一些机器学习方法，发现和研究与癌症发生发展相关的新型体液胞外RNA (extracellular RNA，exRNA)生物标志物，并应用于几种国内高致死癌症的早期诊断和预后辅助治疗。我们将在癌症病人体液 (如血液)中的游离、微囊泡、外泌体、RNP 等不同组分中发现和鉴定标志癌症发生发展的新型 exRNA，构建模型，最终建立一个具有更高精准度和重复性的无创检验癌症（尤其是早期癌症）的方法。</p><h2 id="编程工具介绍"><a href="#编程工具介绍" class="headerlink" title="编程工具介绍"></a>编程工具介绍</h2><p>大作业需要使用python完成，推荐读者使用python3。我们需要一些python的工具包来实现部分功能。推荐使用包管理软件Anaconda来预装一些必需的包以及安装其他需要的包。另外强烈建议使用jupyter notebook进行代码编辑、运行和调试。具体使用方法请参考教程<a href="https://lulab.gitbooks.io/teaching/content/part-iii.-machine-learning-basics/python_tutorial.html" target="_blank" rel="noopener">Anaconda 和 jupyter</a>相关指南。<br>如果本地缺少下列可能需要的包，请使用<code>pip</code>或者<code>conda</code>进行安装。如:</p><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pip <span class="keyword">install</span> tqdm</span><br><span class="line">conda <span class="keyword">install</span> sklearn</span><br></pre></td></tr></table></figure><p>本作业的部分内容可能会涉及到R，推荐读者使用<a href="https://www.rstudio.com/" target="_blank" rel="noopener">Rstudio</a>，也可以在jupyter notebook中安装R kernel</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#导入必需的库</span></span><br><span class="line"><span class="keyword">import</span> gc, argparse, sys, os, errno</span><br><span class="line">%pylab inline</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> PCA</span><br><span class="line"><span class="keyword">from</span> sklearn.manifold <span class="keyword">import</span> TSNE</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> NearestNeighbors</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> LinearSVC</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> roc_auc_score, accuracy_score, get_scorer</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler, RobustScaler, MinMaxScaler, MaxAbsScaler</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> GridSearchCV</span><br><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> RFE, RFECV</span><br><span class="line"><span class="keyword">from</span> sklearn.utils.class_weight <span class="keyword">import</span> compute_sample_weight</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> KFold, StratifiedKFold, ShuffleSplit, LeaveOneOut, \</span><br><span class="line">    RepeatedKFold, RepeatedStratifiedKFold, LeaveOneOut, StratifiedShuffleSplit</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> roc_curve, auc</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm_notebook <span class="keyword">as</span> tqdm</span><br><span class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> pearsonr</span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line">warnings.filterwarnings(<span class="string">'ignore'</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#绘图设置</span></span><br><span class="line">styles = [<span class="string">"white"</span>,<span class="string">"dark"</span>,<span class="string">'whitegrid'</span>,<span class="string">"darkgrid"</span>]</span><br><span class="line">contexts = [<span class="string">'paper'</span>,<span class="string">'talk'</span>,<span class="string">'poster'</span>,<span class="string">'notebook'</span>]</span><br><span class="line">sns.set_context(contexts[<span class="number">1</span>])</span><br><span class="line">sns.set_style(styles[<span class="number">2</span>])</span><br><span class="line">tableau20 = np.array([(<span class="number">31</span>, <span class="number">119</span>, <span class="number">180</span>), (<span class="number">174</span>, <span class="number">199</span>, <span class="number">232</span>), (<span class="number">255</span>, <span class="number">127</span>, <span class="number">14</span>), (<span class="number">255</span>, <span class="number">187</span>, <span class="number">120</span>),  </span><br><span class="line">             (<span class="number">44</span>, <span class="number">160</span>, <span class="number">44</span>), (<span class="number">152</span>, <span class="number">223</span>, <span class="number">138</span>), (<span class="number">214</span>, <span class="number">39</span>, <span class="number">40</span>), (<span class="number">255</span>, <span class="number">152</span>, <span class="number">150</span>),  </span><br><span class="line">             (<span class="number">148</span>, <span class="number">103</span>, <span class="number">189</span>), (<span class="number">197</span>, <span class="number">176</span>, <span class="number">213</span>), (<span class="number">140</span>, <span class="number">86</span>, <span class="number">75</span>), (<span class="number">196</span>, <span class="number">156</span>, <span class="number">148</span>),  </span><br><span class="line">             (<span class="number">227</span>, <span class="number">119</span>, <span class="number">194</span>), (<span class="number">247</span>, <span class="number">182</span>, <span class="number">210</span>), (<span class="number">127</span>, <span class="number">127</span>, <span class="number">127</span>), (<span class="number">199</span>, <span class="number">199</span>, <span class="number">199</span>),  </span><br><span class="line">             (<span class="number">188</span>, <span class="number">189</span>, <span class="number">34</span>), (<span class="number">219</span>, <span class="number">219</span>, <span class="number">141</span>), (<span class="number">23</span>, <span class="number">190</span>, <span class="number">207</span>), (<span class="number">158</span>, <span class="number">218</span>, <span class="number">229</span>)])/<span class="number">255.</span></span><br></pre></td></tr></table></figure><h2 id="数据介绍"><a href="#数据介绍" class="headerlink" title="数据介绍"></a>数据介绍</h2><p>为了减轻工作负担，读者不需要从mapping开始工作，我们为读者准备好了五套处理好的expression matrix，读者在此基础上完成后续的工作。</p><h3 id="expression-matrix"><a href="#expression-matrix" class="headerlink" title="expression matrix"></a>expression matrix</h3><p>expression matrix共有五套，来自每一行为一个feature，每一列为一个样本。其中<em>hcc</em>的expression matrix的feature分别为full length，peak以及两轮peak calling选出的peak数据。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">scirepount = pd.read_table(<span class="string">'data/expression_matrix/GSE71008.txt'</span>)</span><br><span class="line">hcc_full_count = pd.read_table(<span class="string">'data/expression_matrix/transcripts_exrna.txt'</span>)</span><br><span class="line">hcc_peak_count = pd.read_table(<span class="string">'data/expression_matrix/piranha_peaks.txt'</span>)</span><br><span class="line">hcc_peak_iter_count = pd.read_table(<span class="string">'data/expression_matrix/piranha_peaks_iterative.txt'</span>)</span><br><span class="line">exorbase = pd.read_table(<span class="string">'data/expression_matrix/exoRBase.txt'</span>)</span><br><span class="line">scirepount.head()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scirepount.shape, hcc_full_count.shape, hcc_peak_count.shape, hcc_peak_iter_count.shape, exorbase.shape</span><br></pre></td></tr></table></figure><pre><code>((3460, 193), (143666, 62), (1727, 64), (3061, 82), (111131, 86))</code></pre><h3 id="sample-labels"><a href="#sample-labels" class="headerlink" title="sample labels"></a>sample labels</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">exo_samplenames = pd.read_table(<span class="string">'data/labels/exoRBase.txt'</span>,header=<span class="keyword">None</span>)</span><br><span class="line">scirep_samplenames = pd.read_table(<span class="string">'data/labels/GSE71008.txt'</span>,delimiter=<span class="string">','</span> , header=<span class="keyword">None</span>)</span><br><span class="line">hcc_samplenamess = pd.read_table(<span class="string">'data/labels/hccfull.txt'</span>, header=<span class="keyword">None</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hcc_samplenamess.head()</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>0</th>      <th>1</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>17402567-B</td>      <td>stage_A</td>    </tr>    <tr>      <th>1</th>      <td>249136-B</td>      <td>stage_A</td>    </tr>    <tr>      <th>2</th>      <td>385247-B</td>      <td>stage_A</td>    </tr>    <tr>      <th>3</th>      <td>497411-B</td>      <td>stage_A</td>    </tr>    <tr>      <th>4</th>      <td>498221-B</td>      <td>stage_A</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">np.unique(scirep_samplenames[<span class="number">1</span>],return_counts=<span class="keyword">True</span>)</span><br><span class="line">np.unique(exo_samplenames[<span class="number">1</span>],return_counts=<span class="keyword">True</span>)</span><br></pre></td></tr></table></figure><h3 id="other-annotations"><a href="#other-annotations" class="headerlink" title="other annotations"></a>other annotations</h3><h4 id="gene-annotation"><a href="#gene-annotation" class="headerlink" title="gene annotation"></a>gene annotation</h4><p>可以通过feature的transcript id找到feature的transcript_nama, gene_type等信息</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">geneannotation = pd.read_table(<span class="string">'data/transcript_anno.txt'</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">geneannotation.head()</span><br></pre></td></tr></table></figure><h4 id="batch信息"><a href="#batch信息" class="headerlink" title="batch信息"></a>batch信息</h4><p>batch信息记录了对不同样本采取的不同实验条件，包括处理时间，处理材料的规格差异等，可能会造成同类样本的较大差异，称为batch effect。</p><p>对于exoRBase数据，每一种癌症样本均来自不同的实验室，因此其batch与样本类别重合。对于scirep数据和hcc数据，batch信息如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scirepbatch = pd.read_excel(<span class="string">'data/other_annotations/scirep_batch.xlsx'</span>)</span><br><span class="line">hccbatch = pd.read_csv(<span class="string">'data/other_annotations/hcc_batch.csv'</span>,delimiter=<span class="string">'\t'</span>)</span><br></pre></td></tr></table></figure><h3 id="RNA-type-统计信息"><a href="#RNA-type-统计信息" class="headerlink" title="RNA type 统计信息"></a>RNA type 统计信息</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hccrnastats = pd.read_csv(<span class="string">'data/other_annotations/hcc_rna_stats.csv'</span>,index_col=<span class="number">0</span>)</span><br><span class="line">exornastats = pd.read_csv(<span class="string">'data/other_annotations/exorbase_rna_stats.csv'</span>,index_col=<span class="number">0</span>)</span><br><span class="line">scireprnastats = pd.read_csv(<span class="string">'data/other_annotations/scirep_rna_stats.csv'</span>,index_col=<span class="number">0</span>)</span><br></pre></td></tr></table></figure><h2 id="Quiz具体要求"><a href="#Quiz具体要求" class="headerlink" title="Quiz具体要求"></a>Quiz具体要求</h2><p>请读者使用我们提供的五套数据，以下工作：</p><ul><li>完成<strong>数据分析</strong>工作</li><li>完成<strong>特征选择和特征筛除工作</strong>并汇报挑选出的feature。</li><li>完成<strong>模型拟合</strong>并汇报效果。</li><li>提交一份<strong>工作报告</strong>，中英文不限，同时提交<strong>源代码</strong>。</li><li>选择性完成加分项内容。</li></ul><h3 id="基本统计分析"><a href="#基本统计分析" class="headerlink" title="基本统计分析"></a>基本统计分析</h3><ul><li>统计一套数据中不同RNA type在不同样本的counts分布，hcc和scirep测到的主要是小RNA，exoRBase测到的主要是长RNA，观察分布能否得到这样的结论。</li><li>统计某套数据中某种类型的RNA在不同样本中的counts数量，可以分析一些希望重点关注的RNA类型，如lncRNA等。</li><li>对exoRBase和scirep数据做基本的quality control，通过counts或者PCA中明显离群点去除部分样本。参考<a href="#sampleqc"><em>sample QC</em></a>部分</li><li>统计expression matrix中counts数量排在top 20的feature的占比，分析过高的占比可能对scaling造成的影响。参考<a href="#topk"><em>top k feature</em></a>部分</li></ul><h3 id="稳健的特征选择方法"><a href="#稳健的特征选择方法" class="headerlink" title="稳健的特征选择方法"></a>稳健的特征选择方法</h3><ul><li>我们希望读者设计一个稳健的特征选择方法，完成以下几种情况下的feature selection，给出针对每套数据，每种分类条件所挑选的feature。<ul><li>hcc(full length, peak, peak iterative)<ul><li>HCC vs Normal</li><li>Stage A vs Normal</li></ul></li><li>exoRBase<ul><li>HCC vs Normal</li><li>PAAD vs Normal</li></ul></li><li>Scirep<ul><li>CRC vs Normal</li></ul></li></ul></li></ul><p>为了帮助读者确立思路，我们给出一个如下的<strong>示例性流程</strong>，以HCC peak数据为例</p><ul><li>Normalize domain coverage by total coverage of all domains (CPM), Normalize Top20 and others separately. </li><li>Scale each feature (log CPM) independently (using z-scores, min-max, robust normalization)</li><li>Run a classifier (random forest, logistic regression, linear SVM) to select features based on feature importance. Optimize hyper-parameters by 3-fold cross-validation.</li><li><strong>Optionally</strong>, use a recursive feature elimination(RFE).</li><li>Do resampling runs to select robust features:<ul><li>shuffle and split dataset and repeat feature selection for 100 times(shuffle split)</li><li>Or randomly test 1 sample in each run (leave one out).</li></ul></li><li>Select features that are recurrently selected across resampling runs (&gt;50%)</li><li>Refit the classifier on selected features</li></ul><p>以上步骤会挑出在<strong>resampling runs</strong>中出现频数超过总轮数一半的特征。其中第一步分别对top20 feature和其他feature做normalization，可以避免top20 feature对整体分布的影响，第二步读者可以尝试不同的对<strong>feature</strong>进行normalization的策略。第三步读者可以尝试不同的机器学习模型，并且在第四步选择是否使用<strong>RFE</strong>来逐步筛除feature。第五步是挑选稳健feature的关键，可以采取random split和leave one out两种方法，选择重复出现的稳健的feature。</p><p>读者可以设计自己的稳健的特征选择方法，请注意必须要体现出自己的方法的稳健性。</p><h3 id="模型效果分析"><a href="#模型效果分析" class="headerlink" title="模型效果分析"></a>模型效果分析</h3><ul><li>绘制挑选出的feature counts（经过适当的scale）的clustermap，用颜色块表示class。请参考<a href="#visfeature"><em>特征选择结果可视化</em></a>。</li><li>绘制二分类模型的ROC曲线，请注意本问题ROC曲线的特殊之处，具体细节请参考<a href="#roc"><em>用选出的feature进行分类并绘制ROC曲线</em></a>。</li><li>对比hcc数据的full length与peak在挑选出的feature以及分类的结果（ROC曲线）的差异，思考为什么会使用peak数据。</li></ul><h3 id="加分内容"><a href="#加分内容" class="headerlink" title="加分内容"></a>加分内容</h3><p>我们为有余力的读者设置了更多的挑战，完成相应的工作会有一定的加分</p><h4 id="更多模型效果分析-20’"><a href="#更多模型效果分析-20’" class="headerlink" title="更多模型效果分析 (20’)"></a>更多模型效果分析 (20’)</h4><ul><li>尝试减少feature数量（如1-10个feature），分析模型AUROC和ROC曲线。(5’)</li><li>针对不同数据中的同一种疾病，如exoRBase和HCC数据中的同一种疾病HCC，比较挑出的feature的异同。(5’)</li><li>比较挑出的feature，参考<a href="#comparefeature"><em>比较挑出的feature</em></a>部分。(10’)<ul><li>不同模型、不同数据挑出的feature的异同，可以使用Venn图、heatmap图等表示。</li><li>分析feature的鲁棒性，分析不同的条件设置（如模型超参数，scale方案，交叉验证方法）下被挑出的feature。</li></ul></li></ul><h4 id="预处理（30’）"><a href="#预处理（30’）" class="headerlink" title="预处理（30’）"></a>预处理（30’）</h4><p>此部分预处理数据不要求读者将处理后的数据再做整个的feature selection流程，只需要使用PCA/t-SNE可视化效果，并且使用我们提供的alignment score量化不同的scale方法的效果。以下问题只要求在<strong>hcc_peak数据和scirep数据</strong>上尝试即可。参考<a href="#preprocessing"><em>预处理部分教程</em></a></p><ul><li>尝试不同的scale方法（对样本），请参考<a href="#scalemethod"><em>不同的scale策略</em></a>部分<ul><li>使用内参基因对样本做normalization。(5’)</li><li>去掉piRNA，miRNA后再做normalization。(5’)</li><li>SCnorm, TMM等方法做normalization（需使用R）(10’)</li></ul></li><li>去除batch effect（需使用R） (10’)<br>尝试使用RUVs, combat等R package去除batch effect，并分析去除效果。</li></ul><h4 id="解释选出的feature（5’）"><a href="#解释选出的feature（5’）" class="headerlink" title="解释选出的feature（5’）"></a>解释选出的feature（5’）</h4><p>通过查阅文献，阐释挑选出的feature的生物学意义，尤其是研究所挑选出的feature是否被其他文献报道在相关癌症检测中起到作用。</p><h2 id="补充知识（选读）"><a href="#补充知识（选读）" class="headerlink" title="补充知识（选读）"></a>补充知识（选读）</h2><h3 id="通过alignment-score量化PCA和t-SNE可视化结果"><a href="#通过alignment-score量化PCA和t-SNE可视化结果" class="headerlink" title="通过alignment score量化PCA和t-SNE可视化结果"></a>通过alignment score量化PCA和t-SNE可视化结果</h3><p>PCA和t-SNE可以直观的看到样本目前的聚集程度，但是无法量化，尤其是不容易做比较，我们提供以下的两个函数<em>alignment_socre</em> &amp; <em>knn_score</em>分别量化二分类和多分类样本的聚集程度。数值越接近1说明同类样本越聚集。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">alignment_score</span><span class="params">(X, y, K=<span class="number">10</span>)</span>:</span></span><br><span class="line">    N = X.shape[<span class="number">0</span>]</span><br><span class="line">    nn = NearestNeighbors(K)</span><br><span class="line">    nn.fit(X)</span><br><span class="line">    distances, indices = nn.kneighbors(X, K + <span class="number">1</span>)</span><br><span class="line">    neighbor_classes = np.take(y, indices[:, <span class="number">1</span>:])</span><br><span class="line">    same_class_fractions = np.sum(neighbor_classes == y[:, np.newaxis], axis=<span class="number">1</span>)</span><br><span class="line">    score = <span class="number">1.0</span> - (np.mean(same_class_fractions) - K/N)/(K - K/N)</span><br><span class="line">    <span class="keyword">print</span> (same_class_fractions.shape,np.mean(same_class_fractions),K/N,neighbor_classes)</span><br><span class="line">    <span class="keyword">return</span> score</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">knn_score</span><span class="params">(X, y, K=<span class="number">10</span>)</span>:</span></span><br><span class="line">    N = X.shape[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">assert</span> K &lt; N</span><br><span class="line">    nn = NearestNeighbors(K)</span><br><span class="line">    nn.fit(X)</span><br><span class="line">    </span><br><span class="line">    distances, indices = nn.kneighbors(X, K + <span class="number">1</span>)</span><br><span class="line">    neighbor_classes = np.take(y, indices[:, <span class="number">1</span>:])</span><br><span class="line">    same_class_fractions = np.sum(neighbor_classes == y[:, np.newaxis], axis=<span class="number">1</span>)</span><br><span class="line">    </span><br><span class="line">    classes, counts = np.unique(y, return_counts=<span class="keyword">True</span>)</span><br><span class="line">    classes = np.argmax(y.reshape((<span class="number">-1</span>, <span class="number">1</span>)) == classes.reshape((<span class="number">1</span>, <span class="number">-1</span>)), axis=<span class="number">1</span>)</span><br><span class="line">    counts = np.take(counts, classes)</span><br><span class="line">    mean_r = K/(N - <span class="number">1</span>)*counts</span><br><span class="line">    max_r = np.minimum(K, counts)</span><br><span class="line">    <span class="comment">#print (same_class_fractions.shape,mean_r.shape,max_r.shape)</span></span><br><span class="line">    <span class="comment">#scores = (np.mean(same_class_fractions) - mean_r)/(max_r - mean_r)</span></span><br><span class="line">    scores = (same_class_fractions - mean_r)/(max_r - mean_r)</span><br><span class="line">    <span class="comment">#print(scores)</span></span><br><span class="line">    <span class="keyword">return</span> scores.mean()</span><br></pre></td></tr></table></figure><p>如下图所示，可以通过<em>knn_score</em>计算出以batch信息所谓label时scirep数据的alignment score。0.27996表示不同batch的分离程度比较差，基本混合在一起</p><p><img src="http://i1.fuimg.com/640680/ba37a834da15e1ee.png" alt="Markdown"></p><h3 id="基本统计"><a href="#基本统计" class="headerlink" title="基本统计"></a>基本统计</h3><h4 id="统计一套数据中不同RNA-type在不同样本的counts"><a href="#统计一套数据中不同RNA-type在不同样本的counts" class="headerlink" title="统计一套数据中不同RNA type在不同样本的counts"></a>统计一套数据中不同RNA type在不同样本的counts</h4><p><img src="http://i1.fuimg.com/640680/4eb6fea01e086051.png" alt="Markdown"></p><h4 id="统计某套数据中某种类型的RNA在不同样本中的counts数量。"><a href="#统计某套数据中某种类型的RNA在不同样本中的counts数量。" class="headerlink" title="统计某套数据中某种类型的RNA在不同样本中的counts数量。"></a>统计某套数据中某种类型的RNA在不同样本中的counts数量。</h4><p><img src="http://i1.fuimg.com/640680/1878901d4f1fc902.png" alt="Markdown"></p><h4 id="分析每个样本不同RNA所占的比例"><a href="#分析每个样本不同RNA所占的比例" class="headerlink" title="分析每个样本不同RNA所占的比例"></a>分析每个样本不同RNA所占的比例</h4><p><img src="http://i1.fuimg.com/640680/e8766d1d4eee4269.png" alt="Markdown"></p><p><img src="http://i1.fuimg.com/640680/fb6337ad852d4cd9.png" alt="Markdown"></p><h4 id="sample-QC"><a href="#sample-QC" class="headerlink" title="sample QC"></a>sample QC</h4><h5 id="QC-by-counts"><a href="#QC-by-counts" class="headerlink" title="QC by counts"></a>QC by counts</h5><p><img src="http://i1.fuimg.com/640680/1ee5270502206085.png" alt="Markdown"></p><h5 id="QC-by-PCA"><a href="#QC-by-PCA" class="headerlink" title="QC by PCA"></a>QC by PCA</h5><p><img src="http://i1.fuimg.com/640680/d3a6bbc7066c9c9b.jpg" alt="Markdown"></p><h4 id="top-k-feature"><a href="#top-k-feature" class="headerlink" title="top k feature"></a>top k feature</h4><p><img src="http://i1.fuimg.com/640680/938a85448344eab0.png" alt="Markdown"></p><h3 id="可视化结果"><a href="#可视化结果" class="headerlink" title="可视化结果"></a>可视化结果</h3><h4 id="特征选择结果可视化"><a href="#特征选择结果可视化" class="headerlink" title="特征选择结果可视化"></a>特征选择结果可视化</h4><p>使用seaborn的clustermap功能，将挑选出的feature的counts（做过合适的scale）绘制heatmap图并聚类，上方的颜色表示类别，可见同一类被很好的聚在了一起。</p><p><img src="http://i1.fuimg.com/640680/7f79f56b8863e3b1.png" alt="Markdown"></p><h4 id="用选出的feature进行分类并绘制ROC曲线"><a href="#用选出的feature进行分类并绘制ROC曲线" class="headerlink" title="用选出的feature进行分类并绘制ROC曲线"></a>用选出的feature进行分类并绘制ROC曲线</h4><p>请特别注意，这里的ROC曲线有其特殊之处。针对我们样本很少的问题，我们不能专门划分出一部分测试集供测试和绘制曲线。我们使用两种方式划分数据集：</p><ul><li>leave one out, 即每轮随机选择一个样本作为validation set，其他样本作为训练集，对validation set进行预测，最终保证每个样本恰好作为validation set一次。</li><li><p>shuffle split, 即每轮随机选择一些样本作为validation set，其他样本作为训练集，对validation set进行预测，最终每个样本可能在不同轮中一共被预测数次。</p></li><li><p>这样，对于leave one out方法，我们恰好可以将所有样本预测一遍，并绘制出ROC曲线，如下图所示。</p></li><li><p>而对于shuffle split方法，每个样本被预测多次，没法放在一起绘制ROC曲线，但是其每轮都可以单独画一条ROC曲线，下面的图片展示的即为“将各条曲线综合起来”的情况，我们使用阴影区域表示每个点的均值的置信区间。</p></li></ul><p><img src="http://i1.fuimg.com/640680/ae9e7f15b21fd387.png" alt="Markdown"></p><p><img src="http://i1.fuimg.com/640680/6698e9b7c214e49e.png" alt="Markdown"></p><h3 id="比较挑出的feature"><a href="#比较挑出的feature" class="headerlink" title="比较挑出的feature"></a>比较挑出的feature</h3><h4 id="比较不同的模型和参数挑出的feature的差异"><a href="#比较不同的模型和参数挑出的feature的差异" class="headerlink" title="比较不同的模型和参数挑出的feature的差异"></a>比较不同的模型和参数挑出的feature的差异</h4><p>图中有颜色的色块儿表示在该参数条件下被选中的feature，可以发现线性模型挑出的feature更相似，而random forest在不同参数设置下挑出的feature比较稳定。</p><p><img src="http://i1.fuimg.com/640680/1bb2387bf3fa532b.png" alt="Markdown"></p><h4 id="查看feature的鲁棒性"><a href="#查看feature的鲁棒性" class="headerlink" title="查看feature的鲁棒性"></a>查看feature的鲁棒性</h4><p>每一列是一轮测试，可以发现大多数feature在每轮测试中都被挑中，证明这些feature具有很强的鲁棒性，我们可以设置一个阈值，选取在超过50%的轮数中都出现的feature作为最终选择的feature。</p><p><img src="http://i1.fuimg.com/640680/89a22dce74aa130a.png" alt="Markdown"></p><h4 id="利用Venn图分析feature的重合"><a href="#利用Venn图分析feature的重合" class="headerlink" title="利用Venn图分析feature的重合"></a>利用Venn图分析feature的重合</h4><p>这里利用Venn图分析了HCC三种类型的数据（full length, peak, peak_iterative）的重合情况，每一个子图是一个模型。</p><p><img src="http://i1.fuimg.com/640680/88788932223f6d72.png" alt="Markdown"></p><h3 id="预处理部分教程"><a href="#预处理部分教程" class="headerlink" title="预处理部分教程"></a>预处理部分教程</h3><ul><li><a href="https://youngleebbs.gitbook.io/bioinfo-training/part-ii/4.-qc-and-normalization" target="_blank" rel="noopener">normalization</a></li><li><a href="https://youngleebbs.gitbook.io/bioinfo-training/part-ii/5.-imputation-and-confounders" target="_blank" rel="noopener">deal with confounders</a></li></ul><h4 id="不同的scale策略"><a href="#不同的scale策略" class="headerlink" title="不同的scale策略"></a>不同的scale策略</h4><h5 id="不同scale策略比较"><a href="#不同scale策略比较" class="headerlink" title="不同scale策略比较"></a>不同scale策略比较</h5><ul><li>使用CPM(counts per million)</li><li>或者使用可能的内参基因：’MIR1228’, ‘MIR16-1’, ‘MIR16-2’, ‘MIR21’, ‘MIR23A’, ‘MIR23B’, ‘MIR23C’,<pre><code> &#39;MIR451A&#39;, &#39;MIR15A&#39;, &#39;MIR15B&#39;进行scale。</code></pre></li><li>去除piRNA和miRNA后使用CPM(counts per million)</li></ul><p><img src="http://i1.fuimg.com/640680/36fc02c704c83c0a.png" alt="Markdown"></p><h5 id="内参基因的选择"><a href="#内参基因的选择" class="headerlink" title="内参基因的选择"></a>内参基因的选择</h5><p>我们可以绘制density plot或者violin plot来分析不同内参基因的变异系数，选择变异系数小的，比较稳定的miRNA作为内参。可以看到MIR1228, MIR15B的变异系数较大，不够稳定，不应该作为内参</p><p><img src="http://i1.fuimg.com/640680/35fcf6c9629d5d12.png" alt="Markdown"></p><p><img src="http://i1.fuimg.com/640680/5cd256a6b7e8e922.png" alt="Markdown"></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;This is one of the two course quizzes instruction of &lt;a href=&quot;https://lulab.gitbooks.io/teaching/content/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Bioinformatics basic course in Tsinghua University&lt;/a&gt;. You may also find it &lt;a href=&quot;https://lulab.gitbooks.io/teaching/content/quiz/quiz_exrna/quiz_exrna_tutorial.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The related &lt;a href=&quot;https://github.com/lulab/teaching_book/blob/master/quiz/quiz_exrna/quiz_exrna_tutorial.ipynb&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;jupyter file&lt;/a&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="school work" scheme="https://www.cmwonderland.com/blog/categories/school-work/"/>
    
    
      <category term="machine learning" scheme="https://www.cmwonderland.com/blog/tags/machine-learning/"/>
    
      <category term="python" scheme="https://www.cmwonderland.com/blog/tags/python/"/>
    
      <category term="bioinformatics" scheme="https://www.cmwonderland.com/blog/tags/bioinformatics/"/>
    
      <category term="teaching" scheme="https://www.cmwonderland.com/blog/tags/teaching/"/>
    
      <category term="TA" scheme="https://www.cmwonderland.com/blog/tags/TA/"/>
    
  </entry>
  
  <entry>
    <title>Machine Learning Basics Tutorial</title>
    <link href="https://www.cmwonderland.com/blog/2018/10/05/56_machine-learning-basics/"/>
    <id>https://www.cmwonderland.com/blog/2018/10/05/56_machine-learning-basics/</id>
    <published>2018-10-05T02:03:19.000Z</published>
    <updated>2019-04-23T13:07:13.886Z</updated>
    
    <content type="html"><![CDATA[<p>This is one of the chapter in <a href="https://lulab.gitbooks.io/teaching/content/" target="_blank" rel="noopener">Bioinformatics basic course in Tsinghua University</a>. You may also find it <a href="https://lulab.gitbooks.io/teaching/content/part-iii.-machine-learning-basics/1.simple-machine-learning-basics.html" target="_blank" rel="noopener">here</a></p><p>The related <a href="https://github.com/lulab/teaching_book/blob/master/part-iii.-machine-learning-basics/1.simple-machine-learning-basics.ipynb" target="_blank" rel="noopener">jupyter file</a></p><a id="more"></a><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>Machine learning studies how to learn patterns from data and predict characteristics of unknown data.</p><p>According whether the predicted variable is known, machine learning generally fall into two categories:<br>supervised learning and unsupervised learning.</p><p>In supervised learning, the model takes features and class labels<br>or targer values as input to build the model. If the target variable (the variable to predict) is a<br>categorical (e.g. positive/negative), the problem is called classification. If the target variable is<br>continuous (e.g. height), the problem is called regression. Most supervised learning problems fall into<br>these two categories, however, combination of continous output and categorical output or structured output<br>are also possible.</p><p>In unsupervised learning, the target variables are not specified. The objective is to identify internal<br>structures (clusters) of the data. After model fitting, we can assign new samples to clusters or generate<br>samples with similar distribution as the original data. Unsupervised learning are also useful as<br>a data preprocessing step prior to supervised learning.</p><h2 id="Import-data"><a href="#Import-data" class="headerlink" title="Import data"></a>Import data</h2><p>Datasets for machine learning can be loaded from a variety of souces.<br>Tabular data can be loaded through the <a href="https://pandas.pydata.org" target="_blank" rel="noopener"><em>pandas</em></a> package in various formats:</p><div class="table-container"><table><thead><tr><th>Format Type</th><th>Data Description</th><th>Reader</th><th>Writer</th></tr></thead><tbody><tr><td>text</td><td>CSV</td><td><a href="https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html" target="_blank" rel="noopener">pandas.read_csv</a></td><td><a href="https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.to_csv.html" target="_blank" rel="noopener">pandas.to_csv</a></td></tr><tr><td>text</td><td>JSON</td><td><a href="https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_json.html" target="_blank" rel="noopener">pandas.read_json</a></td><td><a href="https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.to_json.html" target="_blank" rel="noopener">pandas.to_json</a></td></tr><tr><td>text</td><td>HTML</td><td><a href="https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_html.html" target="_blank" rel="noopener">pandas.read_html</a></td><td><a href="https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.to_html.html" target="_blank" rel="noopener">pandas.to_html</a></td></tr><tr><td>text</td><td>Local clipboard</td><td><a href="https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_clipboard.html" target="_blank" rel="noopener">pandas.read_clipboard</a></td><td><a href="https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.to_clipboard.html" target="_blank" rel="noopener">pandas.to_clipboard</a></td></tr><tr><td>binary</td><td>MS Excel</td><td><a href="https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_excel.html" target="_blank" rel="noopener">pandas.read_excel</a></td><td><a href="https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.to_excel.html" target="_blank" rel="noopener">pandas.to_excel</a></td></tr><tr><td>binary</td><td>HDF5 Format</td><td><a href="https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_hdf.html" target="_blank" rel="noopener">pandas.read_hdf</a></td><td><a href="https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.to_hdf.html" target="_blank" rel="noopener">pandas.to_hdf</a></td></tr></tbody></table></div><p>You can refer to <a href="https://pandas.pydata.org/pandas-docs/stable/io.html" target="_blank" rel="noopener">Pandas IO Tools</a><br>for more usage of data importing using <em>pandas</em>.</p><p>For large datasets, it is recommended to use binary formats such as <em>HDF5</em> and <em>NPZ</em> for more efficient reading and writing and also reducing disk usage.</p><p>HDF5 format can be read to or write from numpy arrays conveniently using the <a href="http://docs.h5py.org/en/stable/" target="_blank" rel="noopener">h5py</a> package:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> h5py</span><br><span class="line"><span class="comment"># read data assuming that datasets 'X' and 'y' exists in HDF5 file input_file</span></span><br><span class="line"><span class="keyword">with</span> h5py.File(input_file, <span class="string">'r'</span>) <span class="keyword">as</span> f:</span><br><span class="line">    X = f[<span class="string">'X'</span>][:]</span><br><span class="line">    y = f[<span class="string">'y'</span>][:]</span><br><span class="line"><span class="comment"># write data to HDF5 file output_file</span></span><br><span class="line"><span class="comment"># X and y are numpy arrays</span></span><br><span class="line"><span class="keyword">with</span> h5py.File(output_file, <span class="string">'w'</span>) <span class="keyword">as</span> f:</span><br><span class="line">    f.create_dataset(<span class="string">'X'</span>, data=X)</span><br><span class="line">    f.create_dataset(<span class="string">'y'</span>, data=y)</span><br></pre></td></tr></table></figure><p><em>NPZ</em> format is <a href="https://docs.scipy.org/doc/numpy/reference/routines.io.html" target="_blank" rel="noopener">native format</a> for numpy. <em>NPZ/NPY</em> format can be read from file using <a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.load.html#numpy.load" target="_blank" rel="noopener">numpy.load</a> and<br>write to file using <a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.save.html#numpy.save" target="_blank" rel="noopener">numpy.save</a><br>or <a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.savez.html#numpy.savez" target="_blank" rel="noopener">numpy.savez</a>.</p><h2 id="Import-required-Python-packages"><a href="#Import-required-Python-packages" class="headerlink" title="Import required Python packages"></a>Import required Python packages</h2><p>Documentation for required Python packages:</p><ul><li><a href="https://docs.scipy.org/doc/numpy/" target="_blank" rel="noopener">numpy</a>: arrays</li><li><a href="https://pandas.pydata.org/" target="_blank" rel="noopener">pandas</a>: data IO, DataFrame</li><li><a href="https://imbalanced-learn.readthedocs.io/en/stable" target="_blank" rel="noopener">imbalanced-learn</a>: deal with class imbalance</li><li><a href="http://scikit-learn.org/" target="_blank" rel="noopener">scikit-learn</a>: machine learning</li><li><a href="https://www.statsmodels.org/" target="_blank" rel="noopener">statsmodels</a>: statistical functions</li><li><a href="https://matplotlib.org/" target="_blank" rel="noopener">matplotlib</a>: plotting</li><li><a href="https://matplotlib.org/" target="_blank" rel="noopener">seaborn</a>: high-level plotting based on <em>matplotlib</em></li><li><a href="https://jupyter.org/" target="_blank" rel="noopener">jupyter</a>: Python notebook</li><li><a href="https://rasbt.github.io/mlxtend" target="_blank" rel="noopener">mlxtend</a>: Extension of scikit-learn</li><li><a href="https://graphviz.readthedocs.io/en/stable/" target="_blank" rel="noopener">graphviz</a>: Python binding for Graphviz graph drawing software</li><li><a href="http://docs.wand-py.org/en/0.4.4/" target="_blank" rel="noopener">wand</a>: ImageMagick (image processing tool) binding for Python</li></ul><p>For Jupyter Notebook users, run the following magic command to display images inline.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># This is a magic funtion in IPython/Jupyter that import many functions and modules</span></span><br><span class="line"><span class="comment"># from matplotlib, numpy, scipy, which is roughly equivalent to:</span></span><br><span class="line"><span class="comment"># </span></span><br><span class="line"><span class="comment"># import numpy as np</span></span><br><span class="line"><span class="comment"># import numpy.ma as ma</span></span><br><span class="line"><span class="comment"># import matplotlib as mpl</span></span><br><span class="line"><span class="comment"># from matplotlib import cbook, mlab, pyplot as plt</span></span><br><span class="line"><span class="comment"># from matplotlib.pyplot import *</span></span><br><span class="line"><span class="comment"># from numpy import *</span></span><br><span class="line"><span class="comment"># from numpy.fft import *</span></span><br><span class="line"><span class="comment"># from numpy.random import *</span></span><br><span class="line"><span class="comment"># from numpy.linalg import *</span></span><br><span class="line">%pylab inline</span><br></pre></td></tr></table></figure><pre><code>Populating the interactive namespace from numpy and matplotlib</code></pre><p>If you run Python/IPython interactively or in a script, please run the following code instead.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pylab <span class="keyword">import</span> *</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> defaultdict</span><br><span class="line"><span class="comment"># For data importing</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="comment"># For machine learning</span></span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> make_classification, make_regression, make_circles, make_moons, make_gaussian_quantiles</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> KMeans</span><br><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> SVC, LinearSVC</span><br><span class="line"><span class="keyword">from</span> sklearn.gaussian_process <span class="keyword">import</span> GaussianProcessClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> PCA</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> KFold, train_test_split, GridSearchCV, cross_val_score</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score, roc_auc_score, f1_score, recall_score, precision_score, \</span><br><span class="line">    roc_curve, precision_recall_curve, average_precision_score, matthews_corrcoef, confusion_matrix</span><br><span class="line"><span class="keyword">from</span> statsmodels.robust.scale <span class="keyword">import</span> mad</span><br><span class="line"><span class="comment"># For plotting</span></span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line">sns.set()</span><br><span class="line">sns.set_style(<span class="string">'whitegrid'</span>)</span><br><span class="line"><span class="keyword">from</span> matplotlib.colors <span class="keyword">import</span> to_hex</span><br></pre></td></tr></table></figure><h2 id="Initialize-random-seed"><a href="#Initialize-random-seed" class="headerlink" title="Initialize random seed"></a>Initialize random seed</h2><p>We fix the random seed of numpy in this tutorial to make the results reproducible.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">random_state = np.random.RandomState(<span class="number">1289237</span>)</span><br></pre></td></tr></table></figure><h2 id="Generate-datasets"><a href="#Generate-datasets" class="headerlink" title="Generate datasets"></a>Generate datasets</h2><p>You can start with simple datasets that is easy to understand and visualize before handling realistic datasets.<br><em>scikit-learn</em> provides many functions (<a href="http://scikit-learn.org/stable/modules/classes.html#module-sklearn.datasets" target="_blank" rel="noopener">sklearn.datasets</a>) for generating datasets easily.</p><h3 id="Classification-dataset"><a href="#Classification-dataset" class="headerlink" title="Classification dataset"></a>Classification dataset</h3><p>For example, <a href="http://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html#sklearn.datasets.make_classification" target="_blank" rel="noopener">sklearn.datasets.make_classification</a> generates samples from a mixture of Gaussian distributions with parameters to specify the number of classes,<br>number of features, number of classes, etc. The following example generate a two-class classification dataset of 1000 samples with 2 features for visualization. Samples are generated from two independent 2D Gaussian distributions. This dataset is suitable for linear classifier.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">X, y = make_classification(n_samples=<span class="number">1000</span>, n_classes=<span class="number">2</span>, n_features=<span class="number">2</span>,</span><br><span class="line">                           n_informative=<span class="number">2</span>, n_redundant=<span class="number">0</span>, n_clusters_per_class=<span class="number">1</span>,</span><br><span class="line">                           random_state=random_state, class_sep=<span class="number">0.9</span>)</span><br><span class="line">fig, ax = plt.subplots(figsize=(<span class="number">7</span>, <span class="number">7</span>))</span><br><span class="line"><span class="keyword">for</span> label <span class="keyword">in</span> np.unique(y):</span><br><span class="line">    ax.scatter(X[y == label, <span class="number">0</span>], X[y == label, <span class="number">1</span>], s=<span class="number">10</span>, label=str(label))</span><br><span class="line">ax.legend(title=<span class="string">'Class'</span>)</span><br></pre></td></tr></table></figure><p><img src="http://i1.fuimg.com/640680/d09e1bae36643858.png" alt="Markdown"></p><h3 id="Regression-dataset"><a href="#Regression-dataset" class="headerlink" title="Regression dataset"></a>Regression dataset</h3><p>You can also use <a href="http://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_regression.html" target="_blank" rel="noopener">make_regression</a> to generate a simple regression dataset.<br>The following dataset consists of 1000 samples with 1 feature and 1 response variable. A Gaussian noise 10 is added to each response variable.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">X, y = make_regression(n_samples=<span class="number">1000</span>, n_features=<span class="number">1</span>, n_informative=<span class="number">1</span>, noise=<span class="number">10</span>, random_state=random_state)</span><br><span class="line">fig, ax = plt.subplots(figsize=(<span class="number">7</span>, <span class="number">7</span>))</span><br><span class="line">ax.scatter(X[:, <span class="number">0</span>], y, s=<span class="number">5</span>, label=str(label))</span><br><span class="line">ax.set_xlabel(<span class="string">'X'</span>)</span><br><span class="line">ax.set_ylabel(<span class="string">'y'</span>)</span><br></pre></td></tr></table></figure><p><img src="http://i1.fuimg.com/640680/5f2d9d3ef2c4ed55.png" alt="Markdown"></p><h3 id="Specialized-datasets"><a href="#Specialized-datasets" class="headerlink" title="Specialized datasets"></a>Specialized datasets</h3><p><em>scikit-learn</em> also provides sample generators for specialized classification/regression/clustering problems, e.g.<br><a href="http://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_circles.html" target="_blank" rel="noopener">make_circles</a>,<br><a href="http://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_moons.html" target="_blank" rel="noopener">make_moons</a>,<br><a href="http://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_gaussian_quantiles.html" target="_blank" rel="noopener">make_gaussian_quantiles</a>.<br>These datasets can be used to demonstrate cases where simple classifier or clustering algorithms don’t work but<br>non-linear and more complicated algorithms work better.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">fig, axes = plt.subplots(<span class="number">1</span>, <span class="number">3</span>, figsize=(<span class="number">16</span>, <span class="number">5</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i, f <span class="keyword">in</span> enumerate((make_circles, make_moons, make_gaussian_quantiles)):</span><br><span class="line">    <span class="keyword">if</span> f == make_gaussian_quantiles:</span><br><span class="line">        X, y = f(n_samples=<span class="number">1000</span>, random_state=random_state)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        X, y = f(n_samples=<span class="number">1000</span>, noise=<span class="number">0.03</span>,</span><br><span class="line">                 random_state=random_state)</span><br><span class="line">    <span class="keyword">for</span> label <span class="keyword">in</span> np.unique(y):</span><br><span class="line">        axes[i].scatter(X[y == label, <span class="number">0</span>], X[y == label, <span class="number">1</span>], s=<span class="number">5</span>, label=str(label))</span><br><span class="line">    axes[i].legend(title=<span class="string">'Class'</span>)</span><br><span class="line">    axes[i].set_title(f.__name__)</span><br></pre></td></tr></table></figure><p><img src="http://i1.fuimg.com/640680/dba0499f4483b826.png" alt="Markdown"></p><h3 id="The-digits-dataset"><a href="#The-digits-dataset" class="headerlink" title="The digits dataset"></a>The <em>digits</em> dataset</h3><p><em>scikit-learn</em> also includes some commonly used public datasets that is useful for exploring machine learning algorithms in the package. For example, the <em>digits</em> dataset is a small handwriting image dataset of 10 digits.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_digits</span><br><span class="line"></span><br><span class="line">X, y = load_digits(return_X_y=<span class="keyword">True</span>)</span><br><span class="line">fig, ax = plt.subplots(figsize=(<span class="number">10</span>, <span class="number">11</span>))</span><br><span class="line">data = np.swapaxes(X[:<span class="number">16</span>].reshape((<span class="number">-1</span>, <span class="number">8</span>, <span class="number">8</span>)), <span class="number">0</span>, <span class="number">1</span>).reshape((<span class="number">8</span>, <span class="number">-1</span>))</span><br><span class="line"><span class="keyword">with</span> plt.rc_context(&#123;<span class="string">'axes.grid'</span>: <span class="keyword">False</span>&#125;):</span><br><span class="line">    ax.imshow(data, cmap=<span class="string">'Greys'</span>)</span><br><span class="line">ax.set_axis_off()</span><br></pre></td></tr></table></figure><p><img src="http://i1.fuimg.com/640680/2a3087cba4cad1de.png" alt="Markdown"></p><h3 id="Dataset-used-in-this-tutorial"><a href="#Dataset-used-in-this-tutorial" class="headerlink" title="Dataset used in this tutorial"></a>Dataset used in this tutorial</h3><p>We use <em>sklearn.datasets.make_classification</em> to generate a dataset with 2 features</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">X, y = make_classification(n_samples=<span class="number">1000</span>, n_classes=<span class="number">2</span>, n_features=<span class="number">4</span>,</span><br><span class="line">                           n_informative=<span class="number">2</span>, n_redundant=<span class="number">0</span>, n_clusters_per_class=<span class="number">1</span>,</span><br><span class="line">                           class_sep=<span class="number">0.9</span>, random_state=random_state)</span><br></pre></td></tr></table></figure><h2 id="Single-feature-analysis"><a href="#Single-feature-analysis" class="headerlink" title="Single feature analysis"></a>Single feature analysis</h2><h3 id="Analyze-the-separability-of-classes-using-individual-features"><a href="#Analyze-the-separability-of-classes-using-individual-features" class="headerlink" title="Analyze the separability of classes using individual features"></a>Analyze the separability of classes using individual features</h3><p>Plot the distribution of feature values of each feature. A good feature should separate the two class well.<br>The following plot shows that each individual feature can largely separate the two classes, though not perfectly.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">fig, axes = plt.subplots(<span class="number">1</span>, X.shape[<span class="number">1</span>], figsize=(<span class="number">15</span>, <span class="number">4</span>))</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(X.shape[<span class="number">1</span>]):</span><br><span class="line">    <span class="keyword">for</span> label <span class="keyword">in</span> (<span class="number">0</span>, <span class="number">1</span>):</span><br><span class="line">        sns.kdeplot(X[y == label, i], label=str(label), ax=axes[i])</span><br><span class="line">    axes[i].legend(title=<span class="string">'class'</span>)</span><br><span class="line">    axes[i].set_xlabel(<span class="string">'Feature x[&#123;&#125;]'</span>.format(i))</span><br><span class="line">    axes[i].set_ylabel(<span class="string">'Density'</span>)</span><br></pre></td></tr></table></figure><p><img src="http://i1.fuimg.com/640680/1e71af3fee869e60.png" alt="Markdown"></p><h3 id="Feature-correlation-analysis"><a href="#Feature-correlation-analysis" class="headerlink" title="Feature correlation analysis"></a>Feature correlation analysis</h3><p>Sometimes highly correlated features may be detrimental to model performance and feature selection.<br>A redundant feature does not provide more information, but introduces extra parameters to the model to make<br>the model prone to overfitting. For feature selection, the model may assign a small weight to each redundant features<br>too many redundant features may dilute the contribution of individual features. Although the impact of<br>redundant features on model performance depends on the machine learning algorithm used,<br>it is a good practice to identify these features and remove/merge redundant features.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">data = pd.DataFrame(X, columns=[<span class="string">'x[&#123;&#125;]'</span>.format(i) <span class="keyword">for</span> i <span class="keyword">in</span> range(X.shape[<span class="number">1</span>])])</span><br><span class="line">data.loc[:, <span class="string">'classes'</span>] = y.astype(<span class="string">'U'</span>)</span><br><span class="line">g = sns.PairGrid(data, hue=<span class="string">'classes'</span>, vars=[<span class="string">'x[&#123;&#125;]'</span>.format(i) <span class="keyword">for</span> i <span class="keyword">in</span> range(X.shape[<span class="number">1</span>])])</span><br><span class="line">g.map_offdiag(plt.scatter, s=<span class="number">3</span>)</span><br><span class="line">g.map_diag(sns.kdeplot)</span><br><span class="line">g.add_legend()</span><br></pre></td></tr></table></figure><p><img src="http://i1.fuimg.com/640680/507c87a5d099b80e.png" alt="Markdown"></p><h2 id="PCA-analysis"><a href="#PCA-analysis" class="headerlink" title="PCA analysis"></a>PCA analysis</h2><p>A dataset with more than 3 features cannot be visualized directly. We can use dimension reduction<br>to embed the data on a 2D or 3D space. A dimension reduction algorithm maps data points in high dimension to low<br>dimension while preserve distance in their original space as well as possible.</p><p>Principal Component Analysis (PCA) is the most common algorithm for dimension reduction.<br>It maps data to a new space by linear combination of original features such that new features are linearly<br>independent and the total variance is maximized.</p><p>If samples can be separated well in a PCA plot, a linear classifier also works well. Otherwise,<br>a non-linear classifier may improve classification performance.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">X_scaled = StandardScaler().fit_transform(X)</span><br><span class="line">pca = PCA()</span><br><span class="line">X_pca = pca.fit_transform(X)</span><br><span class="line">fig, axes = plt.subplots(<span class="number">1</span>, <span class="number">2</span>, figsize=(<span class="number">15</span>, <span class="number">8</span>))</span><br><span class="line">axes[<span class="number">0</span>].plot(np.arange(<span class="number">0.5</span>, X.shape[<span class="number">1</span>] + <span class="number">0.5</span>), pca.explained_variance_ratio_, marker=<span class="string">'o'</span>)</span><br><span class="line">axes[<span class="number">0</span>].set_xticks(np.arange(<span class="number">0.5</span>, X.shape[<span class="number">1</span>] + <span class="number">0.5</span>))</span><br><span class="line">axes[<span class="number">0</span>].set_xticklabels(np.arange(<span class="number">1</span>, X.shape[<span class="number">1</span>] + <span class="number">1</span>))</span><br><span class="line">axes[<span class="number">0</span>].set_xlabel(<span class="string">'PC rank'</span>)</span><br><span class="line">axes[<span class="number">0</span>].set_ylabel(<span class="string">'Explained variance ratio'</span>)</span><br><span class="line">axes[<span class="number">0</span>].set_ylim(<span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">axes[<span class="number">0</span>].set_xlim(<span class="number">0</span>, X.shape[<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> label <span class="keyword">in</span> np.unique(y):</span><br><span class="line">    axes[<span class="number">1</span>].scatter(X_pca[y == label, <span class="number">0</span>], X_pca[y == label, <span class="number">1</span>], label=label, s=<span class="number">10</span>)</span><br><span class="line">axes[<span class="number">1</span>].set_xlabel(<span class="string">'PC1 (&#123;:.02f&#125;%)'</span>.format(pca.explained_variance_ratio_[<span class="number">0</span>]*<span class="number">100</span>))</span><br><span class="line">axes[<span class="number">1</span>].set_ylabel(<span class="string">'PC2 (&#123;:.02f&#125;%)'</span>.format(pca.explained_variance_ratio_[<span class="number">1</span>]*<span class="number">100</span>))</span><br></pre></td></tr></table></figure><p><img src="http://i1.fuimg.com/640680/4872a27f6929443d.png" alt="Markdown"></p><h2 id="Data-scaling"><a href="#Data-scaling" class="headerlink" title="Data scaling"></a>Data scaling</h2><p>For most machine learning algorithms, it is recommended to scale the features to a common small scale.<br>Features of large or small scale increase the risk of numerical instability and also make the loss function<br>harder to optimize. Feature selection based on fitted coefficients of a linear model assumes that the input<br>features are in the same scale. Performance and convergence speed of gradient-based algorithms<br>such as neural networks are largely degraded if the data is not properly scaled.<br>Decision tree and random forest, however,<br>are less sensitive to data scale because they use rule-based criteria.</p><p>Common data scaling methods include standard/z-score scaling, min-max scaling, robust scaling and abs-max scaling.</p><p>Standard/z-score scaling first shift features to their centers(mean) and then divide by their standard deviation.<br>This method is suitable for most continous features of approximately Gaussian distribution.</p><script type="math/tex; mode=display">\text{zscore}(x_{ij}^{'}) = \frac{x_{ij} - \mu _{ij}}{\sigma _i}</script><p>Min-max scaling method scales data into range [0, 1].<br>This method is suitable for data concentrated within a range and preserves zero values for sparse data.<br>Min-max scaling is also sensitive to outliers in the data. Try removing outliers or clip data into<br>a range before scaling.</p><script type="math/tex; mode=display">\text{min_max}(x_{ij}^{'}) = \frac{x_{ij} - \text{min}_k \mathbf{x}_{ik}}{\text{max}_k x_{ik} - \text{min}_k x_{ik}}</script><p>Max-abs scaling method is similar to min-max scaling, but scales data into range [-1, 1].<br>It does not shift/center the data and thus preserves signs (positive/negative) of features.<br>Like min-max, max-abs is sensitive to outliers.</p><script type="math/tex; mode=display">\text{max_abs}(x_{ij}^{'}) = \frac{x_{ij}}{\text{max}_k \vert x_{ik} \vert}</script><p>Robust scaling method use robust statistics (median, interquartile range) instead of mean and standard deviation.<br>Median and IQR are less sensitive to outliers.<br>For features with large numbers of outliers or largely deviates from normal distribution,<br>robust scaling is recommended.</p><script type="math/tex; mode=display">\text{robust_scale}(x_{ij}^{'}) = \frac{x_{ij} - \text{median}_k x_{ik}}{Q_{0.75}(\mathbf{x}_i) - Q_{0.25}(\mathbf{x}_i)}</script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">x = random_state.normal(<span class="number">10</span>, <span class="number">2</span>, size=<span class="number">1000</span>)</span><br><span class="line">fig, ax = plt.subplots(figsize=(<span class="number">8</span>, <span class="number">6</span>))</span><br><span class="line">sns.distplot(x, ax=ax)</span><br><span class="line">sns.distplot(np.ravel(StandardScaler().fit_transform(x.reshape((<span class="number">-1</span>, <span class="number">1</span>)))), ax=ax)</span><br></pre></td></tr></table></figure><p><img src="http://i1.fuimg.com/640680/6496c7878223c8e0.png" alt="Markdown"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Generate features with different distribution</span></span><br><span class="line">x = np.zeros((<span class="number">1000</span>, <span class="number">4</span>))</span><br><span class="line">x[:, <span class="number">0</span>] = random_state.normal(<span class="number">10</span>, <span class="number">2</span>, size=x.shape[<span class="number">0</span>])</span><br><span class="line">x[:, <span class="number">1</span>] = random_state.gamma(shape=<span class="number">3</span>, scale=<span class="number">4</span>, size=x.shape[<span class="number">0</span>])</span><br><span class="line">x[:, <span class="number">2</span>] = random_state.poisson(<span class="number">5</span>, size=x.shape[<span class="number">0</span>])</span><br><span class="line">x[:, <span class="number">3</span>] = random_state.uniform(<span class="number">-3</span>, <span class="number">6</span>, size=x.shape[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler, MinMaxScaler, MaxAbsScaler, RobustScaler</span><br><span class="line">scalers = &#123;</span><br><span class="line">    <span class="string">'Standard'</span>: StandardScaler(),</span><br><span class="line">    <span class="string">'MinMax'</span>: MinMaxScaler(),</span><br><span class="line">    <span class="string">'MaxAbs'</span>: MaxAbsScaler(),</span><br><span class="line">    <span class="string">'Robust'</span>: RobustScaler()</span><br><span class="line">&#125;</span><br><span class="line">fig, axes = plt.subplots(<span class="number">5</span>, x.shape[<span class="number">1</span>], figsize=(<span class="number">16</span>, <span class="number">20</span>))</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(x.shape[<span class="number">1</span>]):</span><br><span class="line">    sns.distplot(x[:, i], ax=axes[<span class="number">0</span>, i])</span><br><span class="line">    axes[<span class="number">0</span>, i].set_title(<span class="string">'Original feature &#123;&#125;'</span>.format(i + <span class="number">1</span>))</span><br><span class="line"><span class="keyword">for</span> j, scaler_name <span class="keyword">in</span> enumerate(scalers.keys()):</span><br><span class="line">    x_scaled = scalers[scaler_name].fit_transform(x)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(x.shape[<span class="number">1</span>]):</span><br><span class="line">        sns.distplot(x_scaled[:, i], ax=axes[j + <span class="number">1</span>, i])</span><br><span class="line">        axes[j + <span class="number">1</span>, i].set_title(<span class="string">'&#123;&#125; for feature &#123;&#125;'</span>.format(scaler_name, i + <span class="number">1</span>))</span><br></pre></td></tr></table></figure><p><img src="http://i1.fuimg.com/640680/b1dcf9d78e4a221f.png" alt="Markdown"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">X = StandardScaler().fit_transform(X)</span><br></pre></td></tr></table></figure><h2 id="Split-data-into-training-and-test-set"><a href="#Split-data-into-training-and-test-set" class="headerlink" title="Split data into training and test set"></a>Split data into training and test set</h2><p>We should split the dataset into a training and test set to evaluate model performance.<br>During model training, the model overfits to the data to some extent, and so model performance<br>on the training set is generally biases and higher than on the test set. The overfitting issue<br>can be resolved by adding more independent samples to the dataset. The difference of training<br>and test performance decreases with the increase of sample size.</p><p>Here, we use <a href="http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html" target="_blank" rel="noopener">train_test_split</a><br>to randomly set 80% of the samples as training set and 20% as test set.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.2</span>, random_state=random_state)</span><br><span class="line">print(<span class="string">'number of training samples: &#123;&#125;, test samples: &#123;&#125;'</span>.format(X_train.shape[<span class="number">0</span>], X_test.shape[<span class="number">0</span>]))</span><br></pre></td></tr></table></figure><pre><code>number of training samples: 800, test samples: 200</code></pre><h2 id="Train-the-model"><a href="#Train-the-model" class="headerlink" title="Train the model"></a>Train the model</h2><p>During model training, the parameters of the model is adjusted to minimize a loss function.</p><h3 id="Logistic-regression"><a href="#Logistic-regression" class="headerlink" title="Logistic regression"></a>Logistic regression</h3><p>Logistic regression is a linear model for classification. It first forms linear combination of input features<br>and then map the combined value to class probability between 0 and 1 through a non-linear sigmoid function.<br>During model training, the weights of the model are adjusted such that the cross-entropy between model prediction<br>and true labels is minimized.</p><script type="math/tex; mode=display">p(y_i | \mathbf{x}_i) = \frac{1}{1 + \text{exp} \left( \sum_{j=1}^M x_{ij} w_{j} + b \right)}</script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model = LogisticRegression()</span><br><span class="line">_ = model.fit(X_train, y_train)</span><br></pre></td></tr></table></figure><h2 id="Model-inspection"><a href="#Model-inspection" class="headerlink" title="Model inspection"></a>Model inspection</h2><h3 id="Feature-importance"><a href="#Feature-importance" class="headerlink" title="Feature importance"></a>Feature importance</h3><p>For linear models (e.g. Logistic regression, linear regression, linear SVM), feature importance<br>is usually defined as the square of coefficients:</p><script type="math/tex; mode=display">\text{FeatureImportance}_j = w_{j}^2</script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">fig, ax = plt.subplots(figsize=(<span class="number">4</span>, <span class="number">4</span>))</span><br><span class="line">feature_importance = np.square(np.ravel(model.coef_))</span><br><span class="line">ax.bar(np.arange(<span class="number">1</span>, X.shape[<span class="number">1</span>] + <span class="number">1</span>).astype(<span class="string">'U'</span>), feature_importance)</span><br><span class="line">ax.set_xlabel(<span class="string">'Feature'</span>)</span><br><span class="line">_ = ax.set_ylabel(<span class="string">'Feature importance'</span>)</span><br></pre></td></tr></table></figure><p><img src="http://i1.fuimg.com/640680/1504d9deddec2451.png" alt="Markdown"></p><h3 id="Decision-boundary"><a href="#Decision-boundary" class="headerlink" title="Decision boundary"></a>Decision boundary</h3><p>We can inspect decision boundaries of a model by predict class labels on a 2D grid of sample points.<br>You can see that the decision boundary of Logistic regression is a straight line while other classifiers<br>create non-linear and irregular decision boundaries.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">X_grid, Y_grid = np.mgrid[<span class="number">-5</span>:<span class="number">5</span>:<span class="number">0.1</span>, <span class="number">-5</span>:<span class="number">5</span>:<span class="number">0.1</span>]</span><br><span class="line">fig, axes = plt.subplots(<span class="number">2</span>, <span class="number">3</span>, figsize=(<span class="number">15</span>, <span class="number">10</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> matplotlib.colors <span class="keyword">import</span> ListedColormap</span><br><span class="line">cmap = sns.diverging_palette(<span class="number">252</span>, <span class="number">17</span>, n=<span class="number">2</span>)</span><br><span class="line">cmap = ListedColormap(cmap)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Use top 2 features</span></span><br><span class="line">selected_features = np.argsort(-feature_importance)[:<span class="number">2</span>]</span><br><span class="line"><span class="keyword">for</span> n, model_class <span class="keyword">in</span> enumerate((LogisticRegression, SVC,</span><br><span class="line">                                 DecisionTreeClassifier, KNeighborsClassifier,</span><br><span class="line">                                 GaussianProcessClassifier, RandomForestClassifier)):</span><br><span class="line">    i, j = n//<span class="number">3</span>, n%<span class="number">3</span></span><br><span class="line">    model_n = model_class()</span><br><span class="line">    model_n.fit(X_train[:, selected_features], y_train)</span><br><span class="line">    labels_grid = model_n.predict(np.column_stack([np.ravel(X_grid), np.ravel(Y_grid)]))</span><br><span class="line">    </span><br><span class="line">    axes[i, j].pcolor(X_grid, Y_grid, labels_grid.reshape(X_grid.shape), </span><br><span class="line">                          cmap=cmap, linewidth=<span class="number">0</span>, edgecolor=<span class="string">'face'</span>, alpha=<span class="number">0.3</span>)</span><br><span class="line">    axes[i, j].set_title(model_class.__name__)</span><br><span class="line">    <span class="keyword">for</span> label <span class="keyword">in</span> np.unique(y):</span><br><span class="line">        axes[i, j].scatter(X_train[y_train == label, selected_features[<span class="number">0</span>]],</span><br><span class="line">                           X_train[y_train == label, selected_features[<span class="number">1</span>]],</span><br><span class="line">                           s=<span class="number">3</span>, label=str(label))</span><br><span class="line">    axes[i, j].legend(title=<span class="string">'class'</span>)</span><br></pre></td></tr></table></figure><p><img src="http://i1.fuimg.com/640680/6b9145218cefa02b.png" alt="Markdown"></p><h2 id="Evaluate-the-model"><a href="#Evaluate-the-model" class="headerlink" title="Evaluate the model"></a>Evaluate the model</h2><h3 id="Predict-labels-on-the-test-dataset"><a href="#Predict-labels-on-the-test-dataset" class="headerlink" title="Predict labels on the test dataset"></a>Predict labels on the test dataset</h3><p>To evaluate performance of the model, we use the <em>predict</em> method of the estimator<br>to predict class labels of test data. This will return an integer array indicating class labels.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">y_pred = model.predict(X_test)</span><br></pre></td></tr></table></figure><h3 id="Confusion-matrix"><a href="#Confusion-matrix" class="headerlink" title="Confusion matrix"></a>Confusion matrix</h3><p>The most common way to evaluate classification performance is to construct a<br><a href="https://en.wikipedia.org/wiki/Confusion_matrix" target="_blank" rel="noopener">confusion matrix</a>.</p><p>A confusion matrix summarizes the number of correctly or wrongly predicted samples and is usually<br>made up of four entries:</p><div class="table-container"><table><thead><tr><th>Predicted</th><th>Negative</th><th>Positive</th></tr></thead><tbody><tr><td><strong>True</strong></td><td></td><td></td></tr><tr><td><strong>Negative</strong></td><td>True Negative (TN)</td><td>False Negative (FN)</td></tr><tr><td><strong>Positive</strong></td><td>False Positive (FP)</td><td>True Positive (TP)</td></tr></tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">pd.DataFrame(confusion_matrix(y_test, y_pred), </span><br><span class="line">             columns=pd.Series([<span class="string">'Negative'</span>, <span class="string">'Positive'</span>], name=<span class="string">'Predicted'</span>),</span><br><span class="line">             index=pd.Series([<span class="string">'Negative'</span>, <span class="string">'Positive'</span>], name=<span class="string">'True'</span>))</span><br></pre></td></tr></table></figure><div><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th>Predicted</th>      <th>Negative</th>      <th>Positive</th>    </tr>    <tr>      <th>True</th>      <th></th>      <th></th>    </tr>  </thead>  <tbody>    <tr>      <th>Negative</th>      <td>81</td>      <td>8</td>    </tr>    <tr>      <th>Positive</th>      <td>27</td>      <td>84</td>    </tr>  </tbody></table></div><h3 id="Evaluation-metrics-for-classification"><a href="#Evaluation-metrics-for-classification" class="headerlink" title="Evaluation metrics for classification"></a>Evaluation metrics for classification</h3><p>A variety of metrics can be calculate from entries in the confusion matrix.</p><p>Accuracy (0 ~ 1) summarizes both positive and negative predictions, but is biased if the classes are imbalanced:</p><script type="math/tex; mode=display">\text{Accuracy} = \frac{TP + TN}{TP + TN + FP + FN}</script><p>Recall/sensitivity (0 ~ 1) summarizes how well the model finds out positive samples:</p><script type="math/tex; mode=display">\text{Recall/Sensitivity} = \frac{TP}{TP + FN}</script><p>Precision/positive predictive value (0 ~ 1) summarizes how well the model finds out negative samples:</p><script type="math/tex; mode=display">\text{Precision/Positive Predictive Value} = \frac{TP}{TP + FP}</script><p>F1 score (0 ~ 1) balances between positive predictive value (PPV) and true positive rate (TPR) and is more suitable for<br>imbalanced dataset:</p><script type="math/tex; mode=display">\text{F1 score} = 2 \frac{PPV \cdot TPR}{PPV + TPR}</script><p>Matthews correlation coefficient (MCC) (-1 ~ 1) is another metric that balances between recall and precision:</p><script type="math/tex; mode=display">\text{MCC} = \frac{TP \times TN - FP \times FN}{(TP + FN)(TP + FP)(TN + FP)(TN + FN)}</script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">scorers = &#123;<span class="string">'accuracy'</span>: accuracy_score,</span><br><span class="line">           <span class="string">'recall'</span>: recall_score,</span><br><span class="line">           <span class="string">'precision'</span>: precision_score,</span><br><span class="line">           <span class="string">'f1'</span>: f1_score,</span><br><span class="line">           <span class="string">'mcc'</span>: matthews_corrcoef</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">for</span> metric <span class="keyword">in</span> scorers.keys():</span><br><span class="line">    print(<span class="string">'&#123;&#125; = &#123;&#125;'</span>.format(metric, scorers[metric](y_test, y_pred)))</span><br></pre></td></tr></table></figure><pre><code>accuracy = 0.825recall = 0.7567567567567568precision = 0.9130434782608695f1 = 0.8275862068965518mcc = 0.6649535460625479</code></pre><h3 id="Predict-class-probability"><a href="#Predict-class-probability" class="headerlink" title="Predict class probability"></a>Predict class probability</h3><p>Many classifiers first predict a continous value for each sample indicating confidence/probability of the prediction<br>and then choose a fixed cutoff (e.g. 0.5 for probability values) to convert the continous values to binary labels.<br>We can get the raw prediction values through the <em>predict_proba</em> method.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">y_score = model.predict_proba(X_test)</span><br></pre></td></tr></table></figure><h3 id="ROC-curve-and-precision-recall-curve"><a href="#ROC-curve-and-precision-recall-curve" class="headerlink" title="ROC curve and precision-recall curve"></a>ROC curve and precision-recall curve</h3><p>Sometimes a single fixed cutoff is insufficient to evaluate model performance.<br>Receiver Operating Characterisic (ROC) curve and Precision-Recall curve are useful tools to inspect the<br>model performance with different cutoffs. ROC curve and precision-recall curve are also less sensitive<br>to class imbalance.<br>Compared to ROC curve, precision-recall curve are more suitable for extremely imbalanced datasets.</p><p>The area under the ROC curve (AUROC) or average precision (AP) is a single value<br>that summarizes average model performance under different cutoffs and are very commonly used to report<br>classification performance.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">fig, axes = plt.subplots(<span class="number">1</span>, <span class="number">2</span>, figsize=(<span class="number">14</span>, <span class="number">7</span>))</span><br><span class="line"><span class="comment"># ROC curve</span></span><br><span class="line">fpr, tpr, thresholds = roc_curve(y_test, y_score[:, <span class="number">1</span>])</span><br><span class="line">ax = axes[<span class="number">0</span>]</span><br><span class="line">ax.plot(fpr, tpr, label=<span class="string">'ROAUC = &#123;:.4f&#125;'</span>.format(roc_auc_score(y_test, y_score[:, <span class="number">1</span>])))</span><br><span class="line">ax.plot([<span class="number">0</span>, <span class="number">1</span>], [<span class="number">0</span>, <span class="number">1</span>], linestyle=<span class="string">'dashed'</span>)</span><br><span class="line">ax.set_xlabel(<span class="string">'False positive rate'</span>)</span><br><span class="line">ax.set_ylabel(<span class="string">'True positive rate'</span>)</span><br><span class="line">ax.set_title(<span class="string">'ROC curve'</span>)</span><br><span class="line">ax.legend()</span><br><span class="line"><span class="comment"># predision-recall curve</span></span><br><span class="line">precision, recall, thresholds = precision_recall_curve(y_test, y_score[:, <span class="number">1</span>])</span><br><span class="line">ax = axes[<span class="number">1</span>]</span><br><span class="line">ax.plot(precision, recall, label=<span class="string">'AP = &#123;:.4f&#125;'</span>.format(average_precision_score(y_test, y_score[:, <span class="number">1</span>])))</span><br><span class="line">ax.plot([<span class="number">0</span>, <span class="number">1</span>], [<span class="number">1</span>, <span class="number">0</span>], linestyle=<span class="string">'dashed'</span>)</span><br><span class="line">ax.set_xlabel(<span class="string">'Precision'</span>)</span><br><span class="line">ax.set_ylabel(<span class="string">'Recall'</span>)</span><br><span class="line">ax.set_title(<span class="string">'Precision-recall curve'</span>)</span><br><span class="line">ax.legend()</span><br></pre></td></tr></table></figure><p><img src="http://i1.fuimg.com/640680/5be83055f202d1bd.png" alt="Markdown"></p><h2 id="Cross-validation"><a href="#Cross-validation" class="headerlink" title="Cross-validation"></a>Cross-validation</h2><p>For very large datasets, a single split of the dataset into a training set and a test set is sufficient<br>to evaluate the model performance. However, for small dataset, the test samples represent only a small<br>proportion of samples in future predictions. The model performance evaluated on the test samples varies<br>greatly between resamplings of the dataset.</p><h3 id="K-fold-cross-validation"><a href="#K-fold-cross-validation" class="headerlink" title="K-fold cross-validation"></a>K-fold cross-validation</h3><p>Cross-validation is a commonly used technique for model evaluation on small dataset.<br>In <strong>k-fold cross-validation</strong>, the dataset is evenly divided into <em>k</em> partitions(folds).<br>In each round of validation, the model is tested on one parition and trained on remaining <em>(k-1)/k</em><br>partitions. K-fold cross-validation ensures that there is no overlap between training and test samples<br>but can have overlaps between rounds. Each sample is set as test sample for exactly once.<br>Finally, the average performance is calculated across <em>k</em> rounds.</p><p><em>scikit-learn</em> provides [many functions for splitting datasets]<br>(<a href="http://scikit-learn.org/stable/modules/classes.html#module-sklearn.model_selection" target="_blank" rel="noopener">http://scikit-learn.org/stable/modules/classes.html#module-sklearn.model_selection</a>).</p><p>Here, we use <a href="http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html" target="_blank" rel="noopener">KFold</a><br>to create 10-fold cross-validation datasets. 5 and 10 are commonly used values for <em>k</em>.<br>Use 10-fold cross-validation if the sample size and computation burden permits.</p><p>The following code illustrates how <em>KFold</em> splits the dataset.<br>Black boxes indicates test samples in each round.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">n_splits = <span class="number">10</span></span><br><span class="line"></span><br><span class="line">kfold = KFold(n_splits=n_splits, random_state=random_state)</span><br><span class="line">is_train = np.zeros((n_splits, X.shape[<span class="number">0</span>]), dtype=np.bool)</span><br><span class="line"><span class="keyword">for</span> i, (train_index, test_index) <span class="keyword">in</span> enumerate(kfold.split(X, y)):</span><br><span class="line">    is_train[i, train_index] = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">fig, ax = plt.subplots(figsize=(<span class="number">15</span>, <span class="number">3</span>))</span><br><span class="line">ax.pcolormesh(is_train)</span><br><span class="line">ax.set_yticks(np.arange(n_splits) + <span class="number">0.5</span>)</span><br><span class="line">ax.set_yticklabels(np.arange(n_splits) + <span class="number">1</span>)</span><br><span class="line">ax.set_ylabel(<span class="string">'Round'</span>)</span><br><span class="line">ax.set_xlabel(<span class="string">'Sample'</span>)</span><br></pre></td></tr></table></figure><p><img src="http://i1.fuimg.com/640680/ac7db08435dee99a.png" alt="Markdown"></p><p>Then we train the model on each training set and predict labels and scores on the whole dataset.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">predictions = np.zeros((n_splits, X.shape[<span class="number">0</span>]), dtype=np.int32)</span><br><span class="line">predicted_scores = np.zeros((n_splits, X.shape[<span class="number">0</span>]))</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(n_splits):</span><br><span class="line">    model.fit(X[is_train[i]], y[is_train[i]])</span><br><span class="line">    predictions[i] = model.predict(X)</span><br><span class="line">    predicted_scores[i] = model.predict_proba(X)[:, <span class="number">1</span>]</span><br></pre></td></tr></table></figure><h3 id="Collect-evaluation-metrics"><a href="#Collect-evaluation-metrics" class="headerlink" title="Collect evaluation metrics"></a>Collect evaluation metrics</h3><p>Next, we evaluates the model using K-fold cross-validation.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">cv_metrics = pd.DataFrame(np.zeros((n_splits*<span class="number">2</span>, len(scorers) + <span class="number">2</span>)),</span><br><span class="line">                          columns=list(scorers.keys()) + [<span class="string">'roc_auc'</span>, <span class="string">'average_precision'</span>])</span><br><span class="line">cv_metrics.loc[:, <span class="string">'dataset'</span>] = np.empty(n_splits*<span class="number">2</span>, dtype=<span class="string">'U'</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(n_splits):</span><br><span class="line">    <span class="keyword">for</span> metric <span class="keyword">in</span> scorers.keys():</span><br><span class="line">        cv_metrics.loc[i*<span class="number">2</span> + <span class="number">0</span>, metric] = scorers[metric](y[is_train[i]], predictions[i, is_train[i]])</span><br><span class="line">        cv_metrics.loc[i*<span class="number">2</span> + <span class="number">1</span>, metric] = scorers[metric](y[~is_train[i]], predictions[i, ~is_train[i]])</span><br><span class="line">    cv_metrics.loc[i*<span class="number">2</span> + <span class="number">0</span>, <span class="string">'roc_auc'</span>] = roc_auc_score(y[is_train[i]], predicted_scores[i, is_train[i]])</span><br><span class="line">    cv_metrics.loc[i*<span class="number">2</span> + <span class="number">1</span>, <span class="string">'roc_auc'</span>] = roc_auc_score(y[~is_train[i]], predicted_scores[i, ~is_train[i]])</span><br><span class="line">    cv_metrics.loc[i*<span class="number">2</span> + <span class="number">0</span>, <span class="string">'average_precision'</span>] = average_precision_score(y[is_train[i]], </span><br><span class="line">                                                                           predicted_scores[i, is_train[i]])</span><br><span class="line">    cv_metrics.loc[i*<span class="number">2</span> + <span class="number">1</span>, <span class="string">'average_precision'</span>] = average_precision_score(y[~is_train[i]], </span><br><span class="line">                                                                           predicted_scores[i, ~is_train[i]])</span><br><span class="line">    cv_metrics.loc[i*<span class="number">2</span> + <span class="number">0</span>, <span class="string">'dataset'</span>] = <span class="string">'train'</span></span><br><span class="line">    cv_metrics.loc[i*<span class="number">2</span> + <span class="number">1</span>, <span class="string">'dataset'</span>] = <span class="string">'test'</span></span><br><span class="line"></span><br><span class="line">cv_metrics.head()</span><br></pre></td></tr></table></figure><div><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>accuracy</th>      <th>recall</th>      <th>precision</th>      <th>f1</th>      <th>mcc</th>      <th>roc_auc</th>      <th>average_precision</th>      <th>dataset</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>0.832222</td>      <td>0.797386</td>      <td>0.863208</td>      <td>0.828992</td>      <td>0.666847</td>      <td>0.908640</td>      <td>0.931433</td>      <td>train</td>    </tr>    <tr>      <th>1</th>      <td>0.810000</td>      <td>0.809524</td>      <td>0.755556</td>      <td>0.781609</td>      <td>0.614965</td>      <td>0.882184</td>      <td>0.844361</td>      <td>test</td>    </tr>    <tr>      <th>2</th>      <td>0.818889</td>      <td>0.781737</td>      <td>0.843750</td>      <td>0.811561</td>      <td>0.639439</td>      <td>0.898143</td>      <td>0.915890</td>      <td>train</td>    </tr>    <tr>      <th>3</th>      <td>0.900000</td>      <td>0.961538</td>      <td>0.862069</td>      <td>0.909091</td>      <td>0.804601</td>      <td>0.985176</td>      <td>0.988980</td>      <td>test</td>    </tr>    <tr>      <th>4</th>      <td>0.828889</td>      <td>0.796909</td>      <td>0.853428</td>      <td>0.824201</td>      <td>0.659380</td>      <td>0.905196</td>      <td>0.924640</td>      <td>train</td>    </tr>  </tbody></table></div><h3 id="Summarize-evaluate-metrics"><a href="#Summarize-evaluate-metrics" class="headerlink" title="Summarize evaluate metrics"></a>Summarize evaluate metrics</h3><p>Take average of model performance across cross-validation runs:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cv_metrics_mean = cv_metrics.groupby(<span class="string">'dataset'</span>).mean()</span><br><span class="line">cv_metrics_mean</span><br></pre></td></tr></table></figure><div><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>accuracy</th>      <th>recall</th>      <th>precision</th>      <th>f1</th>      <th>mcc</th>      <th>roc_auc</th>      <th>average_precision</th>    </tr>    <tr>      <th>dataset</th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>    </tr>  </thead>  <tbody>    <tr>      <th>test</th>      <td>0.831000</td>      <td>0.794919</td>      <td>0.861380</td>      <td>0.823425</td>      <td>0.667898</td>      <td>0.903903</td>      <td>0.921943</td>    </tr>    <tr>      <th>train</th>      <td>0.833778</td>      <td>0.795302</td>      <td>0.862274</td>      <td>0.827428</td>      <td>0.669625</td>      <td>0.906041</td>      <td>0.924631</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">fig, ax = plt.subplots(figsize=(<span class="number">10</span>, <span class="number">5</span>))</span><br><span class="line">plot_data = pd.melt(cv_metrics, id_vars=[<span class="string">'dataset'</span>], var_name=<span class="string">'metric'</span>, value_name=<span class="string">'value'</span>)</span><br><span class="line">sns.stripplot(x=<span class="string">'metric'</span>, y=<span class="string">'value'</span>, hue=<span class="string">'dataset'</span>, </span><br><span class="line">              dodge=<span class="keyword">True</span>, jitter=<span class="keyword">True</span>, data=plot_data, size=<span class="number">4</span>, ax=ax)</span><br><span class="line"><span class="comment">#sns.pointplot(x='metric', y='value', hue='dataset', data=plot_data, markers="d", </span></span><br><span class="line"><span class="comment">#              join=False, ci=None, ax=ax, dodge=True, palette='dark')</span></span><br><span class="line">ax.set_title(<span class="string">'Model performance using 10-fold cross-validation'</span>)</span><br></pre></td></tr></table></figure><p><img src="http://i1.fuimg.com/640680/1b9d375bb6fba070.png" alt="Markdown"></p><h3 id="ROC-and-PR-curves"><a href="#ROC-and-PR-curves" class="headerlink" title="ROC and PR curves"></a>ROC and PR curves</h3><p>For each cross-validation run, compute an ROC/PR curve.<br>Then plot the mean and confidence intervals across cross-validation runs.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> interp</span><br><span class="line"></span><br><span class="line">fig, axes = plt.subplots(<span class="number">1</span>, <span class="number">2</span>, figsize=(<span class="number">14</span>, <span class="number">7</span>))</span><br><span class="line"><span class="comment"># ROC curve</span></span><br><span class="line">ax = axes[<span class="number">0</span>]</span><br><span class="line">all_fprs = np.linspace(<span class="number">0</span>, <span class="number">1</span>, <span class="number">100</span>)</span><br><span class="line">roc_curves = np.zeros((n_splits, len(all_fprs), <span class="number">2</span>))</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(n_splits):</span><br><span class="line">    fpr, tpr, thresholds = roc_curve(y[~is_train[i]], predicted_scores[i, ~is_train[i]])</span><br><span class="line">    roc_curves[i, :, <span class="number">0</span>] = all_fprs</span><br><span class="line">    roc_curves[i, :, <span class="number">1</span>] = interp(all_fprs, fpr, tpr)</span><br><span class="line">roc_curves = pd.DataFrame(roc_curves.reshape((<span class="number">-1</span>, <span class="number">2</span>)), columns=[<span class="string">'fpr'</span>, <span class="string">'tpr'</span>])</span><br><span class="line">sns.lineplot(x=<span class="string">'fpr'</span>, y=<span class="string">'tpr'</span>, data=roc_curves, ci=<span class="string">'sd'</span>, ax=ax,</span><br><span class="line">             label=<span class="string">'Test AUC = &#123;:.4f&#125;'</span>.format(cv_metrics_mean.loc[<span class="string">'test'</span>, <span class="string">'roc_auc'</span>]))</span><br><span class="line"><span class="comment">#ax.plot(fpr, tpr, label='ROAUC = &#123;:.4f&#125;'.format(roc_auc_score(y_test, y_score[:, 1])))</span></span><br><span class="line"><span class="comment">#ax.plot([0, 1], [0, 1], linestyle='dashed')</span></span><br><span class="line">ax.set_xlabel(<span class="string">'False positive rate'</span>)</span><br><span class="line">ax.set_ylabel(<span class="string">'True positive rate'</span>)</span><br><span class="line">ax.plot([<span class="number">0</span>, <span class="number">1</span>], [<span class="number">0</span>, <span class="number">1</span>], linestyle=<span class="string">'dashed'</span>, color=<span class="string">'gray'</span>)</span><br><span class="line">ax.set_title(<span class="string">'ROC curve'</span>)</span><br><span class="line">ax.legend()</span><br><span class="line"></span><br><span class="line"><span class="comment"># predision-recall curve</span></span><br><span class="line">ax = axes[<span class="number">1</span>]</span><br><span class="line">all_precs = np.linspace(<span class="number">0</span>, <span class="number">1</span>, <span class="number">100</span>)</span><br><span class="line">pr_curves = np.zeros((n_splits, len(all_precs), <span class="number">2</span>))</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(n_splits):</span><br><span class="line">    fpr, tpr, thresholds = precision_recall_curve(y[~is_train[i]], predicted_scores[i, ~is_train[i]])</span><br><span class="line">    pr_curves[i, :, <span class="number">0</span>] = all_precs</span><br><span class="line">    pr_curves[i, :, <span class="number">1</span>] = interp(all_precs, fpr, tpr)</span><br><span class="line">pr_curves = pd.DataFrame(pr_curves.reshape((<span class="number">-1</span>, <span class="number">2</span>)), columns=[<span class="string">'precision'</span>, <span class="string">'recall'</span>])</span><br><span class="line">sns.lineplot(x=<span class="string">'precision'</span>, y=<span class="string">'recall'</span>, data=pr_curves, ci=<span class="string">'sd'</span>, ax=ax,</span><br><span class="line">             label=<span class="string">'Test AP = &#123;:.4f&#125;'</span>.format(cv_metrics_mean.loc[<span class="string">'test'</span>, <span class="string">'average_precision'</span>]))</span><br><span class="line"></span><br><span class="line">ax.set_xlabel(<span class="string">'Precision'</span>)</span><br><span class="line">ax.set_ylabel(<span class="string">'Recall'</span>)</span><br><span class="line">ax.plot([<span class="number">0</span>, <span class="number">1</span>], [<span class="number">1</span>, <span class="number">0</span>], linestyle=<span class="string">'dashed'</span>, color=<span class="string">'gray'</span>)</span><br><span class="line">ax.set_title(<span class="string">'Precision-recall curve'</span>)</span><br><span class="line">ax.legend()</span><br></pre></td></tr></table></figure><p><img src="http://i1.fuimg.com/640680/9d2ae29ab7890051.png" alt="Markdown"></p><h2 id="Homework"><a href="#Homework" class="headerlink" title="Homework"></a>Homework</h2><ol><li><p>Understand and run all code in this tutorial using Jupyter. You can generate different types of dataset or use a real dataset.</p></li><li><p>Try different classifiers (SVC, random forest, logistic regression, KNN) and compare model performance.</p></li><li><p>Try different K’s in K-fold cross-validation and compare mean and variance of model performance.</p></li><li><p>Try different class ratios and compare model performance.</p></li></ol><h2 id="Further-reading"><a href="#Further-reading" class="headerlink" title="Further reading"></a>Further reading</h2><h3 id="Books"><a href="#Books" class="headerlink" title="Books"></a>Books</h3><ol><li>Trevor Hastie, Robert Tibshirani, Jerome Friedman. (2009). The Elements of Statistical Learning. </li><li>Christopher Bishop. (2006). Pattern Recognition and Machine Learning.</li><li>Kevin P. Murphy. (2012). Machine Learning A Probabilisitic Perspective.</li><li>Sergios Theodoridis. (2009). Pattern Recognition.</li></ol><h3 id="Class-imbalance"><a href="#Class-imbalance" class="headerlink" title="Class imbalance"></a>Class imbalance</h3><ol><li>He, H., and Garcia, E.A. (2009). Learning from Imbalanced Data. IEEE Transactions on Knowledge and Data Engineering 21, 1263–1284.</li><li>Batista, G.E.A.P.A., Prati, R.C., and Monard, M.C. (2004). A Study of the Behavior of Several Methods for Balancing Machine Learning Training Data. SIGKDD Explor. Newsl. 6, 20–29.</li><li>Chawla, N.V., Bowyer, K.W., Hall, L.O., and Kegelmeyer, W.P. (2002). SMOTE: Synthetic Minority Over-sampling Technique. J. Artif. Int. Res. 16, 321–357.</li></ol><h3 id="Machine-learning-in-R"><a href="#Machine-learning-in-R" class="headerlink" title="Machine learning in R"></a>Machine learning in R</h3><p>The <em>caret</em> package (a tutorial in GitBook): <a href="http://topepo.github.io/caret" target="_blank" rel="noopener">http://topepo.github.io/caret</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;This is one of the chapter in &lt;a href=&quot;https://lulab.gitbooks.io/teaching/content/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Bioinformatics basic course in Tsinghua University&lt;/a&gt;. You may also find it &lt;a href=&quot;https://lulab.gitbooks.io/teaching/content/part-iii.-machine-learning-basics/1.simple-machine-learning-basics.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The related &lt;a href=&quot;https://github.com/lulab/teaching_book/blob/master/part-iii.-machine-learning-basics/1.simple-machine-learning-basics.ipynb&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;jupyter file&lt;/a&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="machine learning" scheme="https://www.cmwonderland.com/blog/categories/machine-learning/"/>
    
    
      <category term="machine learning" scheme="https://www.cmwonderland.com/blog/tags/machine-learning/"/>
    
      <category term="python" scheme="https://www.cmwonderland.com/blog/tags/python/"/>
    
      <category term="bioinformatics" scheme="https://www.cmwonderland.com/blog/tags/bioinformatics/"/>
    
      <category term="teaching" scheme="https://www.cmwonderland.com/blog/tags/teaching/"/>
    
      <category term="TA" scheme="https://www.cmwonderland.com/blog/tags/TA/"/>
    
  </entry>
  
  <entry>
    <title>High School Experience Sharing Book</title>
    <link href="https://www.cmwonderland.com/blog/2018/09/29/93_book_high_school/"/>
    <id>https://www.cmwonderland.com/blog/2018/09/29/93_book_high_school/</id>
    <published>2018-09-29T11:47:15.000Z</published>
    <updated>2019-04-23T13:07:13.955Z</updated>
    
    <content type="html"><![CDATA[<p>I have invited around 100 elite students writing a book about high school life and their choices and dreams. I managed to publish them and they have been reprinted several times.</p><p>I also organized 6 booklets, purely experience sharing about college entrance exam and high school olympic games.</p><p>They are parts of the contribution during our <strong>return to high school program</strong>. As the team leader, I organized a team with more than three hundreds elite students from top universities in China to return to high school. We built a platform to publish life and thoughts about high school life in a daily basis (and part of the contents turned into the published book). The passages were read more than <strong>440,000</strong> times, influenced more than 5,000 students and their parents. The platform was built on 2014 and it still runs well. Our great work also won us the golden prize in Tsinghua’s return to high school activity.</p><a id="more"></a><h1 id="High-School-Life-and-thoughts-book"><a href="#High-School-Life-and-thoughts-book" class="headerlink" title="High School Life and thoughts book"></a>High School Life and thoughts book</h1><p>The passages were read more than <strong>440,000</strong> times, influenced more than 5,000 students and their parents.</p><p>The book has been reprinted several times and we have handed out several thousands of them.</p><div class="row"><iframe src="https://drive.google.com/file/d/1jITuoSxqjMjI-S4Jc6ovfKTAfsrVRJnV/preview" style="width:100%; height:550px"></iframe></div><h1 id="Knowledge-Sharing-book"><a href="#Knowledge-Sharing-book" class="headerlink" title="Knowledge Sharing book"></a>Knowledge Sharing book</h1><p>As the program leader and counselor, I organized a project to collaborate with the top students in my high school to share the concrete knowledge with students. I divided them into several parts: olympic games, college entrance exam and other kinds of exams. The booklets are amazing, the top students in Tsinghua, Peking and other Universities generally share their knowledge with the younger students.</p><div class="row"><iframe src="https://drive.google.com/file/d/1_KGHT46UhnlMREqiBxXeBDX68f4TqUUM/preview" style="width:100%; height:550px"></iframe></div><div class="row"><iframe src="https://drive.google.com/file/d/1ORhv0DYqV2c2mwXK5eFGinn-1iOYJXY0/preview" style="width:100%; height:550px"></iframe></div><div class="row"><iframe src="https://drive.google.com/file/d/1yHKrTfHUm3fYPuW3b5PIVj6IbKpyGHKm/preview" style="width:100%; height:550px"></iframe></div><div class="row"><iframe src="https://drive.google.com/file/d/1DCtxg6rP0lXamHqDRZ6BOzwjJiXTZl0b/preview" style="width:100%; height:550px"></iframe></div><div class="row"><iframe src="https://drive.google.com/file/d/1KLoi7rKZsLF2xuGxWetXV071_9_qjMmC/preview" style="width:100%; height:550px"></iframe></div><div class="row"><iframe src="https://drive.google.com/file/d/19shxoWS54xQ4qXPc2JR7EZ7hcpGgpHwk/preview" style="width:100%; height:550px"></iframe></div>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;I have invited around 100 elite students writing a book about high school life and their choices and dreams. I managed to publish them and they have been reprinted several times.&lt;/p&gt;
&lt;p&gt;I also organized 6 booklets, purely experience sharing about college entrance exam and high school olympic games.&lt;/p&gt;
&lt;p&gt;They are parts of the contribution during our &lt;strong&gt;return to high school program&lt;/strong&gt;. As the team leader, I organized a team with more than three hundreds elite students from top universities in China to return to high school. We built a platform to publish life and thoughts about high school life in a daily basis (and part of the contents turned into the published book). The passages were read more than &lt;strong&gt;440,000&lt;/strong&gt; times, influenced more than 5,000 students and their parents. The platform was built on 2014 and it still runs well. Our great work also won us the golden prize in Tsinghua’s return to high school activity.&lt;/p&gt;
    
    </summary>
    
      <category term="book" scheme="https://www.cmwonderland.com/blog/categories/book/"/>
    
    
      <category term="life" scheme="https://www.cmwonderland.com/blog/tags/life/"/>
    
      <category term="book" scheme="https://www.cmwonderland.com/blog/tags/book/"/>
    
      <category term="techniques" scheme="https://www.cmwonderland.com/blog/tags/techniques/"/>
    
      <category term="teaching" scheme="https://www.cmwonderland.com/blog/tags/teaching/"/>
    
  </entry>
  
  <entry>
    <title>Teaching Book</title>
    <link href="https://www.cmwonderland.com/blog/2018/09/28/93_gitbook_teaching_book/"/>
    <id>https://www.cmwonderland.com/blog/2018/09/28/93_gitbook_teaching_book/</id>
    <published>2018-09-28T11:47:25.000Z</published>
    <updated>2019-04-23T13:07:13.873Z</updated>
    
    <content type="html"><![CDATA[<p>I have written something about bioinformatics skills as part of two books. The <a href="https://legacy.gitbook.com/book/lulab/teaching/details" target="_blank" rel="noopener">basic teaching book</a> is used to teach undergraduate students in <em>Bioinformatics Basic</em> course. I am a teaching assistant of this course this semester. The <a href="https://lulab.gitbook.io/training/" target="_blank" rel="noopener">advanced teaching book</a> is used to teach graduate student and some senior undergraduate students. </p><p>I have spent many time written several chapters of the books. For Basic teaching book I contributed more than 1/3 of the book.</p><a id="more"></a><h2 id="Basic-teaching-book"><a href="#Basic-teaching-book" class="headerlink" title="Basic teaching book"></a>Basic teaching book</h2><p><a href="https://lulab.gitbooks.io/teaching/content/" target="_blank" rel="noopener">Teaching Book Link</a></p><div class="row"><iframe src="https://drive.google.com/file/d/12ZK_YkhD5V0caL5j_saoMiTX6tFa4BHR/preview" style="width:100%; height:550px"></iframe></div><ul><li><p><a href="https://lulab.gitbooks.io/teaching/content/getting-started.html" target="_blank" rel="noopener">getting started docker</a></p></li><li><p><a href="https://lulab.gitbooks.io/teaching/content/part-i.-basic-tools/1.linux-task.html" target="_blank" rel="noopener">linux</a></p></li><li><p><a href="https://lulab.gitbooks.io/teaching/content/appendix/python_tutorial.html" target="_blank" rel="noopener">python</a></p></li><li><p><a href="https://lulab.gitbooks.io/teaching/content/part-iii.-machine-learning-basics/1.simple-machine-learning-basics.html" target="_blank" rel="noopener">machine learning basics</a></p></li><li><p><a href="https://lulab.gitbooks.io/teaching/content/quiz/quiz_emaize/quiz_emaize_tutorial.html" target="_blank" rel="noopener">eMaize</a></p></li><li><a href="https://lulab.gitbooks.io/teaching/content/quiz/quiz_exrna/quiz_exrna_tutorial.html" target="_blank" rel="noopener">exRNA</a></li></ul><h2 id="Advanced-teaching-book"><a href="#Advanced-teaching-book" class="headerlink" title="Advanced teaching book"></a>Advanced teaching book</h2><p><a href="https://lulab.gitbook.io/training/" target="_blank" rel="noopener">Teaching Book Link</a></p><ul><li><a href="https://lulab.gitbook.io/training/part-ii.-basic-bioinfo-analyses/1.mapping-annotation-and-qc" target="_blank" rel="noopener">mapping</a></li><li><a href="https://lulab.gitbook.io/training/part-iii.-advanced-bioinfo-analyses/3.deep-learning-basics" target="_blank" rel="noopener">deep learning</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;I have written something about bioinformatics skills as part of two books. The &lt;a href=&quot;https://legacy.gitbook.com/book/lulab/teaching/details&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;basic teaching book&lt;/a&gt; is used to teach undergraduate students in &lt;em&gt;Bioinformatics Basic&lt;/em&gt; course. I am a teaching assistant of this course this semester. The &lt;a href=&quot;https://lulab.gitbook.io/training/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;advanced teaching book&lt;/a&gt; is used to teach graduate student and some senior undergraduate students. &lt;/p&gt;
&lt;p&gt;I have spent many time written several chapters of the books. For Basic teaching book I contributed more than 1/3 of the book.&lt;/p&gt;
    
    </summary>
    
      <category term="book" scheme="https://www.cmwonderland.com/blog/categories/book/"/>
    
    
      <category term="life" scheme="https://www.cmwonderland.com/blog/tags/life/"/>
    
      <category term="book" scheme="https://www.cmwonderland.com/blog/tags/book/"/>
    
      <category term="techniques" scheme="https://www.cmwonderland.com/blog/tags/techniques/"/>
    
      <category term="teaching" scheme="https://www.cmwonderland.com/blog/tags/teaching/"/>
    
  </entry>
  
  <entry>
    <title>ECCV 2018 paper reading</title>
    <link href="https://www.cmwonderland.com/blog/2018/09/26/38_ECCV_2018/"/>
    <id>https://www.cmwonderland.com/blog/2018/09/26/38_ECCV_2018/</id>
    <published>2018-09-26T13:23:55.000Z</published>
    <updated>2019-04-23T13:07:13.909Z</updated>
    
    <content type="html"><![CDATA[<p>I mainly focus on semantic segmentation and potentially related papers.</p><a id="more"></a><h1 id="semantic-segmentation"><a href="#semantic-segmentation" class="headerlink" title="semantic segmentation"></a>semantic segmentation</h1><ul><li><p>A Dataset for Lane Instance Segmentation in Urban Environments<br>a dataset paper</p></li><li><p>BiSeNet: Bilateral Segmentation Network for Real-time Semantic Segmentation<br><em>spatial path &amp; context path to solve real time segmentation</em></p></li><li><p>ICNet for Real-Time Semantic Segmentation on High-Resolution Images<br>solve <em>real time segmentation</em></p></li><li><p>Multi-Scale Context Intertwining for Semantic Segmentation<br>a novel scheme for aggregating features from diﬀerent scales, which we refer to as MultiScale Context Intertwining (MSCI).<br>merge pairs of feature maps <em>in a bidirectional and recurrent fashion</em>, via connections between two LSTM chains. By training the parameters of the LSTM units on the segmentation task, the above approach learns how to extract powerful and eﬀective features for pixellevel semantic segmentation, which are then combined hierarchically.</p></li><li><p>Eﬃcient Semantic Scene Completion Network with Spatial Group Convolution<br>Spatial Group Convolution (SGC) for <em>accelerating the computation of 3D dense prediction</em> tasks. SGC is orthogonal to group convolution, <em>which works on spatial dimensions</em> rather than feature channel dimension. It divides input voxels into diﬀerent groups, then conducts 3D sparse convolution on these separated groups.</p></li><li><p>Adaptive Afﬁnity Fields for Semantic Segmentation<br>propose the concept of Adaptive Afﬁnity Fields (AAF) to capture and match the semantic relations between neighbouring pixels in the label space</p></li><li><p>Encoder-Decoder with Atrous Separable Convolution for Semantic Image Segmentation<br>Spatial pyramid pooling module or encode-decoder structure<br>Encoder-Decoder with Atrous Convolution<br>Depthwise separable convolution:<br>DeepLabv3 as encoder<br><a href="https: //github.com/tensorflow/models/tree/master/research/deeplab" target="_blank" rel="noopener">implementation</a></p></li><li><p>MVTec D2S: Densely Segmented Supermarket Dataset<br>a dataset paper<br>a novel benchmark for instance-aware semantic segmentation in an industrial domain, It contains 21 000 high-resolution images with pixel-wise labels of all object instances.  The objects comprise groceries and everyday products from 60 categories.</p></li><li><p>Predicting Future Instance Segmentation by Forecasting Convolutional Features</p></li><li><p>ESPNet: Efﬁcient Spatial Pyramid of Dilated Convolutions for Semantic Segmentation<br>for semantic segmentation of high resolution images under resource constraints. ESPNet is based on a new convolutional module, efﬁcient spatial pyramid (ESP), which is efﬁcient in terms of computation, memory, and power.</p></li><li><p>Penalizing Top Performers: Conservative Loss for Semantic Segmentation Adaptation<br>a novel loss function, i.e., Conservative Loss, which penalizes the extreme good and bad cases while encouraging the moderate examples. More speciﬁcally, it enables the network to learn features that are discriminative by gradient descent and are invariant to the change of domains via gradient ascend method.</p></li><li><p>Aﬃnity Derivation and Graph Merge for Instance Segmentation<br>In our scheme, we use two neural networks with similar structures. One predicts the pixel level semantic score and the other is designed to derive pixel aﬃnities. Regarding pixels as the vertexes and aﬃnities as edges, we then propose a simple yet eﬀective graph merge algorithm to cluster pixels into instances.</p></li><li><p>ExFuse: Enhancing Feature Fusion for Semantic Segmentation<br>In this paper, we ﬁrst point out that a simple fusion of low-level and high-level features could be less eﬀective because of the gap in semantic levels and spatial resolution. We ﬁnd that introducing semantic information into low-level features and high-resolution details into high-level features is more eﬀective for the later fusion. Based on this observation, we propose a new framework, named ExFuse, to bridge the gap between low-level and high-level features thus signiﬁcantly improve the segmentation quality by 4.0% in total.</p></li><li><p>Deep Clustering for Unsupervised Learning of Visual Features<br>a clustering method that jointly learns the parameters of a neural network and the cluster assignments of the resulting features. DeepCluster iteratively groups the features with a standard clustering algorithm, kmeans, and uses the subsequent assignments as supervision to update the weights of the network.</p></li><li><p>Bidirectional Feature Pyramid Network with Recurrent Attention Residual Modules for Shadow Detection<br>recurrent attention residual (RAR) module to combine the contexts in two adjacent CNN layers and learn an attention map to select a residual and then reﬁne the context features. Second, we develop a bidirectional feature pyramid network (BFPN) to aggregate shadow contexts spanned across diﬀerent CNN layers by deploying two series of RAR modules in the network to iteratively combine and reﬁne context features: one series to reﬁne context features from deep to shallow layers, and another series from shallow to deep layers<br>better suppress false detections and enhance shadow details at the same time.</p></li><li><p>Multi-scale Residual Network for Image Super-Resolution<br>a novel multiscale residual network (MSRN) to fully exploit the image features, which outperform most of the state-of-the-art methods. Based on the residual block, we introduce convolution kernels of diﬀerent sizes to adaptively detect the image features in diﬀerent scales. Meanwhile, we let these features interact with each other to get the most eﬃcacious image information, we call this structure Multi-scale Residual Block (MSRB). Furthermore, the outputs of each MSRB are used as the hierarchical features for global feature fusion.</p></li></ul><ul><li>Predicting Future Instance Segmentation by Forecasting Convolutional Features<br>For video next frame prediction</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;I mainly focus on semantic segmentation and potentially related papers.&lt;/p&gt;
    
    </summary>
    
      <category term="machine learning" scheme="https://www.cmwonderland.com/blog/categories/machine-learning/"/>
    
    
      <category term="deep learning" scheme="https://www.cmwonderland.com/blog/tags/deep-learning/"/>
    
      <category term="techniques" scheme="https://www.cmwonderland.com/blog/tags/techniques/"/>
    
      <category term="paper reading" scheme="https://www.cmwonderland.com/blog/tags/paper-reading/"/>
    
  </entry>
  
  <entry>
    <title>Deep Learning in Medical Image</title>
    <link href="https://www.cmwonderland.com/blog/2018/08/16/95_medical_image_project/"/>
    <id>https://www.cmwonderland.com/blog/2018/08/16/95_medical_image_project/</id>
    <published>2018-08-16T11:03:19.000Z</published>
    <updated>2019-04-23T13:07:13.912Z</updated>
    
    <content type="html"><![CDATA[<p>I always have a strong interests in applying deep learning models to medical images analysis. I have two projects related to medical image analysis using deep learning. During the projects I tried to experience the whole pipeline: </p><ul><li>collect data from hospitals and open source database</li><li>clean data and organize information</li><li>learn experience from doctors, develop models and consider about its reliability.</li></ul><p>As a student from life science background with machine learning and deep learning skills, I have a broader mind to think about medical image problems from different views. From my perspectives, deep learning aided medical image analysis will soon have a wide range of application. </p><a id="more"></a><h1 id="Work-Summary"><a href="#Work-Summary" class="headerlink" title="Work Summary"></a>Work Summary</h1><h2 id="X-ray-image-for-heart-disease-analysis"><a href="#X-ray-image-for-heart-disease-analysis" class="headerlink" title="X-ray image for heart disease analysis"></a>X-ray image for heart disease analysis</h2><div class="row">    <embed src="https://arxiv.org/pdf/1808.08277.pdf" width="100%" height="550" type="application/pdf"></div><h2 id="CT-images-for-lung-disease-analysis"><a href="#CT-images-for-lung-disease-analysis" class="headerlink" title="CT images for lung disease analysis"></a>CT images for lung disease analysis</h2><div class="row"><iframe src="https://drive.google.com/file/d/1L6WLM41eIwzIi1NB6x8X6UrChYFtH_2u/preview" style="width:100%; height:550px"></iframe></div><p>We propose some change to analyze the image. For example we propose to use U-net to segment heart mask first. Force the classification model to pay more attention to heart region to make the model more reliable.</p><p>For segmentation task, it is suggested to use DICE coefficient. However, it is really hard to use DICE loss to optimize model. We make some changes to DICE loss to restrict the predicted region.</p><div class="row"><iframe src="https://drive.google.com/file/d/1VE2Ni3iAJLEtiMks2WmuT-uqamUaqxt-/preview" style="width:100%; height:550px"></iframe></div><h1 id="codes"><a href="#codes" class="headerlink" title="codes"></a>codes</h1><p><a href="https://github.com/james20141606/Summer_Intern" target="_blank" rel="noopener">3D deep learning model for lung disease CT images</a><br><a href="https://github.com/james20141606/CardiacAI" target="_blank" rel="noopener">X-ray heart disease image classification</a></p><h1 id="related"><a href="#related" class="headerlink" title="related:"></a>related:</h1><ul><li>X-ray image for heart disease analysis is in a student research training program. With fundings of $20,000</li><li>X-ray image for heart disease analysis also wins second prize in <strong>The First National College Students’ Brain Computation and Application Competition</strong>.</li><li>CT image analysis is under the construction of <a href="http://www.au.tsinghua.edu.cn/publish/au/1714/2011/20110323105408606814635/20110323105408606814635_.html" target="_blank" rel="noopener">Professor Xuegong Zhang</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;I always have a strong interests in applying deep learning models to medical images analysis. I have two projects related to medical image analysis using deep learning. During the projects I tried to experience the whole pipeline: &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;collect data from hospitals and open source database&lt;/li&gt;
&lt;li&gt;clean data and organize information&lt;/li&gt;
&lt;li&gt;learn experience from doctors, develop models and consider about its reliability.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;As a student from life science background with machine learning and deep learning skills, I have a broader mind to think about medical image problems from different views. From my perspectives, deep learning aided medical image analysis will soon have a wide range of application. &lt;/p&gt;
    
    </summary>
    
      <category term="projects" scheme="https://www.cmwonderland.com/blog/categories/projects/"/>
    
    
      <category term="project" scheme="https://www.cmwonderland.com/blog/tags/project/"/>
    
      <category term="deep learning" scheme="https://www.cmwonderland.com/blog/tags/deep-learning/"/>
    
      <category term="computer vision" scheme="https://www.cmwonderland.com/blog/tags/computer-vision/"/>
    
      <category term="research" scheme="https://www.cmwonderland.com/blog/tags/research/"/>
    
      <category term="medical image" scheme="https://www.cmwonderland.com/blog/tags/medical-image/"/>
    
  </entry>
  
  <entry>
    <title>Synaptic Partner and Cluster Project</title>
    <link href="https://www.cmwonderland.com/blog/2018/07/14/97_summerintern_Synaptic_Partner_and_Cluster_Project/"/>
    <id>https://www.cmwonderland.com/blog/2018/07/14/97_summerintern_Synaptic_Partner_and_Cluster_Project/</id>
    <published>2018-07-14T15:58:06.000Z</published>
    <updated>2019-04-23T13:07:13.918Z</updated>
    
    <content type="html"><![CDATA[<p>It is part of my computational task during my summer intern in <a href="https://lichtmanlab.fas.harvard.edu/" target="_blank" rel="noopener">Lichtman Lab</a> and <a href="https://vcg.seas.harvard.edu/people" target="_blank" rel="noopener">Hanspiter Lab</a>.</p><p>It is part of the big synapse project. Also the challenge 3 of <a href="https://cremi.org" target="_blank" rel="noopener">CREMI</a></p><p>For <strong>whole work summary</strong> please <a href="https://www.cmwonderland.com/blog/2018/09/12/100_summer_intern/">see here</a></p><div class="row"><iframe src="https://drive.google.com/file/d/1XyEPj9r7p8VNk5nLlLIPNhZjuDHu2KTY/preview" style="width:100%; height:550px"></iframe></div><p>Also I finished another NMJ project during summer intern in <a href="https://lichtmanlab.fas.harvard.edu/" target="_blank" rel="noopener">Lichtman Lab</a> </p><h1 id="Codes"><a href="#Codes" class="headerlink" title="Codes"></a>Codes</h1><ul><li><a href="https://github.com/james20141606/Summer_Intern/tree/master/synapse_prediction" target="_blank" rel="noopener">Summer_Intern/synaptic_partner at master · james20141606/Summer_Intern · GitHub</a></li><li><a href="https://github.com/james20141606/EM-network" target="_blank" rel="noopener">Synapse polarity</a></li><li><a href="https://github.com/james20141606/Summer_Intern/tree/master/synapse_cluster" target="_blank" rel="noopener">Summer_Intern/synapse_cluster at master · james20141606/Summer_Intern · GitHub</a></li></ul><a id="more"></a><h1 id="weekly-report"><a href="#weekly-report" class="headerlink" title="weekly report"></a>weekly report</h1><h2 id="First"><a href="#First" class="headerlink" title="First"></a>First</h2><div class="row"><iframe src="https://drive.google.com/file/d/1bmWX9M1aTgOw7YB9xrnUNynWfxuoa_Rz/preview" style="width:100%; height:550px"></iframe></div><h2 id="Second"><a href="#Second" class="headerlink" title="Second"></a>Second</h2><div class="row"><iframe src="https://drive.google.com/file/d/1OOaFajkLcwQBEf1XQuEIYqFAkl9psPrt/preview" style="width:100%; height:550px"></iframe></div><h2 id="Third"><a href="#Third" class="headerlink" title="Third"></a>Third</h2><div class="row"><iframe src="https://drive.google.com/file/d/1We4g3Ltd2gqzmICoLtKFKsL-2zP2BVeV/preview" style="width:100%; height:550px"></iframe></div><h2 id="Fourth"><a href="#Fourth" class="headerlink" title="Fourth"></a>Fourth</h2><div class="row"><iframe src="https://drive.google.com/file/d/19zhoBM6GP94a-bNj7bFIZdExC0x6yw_2/preview" style="width:100%; height:550px"></iframe></div><hr><h1 id="first-two-weeks"><a href="#first-two-weeks" class="headerlink" title="first two weeks"></a>first two weeks</h1><h2 id="creteria"><a href="#creteria" class="headerlink" title="creteria"></a>creteria</h2><p>I try to understand the task3, I read through metrics provided by CREMI website, and find the data processing and evaluation scripts provided by Cremi organization.<br><a href="https://github.com/cremi/cremi_python/blob/master/cremi/evaluation/synaptic_partners.py" target="_blank" rel="noopener">cremi_python/synaptic_partners.py at master · cremi/cremi_python · GitHub</a>. </p><p>They made it very hard to use their pipeline to store and process data. Since we have our own pipeline, I only use the core function about evaluation. By rewriting the scripts I understand how to calculate F-score, it is harder to fully understand the criteria since it needs many steps to calculate, so it is essential to read the original scripts.</p><p>I have summarized the metrics and show it to zudi and donglai.</p><p><img src="http://i2.tiimg.com/640680/ad617dc9489cb429.png" alt="Markdown"></p><p>This means we need the location data and neuron_id for wrong partner evaluation</p><h3 id="steps-to-calculate-F-score"><a href="#steps-to-calculate-F-score" class="headerlink" title="steps to calculate F-score"></a>steps to calculate F-score</h3><ul><li>cost_matrix :<ul><li>pre_post_locations get pre and post location，may consider offset shift       get rec and gt location</li><li>pre_post_labels  get pre and post segmentation( GT neuron_id) as rec_labels  segmentation[pre]  return the pixel value of a certain coordinates for further comparison of wrong partners for further comparison of wrong partners</li><li>create cost matrix，find the bigger one of rec and gt location as matrix size  init value is  2*matching_threshold</li><li>use cost function to calculate, for every rec and gt pair, input rec_locations[i], gt_locations[j], rec_labels[i], gt_labels[j], matching_threshold</li><li>in cost function, set max_cost = 2*matching_threshold，fisrt if labels1 != labels2(rec_labels[i], gt_labels[j]), from pre_post_labels we can know rec and gt comes from different segmentation(neuron).return max_cost</li><li>cost function continue, use np.linalg.norm to calculate pre and post L2 distance, if any of it is larger than thres, return max_cost. Else return average of pre and post. i.e. if  wrong partner (rec and gt not in same seg),  or FP: succeed thres</li><li>if none of them happens, return average of pre and post</li><li>return to cost_matrix, if distance less than thres, add potential pair count by 1, through loop, cost_matrix is filled with numbers, but the loop traverse rec_locations，gt_locations, positions not traverseed is max_cost</li></ul></li><li>match using Hungarian method<blockquote><p>All detected pairs that have both annotations inside the matching areas of a ground truth pair are considered potential matches. Of all potential matches, we find true matches by solving an assignment problem minimizing the Euclidean distance. Unmatched detected pairs are considered FP, unmatched ground truth pairs FN. The final score is the F1-score of the FPs and FNs.</p><ul><li>use linear_sum_assignment(costs - np.amax(costs) - 1)  np.amax(costs) almost is max_cost(2*matching_threshold)<ul><li>scpiy的linear<em>sum_assignment <strong>solves assign problems</strong>, which is one of the tricky part in this criteria.<br>let X be a boolean matrix where X[i,j] =1 if row i is assigned to column j. Then the optimal assignment has cost $$min \sum_i \sum_j C</em>{ij}X_{ij}$$, it finds the minimum Euclidean distance in all potential pairs. So we can submit all locations in a random way, it doesn’t matter.<ul><li>retain the assigned pairs by distance less than threshold</li></ul></li></ul></li></ul></blockquote></li><li>unmatched in rec = FP，all pairs detected by models subtracted by cost matrix’s pairs are FP</li><li>unmatched in gt = FN，all GT pairs subtracted by cost matrix’s pairs are FN</li><li>all ground truth elements - FN = TP</li><li>Then we can calculate fscore, precision, recall, fp, fn, filtered_matches</li></ul><h2 id="Study-others’-methods"><a href="#Study-others’-methods" class="headerlink" title="Study others’ methods"></a>Study others’ methods</h2><h4 id="1st-place"><a href="#1st-place" class="headerlink" title="1st place"></a>1st place</h4><p>Last month Funkey put a paper <strong>Synaptic partner prediction from point annotations in insect brains</strong> it is the  top in leaderboard method. They combined synapse detection and partner identification into one steps. They train a 3D Unet，directly predict directed edges formed by voxels. Balance computational resource and coverage of synaptic partner. Then calculate score of all edges from one segment to another segment. Threshold and certify candidate synapse，for candidate synapse, calculate the mass center of all related edges, getting coordinates of synapse’s pre and post.</p><ul><li>3D U-Net architecture to directly identify pairs of voxels that are pre- and postsynaptic to each other</li><li>formulate the problem of synaptic partner identiﬁcation as a classiﬁcation problem on long-range edges between voxels to encode <strong>both the presence of a synaptic pair and its direction</strong>. This formulation allows us to <strong>directly learn from synaptic point annotations</strong> instead of more expensive voxel-based synaptic cleft or vesicle annotations.</li><li>The proposed representation also allows us to learn from synaptic point annotations only, since we do not rely on labeled synaptic features, such as synaptic clefts or vesicle clouds.</li></ul><p>From fig 1we can have a connectome matrix, actually it is what the evaluation scripts do(they are written by funkey group too.)</p><h4 id="2nd-place-by-previous-postdoc-in-Hanspeter-group"><a href="#2nd-place-by-previous-postdoc-in-Hanspeter-group" class="headerlink" title="2nd place by previous postdoc in Hanspeter group"></a>2nd place by previous postdoc in Hanspeter group</h4><p>Use 3D convolutional neural network for two steps.<br>3D U-net+3D CNN, Use 3D U-net to learn labels by formulate a function, then prune it by 3D CNN<br><a href="https://www.dropbox.com/s/vug579prnxt454n/miccai18syn.pdf?dl=0" target="_blank" rel="noopener">https://www.dropbox.com/s/vug579prnxt454n/miccai18syn.pdf?dl=0</a><br>学习代码<a href="https://github.com/paragt/EMSynConn" target="_blank" rel="noopener">GitHub - paragt/EMSynConn: One algorithm to detect synaptic location AND connectivity, both dyadic and polyadic, in Electron Microscopy volume.</a></p><h4 id="4th-place-FN-is-good"><a href="#4th-place-FN-is-good" class="headerlink" title="4th place, FN is good"></a>4th place, FN is good</h4><p>Use Asymmetric Unet<br><a href="https://github.com/nicholasturner1/Synaptor" target="_blank" rel="noopener">GitHub - nicholasturner1/Synaptor: Processing voxelwise Convolutional Network output trained to predict synaptic clefts for connectomics</a></p><h2 id="Cluster"><a href="#Cluster" class="headerlink" title="Cluster"></a>Cluster</h2><p>I did some data visualization for cerebellum and CREMI data which will be used in clustering work. Also implement some computer vision algorithm for feature extraction.<a href="https://github.com/james20141606/Summer_Intern/blob/master/synapse_cluster/jupyter/visualize_cerebellum_sample.ipynb" target="_blank" rel="noopener">visualize cerebellum</a></p><p>I am considering to use deep learning based clustering methods, to do feature selection and clustering simultaneously. Also it is essential to consider model interpretability. </p><p>Resources: <a href="http://elektronn.org/" target="_blank" rel="noopener">ELEKTRONN - Convolutional Neural Network Toolkit in Python. Fast GPU acceleration and easy usage.</a> is used for generate skeletons using deep learning.</p><hr><p> Week 3<br>The main focus of week 3 is on NMJ labeling and synapse prediction project. So the progress of clustering and synaptic partner project is not much.</p><h2 id="cluster"><a href="#cluster" class="headerlink" title="cluster"></a>cluster</h2><p>I have further considered <strong>clustering</strong>  project. Since we will have a huge amount of data to cluster, it is a natural thought to use deep learning based clustering method, which I have mentioned last time. After discussion with donglai and zudi, they also agree we can use a (variational) auto-encoder to cluster and analyze the synapse. If have time, I may try 3D VAE to cluster the synapse, but it need some preprocessing work. We may at first align and rotate the 2D image for better results.</p><p>I have read some papers including<br><a href="https://arxiv.org/pdf/1610.07584.pdf" target="_blank" rel="noopener">Learning a Probabilistic Latent Space of Object Shapes via 3D Generative-Adversarial Modeling</a><br><a href="https://arxiv.org/pdf/1801.07648.pdf" target="_blank" rel="noopener">Clustering with Deep Learning:Taxonomy and New Methods</a></p><p>Which I thought will be useful</p><h2 id="synaptic-partner"><a href="#synaptic-partner" class="headerlink" title="synaptic partner"></a>synaptic partner</h2><p>I have read and summarized some paper and codes last week on synaptic partner project. This week zudi and I discuss about previous work’s strategy. We have decided that I read and study the synaptic partner codes written by a previous postdoc. </p><p>Now the codes is incomplete in github, later we may get the complete codes. The codes isn’t in a very good structure, and task 3 is harder and more complex than synapse prediction, so it will take me some time to fully understand the codes and make more improvements on it.</p><hr><h1 id="Week-4"><a href="#Week-4" class="headerlink" title="Week 4"></a>Week 4</h1><h2 id="synaptic-partner-1"><a href="#synaptic-partner-1" class="headerlink" title="synaptic partner"></a>synaptic partner</h2><p>This week we mainly focus on task 3, synaptic partner prediction, this is a new and more challenging task for us. Previously we never try to predict synaptic partner, so we have to understand this task and process the raw data to get the train label.</p><h3 id="Align-and-process-location-to-create-training-labels"><a href="#Align-and-process-location-to-create-training-labels" class="headerlink" title="Align and process location to create training labels"></a>Align and process location to create training labels</h3><p>I study and understand the synaptic partner’s identification criterion and process the location value in the same alignment steps with raw and clefts image.</p><ul><li>extract location and pre-post id, put these points in a volume</li><li>align the volume, padding and deal with bad slices using same strategy </li></ul><p>location is only point id, we can shift the point by first draw the point in zero array and then extract location. Each point use pre and post id to trace back. The premise is location and clefts matches, I have checked it.</p><p><img src="http://i1.fuimg.com/640680/db4521d532057170.png" alt="Markdown"></p><p><img src="http://i1.fuimg.com/640680/239c484ca9b1ab55.png" alt="Markdown"></p><p>Codes:</p><ul><li>alignment matlab script<br><a href="https://github.com/james20141606/Summer_Intern/blob/master/synaptic_partner/bin/T_align.m" target="_blank" rel="noopener">Summer_Intern/T_align.m at master · james20141606/Summer_Intern · GitHub</a><br>This script can align raw, clefts and location and reverse them</li><li>jupyter<br>Deal with pre and post processing of locations array.<br><a href="https://github.com/james20141606/Summer_Intern/blob/master/synaptic_partner/jupyter/cremi_shift.ipynb" target="_blank" rel="noopener">Summer_Intern/cremi_shift.ipynb at master · james20141606/Summer_Intern · GitHub</a></li></ul><p><strong>visualize shift results</strong></p><p><img src="http://i1.fuimg.com/640680/c6241b5b0bf7630b.png" alt="Markdown"></p><p>I also find that in A, B, C three volumes, the partner numbers differ a lot:432, 1324, 2276<br>But clefts numbers are similar:123, 131, 165</p><p>The align work needs many patience, I did it over ten times to ensure it is 100 percent right. The axis, scatter and imshow tradition and many steps process made it easy to make mistakes. At last I found that it is best to dilate the points in location array and visualize it using imshow uniformly to check the alignment.</p><h3 id="Synaptic-partner-identification-model"><a href="#Synaptic-partner-identification-model" class="headerlink" title="Synaptic partner identification model"></a>Synaptic partner identification model</h3><p>The model can be derived from synapse identification model. We also use 3D U-net and add some changes. We study Funke’s previous work, it has some strengths and drawbacks.</p><p>For example, they use 14 vectors to represent all possible partner vectors. And the model predict a 14 channel one-hot vector. But this methods deliberately overfits on CREMI datasets. Since we would like to develop a model to predict synaptic partners on JWR datasets, we should use a more generalized methods. But the searching space will increase a lot.</p><ul><li>dilate location point<br>for each points(so it can specify location)</li><li>Generate 4 channel output (binary, Z, Y, X)<br>binary for <strong>localization</strong>, and Z, Y, X for vector <strong>orientation</strong><br>We will use cosine loss to evaluate orientation<br>So this can be considered as a multi task training</li><li>use branched model to predict two parts<br>Output mask and vector separately.<br>A very natural thought is we can design the model further to multiply the binary channel to the orientation part as <strong>Attention mechanism</strong>, the two branched models can share weights. I use a similar architecture in another project and it works well</li></ul><p>It is hard to both predict orientation and length. So maybe we can do post-processing work: we only predict orientation, and calculate the distance from pre synapse to clefts, and add the distance to produce post synapse location.</p><h3 id="Hacking-toufiq’s-codes"><a href="#Hacking-toufiq’s-codes" class="headerlink" title="Hacking toufiq’s codes:"></a>Hacking toufiq’s codes:</h3><p>I also try to study and understand Toufiq’s work. I found Toufiq and Lee has done a lot on task 3 and related synapse work. They have some valuable work and codes to be recovered. So I try to find something useful to use. </p><p>They have a github  repo which has many useful codes for synapses. It even has codes for finding seeds etc. <a href="https://github.com/microns-ariadne/pipeline_engine/" target="_blank" rel="noopener">GitHub - microns-ariadne/pipeline_engine: reconstruction pipeline</a></p><p>Prediction of pre and post and segmentation(pre and post is self-labeled and segmentation is predicted) and clefts(ground truth in original dataset)</p><p><img src="http://i1.fuimg.com/640680/44ce375316d09d8a.png" alt="Markdown"></p><p>use binary dilation for gt-syn<br>Use segment_vesicle_style function</p><h2 id="Synapse-cluster"><a href="#Synapse-cluster" class="headerlink" title="Synapse cluster"></a>Synapse cluster</h2><p>Help siyan with 3D skeleton. Direct 3D skeleton isn’t very good since the distance of sections (30/40 nm) is a little long. Direct interpolation or dilation also works badly.</p><p>So I try a ICP and KNN algorithm to maximize matching of two 2D contours and find the nearest neighbor of each point in two neighbor contour. This idea originate from calculating the volume size of a 3D object. After finding each points neighbor, we can do linear interpolation to create another 9 sections for better 3D skeleton.  </p><p>Codes:<br><a href="https://github.com/james20141606/Summer_Intern/blob/master/synapse_cluster/jupyter/ICP_KNN.ipynb" target="_blank" rel="noopener">Summer_Intern/ICP_KNN.ipynb at master · james20141606/Summer_Intern · GitHub</a></p><hr><h1 id="Week-5-amp-6"><a href="#Week-5-amp-6" class="headerlink" title="Week 5 &amp; 6"></a>Week 5 &amp; 6</h1><h2 id="Cluster-1"><a href="#Cluster-1" class="headerlink" title="Cluster"></a>Cluster</h2><p>Use auto encoder to reconstruct synapse and cluster the latent variable. Generate missing slides, intensity, rotation, elastic to force auto-encoder learn</p><p>I also find a paper by FAIR:  Deep Clustering for Unsupervised Learning of Visual Features <a href="https://arxiv.org/pdf/1807.05520v1.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1807.05520v1.pdf</a>, it proposed an end-to-end method using  deep learning for clustering. They test it on  ImageNet and outperforms the current model. Maybe it is also useful in our datasets too.</p><h2 id="Synaptic-partner"><a href="#Synaptic-partner" class="headerlink" title="Synaptic partner"></a>Synaptic partner</h2><h3 id="Run-and-test-a-model-to-predict-synapse-and-synaptic-partner-simultaneously"><a href="#Run-and-test-a-model-to-predict-synapse-and-synaptic-partner-simultaneously" class="headerlink" title="Run and test a model to predict synapse and synaptic partner simultaneously"></a>Run and test a model to predict synapse and synaptic partner simultaneously</h3><p>I try to understand toufiq’s paper <a href="https://arxiv.org/pdf/1807.02739.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1807.02739.pdf</a> Detecting Synapse Location &amp; Connectivity by Signed Proximity Estimation and Pruning with Deep Nets. And rebuild the model using Keras. So we can have two different kinds of models to solve the <strong>synaptic partner problems</strong>. One is discussed before, and the other is toufiq’s model. We will compare this two model and take the advantages of two models to get better performance on CREMI.</p><p>I  rewrite and modify toufiq’s model using our data and understand his solutions about synaptic partner problems.<br>I apply multiple changes to the model.</p><ul><li>Change keras backend from theano to tensorflow and modify the corresponding codes.</li><li>Change depraceted function and update codes.</li><li>Change merge to concatenate, update model, conv3D </li></ul><p>The model looks like this:</p><p><img src="http://i4.fuimg.com/640680/14407c5eb5a7dc2e.png" alt="Markdown"></p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">THEANO_FLAGS=device=cuda<span class="variable">$1</span>,floatX=float32,dnn.enabled=True,dnn.library_path=<span class="regexp">/n/</span>home05<span class="regexp">/paragt/</span>cuda<span class="regexp">/lib64,dnn.include_path=/</span>n<span class="regexp">/home05/</span>paragt<span class="regexp">/cuda/i</span>nclude python -u  bin<span class="regexp">/vertebrate/</span>pixel<span class="regexp">/unet_3d_valid_unnorm_leaky_f24.py --trial=kasthuri_synapse_polarity_full_linear_leaky_f24_316_32 --imagedir=/</span>n<span class="regexp">/coxfs01/</span>paragt<span class="regexp">/test_submit/</span>ecs_synapse_polarity_full<span class="regexp">/grayscale_maps2_ac4/</span>  --gtname=<span class="regexp">/n/</span>coxfs01<span class="regexp">/paragt/</span>test_submit<span class="regexp">/ecs_synapse_polarity_full/</span>ac4_syn_polarity_both_corrected.h5 --ft=<span class="number">0</span></span><br></pre></td></tr></table></figure><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">module <span class="keyword">load</span> cuda/<span class="number">9.0</span>-fasrc01</span><br><span class="line"><span class="keyword">module</span> <span class="keyword">load</span> cudnn/<span class="number">7.0</span><span class="number">.3</span>-fasrc02</span><br><span class="line"><span class="keyword">module</span> <span class="keyword">load</span> Anaconda</span><br><span class="line"><span class="keyword">source</span> ~/anaconda2/<span class="keyword">bin</span>/<span class="keyword">activate</span> kears_theano</span><br><span class="line"></span><br><span class="line">THEANO_FLAGS=device=cuda,floatX=float32,dnn.enabled=<span class="literal">True</span> python -u test_pixelwise.py <span class="comment">--imagedir test_data/grayscale_maps_half/ --savename test_data/jwr_pixelwise_polarity.h5 --modelname models/3D_unet_jwr_synapse_polarity_half_linear_leaky_f24_316_32_100000.json --weightname models/3D_unet_jwr_synapse_polarity_half_linear_leaky_f24_316_32_100000_weights.h5</span></span><br></pre></td></tr></table></figure><p><img src="http://i4.fuimg.com/640680/2a531757ef1d035b.png" alt="Markdown"></p><h3 id="post-processing"><a href="#post-processing" class="headerlink" title="post processing"></a>post processing</h3><p>Toufiq has many post processing methods and it will be useful to process our prediction. So I study his codes and implement them.</p><p>dilate gt-syn to have bigger region</p><p><img src="http://i4.fuimg.com/640680/9cd40ceb9e49ebe8.png" alt="Markdown"></p><p><img src="http://i4.fuimg.com/640680/cb94994ad0869007.png" alt="Markdown"></p><p>some functions in<br><a href="https://github.com/microns-ariadne/pipeline_engine" target="_blank" rel="noopener">https://github.com/microns-ariadne/pipeline_engine</a></p><ul><li>segment_vesicle_style<br>Segment according to the “Vesicle” algorithm  See<br><a href="http://arxiv.org/abs/1403.3724" target="_blank" rel="noopener">http://arxiv.org/abs/1403.3724</a><br>VESICLE: Volumetric Evaluation of  Synaptic Interfaces using Computer Vision at Large Scale</li></ul><p>Volumetric Evaluation of Synaptic Interfaces using Computer vision at Large Scale<br>Segment according to the “Vesicle” algorithm</p><p><img src="http://i4.fuimg.com/640680/abd068c68b9d05f6.png" alt="Markdown"></p><p>It seems the algorithm  <strong>segment_vesicle_style</strong> do some post processing to <strong>smooth the results</strong></p><ul><li>match_synapses_by_overlap(gt_syn_np, syn_seg)<br>Determine the <strong>best ground truth synapse for a detected synapse by overlap</strong>,  <strong>gt_syn_np</strong>: dilated gt synapse, <strong>syn_seg</strong>: post processed prediction<br>Return two vectors. <ul><li>The first vector is the matching label in d for each gt label (with zero for “not a match”). </li><li>The second vector is the matching label in gt for each detected label.</li></ul></li></ul><p>interactively show blend of EM and dilated prediction</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">def draw_synseg(idx):</span><br><span class="line">    fig,<span class="attribute">ax</span>=plt.subplots(1,figsize=(8,8))</span><br><span class="line">    pylab.imshow(img[idx], <span class="attribute">cmap</span>=<span class="string">'gray'</span>)</span><br><span class="line">    pylab.imshow(gt_syn_np[idx], <span class="attribute">cmap</span>=<span class="string">'tab20'</span>, <span class="attribute">alpha</span>=.3)</span><br><span class="line">    pylab.colorbar()</span><br><span class="line">    pylab.show()</span><br><span class="line">interact(draw_synseg, idx=(0, 144))</span><br></pre></td></tr></table></figure><p>Dilated GT</p><p><img src="http://i4.fuimg.com/640680/78d027d947270dee.png" alt="Markdown"></p><p>post processed prediction</p><p><img src="http://i4.fuimg.com/640680/1f61c116cc41a292.png" alt="Markdown"></p><hr><p>Last three weeks<br>Week 7,8,9 (10)</p><p>Continue to improve synaptic partners model. It first uses a 3D U-net  to generates candidate synaptic connections from voxel-wise predictions of signed proximities. A second 3D CNN then prunes the set of candidates to produce the final detection of cleft and polar. </p><p>The U-net first generates candidate with many false positives</p><p><img src="http://i1.fuimg.com/640680/1da2e8575a992b08.png" alt="Markdown"></p><p>Then the 3D CNN uses EM image, predicted candidate and segmentation to classify if a candidate is a syanpse or not.</p><p><img src="http://i1.fuimg.com/640680/2216275efd0ce764.png" alt="Markdown"></p><hr><h4 id="use-bin-vertebrate-pixel-test-py-to-generate-candidate"><a href="#use-bin-vertebrate-pixel-test-py-to-generate-candidate" class="headerlink" title="use bin/vertebrate/pixel/test.py to generate candidate"></a>use bin/vertebrate/pixel/test.py to generate candidate</h4><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">THEANO_FLAGS=device=cuda<span class="variable">$1</span>,floatX=float32,dnn.enabled=True,dnn.library_path=<span class="regexp">/n/</span>home05<span class="regexp">/paragt/</span>cuda<span class="regexp">/lib64,dnn.include_path=/</span>n<span class="regexp">/home05/</span>paragt<span class="regexp">/cuda/i</span>nclude python -u bin<span class="regexp">/vertebrate/</span>pixel<span class="regexp">/test.py --imagedir  vol3_pngspad/</span> --savename jwrprediction<span class="regexp">/jwr_pixelwise_polarity_vol3.h5 --modelname models/</span><span class="number">3</span>D_unet_jwr_synapse_polarity_half_linear_leaky_f24_316_32_100000.json --weightname models<span class="regexp">/3D_unet_jwr_synapse_polarity_half_linear_leaky_f24_316_32_100000_weights.h5</span></span><br></pre></td></tr></table></figure><p>test_pixel_wise.py 是bin/vertebrate/pixel/test.py</p><ul><li>imagedir  /n/coxfs01/xupeng/projects/EMSynConn-master/vol3_image</li><li>imagedir   /zudi_data/jwr-test/grayscale_maps_half/image_00105.png</li><li>savename </li><li>modelname   JWR_annotation/trained_models/Toufiq/keras1/3D_unet_jwr_synapse_polarity_half_linear_leaky_f24_316_32_100000.json</li><li>weightname  JWR_annotation/trained_models/Toufiq/keras1/3D_unet_jwr_synapse_polarity_half_linear_leaky_f24_316_32_100000_weights.h5</li></ul><p>Must keep the following parameters, so we should do padding on jwr data.</p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">patchSize</span> = <span class="number">316</span></span><br><span class="line"><span class="attr">patchSize_out</span> = <span class="number">228</span></span><br><span class="line"><span class="attr">patchZ</span> = <span class="number">32</span></span><br><span class="line"><span class="attr">patchZ_out</span> = <span class="number">4</span></span><br></pre></td></tr></table></figure><h4 id="8-28-CNN"><a href="#8-28-CNN" class="headerlink" title="8.28 CNN"></a>8.28 CNN</h4><h5 id="Step1"><a href="#Step1" class="headerlink" title="Step1"></a>Step1</h5><p>Test.py in <strong>bin/candidate/pixel/test.py</strong></p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/bin/bash</span></span><br><span class="line"><span class="comment"># add all other SBATCH directives here...</span></span><br><span class="line"><span class="comment">#SBATCH -p seas_dgx1 </span></span><br><span class="line"><span class="comment">#SBATCH --gres=gpu:1</span></span><br><span class="line"><span class="comment">#SBATCH -n 1 # Number of cores</span></span><br><span class="line"><span class="comment">#SBATCH -N 1 # Ensure that all cores are on one machine                        </span></span><br><span class="line"><span class="comment">#SBATCH --mem=60000</span></span><br><span class="line"><span class="comment">#SBATCH -t 3-0:00:00</span></span><br><span class="line"><span class="comment">#SBATCH -o jwr_candidate_prune.log</span></span><br><span class="line"></span><br><span class="line"><span class="attribute">pred_thd_start</span>=-0.5</span><br><span class="line"><span class="attribute">iteration_start</span>=21500</span><br><span class="line"><span class="keyword">for</span> ((<span class="attribute">imultiple</span>=0;imultiple&lt;20;imultiple++));</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">    <span class="attribute">iteration1</span>=`echo <span class="variable">$iteration_start</span> + 500*<span class="variable">$imultiple</span> | bc -l`</span><br><span class="line"><span class="attribute">model_name</span>=kasthuri_val_seg_trial_0.3_o100_leaky_f24_160_16_122K_unbiased/syn_prune_kasthuri_val_seg_trial_0.3_o100_leaky_f24_160_16_122K_unbiased_$&#123;iteration1&#125;.json</span><br><span class="line">    <span class="attribute">weightname</span>=kasthuri_val_seg_trial_0.3_o100_leaky_f24_160_16_122K_unbiased/sys_prune_kasthuri_val_seg_trial_0.3_o100_leaky_f24_160_16_122K_unbiased_$&#123;iteration1&#125;_weights.h5</span><br><span class="line">    echo model <span class="variable">$model_name</span></span><br><span class="line">    echo weight <span class="variable">$weightname</span></span><br><span class="line">    echo threshold <span class="variable">$pred_thd</span></span><br><span class="line">    <span class="attribute">THEANO_FLAGS</span>=device=cuda,floatX=float32,dnn.enabled=True python -u test.py  <span class="attribute">--trial</span>=jwrdata_candidate_prune <span class="attribute">--datadir</span>=kasthuri_test_files <span class="attribute">--imagedir</span>=grayscale_maps2_cropped <span class="attribute">--predname</span>=ac3_synapse-polarity_full_linear_leaky_f24_316_32_122500.h5 --syn_gtname ac3_syn_groundtruth_cropped.h5  <span class="attribute">--segname</span>=ac3-seg_m.h5 --seg_gtname ac3_seg_groundtruth_cropped.h5  <span class="attribute">--inputSize_xy</span>=160 <span class="attribute">--inputSize_z</span>=16 --modelname <span class="variable">$model_name</span>  --weightname <span class="variable">$weightname</span>  --cleft_label</span><br><span class="line"></span><br><span class="line">done</span><br><span class="line">exit 0;</span><br></pre></td></tr></table></figure><hr><h5 id="Step2"><a href="#Step2" class="headerlink" title="Step2"></a>Step2</h5><p>First generate proposals</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/bin/bash</span></span><br><span class="line"><span class="comment"># add all other SBATCH directives here...</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#SBATCH -p cox</span></span><br><span class="line"><span class="comment">#SBATCH -n 1 # Number of cores</span></span><br><span class="line"><span class="comment">#SBATCH -N 1 # Ensure that all cores are on one machine                        </span></span><br><span class="line"><span class="comment">#SBATCH --mem=60000</span></span><br><span class="line"><span class="comment">#SBATCH -t 3-00:00:00</span></span><br><span class="line"><span class="comment">#SBATCH -o ecs_synapse_multiclass_f24_316_32_%j.log</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">iter=<span class="number">150000</span></span><br><span class="line">python generate_proposals.py  --trial test_seg_trial_0.<span class="number">3</span>_o100_leaky_f24_160_16 --datadir test_files --imagedir grayscale_maps2_tst4x6x6 --predname test_ecs_synapse_polarity_full_margin_linear_leaky_f24_316_32_196000-cropped.h5  --syn_gtname ecs-syn-tst-groundtruth-polarity.h5  --segname result_ecs-<span class="number">4</span>x6x6-<span class="number">100</span>K-<span class="number">40000</span>-itr3-thd0.<span class="number">1</span>_xml_m.h5  --seg_gtname seg_groundtruth0.h5  --inputSize_xy=<span class="number">160</span> --inputSize_z=<span class="number">16</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">exit</span> <span class="number">0</span>;</span><br></pre></td></tr></table></figure><h5 id="Step3"><a href="#Step3" class="headerlink" title="Step3"></a>Step3</h5><p><strong>submit_test_dgx_kasthuri.sh</strong>  test.py  do prediction</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/bin/bash</span></span><br><span class="line"><span class="comment"># add all other SBATCH directives here...</span></span><br><span class="line"><span class="comment">#SBATCH -p seas_dgx1 </span></span><br><span class="line"><span class="comment">#SBATCH --gres=gpu:1</span></span><br><span class="line"><span class="comment">#SBATCH -n 1 # Number of cores</span></span><br><span class="line"><span class="comment">#SBATCH -N 1 # Ensure that all cores are on one machine                        </span></span><br><span class="line"><span class="comment">#SBATCH --mem=60000</span></span><br><span class="line"><span class="comment">#SBATCH -t 3-0:00:00</span></span><br><span class="line"><span class="comment">#SBATCH -o ecs_test_316_32_%j.log</span></span><br><span class="line">source ~/anaconda2/bin/activate kears_theano</span><br><span class="line"></span><br><span class="line"><span class="attribute">pred_thd_start</span>=-0.5</span><br><span class="line"><span class="attribute">iteration_start</span>=21500</span><br><span class="line"><span class="keyword">for</span> ((<span class="attribute">imultiple</span>=0;imultiple&lt;20;imultiple++));</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">    <span class="attribute">iteration1</span>=`echo <span class="variable">$iteration_start</span> + 500*<span class="variable">$imultiple</span> | bc -l`</span><br><span class="line"><span class="attribute">model_name</span>=kasthuri_val_seg_trial_0.3_o100_leaky_f24_160_16_122K_unbiased/syn_prune_kasthuri_val_seg_trial_0.3_o100_leaky_f24_160_16_122K_unbiased_$&#123;iteration1&#125;.json</span><br><span class="line">    <span class="attribute">weightname</span>=kasthuri_val_seg_trial_0.3_o100_leaky_f24_160_16_122K_unbiased/sys_prune_kasthuri_val_seg_trial_0.3_o100_leaky_f24_160_16_122K_unbiased_$&#123;iteration1&#125;_weights.h5</span><br><span class="line">    echo model <span class="variable">$model_name</span></span><br><span class="line">    echo weight <span class="variable">$weightname</span></span><br><span class="line">    echo threshold <span class="variable">$pred_thd</span></span><br><span class="line">    <span class="attribute">THEANO_FLAGS</span>=device=cuda,floatX=float32,dnn.enabled=True python -u test.py  <span class="attribute">--trial</span>=kasthuri_test_seg_trial_0.3_o100_leaky_f24_160_16_122K <span class="attribute">--datadir</span>=kasthuri_test_files <span class="attribute">--imagedir</span>=grayscale_maps2_cropped <span class="attribute">--predname</span>=ac3_synapse-polarity_full_linear_leaky_f24_316_32_122500.h5 --syn_gtname ac3_syn_groundtruth_cropped.h5  <span class="attribute">--segname</span>=ac3-seg_m.h5 --seg_gtname ac3_seg_groundtruth_cropped.h5  <span class="attribute">--inputSize_xy</span>=160 <span class="attribute">--inputSize_z</span>=16 --modelname <span class="variable">$model_name</span>  --weightname <span class="variable">$weightname</span>  --cleft_label</span><br><span class="line"></span><br><span class="line">done</span><br><span class="line">exit 0;</span><br></pre></td></tr></table></figure><p><strong>run_unet_06_f24_kasthuri.sh</strong>  train a unet_3d_valid_unnorm_leaky_f24 model</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">THEANO_FLAGS=device=gpu<span class="variable">$1</span>,floatX=float32,dnn.enabled=True,dnn.library_path=<span class="regexp">/n/</span>home05<span class="regexp">/paragt/</span>cuda<span class="regexp">/lib64,dnn.include_path=/</span>n<span class="regexp">/home05/</span>paragt<span class="regexp">/cuda/i</span>nclude python -u  unet_3d_valid_unnorm_leaky_f24.py --trial=kasthuri_synapse_polarity_full_linear_leaky_f24_316_32 --imagedir=<span class="regexp">/n/</span>coxfs01<span class="regexp">/paragt/</span>test_submit<span class="regexp">/ecs_synapse_polarity_full/g</span>rayscale_maps2_ac4<span class="regexp">/  --gtname=/</span>n<span class="regexp">/coxfs01/</span>paragt<span class="regexp">/test_submit/</span>ecs_synapse_polarity_full<span class="regexp">/ac4_syn_polarity_both_corrected.h5</span></span><br></pre></td></tr></table></figure><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">pred_thd_start</span>=-0.5</span><br><span class="line"><span class="attribute">iteration_start</span>=21500</span><br><span class="line"><span class="keyword">for</span> ((<span class="attribute">imultiple</span>=0;imultiple&lt;20;imultiple++));</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">    <span class="attribute">iteration1</span>=`echo <span class="variable">$iteration_start</span> + 500*<span class="variable">$imultiple</span> | bc -l`</span><br><span class="line"><span class="attribute">model_name</span>=kasthuri_val_seg_trial_0.3_o100_leaky_f24_160_16_122K_unbiased/syn_prune_kasthuri_val_seg_trial_0.3_o100_leaky_f24_160_16_122K_unbiased_$&#123;iteration1&#125;.json</span><br><span class="line">    <span class="attribute">weightname</span>=kasthuri_val_seg_trial_0.3_o100_leaky_f24_160_16_122K_unbiased/sys_prune_kasthuri_val_seg_trial_0.3_o100_leaky_f24_160_16_122K_unbiased_$&#123;iteration1&#125;_weights.h5</span><br><span class="line">    echo model <span class="variable">$model_name</span></span><br><span class="line">    echo weight <span class="variable">$weightname</span></span><br><span class="line">    echo threshold <span class="variable">$pred_thd</span></span><br><span class="line">done</span><br></pre></td></tr></table></figure><p>We compare the model with SynEM on Kasthuri data. The model makes better prediction.</p><p><img src="http://i1.fuimg.com/640680/8b04e56610dffdea.png" alt="Markdown"></p><p>We will also test another model, Resnet+U-net, originated from task2 and it has many improvements in this summer.<br>It includes dilation CNN, batch normalization for multi-GPU, squeeze-and-excitation block. For polarity prediction, now the pixel can be either background, pre-synapse or post-synapse, so we can adapt the model to 3 channel  output. And we can change the loss function to MSE.</p><p><img src="http://i1.fuimg.com/640680/e80d496181dafa1e.png" alt="Markdown"></p><p>It has better generalization than what Funke’s group’s model since they over fit the CREMI dataset. It performs well on JWR data.</p><p>I will apply our model to predict synEM data. Thus we both test synEM model on our data and test our model on their data, this will give us enough result to compare our model.</p><p>SynEM data has four channels, using different size of synapse. We only use the small polarity for post synapse and large for pre synapse.<br>[image:F10F22C4-AAA4-4868-B496-BF7DB0A73A97-385-0000D376F35FA1C0/屏幕快照 2018-09-04 下午5.27.40.png]</p><p><code>env create -f bin/synapse_pytorch/envs/py3_pytorch.yml</code></p><p><code>source activate py3_pytorch</code></p><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">source activate py3_pytorch</span><br><span class="line">CUDA_VISIBLE_DEVICES=<span class="number">0</span> python3 -u bin/synapse_pytorch/train_sync_polarity.py -t /n/coxfs01/xupeng/projects/synapse/data/synEM/synEM_train_data/ -dn raw/synEM_train_raw_000.h5 -ln label_new/synEM_train_label_new_channel_000.h5 -o outputs/<span class="number">9.6</span>_single -lr <span class="number">1e-03</span> --volume-total <span class="number">1600000</span> --volume-save <span class="number">100000</span> -mi <span class="number">8</span>,<span class="number">160</span>,<span class="number">160</span> -g <span class="number">1</span> -c <span class="number">1</span> -b <span class="number">1</span></span><br></pre></td></tr></table></figure><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">source activate py3_pytorch</span><br><span class="line">CUDA_VISIBLE_DEVICES=<span class="number">0</span> python3 -u bin/synapse_pytorch/train_sync_polarity.py -t data/synEM/synEM/synEM_train_data/ -dn raw/synEM_train_raw_000.h5 -ln label_new/synEM_train_label_new_channel_000.h5 -o outputs/<span class="number">9.6</span>_single -lr <span class="number">1e-03</span> --volume-total <span class="number">1600000</span> --volume-save <span class="number">100000</span> -mi <span class="number">8</span>,<span class="number">160</span>,<span class="number">160</span> -g <span class="number">1</span> -c <span class="number">1</span> -b <span class="number">1</span></span><br></pre></td></tr></table></figure><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">source activate py3_pytorch</span><br><span class="line">CUDA_VISIBLE_DEVICES=<span class="number">0</span> python3 -u bin/synapse_pytorch/train_sync_polarity.py -t /n/coxfs01/zudilin/research/data/JWR/syn_vol1/ -dn im.h5 -ln jwr_syn_polarity.h5 -o outputs/<span class="number">9.10</span>_single -lr <span class="number">1e-03</span> --volume-total <span class="number">1600000</span> --volume-save <span class="number">100000</span> -mi <span class="number">8</span>,<span class="number">160</span>,<span class="number">160</span> -g <span class="number">1</span> -c <span class="number">1</span> -b <span class="number">1</span></span><br></pre></td></tr></table></figure><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">source activate py3_pytorch</span><br><span class="line">CUDA_VISIBLE_DEVICES=<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span> python3 -u bin/synapse_pytorch/train_sync_polarity.py -t /n/coxfs01/xupeng/projects/synapse/data/synEM/synEM_train_data/ -dn raw/synEM_train_raw_000.h5@raw/synEM_train_raw_001.h5@raw/synEM_train_raw_002.h5 -ln label_new/synEM_train_label_new_channel_000.h5@label_new/synEM_train_label_new_channel_001.h5@label_new/synEM_train_label_new_channel_002.h5 -o outputs/<span class="number">9.6</span> -lr <span class="number">1e-03</span> --volume-total <span class="number">1600000</span> --volume-save <span class="number">100000</span> -mi <span class="number">8</span>,<span class="number">160</span>,<span class="number">160</span> -g <span class="number">3</span> -c <span class="number">3</span> -b <span class="number">3</span></span><br></pre></td></tr></table></figure><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/bin/bash</span></span><br><span class="line"><span class="comment"># add all other SBATCH directives here...</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#SBATCH -p cox</span></span><br><span class="line"><span class="comment">#SBATCH --gres=gpu:8</span></span><br><span class="line"><span class="comment">#SBATCH --constraint=titanx</span></span><br><span class="line"><span class="comment">#SBATCH -n 8 # Number of cores</span></span><br><span class="line"><span class="comment">#SBATCH -N 1 # Ensure that all cores are on one machine</span></span><br><span class="line"><span class="comment">#SBATCH --mem=50000</span></span><br><span class="line"><span class="comment">#SBATCH -t 5-00:00:00</span></span><br><span class="line"><span class="comment">#SBATCH -o logs/train_%j.log</span></span><br><span class="line"></span><br><span class="line">module load cuda</span><br><span class="line">source activate py3_pytorch</span><br><span class="line"></span><br><span class="line">CUDA_VISIBLE_DEVICES=<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span> python3 -u bin<span class="regexp">/synapse_pytorch/</span>train_sync_polarity.py -t <span class="regexp">/n/</span>coxfs01<span class="regexp">/xupeng/</span>projects<span class="regexp">/synapse/</span>data<span class="regexp">/synEM/</span>synEM_train_data<span class="regexp">/ -dn raw/</span>synEM_train_raw_000.h5@raw<span class="regexp">/synEM_train_raw_001.h5@raw/</span>synEM_train_raw_002.h5@raw<span class="regexp">/synEM_train_raw_003.h5@raw/</span>synEM_train_raw_004.h5@raw<span class="regexp">/synEM_train_raw_005.h5@raw/</span>synEM_train_raw_006.h5@raw<span class="regexp">/synEM_train_raw_007.h5@raw/</span>synEM_train_raw_008.h5@raw<span class="regexp">/synEM_train_raw_009.h5 -ln label_new/</span>synEM_train_label_new_channel_000.h5@label_new<span class="regexp">/synEM_train_label_new_channel_001.h5@label_new/</span>synEM_train_label_new_channel_002.h5@label_new<span class="regexp">/synEM_train_label_new_channel_003.h5@label_new/</span>synEM_train_label_new_channel_004.h5@label_new<span class="regexp">/synEM_train_label_new_channel_005.h5@label_new/</span>synEM_train_label_new_channel_006.h5@label_new<span class="regexp">/synEM_train_label_new_channel_007.h5@label_new/</span>synEM_train_label_new_channel_008.h5@label_new<span class="regexp">/synEM_train_label_new_channel_009.h5 -o outputs/</span><span class="number">9.5</span>_10_volumes -lr <span class="number">1</span>e-<span class="number">03</span> --volume-total <span class="number">1600000</span> --volume-save <span class="number">100000</span> -mi <span class="number">8</span>,<span class="number">160</span>,<span class="number">160</span> -g <span class="number">8</span> -c <span class="number">8</span> -b <span class="number">32</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># end of program</span></span><br><span class="line"><span class="keyword">exit</span> <span class="number">0</span>;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;It is part of my computational task during my summer intern in &lt;a href=&quot;https://lichtmanlab.fas.harvard.edu/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Lichtman Lab&lt;/a&gt; and &lt;a href=&quot;https://vcg.seas.harvard.edu/people&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Hanspiter Lab&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;It is part of the big synapse project. Also the challenge 3 of &lt;a href=&quot;https://cremi.org&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;CREMI&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;For &lt;strong&gt;whole work summary&lt;/strong&gt; please &lt;a href=&quot;https://www.cmwonderland.com/blog/2018/09/12/100_summer_intern/&quot;&gt;see here&lt;/a&gt;&lt;/p&gt;


	&lt;div class=&quot;row&quot;&gt;
		&lt;iframe src=&quot;https://drive.google.com/file/d/1XyEPj9r7p8VNk5nLlLIPNhZjuDHu2KTY/preview&quot; style=&quot;width:100%; height:550px&quot;&gt;&lt;/iframe&gt;
	&lt;/div&gt;



&lt;p&gt;Also I finished another NMJ project during summer intern in &lt;a href=&quot;https://lichtmanlab.fas.harvard.edu/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Lichtman Lab&lt;/a&gt; &lt;/p&gt;
&lt;h1 id=&quot;Codes&quot;&gt;&lt;a href=&quot;#Codes&quot; class=&quot;headerlink&quot; title=&quot;Codes&quot;&gt;&lt;/a&gt;Codes&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/james20141606/Summer_Intern/tree/master/synapse_prediction&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Summer_Intern/synaptic_partner at master · james20141606/Summer_Intern · GitHub&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/james20141606/EM-network&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Synapse polarity&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/james20141606/Summer_Intern/tree/master/synapse_cluster&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Summer_Intern/synapse_cluster at master · james20141606/Summer_Intern · GitHub&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="projects" scheme="https://www.cmwonderland.com/blog/categories/projects/"/>
    
    
      <category term="project" scheme="https://www.cmwonderland.com/blog/tags/project/"/>
    
      <category term="neural science" scheme="https://www.cmwonderland.com/blog/tags/neural-science/"/>
    
      <category term="summer intern" scheme="https://www.cmwonderland.com/blog/tags/summer-intern/"/>
    
      <category term="connectomics" scheme="https://www.cmwonderland.com/blog/tags/connectomics/"/>
    
      <category term="computational neural science" scheme="https://www.cmwonderland.com/blog/tags/computational-neural-science/"/>
    
      <category term="deep learning" scheme="https://www.cmwonderland.com/blog/tags/deep-learning/"/>
    
      <category term="computer vision" scheme="https://www.cmwonderland.com/blog/tags/computer-vision/"/>
    
      <category term="Jeff Lichtman" scheme="https://www.cmwonderland.com/blog/tags/Jeff-Lichtman/"/>
    
  </entry>
  
</feed>
