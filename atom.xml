<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>WonderLand</title>
  
  <subtitle>Somnium &amp; Somniator</subtitle>
  <link href="/blog/atom.xml" rel="self"/>
  
  <link href="https://www.cmwonderland.com/blog/"/>
  <updated>2018-10-11T11:18:20.187Z</updated>
  <id>https://www.cmwonderland.com/blog/</id>
  
  <author>
    <name>James Chen</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Identification of Cancer Biomarker</title>
    <link href="https://www.cmwonderland.com/blog/2018/10/11/101-exrna-project/"/>
    <id>https://www.cmwonderland.com/blog/2018/10/11/101-exrna-project/</id>
    <published>2018-10-10T16:30:44.000Z</published>
    <updated>2018-10-11T11:18:20.187Z</updated>
    
    <content type="html"><![CDATA[<p><strong>exSeek: Identification of Cancer Biomarker</strong></p><p>The aim of this project is to combine <strong>small cell free RNA sequencing techniques</strong> with <strong>machine learning</strong> to identify promising candidate biomarker for cancers. We establish the pipeline from mapping to feature selection and propose a <strong>robust feature selection method</strong> to identify potential biomarkers.</p><p>Parts of this works difficulty is its steps and precision it requires. For example, we do quality control using many methods and criteria. Since our RNA-seq is different (it has less RNA reads), we have to explore the mapping sequence. I propose a quick mapping order method to check thousands of mapping order in a short time.</p><a id="more"></a><h2 id="Work-Summary"><a href="#Work-Summary" class="headerlink" title="Work Summary"></a>Work Summary</h2><div class="row"><iframe src="https://drive.google.com/file/d/1-o090Cv-_cMOGITgzlC2FrVrlLdA9zva/preview" style="width:100%; height:550px"></iframe></div><p>We use our own data: HCC exRNA and two other data: exoRBase and GSE71008 to establish our robust feature selection methods.</p><p><strong>Our work can be divided into following parts:</strong></p><h3 id="mapping"><a href="#mapping" class="headerlink" title="mapping"></a>mapping</h3><p>We use sequential mapping strategy for small RNA data (HCC exRNA and GSE71008)<br>We use fast mapping order test method to map in thousands of different orders in a very short time and decide the order.<br><img src="http://i2.tiimg.com/640680/a7331057c61ed2a8.png" alt="Markdown"></p><h3 id="construct-expression-matrix"><a href="#construct-expression-matrix" class="headerlink" title="construct expression matrix"></a>construct expression matrix</h3><p>Considering the characteristic of small RNA and exRNA. We think it is better to use domain features instead of full length RNA. So we also do peak calling to construct both full length and peak expression matrix.</p><h3 id="Preprocessing"><a href="#Preprocessing" class="headerlink" title="Preprocessing"></a>Preprocessing</h3><p>All the datasets need to be normalized and remove batch effect.</p><p>I test several normalization method:</p><ul><li>CPM</li><li>remove piRNA and miRNA</li><li>Use several reference miRNA</li><li>SCNorm</li><li>TMM</li><li>RLE</li></ul><p>I also use batch removal method including RUVs and Combat.</p><h3 id="Robust-feature-selection-method"><a href="#Robust-feature-selection-method" class="headerlink" title="Robust feature selection method"></a>Robust feature selection method</h3><p>Our aim is to establish a robust feature selection machine learning model to select very few feature as candidate cancer biomarkers.</p><ul><li>Normalize domain coverage </li><li>Scale each feature (log) independently (using z-scores, min-max, <strong>robust normalization</strong>)</li><li>Run a classifier (<strong>Random Forest, Logistic Regression, Linear SVM</strong>) to select features based on feature importance. Optimize hyper-parameters by <strong>3-fold cross-validation</strong>.</li><li>Optionally, use a recursive feature elimination (<strong>RFE</strong>) to eliminate features.</li><li>Repeat feature selection for 100 times. Randomly remove 10% samples in each run (<strong>Jackknife resampling</strong>) or do <strong>shuflle split</strong>.</li><li>Select features that are recurrently selected across resampling runs (&gt;50%)</li><li>Refit the classifier on selected features</li></ul><p>For detailed illustration of our pipeline please see <strong>Work Summary</strong> above.</p><h2 id="Codes"><a href="#Codes" class="headerlink" title="Codes:"></a>Codes:</h2><p><a href="https://github.com/james20141606/exRNA/" target="_blank" rel="noopener">exSeek GitHub</a></p><h2 id="Related"><a href="#Related" class="headerlink" title="Related"></a>Related</h2><p>As teaching assistant of <a href="https://legacy.gitbook.com/book/lulab/teaching/details" target="_blank" rel="noopener">Bioinformatics Basics</a>. I use part of our work to assign the <a href="https://lulab.gitbooks.io/teaching/content/quiz/quiz_exrna/quiz_exrna_tutorial.html" target="_blank" rel="noopener">final project</a> of this semester’s course.  </p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;strong&gt;exSeek: Identification of Cancer Biomarker&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The aim of this project is to combine &lt;strong&gt;small cell free RNA sequencing techniques&lt;/strong&gt; with &lt;strong&gt;machine learning&lt;/strong&gt; to identify promising candidate biomarker for cancers. We establish the pipeline from mapping to feature selection and propose a &lt;strong&gt;robust feature selection method&lt;/strong&gt; to identify potential biomarkers.&lt;/p&gt;
&lt;p&gt;Parts of this works difficulty is its steps and precision it requires. For example, we do quality control using many methods and criteria. Since our RNA-seq is different (it has less RNA reads), we have to explore the mapping sequence. I propose a quick mapping order method to check thousands of mapping order in a short time.&lt;/p&gt;
    
    </summary>
    
      <category term="projects" scheme="https://www.cmwonderland.com/blog/categories/projects/"/>
    
    
      <category term="project" scheme="https://www.cmwonderland.com/blog/tags/project/"/>
    
      <category term="machine learning" scheme="https://www.cmwonderland.com/blog/tags/machine-learning/"/>
    
      <category term="precision medicine" scheme="https://www.cmwonderland.com/blog/tags/precision-medicine/"/>
    
  </entry>
  
  <entry>
    <title>RNA Structural Motif Finding using Deep Learning</title>
    <link href="https://www.cmwonderland.com/blog/2018/10/11/102-deepshape-project/"/>
    <id>https://www.cmwonderland.com/blog/2018/10/11/102-deepshape-project/</id>
    <published>2018-10-10T16:30:36.000Z</published>
    <updated>2018-10-11T11:18:08.905Z</updated>
    
    <content type="html"><![CDATA[<p><strong>DeepShape: RNA Structural Motif Finding</strong></p><p><strong>DeepShape</strong> is the project I like the most and devote the most during my undergraduate research time. It originates the interests of applying deep learning to predict RNA structure and structure probing data. During a lot of trying we realized current convolutional and recurrent neural network are not suitable to <strong>really understand RNA structure</strong>. We can get a “pseudo” good result yet learn little about the real structure information.</p><p>We then turn to predict RNA motif (especially RNA-protein interaction related motif). It is another harder problem compared with “simply” applying deep neural network to 1D and 2D structure data. We develop the mixture model for PWM optimization. We explore the possibility to use VAE for unsupervised learning. What’s more, I strongly believe a relatively new model: <strong>graph convolutional neural network</strong> has a great potential to really utilize and discover the structural information in motif finding problem. </p><a id="more"></a><h2 id="abstract"><a href="#abstract" class="headerlink" title="abstract"></a>abstract</h2><p>RNAs play key roles in cells through the structural specificity and interactions with proteins known as the RNA-binding proteins(RBP). The binding motifs enable crucial understanding of the regulation of RNAs. Many automatic tools have been developed to predict the RNA-protein binding sites from the rapidly growing multi-resource data, e.g. sequence, structure, their domain specific features. MEME, RNApromo and GraphProt can utilize sequence and structural feature using algorithms like expectation maximization (EM) or support vector machine (SVM). </p><p>However, there are several limitations in existing methods. For example, the SCFG-based model has a very high computational complexity and the position-weight matrix (PWM) model does not learn structural information. Machine learning model like GraphProt and DeepBind relies on class labels and can’t handle unsupervised motif finding task. Deep learning-based algorithms are believed  to be capable of capturing features in structural data, e.g. image and sequence data.  However, current models didn’t incorporate structure probing data like icSHAPE. What’s more, convolutional neural network cannot accept secondary structure data as input.</p><p>We propose to use Variational Auto-Encoder (VAE) as motif model and incorporate it into EM algorithm to predict motif existence and locate motif position.  VAE can encode sequence data and decode it as probability in PWM. It can be optimized by optimizing the combination of KL loss and reconstruction loss. VAE-based mixture model achieves good performance in sequence data (JASPAR). We also propose to use Graph Convolutional Neural Network (GCN) to capture RNA secondary structure feature for structural related motif finding. We first represent RNA structure as graph, encoding nucleotides and base pairs as nodes and edges. We also encode higher level graph features like hairpin, helix and bulge. GCN can incorporate and utilize both sequence and structural features to predict motif existence and location. It achieves good performance compared with other methods considering accuracy and computational efficiency.</p><h2 id="Work-report"><a href="#Work-report" class="headerlink" title="Work report"></a>Work report</h2><p>We are still making progress in DeepShape project, using Graph Convolutional Neural Network to discover structural motif.</p><p>The Project introduction can be divided into two parts: predicting RNA secondary structure probing data and discover motif.</p><h3 id="Predicting-icSHAPE-secondary-structure-probing-data"><a href="#Predicting-icSHAPE-secondary-structure-probing-data" class="headerlink" title="Predicting icSHAPE: secondary structure probing data"></a>Predicting icSHAPE: secondary structure probing data</h3><div class="row"><iframe src="https://drive.google.com/file/d/1Iv1r7LUNpYxNrXm450GGUzT67M61qf4E/preview" style="width:100%; height:550px"></iframe></div><h3 id="methods"><a href="#methods" class="headerlink" title="methods:"></a>methods:</h3><p>We use window to convert RNA sequence into uniform slices for 1D deep learning model. We also try something <strong>new and fun</strong>: we convert one sequence to a 2D map and use <strong>specialized designed 2D U-net</strong> to predict it. (<em>Later we find that google use the similar idea to predict SNP as images</em>).</p><ul><li>1D<ul><li>CNN</li><li>RNN</li><li>ResNet</li><li>Seq2Seq</li><li>Attention</li></ul></li><li>2D<ul><li>U-net</li></ul></li></ul><h3 id="Discover-MOTIF-predict-existence-and-location-of-motif"><a href="#Discover-MOTIF-predict-existence-and-location-of-motif" class="headerlink" title="Discover MOTIF: predict existence and location of motif"></a>Discover MOTIF: predict existence and location of motif</h3><div class="row"><iframe src="https://drive.google.com/file/d/11XfyNguAXpVCcWGKQhgyspLA7w5M2fYa/preview" style="width:100%; height:550px"></iframe></div><h3 id="methods-1"><a href="#methods-1" class="headerlink" title="methods:"></a>methods:</h3><p>We revise and improve MEME’s EM algorithm to Mixture-PWM to make the model more robust to noises.</p><p>We also replace the PWM matrix with a Variational Auto-Encoder (<strong>VAE</strong>).</p><p>We then use Graph Convolutional Neural Network (<strong>GCN</strong>) to explore the possibility to predict <strong>Structural related motif</strong>. During our long time exploration, we find GCN may be the best method (in deep learning) to truly understand the structural information in RNA sequence.</p><h2 id="Codes"><a href="#Codes" class="headerlink" title="Codes:"></a>Codes:</h2><p><a href="https://github.com/james20141606/Deepshape/" target="_blank" rel="noopener">DeepShape GitHub</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;strong&gt;DeepShape: RNA Structural Motif Finding&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;DeepShape&lt;/strong&gt; is the project I like the most and devote the most during my undergraduate research time. It originates the interests of applying deep learning to predict RNA structure and structure probing data. During a lot of trying we realized current convolutional and recurrent neural network are not suitable to &lt;strong&gt;really understand RNA structure&lt;/strong&gt;. We can get a “pseudo” good result yet learn little about the real structure information.&lt;/p&gt;
&lt;p&gt;We then turn to predict RNA motif (especially RNA-protein interaction related motif). It is another harder problem compared with “simply” applying deep neural network to 1D and 2D structure data. We develop the mixture model for PWM optimization. We explore the possibility to use VAE for unsupervised learning. What’s more, I strongly believe a relatively new model: &lt;strong&gt;graph convolutional neural network&lt;/strong&gt; has a great potential to really utilize and discover the structural information in motif finding problem. &lt;/p&gt;
    
    </summary>
    
      <category term="projects" scheme="https://www.cmwonderland.com/blog/categories/projects/"/>
    
    
      <category term="project" scheme="https://www.cmwonderland.com/blog/tags/project/"/>
    
      <category term="deep learning" scheme="https://www.cmwonderland.com/blog/tags/deep-learning/"/>
    
      <category term="RNA structure" scheme="https://www.cmwonderland.com/blog/tags/RNA-structure/"/>
    
      <category term="VAE" scheme="https://www.cmwonderland.com/blog/tags/VAE/"/>
    
      <category term="GCN" scheme="https://www.cmwonderland.com/blog/tags/GCN/"/>
    
  </entry>
  
  <entry>
    <title>Summer Intern Project Summary</title>
    <link href="https://www.cmwonderland.com/blog/2018/10/10/100_summer_intern/"/>
    <id>https://www.cmwonderland.com/blog/2018/10/10/100_summer_intern/</id>
    <published>2018-10-10T14:05:19.000Z</published>
    <updated>2018-10-11T11:19:09.401Z</updated>
    
    <content type="html"><![CDATA[<p>This page summarize my summer intern work, includes final report, weekly report, codes, presentation.</p><p>To sum up, I mainly do two projects in this summer, which can be divided again into four works:</p><ul><li><p><a href="https://lichtmanlab.fas.harvard.edu/" target="_blank" rel="noopener">Lichtman Lab</a>:</p><ul><li>NMJ tracing and segmenting with statistical work</li><li>NMJ automatic segmentation pipeline</li></ul></li><li><p><a href="https://vcg.seas.harvard.edu/people" target="_blank" rel="noopener">Hanspiter Lab</a>:</p><ul><li>Synapse prediction</li><li>Synaptic polarity prediction</li></ul></li></ul><p>For NMJ tracing, segmenting and automatic prediction work, we push forward the project with the generous daily help of our mentor Jeff. </p><p>For Synapse project, I work with Zudi and Donglai, we now rank No.1 in the <a href="https://cremi.org" target="_blank" rel="noopener">CREMI contest</a>. And we will submit a paper to CVPR this November.</p><a id="more"></a><h1 id="final-report"><a href="#final-report" class="headerlink" title="final report"></a>final report</h1><ul><li>online pdf</li></ul><div class="row"><iframe src="https://drive.google.com/file/d/1XyEPj9r7p8VNk5nLlLIPNhZjuDHu2KTY/preview" style="width:100%; height:550px"></iframe></div><ul><li>pdf in github</li></ul><p>You may also find the <a href="https://github.com/james20141606/Summer_Intern/blob/master/summer_intern_report_xupeng.pdf" target="_blank" rel="noopener"><strong>PDF Version</strong></a> of this report from github.</p><h1 id="presentation"><a href="#presentation" class="headerlink" title="presentation"></a>presentation</h1><h2 id="in-Lichtman-lab"><a href="#in-Lichtman-lab" class="headerlink" title="in Lichtman lab"></a>in Lichtman lab</h2><ul><li>online pdf</li></ul><div class="row"><iframe src="https://drive.google.com/file/d/1pLtw2eLJl9kMVj1pGSCqehcBfjVdBZ4c/preview" style="width:100%; height:550px"></iframe></div><h2 id="in-Tsinghua"><a href="#in-Tsinghua" class="headerlink" title="in Tsinghua"></a>in Tsinghua</h2><ul><li>online pdf</li></ul><div class="row"><iframe src="https://drive.google.com/file/d/1mVOPchbWZ9nsODPklNjw_OGwl2vehKdF/preview" style="width:100%; height:550px"></iframe></div><h1 id="codes"><a href="#codes" class="headerlink" title="codes"></a>codes</h1><p><a href="https://github.com/james20141606/Summer_Intern" target="_blank" rel="noopener">Main codes</a><br><a href="https://github.com/james20141606/NMJ_automatic_pipeline" target="_blank" rel="noopener">Automatic pipeline</a><br><a href="https://github.com/james20141606/EM-network" target="_blank" rel="noopener">Synapse polarity</a></p><h1 id="detailed-progress"><a href="#detailed-progress" class="headerlink" title="detailed progress"></a>detailed progress</h1><p>I summarized my daily progress about the following project during my summer intern, please visit the related web pages:</p><p><a href="https://www.cmwonderland.com/2018/07/14/summerintern_NMJ/">NMJ project</a><br><a href="https://www.cmwonderland.com/2018/07/14/summerintern_Synapse_Prediction/">Synapse Prediction</a><br><a href="https://www.cmwonderland.com/2018/07/14/summerintern_Synaptic_Partner_and_Cluster_Project/">Synaptic Partner and Cluster Project</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;This page summarize my summer intern work, includes final report, weekly report, codes, presentation.&lt;/p&gt;
&lt;p&gt;To sum up, I mainly do two projects in this summer, which can be divided again into four works:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&quot;https://lichtmanlab.fas.harvard.edu/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Lichtman Lab&lt;/a&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;NMJ tracing and segmenting with statistical work&lt;/li&gt;
&lt;li&gt;NMJ automatic segmentation pipeline&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&quot;https://vcg.seas.harvard.edu/people&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Hanspiter Lab&lt;/a&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Synapse prediction&lt;/li&gt;
&lt;li&gt;Synaptic polarity prediction&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For NMJ tracing, segmenting and automatic prediction work, we push forward the project with the generous daily help of our mentor Jeff. &lt;/p&gt;
&lt;p&gt;For Synapse project, I work with Zudi and Donglai, we now rank No.1 in the &lt;a href=&quot;https://cremi.org&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;CREMI contest&lt;/a&gt;. And we will submit a paper to CVPR this November.&lt;/p&gt;
    
    </summary>
    
      <category term="projects" scheme="https://www.cmwonderland.com/blog/categories/projects/"/>
    
    
      <category term="project" scheme="https://www.cmwonderland.com/blog/tags/project/"/>
    
      <category term="neural science" scheme="https://www.cmwonderland.com/blog/tags/neural-science/"/>
    
      <category term="summer intern" scheme="https://www.cmwonderland.com/blog/tags/summer-intern/"/>
    
      <category term="connectomics" scheme="https://www.cmwonderland.com/blog/tags/connectomics/"/>
    
      <category term="computational neural science" scheme="https://www.cmwonderland.com/blog/tags/computational-neural-science/"/>
    
      <category term="deep learning" scheme="https://www.cmwonderland.com/blog/tags/deep-learning/"/>
    
      <category term="computer vision" scheme="https://www.cmwonderland.com/blog/tags/computer-vision/"/>
    
      <category term="Jeff Lichtman" scheme="https://www.cmwonderland.com/blog/tags/Jeff-Lichtman/"/>
    
  </entry>
  
  <entry>
    <title>Machine Learning for Traits Prediction</title>
    <link href="https://www.cmwonderland.com/blog/2018/10/10/96-emaize-project/"/>
    <id>https://www.cmwonderland.com/blog/2018/10/10/96-emaize-project/</id>
    <published>2018-10-10T12:30:51.000Z</published>
    <updated>2018-10-11T11:18:37.447Z</updated>
    
    <content type="html"><![CDATA[<p><strong>eMaize: Machine Learning for Traits Prediction</strong></p><p>Heterosis is the improved or increased function of any biological quality in a hybrid offspring. We have studied yet the largest maize SNP dataset for traits prediction.</p><p>We develop linear and non-linear models which consider relationships between different hybrids as well as other effect. Specially designed model proved to be efficient and robust in prediction maize’s traits.</p><p>We proposed a new mixed linear model <strong>Mixed Ridge</strong> with Fast cross validation to pick parameters. We also propose <strong>Metric Regressor</strong> for few shot learning.</p><a id="more"></a><h2 id="Preprint-paper"><a href="#Preprint-paper" class="headerlink" title="Preprint paper:"></a>Preprint paper:</h2><div class="row">    <embed src="https://arxiv.org/pdf/1808.06275.pdf" width="100%" height="550" type="application/pdf"></div><h2 id="Codes"><a href="#Codes" class="headerlink" title="Codes:"></a>Codes:</h2><p><a href="https://github.com/james20141606/eMaize/" target="_blank" rel="noopener">eMaize GitHub</a></p><h2 id="Presentation"><a href="#Presentation" class="headerlink" title="Presentation"></a>Presentation</h2><div class="row"><iframe src="https://drive.google.com/file/d/1m3fLr_DUkF2NB_DU_YRfAAMV-vkU09AA/preview" style="width:100%; height:550px"></iframe></div><h2 id="Related"><a href="#Related" class="headerlink" title="Related"></a>Related</h2><h3 id="proposal"><a href="#proposal" class="headerlink" title="proposal"></a>proposal</h3><div class="row"><iframe src="https://drive.google.com/file/d/1uD61pNPaNcpAn_MPE9jSjk25qIwhdFAm/preview" style="width:100%; height:550px"></iframe></div>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;strong&gt;eMaize: Machine Learning for Traits Prediction&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Heterosis is the improved or increased function of any biological quality in a hybrid offspring. We have studied yet the largest maize SNP dataset for traits prediction.&lt;/p&gt;
&lt;p&gt;We develop linear and non-linear models which consider relationships between different hybrids as well as other effect. Specially designed model proved to be efficient and robust in prediction maize’s traits.&lt;/p&gt;
&lt;p&gt;We proposed a new mixed linear model &lt;strong&gt;Mixed Ridge&lt;/strong&gt; with Fast cross validation to pick parameters. We also propose &lt;strong&gt;Metric Regressor&lt;/strong&gt; for few shot learning.&lt;/p&gt;
    
    </summary>
    
      <category term="projects" scheme="https://www.cmwonderland.com/blog/categories/projects/"/>
    
    
      <category term="project" scheme="https://www.cmwonderland.com/blog/tags/project/"/>
    
      <category term="machine learning" scheme="https://www.cmwonderland.com/blog/tags/machine-learning/"/>
    
      <category term="breeding" scheme="https://www.cmwonderland.com/blog/tags/breeding/"/>
    
      <category term="linear mixed model" scheme="https://www.cmwonderland.com/blog/tags/linear-mixed-model/"/>
    
  </entry>
  
  <entry>
    <title>MDN for Signal Position Prediction</title>
    <link href="https://www.cmwonderland.com/blog/2018/10/09/94-signal-project/"/>
    <id>https://www.cmwonderland.com/blog/2018/10/09/94-signal-project/</id>
    <published>2018-10-08T16:50:56.000Z</published>
    <updated>2018-10-11T11:18:53.942Z</updated>
    
    <content type="html"><![CDATA[<p>This page summarize our work on using mixture density network to jointly predict position coordinates.</p><p>We collaborate with Jun Li in New York University. </p><h2 id="presentation-of-current-work"><a href="#presentation-of-current-work" class="headerlink" title="presentation of current work"></a>presentation of current work</h2><div class="row"><iframe src="https://drive.google.com/file/d/12kdQZKUrz-z_4k-eSW83ogKvTRwPjn3o/preview" style="width:100%; height:550px"></iframe></div><h2 id="methods"><a href="#methods" class="headerlink" title="methods"></a>methods</h2><h3 id="model"><a href="#model" class="headerlink" title="model"></a>model</h3><p>We use pytorch and tensorflow to develop our mixture density network. </p><ul><li>A MLP is used to generate pi, mu and sigma for 2D isotropic gaussian distribution.</li><li>Several 2D gaussian distribution is mixed to form a mixed gaussian distribution.<br><img src="http://i2.tiimg.com/640680/4d39615fdca66f67.png" alt="Markdown"></li><li>We use Maximum Likelihood Estimation, choose negetive log likelihood as our loss function for optimization</li><li><img src="http://i2.tiimg.com/640680/abf549073048f5f9.png" alt="Markdown"></li></ul><p>Several tricks:</p><ul><li>deal with loss nan: we use log transform of signa, mu and pi, also a cutoff of sigma and pseudo counts of pi is used to prevend loss explosion of vanishing</li><li>z score normalization to optimize the model easier.</li><li>we use mean shift to find modes in gaussian mixture</li></ul><p><img src="http://i2.tiimg.com/640680/0ef0ba152c39f99f.png" alt="Markdown"></p><h3 id="result"><a href="#result" class="headerlink" title="result"></a>result</h3><p><img src="http://i2.tiimg.com/640680/e7e107d4d04e6849.png" alt="Markdown"></p><h3 id="data"><a href="#data" class="headerlink" title="data"></a>data</h3><h4 id="mountain-data"><a href="#mountain-data" class="headerlink" title="mountain data"></a>mountain data</h4><ul><li>data position<br><img src="http://i2.tiimg.com/640680/1668bdf4741445b1.png" alt="Markdown"></li><li>t-SNE to cluster data<br><img src="http://i2.tiimg.com/640680/c06e0baac3381bc4.png" alt="Markdown"></li><li>feature distribution<br><img src="http://i2.tiimg.com/640680/258900a437c4a544.png" alt="Markdown"></li></ul><h4 id="city-data"><a href="#city-data" class="headerlink" title="city data"></a>city data</h4><ul><li>data position<br><img src="http://i2.tiimg.com/640680/c84923de5dd7b62a.png" alt="Markdown"></li><li>receriver position<br><img src="http://i2.tiimg.com/640680/37d804dc03e44805.png" alt="Markdown"></li><li>transmitter position<br><img src="http://i2.tiimg.com/640680/ed56538e48c4a54f.png" alt="Markdown"></li></ul><h4 id="explore-useful-features"><a href="#explore-useful-features" class="headerlink" title="explore useful features"></a>explore useful features</h4><p>We use PCC to quantify the PCC between samples’ features and distance. We use dynamic weight to pick features having higher relation with distance. It seems TOA has the significant higher weight<br><img src="http://i2.tiimg.com/640680/1533405e66d3b4c4.gif" alt="Markdown"></p><p>We plan to use some <strong>imputation method</strong>, including some methods from single cell analysis. We also aim to use <strong>RNN</strong> for changeable size feature and <strong>attention model</strong> to pick more related features.</p><h2 id="codes"><a href="#codes" class="headerlink" title="codes"></a>codes</h2><p><a href="https://github.com/james20141606/Signal" target="_blank" rel="noopener">https://github.com/james20141606/Signal</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;This page summarize our work on using mixture density network to jointly predict position coordinates.&lt;/p&gt;
&lt;p&gt;We collaborate with Jun Li 
      
    
    </summary>
    
      <category term="projects" scheme="https://www.cmwonderland.com/blog/categories/projects/"/>
    
    
      <category term="project" scheme="https://www.cmwonderland.com/blog/tags/project/"/>
    
      <category term="machine learning" scheme="https://www.cmwonderland.com/blog/tags/machine-learning/"/>
    
      <category term="signal" scheme="https://www.cmwonderland.com/blog/tags/signal/"/>
    
      <category term="MLP" scheme="https://www.cmwonderland.com/blog/tags/MLP/"/>
    
      <category term="Mixture model" scheme="https://www.cmwonderland.com/blog/tags/Mixture-model/"/>
    
      <category term="MDN" scheme="https://www.cmwonderland.com/blog/tags/MDN/"/>
    
      <category term="attention mechanism" scheme="https://www.cmwonderland.com/blog/tags/attention-mechanism/"/>
    
  </entry>
  
  <entry>
    <title>QUIZ Predicting maize traits using SNP data</title>
    <link href="https://www.cmwonderland.com/blog/2018/10/06/31_quiz_emaize_tutorial/"/>
    <id>https://www.cmwonderland.com/blog/2018/10/06/31_quiz_emaize_tutorial/</id>
    <published>2018-10-06T12:03:19.000Z</published>
    <updated>2018-10-10T05:01:20.641Z</updated>
    
    <content type="html"><![CDATA[<p>This is one of the two course quizzes instruction of <a href="https://lulab.gitbooks.io/teaching/content/" target="_blank" rel="noopener">Bioinformatics basic course in Tsinghua University</a>. You may also find it <a href="https://lulab.gitbooks.io/teaching/content/quiz/quiz_exrna/quiz_emaize_tutorial.html" target="_blank" rel="noopener">here</a>.</p><p>The related <a href="https://github.com/lulab/teaching_book/blob/master/quiz/quiz_emaize/quiz_emaize_tutorial.ipynb" target="_blank" rel="noopener">jupyter file</a></p><a id="more"></a><h1 id="eMaize玉米育种挑战赛"><a href="#eMaize玉米育种挑战赛" class="headerlink" title="eMaize玉米育种挑战赛"></a>eMaize玉米育种挑战赛</h1><p>请在<a href="https://cloud.tsinghua.edu.cn/f/3f4fc999720d45f198ca/" target="_blank" rel="noopener">quiz_emaize_tutorial_shared</a>下载相关数据，并下载该<a href="https://cloud.tsinghua.edu.cn/f/def95f1d1beb4031bf2f/" target="_blank" rel="noopener">文件夹</a>下的内容，打开<code>quiz_emaize_tutorial.ipynb</code>文件阅读详细的<strong>Quiz指南</strong>。</p><h2 id="eMaize背景简介"><a href="#eMaize背景简介" class="headerlink" title="eMaize背景简介"></a>eMaize背景简介</h2><p>eMaize挑战赛是<a href="http://emaize.imaze.org/emaize/emaize_cn.php" target="_blank" rel="noopener">一个通过机器学习方法预测玉米性状的比赛</a>，要求我们以SNP作为特征，通过训练一个模型，<strong>对玉米的三个性状进行预测</strong>。</p><p>本教程将会包括：</p><ul><li>介绍数据的情况，使用方式</li><li>具体任务要求</li><li>一些机器学习的概念方法以及工具使用</li></ul><h2 id="编程工具介绍"><a href="#编程工具介绍" class="headerlink" title="编程工具介绍"></a>编程工具介绍</h2><p>大作业需要使用python完成，推荐读者使用python3。我们需要一些python的工具包来实现部分功能。推荐使用包管理软件Anaconda来预装一些必需的包以及安装其他需要的包。另外强烈建议使用jupyter notebook进行代码编辑、运行和调试。具体使用方法请参考教程<a href="https://lulab.gitbooks.io/teaching/content/part-iii.-machine-learning-basics/python_tutorial.html" target="_blank" rel="noopener">Anaconda 和 jupyter</a>相关指南。<br>如果本地缺少下列可能需要的包，请使用<code>pip</code>或者<code>conda</code>进行安装。如:</p><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pip <span class="keyword">install</span> tqdm</span><br><span class="line">conda <span class="keyword">install</span> sklearn</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#导入必需的库</span></span><br><span class="line">%pylab inline</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.random_projection <span class="keyword">import</span> SparseRandomProjection</span><br><span class="line"><span class="keyword">import</span> scipy.stats</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> sklearn</span><br><span class="line"><span class="keyword">import</span> h5py</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> r2_score</span><br><span class="line"><span class="keyword">from</span> scipy.stats.stats <span class="keyword">import</span> pearsonr</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line"><span class="keyword">import</span> xgboost</span><br><span class="line"><span class="keyword">from</span> xgboost.sklearn <span class="keyword">import</span> XGBRegressor</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> Ridge</span><br><span class="line"><span class="keyword">from</span> sklearn.kernel_ridge <span class="keyword">import</span> KernelRidge</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> neighbors</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestRegressor</span><br><span class="line"><span class="keyword">from</span> sklearn.gaussian_process <span class="keyword">import</span> GaussianProcessRegressor</span><br><span class="line"><span class="keyword">from</span> sklearn.gaussian_process.kernels <span class="keyword">import</span> DotProduct</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm_notebook <span class="keyword">as</span> tqdm</span><br><span class="line"><span class="keyword">from</span> IPython.display <span class="keyword">import</span> display, Image</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line">warnings.filterwarnings(<span class="string">'ignore'</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">styles = [<span class="string">"white"</span>,<span class="string">"dark"</span>,<span class="string">'whitegrid'</span>,<span class="string">"darkgrid"</span>]</span><br><span class="line">contexts = [<span class="string">'paper'</span>,<span class="string">'talk'</span>,<span class="string">'poster'</span>,<span class="string">'notebook'</span>]</span><br><span class="line">sns.set_context(contexts[<span class="number">1</span>])</span><br><span class="line">sns.set_style(styles[<span class="number">2</span>])</span><br></pre></td></tr></table></figure><h2 id="数据介绍"><a href="#数据介绍" class="headerlink" title="数据介绍"></a>数据介绍</h2><p>原始数据中有6210个样本，其中4754个样本作为训练集，1456个样本作为测试集 <br></p><ul><li><strong>genotype</strong>：SNP (Single-nucleotide polymorphism) 数据<br>  每个位点可能有三种情况，如AA，AT，TT，每个样本SNP位点约为190万个，数据位置<code>data/genotype_2bit/</code>，包含十个染色体各自的SNP，使用时需要整合在一起。 <br></li><li><strong>trait</strong>：<br>  共三种，trait1开花期，trait2株高，trait3产量，为连续值，只提供训练集样本的性状数据。<code>data/pheno_emaize.txt</code> <br><br><br><br>作为示例仅仅使用每个样本的5000个SNP，在做大作业的过程中请使用全部的SNP。<br></li></ul><h3 id="Genotype数据"><a href="#Genotype数据" class="headerlink" title="Genotype数据"></a>Genotype数据</h3><h4 id="SNP数据存储格式"><a href="#SNP数据存储格式" class="headerlink" title="SNP数据存储格式"></a>SNP数据存储格式</h4><p>txt存储格式不适合大数据读取的问题，对内存的占用过多 <br><br>对于结构化的、能够存储为矩阵的数据，可以使用HDF5格式存取，内存占用小，读取速度快。</p><blockquote><p>tips: 在命令行查看数据shape的方法为：<br>cd至文件路径下，输入：h5ls filename</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#使用h5py读取5000个SNP，此时数据为原始的碱基信息</span></span><br><span class="line"><span class="keyword">with</span> h5py.File(<span class="string">'data/snp_5000'</span>,<span class="string">'r'</span>) <span class="keyword">as</span> f:</span><br><span class="line">    <span class="keyword">print</span> (list(f.keys()))</span><br><span class="line">    snps = f[<span class="string">'snp'</span>][:]</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#使用h5py读取5000个SNP，此时为原始的碱基信息转化为数值信息后的数据</span></span><br><span class="line"><span class="keyword">with</span> h5py.File(<span class="string">'data/2bit_geno'</span>,<span class="string">'r'</span>) <span class="keyword">as</span> f:</span><br><span class="line">    <span class="keyword">print</span> (list(f.keys()))</span><br><span class="line">    snps_2bit = f[<span class="string">'data'</span>][:]</span><br><span class="line">snps_2bit.shape</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#使用h5py读取一个染色体的SNP示例，此时文件内为我们处理好的数值化数据，注意需要先解压文件：</span></span><br><span class="line"><span class="keyword">with</span> h5py.File(<span class="string">'data/genotype_2bit/chr1.h5'</span>,<span class="string">'r'</span>) <span class="keyword">as</span> f:</span><br><span class="line">    <span class="keyword">print</span> (list(f.keys()))</span><br><span class="line">    chr1_snps = f[<span class="string">'data'</span>][:]</span><br><span class="line">chr1_snps.shape, chr1_snps.dtype</span><br></pre></td></tr></table></figure><h4 id="性状数据"><a href="#性状数据" class="headerlink" title="性状数据"></a>性状数据</h4><p>使用numpy/pandas均可读取性状数据，计算时一般使用numpy.array的形式</p><p>前4764个样本的性状是已知的，后1454个样本性状待预测</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">traits = pd.read_csv(<span class="string">'data/pheno_emaize.txt'</span>,<span class="string">'\t'</span>)</span><br><span class="line">display(traits.head())</span><br><span class="line">display(traits.tail())</span><br></pre></td></tr></table></figure><h5 id="查看性状的分布情况"><a href="#查看性状的分布情况" class="headerlink" title="查看性状的分布情况"></a>查看性状的分布情况</h5><p>注意，对性状数据已经做过了normalization</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">trait1 = np.array(traits[<span class="string">'trait1'</span>])[:<span class="number">4754</span>]</span><br><span class="line">trait2 = np.array(traits[<span class="string">'trait2'</span>])[:<span class="number">4754</span>]</span><br><span class="line">trait3 = np.array(traits[<span class="string">'trait3'</span>])[:<span class="number">4754</span>]</span><br><span class="line">fig, ax = plt.subplots(<span class="number">1</span>,<span class="number">3</span>, figsize=(<span class="number">15</span>,<span class="number">4</span>))</span><br><span class="line">ax[<span class="number">0</span>].hist(trait1,bins = <span class="number">20</span>,color=<span class="string">'b'</span>,alpha=<span class="number">0.6</span>)</span><br><span class="line">ax[<span class="number">0</span>].set_title(<span class="string">'Normalized Trait1: Flowering Time'</span>,fontsize=<span class="number">14</span>)</span><br><span class="line">ax[<span class="number">1</span>].hist(trait2,bins = <span class="number">20</span>,color=<span class="string">'g'</span>,alpha=<span class="number">0.6</span>)</span><br><span class="line">ax[<span class="number">1</span>].set_title(<span class="string">'Normalized Trait2: Height'</span>,fontsize=<span class="number">14</span>)               </span><br><span class="line">ax[<span class="number">2</span>].hist(trait3,bins = <span class="number">20</span>,color=<span class="string">'r'</span>,alpha=<span class="number">0.6</span>)</span><br><span class="line">ax[<span class="number">2</span>].set_title(<span class="string">'Normalized Trait3: Yield'</span>,fontsize=<span class="number">14</span>)</span><br></pre></td></tr></table></figure><p><img src="http://i1.fuimg.com/640680/4d02e8859cdfd53f.png" alt="Markdown"></p><h2 id="Quiz具体要求"><a href="#Quiz具体要求" class="headerlink" title="Quiz具体要求"></a>Quiz具体要求</h2><p>之前的部分我们介绍了基本的背景知识，接下来我们会提出解答本题目的具体要求：</p><ul><li>完成<strong>特征选择和特征筛除工作</strong>。</li><li>完成<strong>对三种性状的预测</strong>并提交预测结果，允许多次提交预测结果以获得更好的结果。</li><li>提交一份<strong>工作报告</strong>，中英文不限，同时提交<strong>源代码</strong>。</li><li>选择性完成加分项内容。</li></ul><h3 id="特征选择和冗余特征筛除"><a href="#特征选择和冗余特征筛除" class="headerlink" title="特征选择和冗余特征筛除"></a>特征选择和冗余特征筛除</h3><p>本挑战原始特征数量接近2,000,000，超过大多数机器学习模型的输入限制，特征间相关性很强，冗余特征很多，且过多的特征数量导致计算开销非常大，这都需要完成特征选择和去除冗余的步骤。</p><p>鉴于本问题原始特征数量过于巨大，并不是每种特征选择和降维方法都适合，请读者思考和选择合适的特征选择与降维方法，在这里仅提供几个方法参考：</p><ul><li>特征选择：<ul><li>ANOVA（方差分析）</li><li>基于模型权重排序（如线性模型）</li></ul></li><li>降维：<ul><li>PCA</li><li>SVD</li><li>Random Projection</li></ul></li></ul><blockquote><p>tips: 请思考是否需要针对特征选择或者降维后的数据做scale</p></blockquote><h3 id="完成对测试集三种性状的预测，尝试得到尽可能好的预测结果"><a href="#完成对测试集三种性状的预测，尝试得到尽可能好的预测结果" class="headerlink" title="完成对测试集三种性状的预测，尝试得到尽可能好的预测结果"></a>完成对测试集三种性状的预测，尝试得到尽可能好的预测结果</h3><ul><li>请思考和探索使用何种回归模型，读者可以尝试多种模型并比较其结果，在<em>编程工具介绍</em>部分读者可以看到一些机器学习模型的方法，也推荐读者思考和使用其他模型。</li><li>思考和探索是否对每个性状使用不同的模型</li><li>根据训练集与测试集的特殊划分方式（见<em>查看训练集与测试集的划分</em>部分）思考可以使用的策略。</li></ul><h3 id="加分内容"><a href="#加分内容" class="headerlink" title="加分内容"></a>加分内容</h3><p>为了更完整地展示emaize挑战的困难与有趣之处，我们为有余力的读者设置了更多的挑战。</p><h4 id="对模型进行鲁棒性测试-10’"><a href="#对模型进行鲁棒性测试-10’" class="headerlink" title="对模型进行鲁棒性测试 (10’)"></a>对模型进行鲁棒性测试 (10’)</h4><p>这是一个并不非常困难的但是对于本问题比较重要的工作，该工作可以细分为以下几项内容：</p><ul><li>在读者已有的数据（训练集数据）上进行多轮（如100、1000轮）交叉验证，测试模型的鲁棒性</li><li>设计不同的数据集划分方式，除了随机划分训练集与验证集，还可以有其他特殊的设计方法</li><li>统计测试结果，以多种形式展现，包括统计数据和图示。</li></ul><p>为了帮助读者完成测试，我们会给读者提供部分代码和一些相关的统计图，供读者使用和仿照设计，详见<em>补充知识</em>的<em>模型鲁棒性测试</em>部分。</p><h4 id="使用ANOVA进行特征选择的加速算法-5’"><a href="#使用ANOVA进行特征选择的加速算法-5’" class="headerlink" title="使用ANOVA进行特征选择的加速算法 (5’)"></a>使用ANOVA进行特征选择的加速算法 (5’)</h4><p>方差分析方法可以利用p值挑选feature <br><br>调用scipy.stats.f_oneway,利用SNPs和性状可以很容易地计算出p-value，进而挑选特征，但是对于大量数据来说速度较慢 <br><br>我们可以设计一种加速ANOVA计算的方法完成计算，相比于scipy.stats的方法可以提升计算速度数百倍。为了帮助读者实现这一功能，我们提供给读者设计的基本思路，请参考<a href="#fastanova"><em>ANOVA加速算法部分</em></a>，有能力的读者可以根据基本思路实现ANOVA的加速算法。</p><h4 id="混合线性模型-20’"><a href="#混合线性模型-20’" class="headerlink" title="混合线性模型 (20’)"></a>混合线性模型 (20’)</h4><p>育种领域的一个经典模型是混合线性模型(linear mixed model)，请尝试设计一个混合线性模型来解决本问题。</p><ul><li><p>可以研究并调用<a href="https://github.com/MicrosoftGenomics/FaST-LMM" target="_blank" rel="noopener">FaST-LMM package</a>，研究其原理并应用于我们的数据中，试图在测试集上获得好的预测结果(5’)</p></li><li><p>根据其思路进行改进，设计一个类似的混合线性模型，并且可以通过快速的交叉验证挑选超参数，最终在测试集上获得好的效果。详细内容可以参考<a href="assets/Mixed_ridge&amp;Fast_cv.pdf">这篇文档</a>。(15’)</p></li></ul><h2 id="补充知识（选读）"><a href="#补充知识（选读）" class="headerlink" title="补充知识（选读）"></a>补充知识（选读）</h2><h3 id="测试预测结果"><a href="#测试预测结果" class="headerlink" title="测试预测结果"></a>测试预测结果</h3><h5 id="查看训练集与测试集的划分"><a href="#查看训练集与测试集的划分" class="headerlink" title="查看训练集与测试集的划分"></a>查看训练集与测试集的划分</h5><p>请读者特别关注这个信息，训练集与测试集特殊的划分方式是本问题的一个特点与难点，也是想解决好本问题的关键。</p><p>下图中彩色部分为训练集性状，白色部分为待预测性状 <br><br>可以发现其划分方式并不随机，这会导致常规的机器学习方法出现一些问题，常规的机器学习问题中，每个样本彼此独立，但是对于育种问题，很多样本可能有同一个父本或者母本，比如图中的每一行样本都来自同一个父本，每一列样本都来自同一个母本。读者需要自己思考待预测样本和已有样本的关系，结合机器学习的特点“通过学习已有数据的特征对未知数据进行预测”，思考并观察预测结果的好坏。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">generate_parent_table</span><span class="params">(phenotype_file)</span>:</span></span><br><span class="line">    phenotypes = pd.read_table(phenotype_file)</span><br><span class="line">    pedigree = phenotypes[<span class="string">'pedigree'</span>].str.split(<span class="string">'_'</span>, expand=<span class="keyword">True</span>)</span><br><span class="line">    pedigree.columns = [<span class="string">'f'</span>, <span class="string">'X'</span>, <span class="string">'m'</span>]</span><br><span class="line">    phenotypes = pd.concat([phenotypes, pedigree], axis=<span class="number">1</span>)</span><br><span class="line">    phenotypes[<span class="string">'number'</span>] = np.arange(phenotypes.shape[<span class="number">0</span>])</span><br><span class="line">    parent_table = phenotypes.pivot_table(values=<span class="string">'number'</span></span><br><span class="line">                                          , index=[<span class="string">'m'</span>], columns=[<span class="string">'f'</span>], dropna=<span class="keyword">False</span>)</span><br><span class="line">    male_ids = [<span class="string">'m%d'</span> % i <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, parent_table.shape[<span class="number">0</span>] + <span class="number">1</span>)]</span><br><span class="line">    female_ids = [<span class="string">'f%d'</span> % i <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, parent_table.shape[<span class="number">1</span>] + <span class="number">1</span>)]</span><br><span class="line">    parent_table = parent_table.loc[male_ids, female_ids]</span><br><span class="line">    <span class="keyword">return</span> parent_table</span><br><span class="line">phenotype_file = <span class="string">'data/pheno_emaize.txt'</span></span><br><span class="line">parent_table = generate_parent_table(phenotype_file)</span><br><span class="line">phenotypes = pd.read_table(<span class="string">'data/pheno_emaize.txt'</span>)</span><br><span class="line">fig, ax = subplots(<span class="number">3</span>,<span class="number">1</span>, figsize=(<span class="number">15</span>, <span class="number">10</span>))</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">3</span>):</span><br><span class="line">    trait = [<span class="string">'trait1'</span>,<span class="string">'trait2'</span>,<span class="string">'trait3'</span>][i]</span><br><span class="line">    ax[i].imshow(np.take(np.ravel(phenotypes[trait].values), parent_table), cmap=cm.RdBu)</span><br><span class="line">    ax[i].set_title(<span class="string">'Phenotypes of training data (%s)'</span>%trait)</span><br><span class="line">    ax[i].set_ylabel(<span class="string">'male'</span>)</span><br><span class="line">    ax[i].set_xlabel(<span class="string">'female'</span>)</span><br><span class="line">plt.tight_layout()</span><br></pre></td></tr></table></figure><p><img src="http://i1.fuimg.com/640680/d2f0f8536f919855.png" alt="Markdown"></p><h5 id="测试集具体划分"><a href="#测试集具体划分" class="headerlink" title="测试集具体划分"></a>测试集具体划分</h5><p>我们会把测试区域分为三个部分，来测试提交的结果，三个区域分别为下图的淡蓝色，黄色和红色区域，请读者思考它们各自的特征。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">fig,ax=plt.subplots(figsize=(<span class="number">20</span>,<span class="number">5</span>))</span><br><span class="line">testexample = np.zeros([<span class="number">30</span>,<span class="number">207</span>])</span><br><span class="line">testexample[<span class="number">25</span>:,:<span class="number">202</span>] = <span class="number">100</span></span><br><span class="line">testexample[:<span class="number">25</span>,<span class="number">202</span>:] = <span class="number">200</span></span><br><span class="line">testexample[<span class="number">25</span>:,<span class="number">202</span>:] = <span class="number">300</span></span><br><span class="line">ax.imshow(testexample,cmap=<span class="string">'jet'</span>)</span><br></pre></td></tr></table></figure><p><img src="http://i1.fuimg.com/640680/8ad266b66785548e.png" alt="Markdown"></p><h5 id="评价指标"><a href="#评价指标" class="headerlink" title="评价指标"></a>评价指标</h5><p>对于回归问题，我们一般使用<script type="math/tex">r^2</script>和pearson correlation coefficient(PCC)衡量，其定义如下：</p><p><script type="math/tex">r^2 = 1-\frac{SS_{res}}{SS_{tot}}</script><br></p><p><script type="math/tex">PCC = \frac{cov(X,Y)}{\sigma_X \sigma_Y} = \frac{E[(X-\mu_X)(Y-\mu_Y)]}{\sigma_X \sigma_Y}</script><br></p><h3 id="将SNP数据编码为向量"><a href="#将SNP数据编码为向量" class="headerlink" title="将SNP数据编码为向量"></a>将SNP数据编码为向量</h3><p>每个位点的碱基只有三种情况，不会出现更多碱基组合的可能，比如某位点仅有AA，AT，TT三种可能的情况<br><br>我们可以采取三种方式对其编码：</p><ul><li>转化为0、1、2。找到minor allele frequency（MAF），即两种碱基（如A、T）中出现频率低的那个，以A作为MAF为例，则TT为0，AT为1，AA为2，这样可以突出MAF</li><li>转化为3-bit one hot vector,<script type="math/tex">[1,0,0]^T,[0,1,0]^T,[0,0,1]^T</script>这样可以保持三种向量在空间距离的一致</li><li>转化为2-bit vector,则AA，AT，TT分别编为<script type="math/tex">[1,0]^T,[1,1]^T,[0,1]^T</script>,不需要考虑MAF<br>我们采取第三种方式处理了数据并提供给读者</li></ul><h4 id="具体处理过程"><a href="#具体处理过程" class="headerlink" title="具体处理过程"></a>具体处理过程</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">convert_2bit</span><span class="params">(seq)</span>:</span></span><br><span class="line">    genotypes = np.zeros([<span class="number">6210</span>,<span class="number">2</span>])</span><br><span class="line">    a = seq[<span class="number">1</span>].split(<span class="string">'/'</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">6210</span>):</span><br><span class="line">        <span class="keyword">if</span> seq[<span class="number">4</span>:][i] == a[<span class="number">0</span>] + a[<span class="number">0</span>]:</span><br><span class="line">            genotypes[i] = np.array([<span class="number">0</span>,<span class="number">1</span>])</span><br><span class="line">        <span class="keyword">if</span> seq[<span class="number">4</span>:][i] == a[<span class="number">0</span>] + a[<span class="number">1</span>]:</span><br><span class="line">            genotypes[i] = np.array([<span class="number">1</span>,<span class="number">0</span>])</span><br><span class="line">        <span class="keyword">if</span> seq[<span class="number">4</span>:][i] == a[<span class="number">1</span>] + a[<span class="number">1</span>]:</span><br><span class="line">            genotypes[i] = np.array([<span class="number">1</span>,<span class="number">1</span>])</span><br><span class="line">    genotypes = genotypes.astype(<span class="string">'int'</span>).T</span><br><span class="line">    <span class="keyword">return</span> genotypes</span><br></pre></td></tr></table></figure><p>真实转换时python的转换速度较慢，这里为了展示基本的原理使用了python来演示。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">snps = snps.astype(<span class="string">'str'</span>)</span><br><span class="line">snps.shape</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">convert_2bit(snps[<span class="number">2</span>].astype(<span class="string">'str'</span>))</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">geno_conv = np.ndarray([<span class="number">10000</span>,<span class="number">6210</span>])</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> tqdm(range(<span class="number">5000</span>)):</span><br><span class="line">    geno_conv[i*<span class="number">2</span>:(i+<span class="number">1</span>)*<span class="number">2</span>] = convert_2bit(snps[i+<span class="number">1</span>])</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#查看SNP的大致情况，取前100行（50个位点），前50个样本，</span></span><br><span class="line">fig, ax = plt.subplots(figsize=(<span class="number">20</span>,<span class="number">10</span>))</span><br><span class="line">ax.matshow(geno_conv[:<span class="number">100</span>,:<span class="number">50</span>],cmap = cm.binary_r)</span><br></pre></td></tr></table></figure><p><img src="http://i1.fuimg.com/640680/870c6a096a867529.png" alt="Markdown"></p><h3 id="模型鲁棒性测试"><a href="#模型鲁棒性测试" class="headerlink" title="模型鲁棒性测试"></a>模型鲁棒性测试</h3><h4 id="设计特殊的交叉验证方式"><a href="#设计特殊的交叉验证方式" class="headerlink" title="设计特殊的交叉验证方式"></a>设计特殊的交叉验证方式</h4><p>不同的样本具有关联性，有的样本可能来自同一亲本，而训练集和测试集的划分并不是随机的<br>因此我们可以专门设计交叉验证时数据集的划分方式：</p><ul><li>random</li><li>by female</li><li>by male</li><li>cross sampling</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> method <span class="keyword">in</span> (<span class="string">'random'</span>, <span class="string">'by_female'</span>, <span class="string">'by_male'</span>, <span class="string">'cross'</span>):</span><br><span class="line">    <span class="keyword">with</span> h5py.File(<span class="string">'data/cv_index.%s'</span>%method, <span class="string">'r'</span>) <span class="keyword">as</span> f:</span><br><span class="line">        index_train = f[<span class="string">'0/train'</span>][:]</span><br><span class="line">        index_test = f[<span class="string">'0/test'</span>][:]</span><br><span class="line">    fig, ax = subplots(<span class="number">2</span>, <span class="number">1</span>, figsize=(<span class="number">16</span>, <span class="number">6</span>))</span><br><span class="line">    sampling_table = np.zeros(np.prod(parent_table.shape))</span><br><span class="line">    sampling_table[index_train] = <span class="number">1</span></span><br><span class="line">    sampling_table = np.take(sampling_table, parent_table)</span><br><span class="line">    ax[<span class="number">0</span>].imshow(sampling_table, cmap=cm.Greys)</span><br><span class="line">    ax[<span class="number">0</span>].set_title(<span class="string">'Training samples (%s)'</span>%method)</span><br><span class="line"></span><br><span class="line">    sampling_table = np.zeros(np.prod(parent_table.shape))</span><br><span class="line">    sampling_table[index_test] = <span class="number">1</span></span><br><span class="line">    sampling_table = np.take(sampling_table, parent_table)</span><br><span class="line">    ax[<span class="number">1</span>].imshow(sampling_table, cmap=cm.Greys)</span><br><span class="line">    ax[<span class="number">1</span>].set_title(<span class="string">'Test samples (%s)'</span>%method)</span><br><span class="line">    plt.tight_layout()</span><br></pre></td></tr></table></figure><p>请在jupyter文件中查看相关图片。</p><h3 id="ANOVA加速算法"><a href="#ANOVA加速算法" class="headerlink" title="ANOVA加速算法"></a>ANOVA加速算法</h3><p>思路简要提示：</p><p><img src="http://i1.fuimg.com/640680/ef4e5c183a271656.png" alt="Markdown"></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;This is one of the two course quizzes instruction of &lt;a href=&quot;https://lulab.gitbooks.io/teaching/content/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Bioinformatics basic course in Tsinghua University&lt;/a&gt;. You may also find it &lt;a href=&quot;https://lulab.gitbooks.io/teaching/content/quiz/quiz_exrna/quiz_emaize_tutorial.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The related &lt;a href=&quot;https://github.com/lulab/teaching_book/blob/master/quiz/quiz_emaize/quiz_emaize_tutorial.ipynb&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;jupyter file&lt;/a&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="school work" scheme="https://www.cmwonderland.com/blog/categories/school-work/"/>
    
    
      <category term="machine learning" scheme="https://www.cmwonderland.com/blog/tags/machine-learning/"/>
    
      <category term="python" scheme="https://www.cmwonderland.com/blog/tags/python/"/>
    
      <category term="bioinformatics" scheme="https://www.cmwonderland.com/blog/tags/bioinformatics/"/>
    
      <category term="teaching" scheme="https://www.cmwonderland.com/blog/tags/teaching/"/>
    
      <category term="TA" scheme="https://www.cmwonderland.com/blog/tags/TA/"/>
    
  </entry>
  
  <entry>
    <title>Python Tutorial</title>
    <link href="https://www.cmwonderland.com/blog/2018/10/06/55_python_basics/"/>
    <id>https://www.cmwonderland.com/blog/2018/10/06/55_python_basics/</id>
    <published>2018-10-06T12:03:19.000Z</published>
    <updated>2018-10-10T05:02:29.145Z</updated>
    
    <content type="html"><![CDATA[<p>This is one of the chapter in <a href="https://lulab.gitbooks.io/teaching/content/" target="_blank" rel="noopener">Bioinformatics basic course in Tsinghua University</a>. You may also find it <a href="https://lulab.gitbooks.io/teaching/content/appendix/python_tutorial.html" target="_blank" rel="noopener">here</a></p><p>The related <a href="https://github.com/lulab/teaching_book/blob/master/appendix/python_tutorial.ipynb" target="_blank" rel="noopener">jupyter file</a></p><a id="more"></a><h2 id="Python-Tutorial"><a href="#Python-Tutorial" class="headerlink" title="Python Tutorial"></a>Python Tutorial</h2><p><img src="http://i2.tiimg.com/640680/bd9bf324c62838ea.png" alt="Markdown"></p><h2 id="Install-Anaconda-Python"><a href="#Install-Anaconda-Python" class="headerlink" title="Install Anaconda Python"></a>Install Anaconda Python</h2><p>URL: (<a href="https://www.anaconda.com/download/" target="_blank" rel="noopener">https://www.anaconda.com/download/</a>)</p><ul><li>Easy install of data science packages (binary distribution)</li><li>Package management with </li></ul><p><code>conda</code></p><p><img src="http://i2.tiimg.com/640680/6c673d3d2a99eb69.png" alt="Markdown"></p><p>Install Python packages using conda:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda install h5py</span><br></pre></td></tr></table></figure><p>Update a package to the latest version:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda update h5py</span><br></pre></td></tr></table></figure><p>Install Python packages using pip:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install h5py</span><br></pre></td></tr></table></figure><p>Update a package using pip:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install --upgrade h5py</span><br></pre></td></tr></table></figure><h2 id="Python-language-tips"><a href="#Python-language-tips" class="headerlink" title="Python language tips"></a>Python language tips</h2><h3 id="Compatibility-between-Python-3-x-and-Python-2-x"><a href="#Compatibility-between-Python-3-x-and-Python-2-x" class="headerlink" title="Compatibility between Python 3.x and Python 2.x"></a>Compatibility between Python 3.x and Python 2.x</h3><p><strong>Biggest difference</strong>: print is a function rather than statement in Python 3</p><p>This does not work in Python 3</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">print</span> <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span></span><br></pre></td></tr></table></figure><p><strong>Solution</strong>: use the <code>__future__</code> module</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"><span class="comment"># this works both in Python 2 and Python 3</span></span><br><span class="line">print(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>)</span><br></pre></td></tr></table></figure><p><strong>Second biggest difference</strong>: some package/function names in the standard library are changed</p><p><strong>Python 2</strong> =&gt; <strong>Python 3</strong></p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">cStringIO =&gt; io.StringIO</span><br><span class="line">Queue =&gt; queue</span><br><span class="line">cPickle =&gt; pickle</span><br><span class="line">ConfigParser =&gt; configparser</span><br><span class="line">HTMLParser =&gt; html.parser</span><br><span class="line">SocketServer =&gt; socketserver</span><br><span class="line">SimpleHTTPServer =&gt; http.server</span><br></pre></td></tr></table></figure><p><strong>Solution</strong>: use the <code>six</code> module</p><ul><li>Refer to (<a href="https://docs.python.org/3/library/__future__.html" target="_blank" rel="noopener">https://docs.python.org/3/library/__future__.html</a>) for usage of the <code>__future__</code> module.</li><li>Refer to (<a href="https://pythonhosted.org/six/" target="_blank" rel="noopener">https://pythonhosted.org/six/</a>) for usage of the <code>six</code> module.</li></ul><h3 id="Get-away-from-IndentationError"><a href="#Get-away-from-IndentationError" class="headerlink" title="Get away from IndentationError"></a>Get away from IndentationError</h3><p>Python forces usage of tabs/spaces to indent code</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># use a tab</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">3</span>):</span><br><span class="line">    print(i)</span><br><span class="line"><span class="comment"># use 2 spaces</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">3</span>):</span><br><span class="line">  print(i)</span><br><span class="line"><span class="comment"># use 4 spaces</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">3</span>):</span><br><span class="line">    print(i)</span><br></pre></td></tr></table></figure><p><strong>Best practice</strong>: always use 4 spaces. You can set whether to use spaces(soft tabs) or tabs for indentation.</p><p>In vim editor, use <code>:set list</code> to inspect incorrect number of spaces/tabs.</p><h3 id="Add-Shebang-and-encoding-at-the-beginning-of-executable-scripts"><a href="#Add-Shebang-and-encoding-at-the-beginning-of-executable-scripts" class="headerlink" title="Add Shebang and encoding at the beginning of executable scripts"></a>Add Shebang and encoding at the beginning of executable scripts</h3><p>Create a file named <code>welcome.py</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#! /usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*- coding: UTF-8 -*-</span></span><br><span class="line">print(<span class="string">'welcome to python!'</span>)</span><br></pre></td></tr></table></figure><p>Then set the python script as executable:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">chmod +x welcome.py</span><br></pre></td></tr></table></figure><p>Now you can run the script without specifying the Python interpreter:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./welcome.py</span><br></pre></td></tr></table></figure></p><h3 id="All-variables-functions-classes-are-dynamic-objects"><a href="#All-variables-functions-classes-are-dynamic-objects" class="headerlink" title="All variables, functions, classes are dynamic objects"></a>All variables, functions, classes are dynamic objects</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyClass</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, name)</span>:</span></span><br><span class="line">        self.name = name</span><br><span class="line"><span class="comment"># assign an integer to a</span></span><br><span class="line">a = <span class="number">1</span></span><br><span class="line">print(type(a))</span><br><span class="line"><span class="comment"># assign a string to a</span></span><br><span class="line">a = <span class="string">'abc'</span></span><br><span class="line">print(type(a))</span><br><span class="line"><span class="comment"># assign a function to a</span></span><br><span class="line">a = range</span><br><span class="line">print(type(a))</span><br><span class="line">print(a(<span class="number">10</span>))</span><br><span class="line"><span class="comment"># assign a class to a</span></span><br><span class="line">a = MyClass</span><br><span class="line">print(type(a))</span><br><span class="line">b = a(<span class="string">'myclass'</span>)</span><br><span class="line">print(b.name)</span><br><span class="line"><span class="comment"># assign an instance of a class to a</span></span><br><span class="line">a = MyClass(<span class="string">'myclass'</span>)</span><br><span class="line">print(b.name)</span><br><span class="line"><span class="comment"># get type of a</span></span><br><span class="line">print(type(a))</span><br></pre></td></tr></table></figure><h3 id="All-python-variables-are-pointers-references"><a href="#All-python-variables-are-pointers-references" class="headerlink" title="All python variables are pointers/references"></a>All python variables are pointers/references</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">a = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]</span><br><span class="line">print(<span class="string">'a = '</span>, a)</span><br><span class="line"><span class="comment"># this add another refrence to the list</span></span><br><span class="line">b = a</span><br><span class="line">print(<span class="string">'b = '</span>, b)</span><br><span class="line"><span class="comment"># this will change contents of both a and b</span></span><br><span class="line">b[<span class="number">2</span>] = <span class="number">4</span></span><br><span class="line">print(<span class="string">'a = '</span>, a)</span><br><span class="line">print(<span class="string">'b = '</span>, b)</span><br></pre></td></tr></table></figure><h3 id="Use-deepcopy-if-you-really-want-to-COPY-a-variable"><a href="#Use-deepcopy-if-you-really-want-to-COPY-a-variable" class="headerlink" title="Use deepcopy if you really want to COPY a variable"></a>Use <code>deepcopy</code> if you really want to COPY a variable</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> copy <span class="keyword">import</span> deepcopy</span><br><span class="line">a = &#123;<span class="string">'A'</span>: [<span class="number">1</span>], <span class="string">'B'</span>: [<span class="number">2</span>], <span class="string">'C'</span>: [<span class="number">3</span>]&#125;</span><br><span class="line">print(a)</span><br><span class="line"><span class="comment"># shallow copy</span></span><br><span class="line">b = dict(a)</span><br><span class="line"><span class="comment"># modify elements of b will change contents of a</span></span><br><span class="line">b[<span class="string">'A'</span>].append(<span class="number">2</span>)</span><br><span class="line">print(<span class="string">'a = '</span>, a)</span><br><span class="line">print(<span class="string">'b = '</span>, b)</span><br><span class="line"><span class="comment"># this also does not work</span></span><br><span class="line">c = &#123;k:v <span class="keyword">for</span> k, v <span class="keyword">in</span> a&#125;</span><br><span class="line">c[<span class="string">'A'</span>].append(<span class="number">3</span>)</span><br><span class="line">print(<span class="string">'a = '</span>, a)</span><br><span class="line">print(<span class="string">'c = '</span>, c)</span><br><span class="line"><span class="comment"># recurrently copy every object of a</span></span><br><span class="line">d = deepcopy(a)</span><br><span class="line"><span class="comment"># modify elements of c will not change contents of a</span></span><br><span class="line">d[<span class="string">'A'</span>].append(<span class="number">2</span>)</span><br><span class="line">print(<span class="string">'a = '</span>, a)</span><br><span class="line">print(<span class="string">'d = '</span>, d)</span><br></pre></td></tr></table></figure><h3 id="What-if-I-accidentally-overwrite-my-builtin-functions"><a href="#What-if-I-accidentally-overwrite-my-builtin-functions" class="headerlink" title="What if I accidentally overwrite my builtin functions?"></a>What if I accidentally overwrite my builtin functions?</h3><p>You can refer to (<a href="https://docs.python.org/2/library/functions.html" target="_blank" rel="noopener">https://docs.python.org/2/library/functions.html</a>) for builtin functions in the standard library.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">A = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>]</span><br><span class="line"><span class="comment"># Ops! the builtin function sum is overwritten by a number</span></span><br><span class="line">sum = sum(A)</span><br><span class="line"><span class="comment"># this will raise an error because sum is not a function now</span></span><br><span class="line">print(sum(A))</span><br><span class="line"><span class="comment"># recover the builtin function into the current environment</span></span><br><span class="line"><span class="keyword">from</span> __builtin__ <span class="keyword">import</span> sum</span><br><span class="line"><span class="comment"># this works because sum is a function</span></span><br><span class="line">print(sum(A))</span><br></pre></td></tr></table></figure><p><strong>Note</strong>: in Python 3, you should import from <code>builtins</code> rather than <code>__builtin__</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> builtins <span class="keyword">import</span> sum</span><br></pre></td></tr></table></figure><h3 id="int-is-of-arbitrary-precision-in-Python"><a href="#int-is-of-arbitrary-precision-in-Python" class="headerlink" title="int is of arbitrary precision in Python!"></a><code>int</code> is of arbitrary precision in Python!</h3><p>In Pyhton:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="number">2</span>**<span class="number">10000</span>)</span><br></pre></td></tr></table></figure><p>In R:</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="number">2</span>^<span class="number">10000</span>)</span><br></pre></td></tr></table></figure><h3 id="Easiest-way-to-swap-values-of-two-variables"><a href="#Easiest-way-to-swap-values-of-two-variables" class="headerlink" title="Easiest way to swap values of two variables"></a>Easiest way to swap values of two variables</h3><p>In C/C++:</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> a = <span class="number">1</span>, b = <span class="number">2</span>, t;</span><br><span class="line">t = a;</span><br><span class="line">a = b;</span><br><span class="line">b = t;</span><br></pre></td></tr></table></figure><p>In Python:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">a = <span class="number">1</span></span><br><span class="line">b = <span class="number">2</span></span><br><span class="line">b, a = a, b</span><br><span class="line">print(a, b)</span><br></pre></td></tr></table></figure><h3 id="List-comprehension"><a href="#List-comprehension" class="headerlink" title="List comprehension"></a>List comprehension</h3><p>Use for-loops:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">a = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>):</span><br><span class="line">    a.append(i + <span class="number">10</span>)</span><br><span class="line">print(a)</span><br></pre></td></tr></table></figure><p>Use list comprehension</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">a = [i + <span class="number">10</span> <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>)]</span><br><span class="line">print(a)</span><br></pre></td></tr></table></figure><h3 id="Dict-comprehension"><a href="#Dict-comprehension" class="headerlink" title="Dict comprehension"></a>Dict comprehension</h3><p>Use for-loops:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">a = &#123;&#125;</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>):</span><br><span class="line">    a[i] = chr(ord(<span class="string">'A'</span>) + i) </span><br><span class="line">print(a)</span><br></pre></td></tr></table></figure><p>Use dict comprehension:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">a = &#123;i:chr(ord(<span class="string">'A'</span>) + i) <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>)&#125;</span><br><span class="line">print(a)</span><br></pre></td></tr></table></figure></p><h3 id="For-the-one-liners"><a href="#For-the-one-liners" class="headerlink" title="For the one-liners"></a>For the one-liners</h3><p>Use ‘;’ instead of ‘\n’:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># print the first column of each line</span></span><br><span class="line">python -c <span class="string">'import sys; print("\n".join(line.split("\t")[0] for line in sys.stdin))'</span></span><br></pre></td></tr></table></figure><p>For more examples of one-liners, please refer to (<a href="https://wiki.python.org/moin/Powerful%20Python%20One-Liners" target="_blank" rel="noopener">https://wiki.python.org/moin/Powerful%20Python%20One-Liners</a>).</p><h3 id="Read-from-standard-input"><a href="#Read-from-standard-input" class="headerlink" title="Read from standard input"></a>Read from standard input</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="comment"># read line by line</span></span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</span><br><span class="line">    print(line)</span><br></pre></td></tr></table></figure><h3 id="Order-of-dict-keys-are-NOT-as-you-expected"><a href="#Order-of-dict-keys-are-NOT-as-you-expected" class="headerlink" title="Order of dict keys are NOT as you expected"></a>Order of dict keys are NOT as you expected</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">a = &#123;<span class="string">'A'</span>: <span class="number">1</span>, <span class="string">'B'</span>: <span class="number">2</span>, <span class="string">'C'</span>: <span class="number">3</span>, <span class="string">'D'</span>: <span class="number">4</span>, <span class="string">'E'</span>: <span class="number">5</span>, <span class="string">'F'</span>: <span class="number">6</span>&#125;</span><br><span class="line"><span class="comment"># not in lexicographical order</span></span><br><span class="line">print([key <span class="keyword">for</span> key <span class="keyword">in</span> a])</span><br><span class="line"><span class="comment"># now in lexicographical order</span></span><br><span class="line">print([key <span class="keyword">for</span> key <span class="keyword">in</span> sorted(a)])</span><br></pre></td></tr></table></figure><h3 id="Use-enumerate-to-add-a-number-during-iteration"><a href="#Use-enumerate-to-add-a-number-during-iteration" class="headerlink" title="Use enumerate() to add a number during iteration"></a>Use enumerate() to add a number during iteration</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">A = [<span class="string">'a'</span>, <span class="string">'b'</span>, <span class="string">'c'</span>, <span class="string">'d'</span>]</span><br><span class="line"><span class="keyword">for</span> i, a <span class="keyword">in</span> enumerate(A):</span><br><span class="line">    print(i, a)</span><br></pre></td></tr></table></figure><h3 id="Reverse-a-list"><a href="#Reverse-a-list" class="headerlink" title="Reverse a list"></a>Reverse a list</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># a = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]</span></span><br><span class="line">a = range(<span class="number">10</span>)</span><br><span class="line">print(a)</span><br><span class="line">print(a[::<span class="number">-1</span>])</span><br></pre></td></tr></table></figure><h3 id="Strings-are-immutable-in-Python"><a href="#Strings-are-immutable-in-Python" class="headerlink" title="Strings are immutable in Python"></a>Strings are immutable in Python</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">a = <span class="string">'ABCDF'</span></span><br><span class="line"><span class="comment"># will raise an Error</span></span><br><span class="line">a[<span class="number">4</span>] = <span class="string">'E'</span></span><br><span class="line"><span class="comment"># convert str to bytearray</span></span><br><span class="line">b = bytearray(a)</span><br><span class="line"><span class="comment"># bytearray are mutable</span></span><br><span class="line">b[<span class="number">4</span>] = <span class="string">'E'</span></span><br><span class="line"><span class="comment"># convert bytearray to str</span></span><br><span class="line">print(str(b))</span><br></pre></td></tr></table></figure><h3 id="tuples-are-hashable-while-lists-are-not-hashable"><a href="#tuples-are-hashable-while-lists-are-not-hashable" class="headerlink" title="tuples are hashable while lists are not hashable"></a>tuples are hashable while lists are not hashable</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># create dict using tuples as keys</span></span><br><span class="line">d = &#123;</span><br><span class="line">    (<span class="string">'chr1'</span>, <span class="number">1000</span>, <span class="number">2000</span>): <span class="string">'featureA'</span>,</span><br><span class="line">    (<span class="string">'chr1'</span>, <span class="number">2000</span>, <span class="number">3000</span>): <span class="string">'featureB'</span>,</span><br><span class="line">    (<span class="string">'chr1'</span>, <span class="number">3000</span>, <span class="number">4000</span>): <span class="string">'featureC'</span>,</span><br><span class="line">    (<span class="string">'chr1'</span>, <span class="number">4000</span>, <span class="number">5000</span>): <span class="string">'featureD'</span>,</span><br><span class="line">    (<span class="string">'chr1'</span>, <span class="number">5000</span>, <span class="number">6000</span>): <span class="string">'featureE'</span>,</span><br><span class="line">    (<span class="string">'chr1'</span>, <span class="number">6000</span>, <span class="number">7000</span>): <span class="string">'featureF'</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment"># query the dict using tuples</span></span><br><span class="line">print(d[(<span class="string">'chr1'</span>, <span class="number">3000</span>, <span class="number">4000</span>)])</span><br><span class="line">print(d[(<span class="string">'chr1'</span>, <span class="number">6000</span>, <span class="number">7000</span>)])</span><br><span class="line"><span class="comment"># will raise an error</span></span><br><span class="line">d = &#123;[<span class="string">'chr1'</span>, <span class="number">1000</span>, <span class="number">2000</span>]: <span class="string">'featureA'</span>&#125;</span><br></pre></td></tr></table></figure><h3 id="Use-itertools"><a href="#Use-itertools" class="headerlink" title="Use itertools"></a>Use itertools</h3><p>Nested loops in a more concise way:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">A = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]</span><br><span class="line">B = [<span class="string">'a'</span>, <span class="string">'b'</span>, <span class="string">'c'</span>]</span><br><span class="line">C = [<span class="string">'i'</span>, <span class="string">'j'</span>, <span class="string">'k'</span>]</span><br><span class="line">D = [<span class="string">'x'</span>, <span class="string">'y'</span>, <span class="string">'z'</span>]</span><br><span class="line"><span class="comment"># Use nested for-loops</span></span><br><span class="line"><span class="keyword">for</span> a <span class="keyword">in</span> A:</span><br><span class="line">    <span class="keyword">for</span> b <span class="keyword">in</span> B:</span><br><span class="line">        <span class="keyword">for</span> c <span class="keyword">in</span> C:</span><br><span class="line">            <span class="keyword">for</span> d <span class="keyword">in</span> D:</span><br><span class="line">                print(a, b, c, d)</span><br><span class="line"><span class="comment"># Use itertools.product</span></span><br><span class="line"><span class="keyword">import</span> itertools</span><br><span class="line"><span class="keyword">for</span> a, b, c, d <span class="keyword">in</span> itertools.product(A, B, C, D):</span><br><span class="line">    print(a, b, c, d)</span><br></pre></td></tr></table></figure><p>Get all combinations of a list:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">A = [<span class="string">'A'</span>, <span class="string">'B'</span>, <span class="string">'C'</span>, <span class="string">'D'</span>]</span><br><span class="line"><span class="comment"># Use itertools.combinations</span></span><br><span class="line"><span class="keyword">import</span> itertools</span><br><span class="line"><span class="keyword">for</span> a, b, c <span class="keyword">in</span> itertools.combinations(A, <span class="number">3</span>):</span><br><span class="line">    print(a, b, c)</span><br></pre></td></tr></table></figure><h3 id="Convert-iterables-to-lists"><a href="#Convert-iterables-to-lists" class="headerlink" title="Convert iterables to lists"></a>Convert iterables to lists</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> itertools</span><br><span class="line">A = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]</span><br><span class="line">B = [<span class="string">'a'</span>, <span class="string">'b'</span>, <span class="string">'c'</span>]</span><br><span class="line">a = itertools.product(A, B)</span><br><span class="line"><span class="comment"># a is a iterable rather than a list</span></span><br><span class="line">print(a)</span><br><span class="line"><span class="comment"># a is a list now</span></span><br><span class="line">a = list(a)</span><br><span class="line">print(a)</span><br></pre></td></tr></table></figure><h3 id="Use-the-zip-function-to-transpose-nested-lists-tuples-iterables"><a href="#Use-the-zip-function-to-transpose-nested-lists-tuples-iterables" class="headerlink" title="Use the zip() function to transpose nested lists/tuples/iterables"></a>Use the zip() function to transpose nested lists/tuples/iterables</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">records = [</span><br><span class="line">    (<span class="string">'chr1'</span>, <span class="number">1000</span>, <span class="number">2000</span>),</span><br><span class="line">    (<span class="string">'chr1'</span>, <span class="number">2000</span>, <span class="number">3000</span>),</span><br><span class="line">    (<span class="string">'chr1'</span>, <span class="number">3000</span>, <span class="number">4000</span>),</span><br><span class="line">    (<span class="string">'chr1'</span>, <span class="number">4000</span>, <span class="number">5000</span>),</span><br><span class="line">    (<span class="string">'chr1'</span>, <span class="number">5000</span>, <span class="number">6000</span>),</span><br><span class="line">    (<span class="string">'chr1'</span>, <span class="number">6000</span>, <span class="number">7000</span>)</span><br><span class="line">]</span><br><span class="line"><span class="comment"># iterate by rows</span></span><br><span class="line"><span class="keyword">for</span> chrom, start, end <span class="keyword">in</span> records:</span><br><span class="line">    print(chrom, start, end)</span><br><span class="line"><span class="comment"># extract columns</span></span><br><span class="line">chroms, starts, ends = zip(*records)</span><br><span class="line"><span class="comment"># build records from columns</span></span><br><span class="line"><span class="comment"># now records2 is the same as records</span></span><br><span class="line">records2 = zip(chroms, starts, ends)</span><br><span class="line">print(records)</span><br></pre></td></tr></table></figure><h3 id="Global-and-local-variables"><a href="#Global-and-local-variables" class="headerlink" title="Global and local variables"></a>Global and local variables</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># a is global</span></span><br><span class="line">a = <span class="number">1</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">print_local</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="comment"># a is local</span></span><br><span class="line">    a = <span class="number">2</span></span><br><span class="line">    print(a)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">print_global</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="comment"># a is global</span></span><br><span class="line">    <span class="keyword">global</span> a</span><br><span class="line">    a = <span class="number">2</span></span><br><span class="line">    print(a)</span><br><span class="line"></span><br><span class="line"><span class="comment"># print global variable</span></span><br><span class="line">print(a)</span><br><span class="line"><span class="comment"># print local variable from function</span></span><br><span class="line">print_local()</span><br><span class="line"><span class="comment"># a is unchanged</span></span><br><span class="line">print(a)</span><br><span class="line"><span class="comment"># change and print global from function</span></span><br><span class="line">print_global()</span><br><span class="line"><span class="comment"># a is changed</span></span><br><span class="line">print(a)</span><br></pre></td></tr></table></figure><h3 id="Use-defaultdict"><a href="#Use-defaultdict" class="headerlink" title="Use defaultdict"></a>Use defaultdict</h3><p>Use <code>dict</code>:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">d = &#123;&#125;</span><br><span class="line">d[<span class="string">'a'</span>] = []</span><br><span class="line">d[<span class="string">'b'</span>] = []</span><br><span class="line">d[<span class="string">'c'</span>] = []</span><br><span class="line"><span class="comment"># extend list with new elements</span></span><br><span class="line">d[<span class="string">'a'</span>] += [<span class="number">1</span>, <span class="number">2</span>]</span><br><span class="line">d[<span class="string">'b'</span>] += [<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>]</span><br><span class="line">d[<span class="string">'c'</span>] += [<span class="number">6</span>]</span><br><span class="line"><span class="keyword">for</span> key, val <span class="keyword">in</span> d.items():</span><br><span class="line">    print(key, val)</span><br></pre></td></tr></table></figure><p>Use <code>defaultdict</code>:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> defaultdict</span><br><span class="line"><span class="comment"># a new list is created automatically when new elements are added</span></span><br><span class="line">d = defaultdict(list)</span><br><span class="line"><span class="comment"># extend list with new elements</span></span><br><span class="line">d[<span class="string">'a'</span>] += [<span class="number">1</span>, <span class="number">2</span>]</span><br><span class="line">d[<span class="string">'b'</span>] += [<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>]</span><br><span class="line">d[<span class="string">'c'</span>] += [<span class="number">6</span>]</span><br><span class="line"><span class="keyword">for</span> key, val <span class="keyword">in</span> d.items():</span><br><span class="line">    print(key, val)</span><br></pre></td></tr></table></figure><h3 id="Use-generators"><a href="#Use-generators" class="headerlink" title="Use generators"></a>Use generators</h3><p>Example: read a large FASTA file</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">append_extra_line</span><span class="params">(f)</span>:</span></span><br><span class="line">    <span class="string">"""Yield an empty line after the last line in the file</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> f:</span><br><span class="line">        <span class="keyword">yield</span> line</span><br><span class="line">    <span class="keyword">yield</span> <span class="string">''</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">read_fasta</span><span class="params">(filename)</span>:</span></span><br><span class="line">    <span class="keyword">with</span> open(filename, <span class="string">'r'</span>) <span class="keyword">as</span> f:</span><br><span class="line">        name = <span class="keyword">None</span></span><br><span class="line">        seq = <span class="string">''</span></span><br><span class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> append_extra_line(f):</span><br><span class="line">            <span class="keyword">if</span> line.startswith(<span class="string">'&gt;'</span>) <span class="keyword">or</span> (len(line) == <span class="number">0</span>):</span><br><span class="line">                <span class="keyword">if</span> (len(seq) &gt; <span class="number">0</span>) <span class="keyword">and</span> (name <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>):</span><br><span class="line">                    <span class="keyword">yield</span> (name, seq)</span><br><span class="line">                <span class="keyword">if</span> line.startswith(<span class="string">'&gt;'</span>):</span><br><span class="line">                    name = line.strip()[<span class="number">1</span>:].split()[<span class="number">0</span>]</span><br><span class="line">                    seq = <span class="string">''</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">if</span> name <span class="keyword">is</span> <span class="keyword">None</span>:</span><br><span class="line">                    <span class="keyword">raise</span> ValueError(<span class="string">'the first line does not start with "&gt;"'</span>)</span><br><span class="line">                seq += line.strip()</span><br><span class="line"><span class="comment"># print sequence name and length of each </span></span><br><span class="line"><span class="keyword">for</span> name, seq <span class="keyword">in</span> read_fasta(<span class="string">'test.fa'</span>):</span><br><span class="line">    print(name, len(seq))</span><br></pre></td></tr></table></figure><h3 id="Turn-off-annoying-KeyboardInterrupt-and-BrokenPipe-Error"><a href="#Turn-off-annoying-KeyboardInterrupt-and-BrokenPipe-Error" class="headerlink" title="Turn off annoying KeyboardInterrupt and BrokenPipe Error"></a>Turn off annoying KeyboardInterrupt and BrokenPipe Error</h3><p>Without exception handling (press Ctrl+C):</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line">time.sleep(<span class="number">300</span>)</span><br></pre></td></tr></table></figure><p>With exception handling (press Ctrl+C):</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> errno</span><br><span class="line"></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    time.sleep(<span class="number">300</span>)</span><br><span class="line"><span class="keyword">except</span> KeyboardInterrupt:</span><br><span class="line">    sys.exit(<span class="number">1</span>)</span><br><span class="line"><span class="keyword">except</span> OSError <span class="keyword">as</span> e:</span><br><span class="line">    <span class="keyword">if</span> e.errno == errno.EPIPE:</span><br><span class="line">        sys.exit(-e.errno)</span><br></pre></td></tr></table></figure><h3 id="Class-and-instance-variables"><a href="#Class-and-instance-variables" class="headerlink" title="Class and instance variables"></a>Class and instance variables</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyClass</span><span class="params">()</span>:</span></span><br><span class="line">    name = <span class="string">'class_name'</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, name)</span>:</span></span><br><span class="line">        self.name = name</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">change_name</span><span class="params">(self, name)</span>:</span></span><br><span class="line">        self.name = name</span><br><span class="line"></span><br><span class="line"><span class="comment"># print class variable</span></span><br><span class="line">print(MyClass.name)</span><br><span class="line"><span class="comment"># create an instance from MyClass</span></span><br><span class="line">a = MyClass(<span class="string">'instance_name'</span>)</span><br><span class="line"><span class="comment"># print instance name</span></span><br><span class="line">print(a.name)</span><br><span class="line"><span class="comment"># change instance name</span></span><br><span class="line">a.change_name(<span class="string">'instance_new_name'</span>)</span><br><span class="line">print(a.name)</span><br><span class="line">print(MyClass.name)</span><br><span class="line"><span class="comment"># change class name</span></span><br><span class="line">MyClass.name = <span class="string">'class_new_name'</span></span><br><span class="line">print(a.name)</span><br><span class="line">print(MyClass.name)</span><br></pre></td></tr></table></figure><h2 id="Useful-Python-packages-for-data-analysis"><a href="#Useful-Python-packages-for-data-analysis" class="headerlink" title="Useful Python packages for data analysis"></a>Useful Python packages for data analysis</h2><h3 id="Browser-based-interactive-programming-in-Python-jupyter"><a href="#Browser-based-interactive-programming-in-Python-jupyter" class="headerlink" title="Browser-based interactive programming in Python: jupyter"></a>Browser-based interactive programming in Python: jupyter</h3><p>URL: (<a href="http://jupyter.org/" target="_blank" rel="noopener">http://jupyter.org/</a>)</p><p><strong>Start jupyter notebook</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jupyter notebook --no-browser</span><br></pre></td></tr></table></figure><p><strong>Jupyter notebooks manager</strong></p><p><img src="http://i2.tiimg.com/640680/883fecd2e4eb8e5b.png" alt="Markdown"></p><p><strong>Jupyter process manager</strong></p><p><img src="http://i2.tiimg.com/640680/118f51c0d90051c8.png" alt="Markdown"></p><p><strong>Jupyter notebook</strong></p><p><img src="http://i2.tiimg.com/640680/98f28eb528ec01b8.png" alt="Markdown"></p><p><strong>Integrate with matplotlib</strong></p><p><img src="http://i2.tiimg.com/640680/88d0bef8d04a30c6.png" alt="Markdown"></p><p><strong>Browser-based text editor</strong></p><p><img src="http://i2.tiimg.com/640680/3ff9089547169bd3.png" alt="Markdown"></p><p><strong>Browser-based terminal</strong></p><p><img src="http://i2.tiimg.com/640680/782990d4fc31ded7.png" alt="Markdown"></p><p><strong>Display image</strong></p><p><img src="http://i2.tiimg.com/640680/0bb4e663938fe506.png" alt="Markdown"></p><p><strong>Display dataframe</strong></p><p><img src="http://i2.tiimg.com/640680/f3d01d72d42e8579.png" alt="Markdown"></p><p><strong>Display audio</strong></p><p><img src="http://i2.tiimg.com/640680/56c5bcb9364c6462.png" alt="Markdown"></p><p><strong>Embedded markdown</strong></p><p><img src="http://i2.tiimg.com/640680/e917186572eb56a1.png" alt="Markdown"></p><h3 id="Python-packages-for-scientific-computing"><a href="#Python-packages-for-scientific-computing" class="headerlink" title="Python packages for scientific computing"></a>Python packages for scientific computing</h3><p><img src="http://i2.tiimg.com/640680/6a9c55b2916eea12.jpg" alt="Markdown"></p><h3 id="Vector-arithmetics-numpy"><a href="#Vector-arithmetics-numpy" class="headerlink" title="Vector arithmetics: numpy"></a>Vector arithmetics: numpy</h3><p>URL: (<a href="http://www.numpy.org/" target="_blank" rel="noopener">http://www.numpy.org/</a>)</p><p>Example:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="comment"># create an empty matrix of shape (5, 4)</span></span><br><span class="line">X = np.zeros((<span class="number">5</span>, <span class="number">4</span>), dtype=np.int32)</span><br><span class="line"><span class="comment"># create an array of length 5: [0, 1, 2, 3, 4]</span></span><br><span class="line">y = np.arange(<span class="number">5</span>)</span><br><span class="line"><span class="comment"># create an array of length 4: [0, 1, 2, 3]</span></span><br><span class="line">z = np.arange(<span class="number">4</span>)</span><br><span class="line"><span class="comment"># set Row 1 to [0, 1, 2, 3]</span></span><br><span class="line">X[<span class="number">0</span>] = np.arange(<span class="number">4</span>)</span><br><span class="line"><span class="comment"># set Row 2 to [1, 1, 1, 1]</span></span><br><span class="line">X[<span class="number">1</span>] = <span class="number">1</span></span><br><span class="line"><span class="comment"># add 1 to all elements</span></span><br><span class="line">X += <span class="number">1</span></span><br><span class="line"><span class="comment"># add y to each row of X</span></span><br><span class="line">X += y.reshape((<span class="number">-1</span>, <span class="number">1</span>))</span><br><span class="line"><span class="comment"># add z to each column of X</span></span><br><span class="line">X += z.reshape((<span class="number">1</span>, <span class="number">-1</span>))</span><br><span class="line"><span class="comment"># get row sums =&gt; </span></span><br><span class="line">row_sums = X.sum(axis=<span class="number">1</span>)</span><br><span class="line"><span class="comment"># get column sums</span></span><br><span class="line">col_sums = X.sum(axis=<span class="number">0</span>)</span><br><span class="line"><span class="comment"># matrix multiplication</span></span><br><span class="line">A = X.dot(X.T)</span><br><span class="line"><span class="comment"># save matrix to text file</span></span><br><span class="line">np.savetxt(<span class="string">'data.txt'</span>, A)</span><br></pre></td></tr></table></figure><h3 id="Numerical-analysis-probability-distribution-signal-processing-etc-scipy"><a href="#Numerical-analysis-probability-distribution-signal-processing-etc-scipy" class="headerlink" title="Numerical analysis (probability distribution, signal processing, etc.): scipy"></a>Numerical analysis (probability distribution, signal processing, etc.): scipy</h3><p>URL: (<a href="https://www.scipy.org/" target="_blank" rel="noopener">https://www.scipy.org/</a>)</p><p>scipy.stats contains a large number probability distributions:<br><img src="http://i2.tiimg.com/640680/7f5bc15337bf554a.png" alt="Markdown"></p><p>Unified interface for all probability distributions:<br><img src="http://i2.tiimg.com/640680/b2b4f50de382d817.png" alt="Markdown"></p><h3 id="Just-in-time-JIT-compiler-for-vector-arithmetics"><a href="#Just-in-time-JIT-compiler-for-vector-arithmetics" class="headerlink" title="Just-in-time (JIT) compiler for vector arithmetics"></a>Just-in-time (JIT) compiler for vector arithmetics</h3><p>URL: (<a href="https://numba.pydata.org/" target="_blank" rel="noopener">https://numba.pydata.org/</a>)</p><p>Compile python for-loops to native code to achive similar performance to C/C++ code.<br>Example:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> numba <span class="keyword">import</span> jit</span><br><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> arange</span><br><span class="line"></span><br><span class="line"><span class="comment"># jit decorator tells Numba to compile this function.</span></span><br><span class="line"><span class="comment"># The argument types will be inferred by Numba when function is called.</span></span><br><span class="line"><span class="meta">@jit</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sum2d</span><span class="params">(arr)</span>:</span></span><br><span class="line">    M, N = arr.shape</span><br><span class="line">    result = <span class="number">0.0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(M):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(N):</span><br><span class="line">            result += arr[i,j]</span><br><span class="line">    <span class="keyword">return</span> result</span><br><span class="line"></span><br><span class="line">a = arange(<span class="number">9</span>).reshape(<span class="number">3</span>,<span class="number">3</span>)</span><br><span class="line">print(sum2d(a))</span><br></pre></td></tr></table></figure><h3 id="Library-for-symbolic-computation-sympy"><a href="#Library-for-symbolic-computation-sympy" class="headerlink" title="Library for symbolic computation: sympy"></a>Library for symbolic computation: sympy</h3><p>URL: (<a href="http://www.sympy.org/en/index.html" target="_blank" rel="noopener">http://www.sympy.org/en/index.html</a>)</p><p><img src="http://i2.tiimg.com/640680/0533f1359890e8ed.png" alt="Markdown"></p><h3 id="Operation-on-data-frames-pandas"><a href="#Operation-on-data-frames-pandas" class="headerlink" title="Operation on data frames: pandas"></a>Operation on data frames: pandas</h3><p>URL: (<a href="http://pandas.pydata.org/pandas-docs/stable/" target="_blank" rel="noopener">http://pandas.pydata.org/pandas-docs/stable/</a>)</p><p>Example:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="comment"># read a bed file</span></span><br><span class="line">genes = pd.read_table(<span class="string">'gene.bed'</span>, header=<span class="keyword">None</span>, sep=<span class="string">'\t'</span>,</span><br><span class="line">                     names=(<span class="string">'chrom'</span>, <span class="string">'start'</span>, <span class="string">'end'</span>, <span class="string">'gene_id'</span>, <span class="string">'score'</span>, <span class="string">'strand'</span>, <span class="string">'biotype'</span>))</span><br><span class="line"><span class="comment"># get all gene IDs</span></span><br><span class="line">gene_ids = genes[<span class="string">'gene_id'</span>]</span><br><span class="line"><span class="comment"># set gene_id as index</span></span><br><span class="line">genes.index = genes[<span class="string">'gene_id'</span>]</span><br><span class="line"><span class="comment"># get row with given gene_id</span></span><br><span class="line">gene = genes.loc[<span class="string">'ENSG00000212325.1'</span>]</span><br><span class="line"><span class="comment"># get rows with biotype = 'protein_coding'</span></span><br><span class="line">genes_selected = genes[genes[<span class="string">'biotype'</span>] == <span class="string">'protein_coding'</span>]]</span><br><span class="line"><span class="comment"># get protein coding genes in chr1</span></span><br><span class="line">genes_selected = genes.query(<span class="string">'(biotype == "protein_coding") and (chrom == "chr1")'</span>)</span><br><span class="line"><span class="comment"># count genes for each biotype</span></span><br><span class="line">biotype_counts = genes.groupby(<span class="string">'biotype'</span>)[<span class="string">'gene_id'</span>].count()</span><br><span class="line"><span class="comment"># add a column for gene length</span></span><br><span class="line">genes[<span class="string">'length'</span>] = genes[<span class="string">'end'</span>] - genes[<span class="string">'start'</span>]</span><br><span class="line"><span class="comment"># calculate average gene length for each chromosome and biotype</span></span><br><span class="line">length_table = genes.pivot_table(values=<span class="string">'length'</span>, index=<span class="string">'biotype'</span>, columns=<span class="string">'chrom'</span>)</span><br><span class="line"><span class="comment"># save DataFrame to Excel file</span></span><br><span class="line">length_table.to_excel(<span class="string">'length_table.xlsx'</span>)</span><br></pre></td></tr></table></figure><h3 id="Basic-graphics-and-plotting-matplotlib"><a href="#Basic-graphics-and-plotting-matplotlib" class="headerlink" title="Basic graphics and plotting: matplotlib"></a>Basic graphics and plotting: matplotlib</h3><p>URL: (<a href="https://matplotlib.org/contents.html" target="_blank" rel="noopener">https://matplotlib.org/contents.html</a>)</p><p><img src="http://i2.tiimg.com/640680/73c9ac2564d70838.png" alt="Markdown"></p><h3 id="Statistical-data-visualization-seaborn"><a href="#Statistical-data-visualization-seaborn" class="headerlink" title="Statistical data visualization: seaborn"></a>Statistical data visualization: seaborn</h3><p>URL: (<a href="https://seaborn.pydata.org/" target="_blank" rel="noopener">https://seaborn.pydata.org/</a>)</p><p><img src="http://i2.tiimg.com/640680/39a71f7469439ab1.png" alt="Markdown"></p><h3 id="Interactive-programming-in-Python-ipython"><a href="#Interactive-programming-in-Python-ipython" class="headerlink" title="Interactive programming in Python: ipython"></a>Interactive programming in Python: ipython</h3><p>URL: (<a href="http://ipython.org/ipython-doc/stable/index.html" target="_blank" rel="noopener">http://ipython.org/ipython-doc/stable/index.html</a>)</p><p><img src="http://i2.tiimg.com/640680/0bec0a9639a5c1e2.png" alt="Markdown"></p><h3 id="Statistical-tests-statsmodels"><a href="#Statistical-tests-statsmodels" class="headerlink" title="Statistical tests: statsmodels"></a>Statistical tests: statsmodels</h3><p>URL: (<a href="https://www.statsmodels.org/stable/index.html" target="_blank" rel="noopener">https://www.statsmodels.org/stable/index.html</a>)</p><p><img src="http://i2.tiimg.com/640680/68736b715f5d433b.png" alt="Markdown"></p><h3 id="Machine-learning-algorithms-scikit-learn"><a href="#Machine-learning-algorithms-scikit-learn" class="headerlink" title="Machine learning algorithms: scikit-learn"></a>Machine learning algorithms: scikit-learn</h3><p>URL: (<a href="http://scikit-learn.org/" target="_blank" rel="noopener">http://scikit-learn.org/</a>)</p><p><img src="http://i2.tiimg.com/640680/bc36e9b169826b32.png" alt="Markdown"></p><p>Example:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> make_classification</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> roc_auc_score, accuracy_score</span><br><span class="line"></span><br><span class="line"><span class="comment"># generate ramdom data</span></span><br><span class="line">X, y = make_classification(n_samples=<span class="number">1000</span>, n_classes=<span class="number">2</span>, n_features=<span class="number">10</span>)</span><br><span class="line"><span class="comment"># split dataset into training and test dataset</span></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.2</span>)</span><br><span class="line"><span class="comment"># create an classifier object</span></span><br><span class="line">model = LogisticRegression()</span><br><span class="line"><span class="comment"># training the classifier</span></span><br><span class="line">model.fit(X_train, y_train)</span><br><span class="line"><span class="comment"># predict outcomes on the test dataset</span></span><br><span class="line">y_pred = model.predict(X_test)</span><br><span class="line"><span class="comment"># evalualte the classification performance</span></span><br><span class="line">print(<span class="string">'roc_auc_score = %f'</span>%roc_auc_score(y_test, y_pred))</span><br><span class="line">print(<span class="string">'accuracy_score = %f'</span>%accuracy_score(y_test, y_pred))</span><br></pre></td></tr></table></figure><h3 id="Natural-language-analysis-gensim"><a href="#Natural-language-analysis-gensim" class="headerlink" title="Natural language analysis: gensim"></a>Natural language analysis: gensim</h3><p>URL: (<a href="https://radimrehurek.com/gensim/" target="_blank" rel="noopener">https://radimrehurek.com/gensim/</a>)</p><h3 id="HTTP-library-requests"><a href="#HTTP-library-requests" class="headerlink" title="HTTP library: requests"></a>HTTP library: requests</h3><p>URL: (<a href="http://docs.python-requests.org/en/master/" target="_blank" rel="noopener">http://docs.python-requests.org/en/master/</a>)</p><p><img src="http://i2.tiimg.com/640680/2360c5310673162a.png" alt="Markdown"></p><h3 id="Lightweight-Web-framework-flask"><a href="#Lightweight-Web-framework-flask" class="headerlink" title="Lightweight Web framework: flask"></a>Lightweight Web framework: flask</h3><p>URL: (<a href="http://flask.pocoo.org/" target="_blank" rel="noopener">http://flask.pocoo.org/</a>)</p><p><img src="http://i2.tiimg.com/640680/186cb62c6e00df0e.png" alt="Markdown"></p><h3 id="Deep-learning-framework-tensorflow"><a href="#Deep-learning-framework-tensorflow" class="headerlink" title="Deep learning framework: tensorflow"></a>Deep learning framework: tensorflow</h3><p>URL: (<a href="http://tensorflow.org/" target="_blank" rel="noopener">http://tensorflow.org/</a>)</p><h3 id="High-level-deep-learning-framework-keras"><a href="#High-level-deep-learning-framework-keras" class="headerlink" title="High-level deep learning framework: keras"></a>High-level deep learning framework: keras</h3><p>URL: (<a href="https://keras.io/" target="_blank" rel="noopener">https://keras.io/</a>)</p><h3 id="Operation-on-sequence-and-alignment-formats-biopython"><a href="#Operation-on-sequence-and-alignment-formats-biopython" class="headerlink" title="Operation on sequence and alignment formats: biopython"></a>Operation on sequence and alignment formats: biopython</h3><p>URL: (<a href="http://biopython.org/" target="_blank" rel="noopener">http://biopython.org/</a>)</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> Bio <span class="keyword">import</span> SeqIO</span><br><span class="line"><span class="keyword">for</span> record <span class="keyword">in</span> SeqIO.parse(<span class="string">'test.fa'</span>, <span class="string">'fasta'</span>):</span><br><span class="line">    print(record.id, len(record.seq))</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> Bio <span class="keyword">import</span> SeqIO</span><br><span class="line"><span class="keyword">from</span> Bio.Seq <span class="keyword">import</span> Seq</span><br><span class="line"><span class="keyword">from</span> Bio.SeqRecord <span class="keyword">import</span> SeqRecord</span><br><span class="line">sequences = [</span><br><span class="line">    SeqRecord(Seq(<span class="string">'ACCGGTATCTATATCCCCGAGAGGAATGGGTCAGACATGGACCTAC'</span>), id=<span class="string">'A'</span>, description=<span class="string">''</span>),</span><br><span class="line">    SeqRecord(Seq(<span class="string">'TTACAATGTGGCAGTGAACGCGTGACAATCCTCCCCGTTGGACAT'</span>), id=<span class="string">'B'</span>, description=<span class="string">''</span>),</span><br><span class="line">    SeqRecord(Seq(<span class="string">'CAAAGCTGCATCGAATTGTCGAGACAACACTAGATTTAAGCGCA'</span>), id=<span class="string">'C'</span>, description=<span class="string">''</span>),</span><br><span class="line">    SeqRecord(Seq(<span class="string">'CGCCCGCGAGGGCAATCAGGACGGATTTACGGAT'</span>), id=<span class="string">'D'</span>, description=<span class="string">''</span>),</span><br><span class="line">    SeqRecord(Seq(<span class="string">'CCGCCCACGCTCCCGTTTTCTTCCATACCTGTCC'</span>), id=<span class="string">'E'</span>, description=<span class="string">''</span>)</span><br><span class="line">]</span><br><span class="line"><span class="keyword">with</span> open(<span class="string">'test_out.fa'</span>, <span class="string">'w'</span>) <span class="keyword">as</span> f:</span><br><span class="line">    SeqIO.write(sequences, f, <span class="string">'fasta'</span>)</span><br></pre></td></tr></table></figure><h3 id="Operation-on-genomic-formats-BigWig-etc-bx-python"><a href="#Operation-on-genomic-formats-BigWig-etc-bx-python" class="headerlink" title="Operation on genomic formats (BigWig,etc.): bx-python"></a>Operation on genomic formats (BigWig,etc.): bx-python</h3><h3 id="Operation-on-HDF5-files-h5py"><a href="#Operation-on-HDF5-files-h5py" class="headerlink" title="Operation on HDF5 files: h5py"></a>Operation on HDF5 files: h5py</h3><p>URL: (<a href="https://www.h5py.org/" target="_blank" rel="noopener">https://www.h5py.org/</a>)</p><p>Save data to an HDF5 file</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> h5py</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="comment"># generate data</span></span><br><span class="line">chroms = [<span class="string">'chr1'</span>, <span class="string">'chr2'</span>, <span class="string">'chr3'</span>]</span><br><span class="line">chrom_sizes = &#123;</span><br><span class="line">    <span class="string">'chr1'</span>: <span class="number">15000</span>,</span><br><span class="line">    <span class="string">'chr2'</span>: <span class="number">12000</span>,</span><br><span class="line">    <span class="string">'chr3'</span>: <span class="number">11000</span></span><br><span class="line">&#125;</span><br><span class="line">coverage = &#123;&#125;</span><br><span class="line">counts = &#123;&#125;</span><br><span class="line"><span class="keyword">for</span> chrom, size <span class="keyword">in</span> chrom_sizes.items():</span><br><span class="line">    coverage[chrom] = np.random.randint(<span class="number">10</span>, <span class="number">1000</span>, size=size)</span><br><span class="line">    counts[chrom] = np.random.randint(<span class="number">1000</span>, size=size)%coverage[chrom]</span><br><span class="line"><span class="comment"># save data to an HDF5 file</span></span><br><span class="line"><span class="keyword">with</span> h5py.File(<span class="string">'dataset.h5'</span>, <span class="string">'w'</span>) <span class="keyword">as</span> f:</span><br><span class="line">    <span class="keyword">for</span> chrom <span class="keyword">in</span> chrom_sizes:</span><br><span class="line">        g = f.create_group(chrom)</span><br><span class="line">        g.create_dataset(<span class="string">'coverage'</span>, data=coverage[chrom])</span><br><span class="line">        g.create_dataset(<span class="string">'counts'</span>, data=counts[chrom])</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">h5ls -r dataset.h5</span><br></pre></td></tr></table></figure><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">/                        Group</span><br><span class="line">/chr1                    Group</span><br><span class="line">/chr1/counts             Dataset &#123;15000&#125;</span><br><span class="line">/chr1/coverage           Dataset &#123;15000&#125;</span><br><span class="line">/chr2                    Group</span><br><span class="line">/chr2/counts             Dataset &#123;12000&#125;</span><br><span class="line">/chr2/coverage           Dataset &#123;12000&#125;</span><br><span class="line">/chr3                    Group</span><br><span class="line">/chr3/counts             Dataset &#123;11000&#125;</span><br><span class="line">/chr3/coverage           Dataset &#123;11000&#125;</span><br></pre></td></tr></table></figure><p>Read data from an HDF file:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> h5py</span><br><span class="line"><span class="comment"># read data from an HDF5 file</span></span><br><span class="line"><span class="keyword">with</span> h5py.File(<span class="string">'dataset.h5'</span>, <span class="string">'r'</span>) <span class="keyword">as</span> f:</span><br><span class="line">    coverage = &#123;&#125;</span><br><span class="line">    counts = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> chrom <span class="keyword">in</span> f.keys():</span><br><span class="line">        coverage[chrom] = f[chrom + <span class="string">'/coverage'</span>][:]</span><br><span class="line">        counts[chrom] = f[chrom + <span class="string">'/counts'</span>][:]</span><br></pre></td></tr></table></figure><h3 id="Mixed-C-C-and-python-programming-cython"><a href="#Mixed-C-C-and-python-programming-cython" class="headerlink" title="Mixed C/C++ and python programming: cython"></a>Mixed C/C++ and python programming: cython</h3><p>URL: (<a href="http://cython.org/" target="_blank" rel="noopener">http://cython.org/</a>)</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">cimport numpy <span class="keyword">as</span> np</span><br><span class="line">cimport cython</span><br><span class="line"><span class="keyword">from</span> cython.parallel <span class="keyword">import</span> prange</span><br><span class="line"><span class="keyword">from</span> cython.parallel cimport parallel</span><br><span class="line">cimport openmp</span><br><span class="line"></span><br><span class="line"><span class="meta">@cython.boundscheck(False) # turn off bounds-checking for entire function</span></span><br><span class="line"><span class="meta">@cython.wraparound(False)  # turn off negative index wrapping for entire function</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">compute_mse_grad_linear_ard</span><span class="params">(np.ndarray[np.float64_t, ndim=<span class="number">1</span>] w,</span></span></span><br><span class="line"><span class="function"><span class="params">        np.ndarray[np.float64_t, ndim=<span class="number">2</span>] X1,</span></span></span><br><span class="line"><span class="function"><span class="params">        np.ndarray[np.float64_t, ndim=<span class="number">2</span>] X2,</span></span></span><br><span class="line"><span class="function"><span class="params">        np.ndarray[np.float64_t, ndim=<span class="number">2</span>] Kinv1,</span></span></span><br><span class="line"><span class="function"><span class="params">        np.ndarray[np.float64_t, ndim=<span class="number">2</span>] K2,</span></span></span><br><span class="line"><span class="function"><span class="params">        np.ndarray[np.float64_t, ndim=<span class="number">2</span>] a,</span></span></span><br><span class="line"><span class="function"><span class="params">        np.ndarray[np.float64_t, ndim=<span class="number">2</span>] err,</span></span></span><br><span class="line"><span class="function"><span class="params">        np.ndarray[np.float64_t, ndim=<span class="number">2</span>] mask=None)</span>:</span></span><br><span class="line">    <span class="string">'''Compute the gradients of MSE on the test samples with respect to relevance vector w.</span></span><br><span class="line"><span class="string">    :param w: 1D array of shape [n_features]</span></span><br><span class="line"><span class="string">    :return: gradients of MSE wrt. 2, 1D array of shape [n_features]</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    cdef np.int64_t N1, N2, p</span><br><span class="line">    cdef np.int64_t k, i, j, m</span><br><span class="line">    N1 = X1.shape[<span class="number">0</span>]</span><br><span class="line">    N2 = X2.shape[<span class="number">0</span>]</span><br><span class="line">    p = X2.shape[<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">    cdef np.ndarray[np.float64_t, ndim=<span class="number">2</span>] K2Kinv1 = K2.dot(Kinv1)</span><br><span class="line">    cdef np.ndarray[np.float64_t, ndim=<span class="number">1</span>] mse_grad = np.zeros_like(w)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#cdef np.ndarray[np.float64_t, ndim=3] K1_grad = np.zeros((p, N1, N1), dtype=np.float64)</span></span><br><span class="line">    <span class="comment">#cdef np.ndarray[np.float64_t, ndim=3] K2_grad = np.zeros((p, N2, N1), dtype=np.float64)</span></span><br><span class="line">    <span class="comment">#cdef np.ndarray[np.float64_t, ndim=3] K_grad =  np.zeros((p, N2, N1), dtype=np.float64)</span></span><br><span class="line">    cdef np.int64_t max_n_threads = openmp.omp_get_max_threads()</span><br><span class="line">    cdef np.ndarray[np.float64_t, ndim=<span class="number">3</span>] K1_grad = np.zeros((max_n_threads, N1, N1), dtype=np.float64)</span><br><span class="line">    cdef np.ndarray[np.float64_t, ndim=<span class="number">3</span>] K2_grad = np.zeros((max_n_threads, N2, N1), dtype=np.float64)</span><br><span class="line">    cdef np.ndarray[np.float64_t, ndim=<span class="number">3</span>] K_grad  = np.zeros((max_n_threads, N1, N1), dtype=np.float64)</span><br><span class="line"></span><br><span class="line">    cdef np.int64_t thread_id</span><br><span class="line">    <span class="keyword">with</span> nogil, parallel():</span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> prange(p):</span><br><span class="line">            thread_id = openmp.omp_get_thread_num()</span><br><span class="line">            <span class="comment"># compute K1_grad</span></span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> range(N1):</span><br><span class="line">                <span class="keyword">for</span> j <span class="keyword">in</span> range(N1):</span><br><span class="line">                    K1_grad[thread_id, i, j] = <span class="number">2.0</span>*w[k]*X1[i, k]*X1[j, k]</span><br><span class="line">            <span class="comment"># compute K2_grad</span></span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> range(N2):</span><br><span class="line">                <span class="keyword">for</span> j <span class="keyword">in</span> range(N1):</span><br><span class="line">                    K2_grad[thread_id, i, j] = <span class="number">2.0</span>*w[k]*X2[i, k]*X1[j, k]</span><br><span class="line">            <span class="comment"># compute K_grad</span></span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> range(N2):</span><br><span class="line">                <span class="keyword">for</span> j <span class="keyword">in</span> range(N1):</span><br><span class="line">                    K_grad[thread_id, i, j] = K2_grad[thread_id, i, j]</span><br><span class="line">                    <span class="keyword">for</span> m <span class="keyword">in</span> range(N1):</span><br><span class="line">                        K_grad[thread_id, i, j] += K2Kinv1[i, m]*K1_grad[thread_id, m, j]</span><br><span class="line">            <span class="comment"># compute mse_grad</span></span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> range(N2):</span><br><span class="line">                <span class="keyword">for</span> j <span class="keyword">in</span> range(N1):</span><br><span class="line">                    mse_grad[k] += err[i, <span class="number">0</span>]*K_grad[thread_id, i, j]*a[j, <span class="number">0</span>]</span><br><span class="line">    <span class="keyword">return</span> mse_grad, K_grad</span><br></pre></td></tr></table></figure><h3 id="Progress-bar-tqdm"><a href="#Progress-bar-tqdm" class="headerlink" title="Progress bar: tqdm"></a>Progress bar: tqdm</h3><p>URL: (<a href="https://pypi.python.org/pypi/tqdm" target="_blank" rel="noopener">https://pypi.python.org/pypi/tqdm</a>)</p><p><img src="http://i2.tiimg.com/640680/010f81392dd7104a.png" alt="Markdown"></p><p><img src="http://i2.tiimg.com/640680/70da70ed24b4932f.png" alt="Markdown"></p><h2 id="Example-Python-scripts"><a href="#Example-Python-scripts" class="headerlink" title="Example Python scripts"></a>Example Python scripts</h2><h3 id="View-a-table-in-a-pretty-way"><a href="#View-a-table-in-a-pretty-way" class="headerlink" title="View a table in a pretty way"></a>View a table in a pretty way</h3><p>The original table is ugly:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">head -n 15 metadata.tsv</span><br></pre></td></tr></table></figure><p>Output:</p><figure class="highlight nimrod"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">File</span> accession<span class="type">File</span> format<span class="type">Output</span> <span class="keyword">type</span><span class="type">Experiment</span> accession<span class="type">Assay</span><span class="type">Biosample</span> term id</span><br><span class="line"><span class="type">ENCFF983DFB</span>fastqreads<span class="type">ENCSR429XTR</span><span class="type">ChIP</span>-<span class="built_in">seq</span><span class="type">EFO</span>:<span class="number">0002067</span></span><br><span class="line"><span class="type">ENCFF590TBW</span>fastqreads<span class="type">ENCSR429XTR</span><span class="type">ChIP</span>-<span class="built_in">seq</span><span class="type">EFO</span>:<span class="number">0002067</span></span><br><span class="line"><span class="type">ENCFF258RWG</span>bamunfiltered alignments<span class="type">ENCSR429XTR</span><span class="type">ChIP</span>-<span class="built_in">seq</span><span class="type">EFO</span>:<span class="number">0002067</span></span><br><span class="line"><span class="type">ENCFF468LRV</span>bamunfiltered alignments<span class="type">ENCSR429XTR</span><span class="type">ChIP</span>-<span class="built_in">seq</span><span class="type">EFO</span>:<span class="number">0002067</span></span><br><span class="line"><span class="type">ENCFF216EBS</span>bamalignments<span class="type">ENCSR429XTR</span><span class="type">ChIP</span>-<span class="built_in">seq</span><span class="type">EFO</span>:<span class="number">0002067</span></span><br><span class="line"><span class="type">ENCFF232QFN</span>bamunfiltered alignments<span class="type">ENCSR429XTR</span><span class="type">ChIP</span>-<span class="built_in">seq</span><span class="type">EFO</span>:<span class="number">0002067</span></span><br><span class="line"><span class="type">ENCFF682NGE</span>bamalignments<span class="type">ENCSR429XTR</span><span class="type">ChIP</span>-<span class="built_in">seq</span><span class="type">EFO</span>:<span class="number">0002067</span></span><br><span class="line"><span class="type">ENCFF328UKA</span>bamunfiltered alignments<span class="type">ENCSR429XTR</span><span class="type">ChIP</span>-<span class="built_in">seq</span><span class="type">EFO</span>:<span class="number">0002067</span></span><br><span class="line"><span class="type">ENCFF165COO</span>bamalignments<span class="type">ENCSR429XTR</span><span class="type">ChIP</span>-<span class="built_in">seq</span><span class="type">EFO</span>:<span class="number">0002067</span></span><br><span class="line"><span class="type">ENCFF466OLG</span>bamalignments<span class="type">ENCSR429XTR</span><span class="type">ChIP</span>-<span class="built_in">seq</span><span class="type">EFO</span>:<span class="number">0002067</span></span><br><span class="line"><span class="type">ENCFF595HIY</span>bigBed narrowPeakpeaks<span class="type">ENCSR429XTR</span><span class="type">ChIP</span>-<span class="built_in">seq</span><span class="type">EFO</span>:<span class="number">0002067</span></span><br><span class="line"><span class="type">ENCFF494CKB</span>bigWigfold change over control<span class="type">ENCSR429XTR</span><span class="type">ChIP</span>-<span class="built_in">seq</span><span class="type">EFO</span>:<span class="number">0002067</span></span><br><span class="line"><span class="type">ENCFF308BXW</span>bigWigfold change over control<span class="type">ENCSR429XTR</span><span class="type">ChIP</span>-<span class="built_in">seq</span><span class="type">EFO</span>:<span class="number">0002067</span></span><br><span class="line"><span class="type">ENCFF368IHM</span>bed narrowPeakpeaks<span class="type">ENCSR429XTR</span><span class="type">ChIP</span>-<span class="built_in">seq</span><span class="type">EFO</span>:<span class="number">0002067</span></span><br></pre></td></tr></table></figure><p>Now display the table more clearly:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">head -n 15 metadata.tsv | tvi -d $<span class="string">'\t'</span> -j center</span><br></pre></td></tr></table></figure><p>Output:</p><figure class="highlight nimrod"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">File</span> accession    <span class="type">File</span> format          <span class="type">Output</span> <span class="keyword">type</span>        <span class="type">Experiment</span> accession  <span class="type">Assay</span>   <span class="type">Biosample</span> term id</span><br><span class="line"> <span class="type">ENCFF983DFB</span>         fastq                reads               <span class="type">ENCSR429XTR</span>      <span class="type">ChIP</span>-<span class="built_in">seq</span>    <span class="type">EFO</span>:<span class="number">0002067</span></span><br><span class="line"> <span class="type">ENCFF590TBW</span>         fastq                reads               <span class="type">ENCSR429XTR</span>      <span class="type">ChIP</span>-<span class="built_in">seq</span>    <span class="type">EFO</span>:<span class="number">0002067</span></span><br><span class="line"> <span class="type">ENCFF258RWG</span>          bam         unfiltered alignments       <span class="type">ENCSR429XTR</span>      <span class="type">ChIP</span>-<span class="built_in">seq</span>    <span class="type">EFO</span>:<span class="number">0002067</span></span><br><span class="line"> <span class="type">ENCFF468LRV</span>          bam         unfiltered alignments       <span class="type">ENCSR429XTR</span>      <span class="type">ChIP</span>-<span class="built_in">seq</span>    <span class="type">EFO</span>:<span class="number">0002067</span></span><br><span class="line"> <span class="type">ENCFF216EBS</span>          bam               alignments            <span class="type">ENCSR429XTR</span>      <span class="type">ChIP</span>-<span class="built_in">seq</span>    <span class="type">EFO</span>:<span class="number">0002067</span></span><br><span class="line"> <span class="type">ENCFF232QFN</span>          bam         unfiltered alignments       <span class="type">ENCSR429XTR</span>      <span class="type">ChIP</span>-<span class="built_in">seq</span>    <span class="type">EFO</span>:<span class="number">0002067</span></span><br><span class="line"> <span class="type">ENCFF682NGE</span>          bam               alignments            <span class="type">ENCSR429XTR</span>      <span class="type">ChIP</span>-<span class="built_in">seq</span>    <span class="type">EFO</span>:<span class="number">0002067</span></span><br><span class="line"> <span class="type">ENCFF328UKA</span>          bam         unfiltered alignments       <span class="type">ENCSR429XTR</span>      <span class="type">ChIP</span>-<span class="built_in">seq</span>    <span class="type">EFO</span>:<span class="number">0002067</span></span><br><span class="line"> <span class="type">ENCFF165COO</span>          bam               alignments            <span class="type">ENCSR429XTR</span>      <span class="type">ChIP</span>-<span class="built_in">seq</span>    <span class="type">EFO</span>:<span class="number">0002067</span></span><br><span class="line"> <span class="type">ENCFF466OLG</span>          bam               alignments            <span class="type">ENCSR429XTR</span>      <span class="type">ChIP</span>-<span class="built_in">seq</span>    <span class="type">EFO</span>:<span class="number">0002067</span></span><br><span class="line"> <span class="type">ENCFF595HIY</span>   bigBed narrowPeak          peaks               <span class="type">ENCSR429XTR</span>      <span class="type">ChIP</span>-<span class="built_in">seq</span>    <span class="type">EFO</span>:<span class="number">0002067</span></span><br><span class="line"> <span class="type">ENCFF494CKB</span>        bigWig       fold change over control     <span class="type">ENCSR429XTR</span>      <span class="type">ChIP</span>-<span class="built_in">seq</span>    <span class="type">EFO</span>:<span class="number">0002067</span></span><br><span class="line"> <span class="type">ENCFF308BXW</span>        bigWig       fold change over control     <span class="type">ENCSR429XTR</span>      <span class="type">ChIP</span>-<span class="built_in">seq</span>    <span class="type">EFO</span>:<span class="number">0002067</span></span><br><span class="line"> <span class="type">ENCFF368IHM</span>    bed narrowPeak            peaks               <span class="type">ENCSR429XTR</span>      <span class="type">ChIP</span>-<span class="built_in">seq</span>    <span class="type">EFO</span>:<span class="number">0002067</span></span><br></pre></td></tr></table></figure><p>You can also get some help by typing <code>tvi -h</code>:</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">usage: tvi [-h] [-d DELIMITER] [-j &#123;left,right,center&#125;] [-s SEPARATOR]</span><br><span class="line">           [infile]</span><br><span class="line"></span><br><span class="line"><span class="builtin-name">Print</span> tables pretty</span><br><span class="line"></span><br><span class="line">positional arguments:</span><br><span class="line">  infile                input file,<span class="built_in"> default </span>is stdin</span><br><span class="line"></span><br><span class="line">optional arguments:</span><br><span class="line">  -h, --help            show this help message <span class="keyword">and</span> exit</span><br><span class="line">  -d DELIMITER          delimiter of fields of input.<span class="built_in"> Default </span>is white space.</span><br><span class="line">  -j &#123;left,right,center&#125;</span><br><span class="line">                        justification, either left, right <span class="keyword">or</span> center. Default</span><br><span class="line">                        is left</span><br><span class="line">  -s SEPARATOR          separator of fields <span class="keyword">in</span> output</span><br></pre></td></tr></table></figure><p><code>tvi.py</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#! /usr/bin/env python</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> cStringIO <span class="keyword">import</span> StringIO</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></span><br><span class="line">parser = argparse.ArgumentParser(description=<span class="string">'Print tables pretty'</span>)</span><br><span class="line">parser.add_argument(<span class="string">'infile'</span>, type=str, nargs=<span class="string">'?'</span>,</span><br><span class="line"> help=<span class="string">'input file, default is stdin'</span>)</span><br><span class="line">parser.add_argument(<span class="string">'-d'</span>, dest=<span class="string">'delimiter'</span>, type=str,</span><br><span class="line"> required=<span class="keyword">False</span>,</span><br><span class="line"> help=<span class="string">'delimiter of fields of input. Default is white space.'</span>)</span><br><span class="line">parser.add_argument(<span class="string">'-j'</span>, dest=<span class="string">'justify'</span>, type=str,</span><br><span class="line"> required=<span class="keyword">False</span>, default=<span class="string">'left'</span>,</span><br><span class="line"> choices=[<span class="string">'left'</span>, <span class="string">'right'</span>, <span class="string">'center'</span>],</span><br><span class="line"> help=<span class="string">'justification, either left, right or center. Default is left'</span>)</span><br><span class="line">parser.add_argument(<span class="string">'-s'</span>, dest=<span class="string">'separator'</span>, type=str,</span><br><span class="line"> required=<span class="keyword">False</span>, default=<span class="string">' '</span>,</span><br><span class="line"> help=<span class="string">'separator of fields in output'</span>)</span><br><span class="line">args = parser.parse_args()</span><br><span class="line"></span><br><span class="line">table = []</span><br><span class="line">maxwidth = []</span><br><span class="line"></span><br><span class="line"><span class="comment"># default is to read from stdin</span></span><br><span class="line">fin = sys.stdin</span><br><span class="line"><span class="keyword">if</span> args.infile:</span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">fin = open(args.infile, <span class="string">'rt'</span>)</span><br><span class="line"><span class="keyword">except</span> IOError <span class="keyword">as</span> e:</span><br><span class="line">sys.stderr.write(<span class="string">'Error: %s: %s\n'</span>%(e.strerror, args.infile))</span><br><span class="line">sys.exit(e.errno)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> fin:</span><br><span class="line">fields = <span class="keyword">None</span></span><br><span class="line"><span class="comment"># split line by delimiter</span></span><br><span class="line"><span class="keyword">if</span> args.delimiter:</span><br><span class="line">fields = line.strip().split(args.delimiter)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">fields = line.strip().split()</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> xrange(len(fields)):</span><br><span class="line">width = len(fields[i])</span><br><span class="line"><span class="keyword">if</span> (i+<span class="number">1</span>) &gt; len(maxwidth):</span><br><span class="line">maxwidth.append(width)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line"><span class="keyword">if</span> width &gt; maxwidth[i]:</span><br><span class="line">maxwidth[i] = width</span><br><span class="line">table.append(fields)</span><br><span class="line">fin.close()</span><br><span class="line"></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line"><span class="keyword">for</span> fields <span class="keyword">in</span> table:</span><br><span class="line">line = StringIO()</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> xrange(len(fields)):</span><br><span class="line"><span class="comment"># format field with different justification</span></span><br><span class="line">nSpace = maxwidth[i] - len(fields[i])</span><br><span class="line"><span class="keyword">if</span> args.justify == <span class="string">'left'</span>:</span><br><span class="line">line.write(fields[i])</span><br><span class="line"><span class="keyword">for</span> j <span class="keyword">in</span> xrange(nSpace):</span><br><span class="line">line.write(<span class="string">' '</span>)</span><br><span class="line"><span class="keyword">elif</span> args.justify == <span class="string">'right'</span>:</span><br><span class="line"><span class="keyword">for</span> j <span class="keyword">in</span> xrange(nSpace):</span><br><span class="line">line.write(<span class="string">' '</span>)</span><br><span class="line">line.write(fields[i])</span><br><span class="line"><span class="keyword">elif</span> args.justify == <span class="string">'center'</span>:</span><br><span class="line"><span class="keyword">for</span> j <span class="keyword">in</span> xrange(nSpace/<span class="number">2</span>):</span><br><span class="line">line.write(<span class="string">' '</span>)</span><br><span class="line">line.write(fields[i])</span><br><span class="line"><span class="keyword">for</span> j <span class="keyword">in</span> xrange(nSpace - nSpace/<span class="number">2</span>):</span><br><span class="line">line.write(<span class="string">' '</span>)</span><br><span class="line"></span><br><span class="line">line.write(args.separator)</span><br><span class="line"><span class="keyword">print</span> line.getvalue()</span><br><span class="line">line.close()</span><br><span class="line"><span class="keyword">except</span> IOError:</span><br><span class="line">sys.exit(<span class="number">-1</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">main()</span><br></pre></td></tr></table></figure><h3 id="Generate-a-random-FASTA-file"><a href="#Generate-a-random-FASTA-file" class="headerlink" title="Generate a random FASTA file"></a>Generate a random FASTA file</h3><p><code>seqgen.py</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#! /usr/bin/env python</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"><span class="keyword">import</span> textwrap</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">write_fasta</span><span class="params">(fout, seq, name=<span class="string">'seq'</span>, description=None)</span>:</span></span><br><span class="line"><span class="keyword">if</span> description:</span><br><span class="line">fout.write(<span class="string">'&gt;'</span> + name + <span class="string">' '</span> + description + <span class="string">'\n'</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">fout.write(<span class="string">'&gt;'</span> + name + <span class="string">'\n'</span>)</span><br><span class="line">fout.write(textwrap.fill(seq) + <span class="string">'\n'</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></span><br><span class="line">parser = argparse.ArgumentParser(description=<span class="string">'Generate sequences and output in various formats'</span>)</span><br><span class="line">parser.add_argument(<span class="string">'-n'</span>, <span class="string">'--number'</span>, dest=<span class="string">'number'</span>, type=int, required=<span class="keyword">False</span>,</span><br><span class="line"> default=<span class="number">10</span>, help=<span class="string">'Number of sequences to generate'</span>)</span><br><span class="line">parser.add_argument(<span class="string">'--min-length'</span>, dest=<span class="string">'min_length'</span>, type=int, required=<span class="keyword">False</span>,</span><br><span class="line"> default=<span class="number">30</span>, help=<span class="string">'Minimal length'</span>)</span><br><span class="line">parser.add_argument(<span class="string">'--max-length'</span>, dest=<span class="string">'max_length'</span>, type=int, required=<span class="keyword">False</span>,</span><br><span class="line"> default=<span class="number">50</span>, help=<span class="string">'Maximal length'</span>)</span><br><span class="line">parser.add_argument(<span class="string">'-l'</span>, <span class="string">'--length'</span>, type=int, required=<span class="keyword">False</span>,</span><br><span class="line"> help=<span class="string">'Fixed length. If specified, --min-length and --max-length will be ignored.'</span>)</span><br><span class="line">parser.add_argument(<span class="string">'-a'</span>, <span class="string">'--alphabet'</span>, type=str, required=<span class="keyword">False</span>,</span><br><span class="line"> default=<span class="string">'ATGC'</span>, help=<span class="string">'Letters to used in the sequences'</span>)</span><br><span class="line">parser.add_argument(<span class="string">'-f'</span>, <span class="string">'--format'</span>, type=str, required=<span class="keyword">False</span>,</span><br><span class="line"> choices=[<span class="string">'fasta'</span>, <span class="string">'text'</span>], default=<span class="string">'fasta'</span>, help=<span class="string">'Output formats'</span>)</span><br><span class="line">parser.add_argument(<span class="string">'-o'</span>, <span class="string">'--outfile'</span>, type=argparse.FileType(<span class="string">'w'</span>), required=<span class="keyword">False</span>,</span><br><span class="line"> default=sys.stdout, help=<span class="string">'Output file name'</span>)</span><br><span class="line">parser.add_argument(<span class="string">'-p'</span>, <span class="string">'--prefix'</span>, type=str, required=<span class="keyword">False</span>,</span><br><span class="line"> default=<span class="string">'RN_'</span>, help=<span class="string">'Prefix of sequence names for fasta format'</span>)</span><br><span class="line">args = parser.parse_args()</span><br><span class="line"></span><br><span class="line">rand = random.Random()</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> xrange(args.number):</span><br><span class="line"><span class="keyword">if</span> args.length:</span><br><span class="line">length = args.length</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">length = rand.randint(args.min_length, args.max_length)</span><br><span class="line">seq = bytearray(length)</span><br><span class="line"><span class="keyword">for</span> j <span class="keyword">in</span> xrange(length):</span><br><span class="line">seq[j] = rand.choice(args.alphabet)</span><br><span class="line"><span class="keyword">if</span> args.format == <span class="string">'fasta'</span>:</span><br><span class="line">write_fasta(args.outfile, str(seq), args.prefix + <span class="string">'%08d'</span>%i)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">args.outfile.write(seq + <span class="string">'\n'</span>)</span><br><span class="line">args.outfile.close()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">main()</span><br></pre></td></tr></table></figure><h2 id="Weekly-tasks"><a href="#Weekly-tasks" class="headerlink" title="Weekly tasks"></a>Weekly tasks</h2><p>All files you need for completing the tasks can be found at: <a href="assets/weekly_tasks.zip">weekly_tasks.zip</a></p><p><strong>Task 1: run examples (Python tips, numpy, pandas) in this tutorial</strong></p><p>Install Anaconda on your PC. Try to understand example code and run in Jupyter or IPython.</p><p><strong>Task 2: write a Python program to convert a GTF file to BED12 format</strong> </p><ul><li>Please refer to (<a href="https://genome.ucsc.edu/FAQ/FAQformat.html#format1" target="_blank" rel="noopener">https://genome.ucsc.edu/FAQ/FAQformat.html#format1</a>) for BED12 format and refer to (<a href="https://www.ensembl.org/info/website/upload/gff.html" target="_blank" rel="noopener">https://www.ensembl.org/info/website/upload/gff.html</a>) for GTF format.<br>GTF example:</li></ul><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">chr1</span>HAVANAgene<span class="number">29554</span><span class="number">31109</span>.+.gene_id <span class="string">"ENSG00000243485.5"</span>; <span class="attribute">gene_type</span> <span class="string">"lincRNA"</span>; <span class="attribute">gene_name</span> <span class="string">"MIR1302-2HG"</span>; <span class="attribute">level</span> <span class="number">2</span>; <span class="attribute">tag</span> <span class="string">"ncRNA_host"</span>; <span class="attribute">havana_gene</span> <span class="string">"OTTHUMG00000000959.2"</span>;</span><br><span class="line"><span class="attribute">chr1</span>HAVANAtranscript<span class="number">29554</span><span class="number">31097</span>.+.gene_id <span class="string">"ENSG00000243485.5"</span>; <span class="attribute">transcript_id</span> <span class="string">"ENST00000473358.1"</span>; <span class="attribute">gene_type</span> <span class="string">"lincRNA"</span>; <span class="attribute">gene_name</span> <span class="string">"MIR1302-2HG"</span>; <span class="attribute">transcript_type</span> <span class="string">"lincRNA"</span>; <span class="attribute">transcript_name</span> <span class="string">"MIR1302-2HG-202"</span>; <span class="attribute">level</span> <span class="number">2</span>; <span class="attribute">transcript_support_level</span> <span class="string">"5"</span>; <span class="attribute">tag</span> <span class="string">"not_best_in_genome_evidence"</span>; <span class="attribute">tag</span> <span class="string">"dotter_confirmed"</span>; <span class="attribute">tag</span> <span class="string">"basic"</span>; <span class="attribute">havana_gene</span> <span class="string">"OTTHUMG00000000959.2"</span>; <span class="attribute">havana_transcript</span> <span class="string">"OTTHUMT00000002840.1"</span>;</span><br><span class="line"><span class="attribute">chr1</span>HAVANAexon<span class="number">29554</span><span class="number">30039</span>.+.gene_id <span class="string">"ENSG00000243485.5"</span>; <span class="attribute">transcript_id</span> <span class="string">"ENST00000473358.1"</span>; <span class="attribute">gene_type</span> <span class="string">"lincRNA"</span>; <span class="attribute">gene_name</span> <span class="string">"MIR1302-2HG"</span>; <span class="attribute">transcript_type</span> <span class="string">"lincRNA"</span>; <span class="attribute">transcript_name</span> <span class="string">"MIR1302-2HG-202"</span>; <span class="attribute">exon_number</span> <span class="number">1</span>; <span class="attribute">exon_id</span> <span class="string">"ENSE00001947070.1"</span>; <span class="attribute">level</span> <span class="number">2</span>; <span class="attribute">transcript_support_level</span> <span class="string">"5"</span>; <span class="attribute">tag</span> <span class="string">"not_best_in_genome_evidence"</span>; <span class="attribute">tag</span> <span class="string">"dotter_confirmed"</span>; <span class="attribute">tag</span> <span class="string">"basic"</span>; <span class="attribute">havana_gene</span> <span class="string">"OTTHUMG00000000959.2"</span>; <span class="attribute">havana_transcript</span> <span class="string">"OTTHUMT00000002840.1"</span>;</span><br></pre></td></tr></table></figure><p>BED12 example:</p><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">chr1<span class="number">67522353</span><span class="number">67532326</span>ENST00000230113<span class="number">0</span>+<span class="number">0</span><span class="number">0</span><span class="number">0</span><span class="number">5</span><span class="number">45</span>,<span class="number">60</span>,<span class="number">97</span>,<span class="number">64</span>,<span class="number">221</span>,<span class="number">0</span>,<span class="number">5024</span>,<span class="number">7299</span>,<span class="number">7961</span>,<span class="number">9752</span>,</span><br><span class="line">chr1<span class="number">39249837</span><span class="number">39257649</span>ENST00000289890<span class="number">0</span>-<span class="number">0</span><span class="number">0</span><span class="number">0</span><span class="number">3</span><span class="number">365</span>,<span class="number">78</span>,<span class="number">115</span>,<span class="number">0</span>,<span class="number">4304</span>,<span class="number">7697</span>,</span><br><span class="line">chr1<span class="number">144245237</span><span class="number">144250279</span>ENST00000294715<span class="number">0</span>-<span class="number">0</span><span class="number">0</span><span class="number">0</span><span class="number">3</span><span class="number">78</span>,<span class="number">135</span>,<span class="number">55</span>,<span class="number">0</span>,<span class="number">448</span>,<span class="number">4987</span>,</span><br><span class="line">chr1<span class="number">15111814</span><span class="number">15152464</span>ENST00000310916<span class="number">0</span>-<span class="number">0</span><span class="number">0</span><span class="number">0</span><span class="number">6</span><span class="number">5993</span>,<span class="number">578</span>,<span class="number">121</span>,<span class="number">88</span>,<span class="number">146</span>,<span class="number">174</span>,<span class="number">0</span>,<span class="number">6512</span>,<span class="number">8762</span>,<span class="number">9157</span>,<span class="number">12413</span>,<span class="number">40476</span>,</span><br><span class="line">chr1<span class="number">34975698</span><span class="number">34978706</span>ENST00000311990<span class="number">0</span>-<span class="number">0</span><span class="number">0</span><span class="number">0</span><span class="number">3</span><span class="number">1704</span>,<span class="number">154</span>,<span class="number">29</span>,<span class="number">0</span>,<span class="number">2232</span>,<span class="number">2979</span>,</span><br></pre></td></tr></table></figure><ul><li>The GTF file is <code>weekly_tasks/gencode.v27.long_noncoding_RNAs.gtf</code>.</li><li>Each line in the output file is a transcript with the 4th columns as transcript ID</li><li>The version number of the transcript ID should be stripped (e.g. ENST00000473358.1 =&gt; ENST00000473358). </li><li>The output file is sorted <strong>first by transcript IDs</strong> and <strong>then by chromosome</strong> in lexicographical order. </li><li>Column 5, 7, 8, 9 in the BED12 file should be set to 0.</li><li>Please do NOT use any external tools (e.g. <code>sort</code>, <code>awk</code>, etc.) in your program other than Python.</li><li>An example output can be found in <code>weekly_tasks/transcripts.bed</code>.</li></ul><p><strong>Hint:</strong> use <code>dict</code>, <code>list</code>, <code>tuple</code>, <code>str.split</code>, <code>re.match</code>, <code>sorted</code>.</p><p><strong>Task 3: write a Python program to add a prefix to all directories</strong></p><ul><li>Each prefix is a two-digit number starting from 00 and ‘-‘. If the number is less than 10, a single ‘0’ letter should be filled.</li><li>The files/directories should be numbered according to the <strong>lexicographical</strong> order.<br>For example, if the original directory structure is:</li></ul><figure class="highlight dns"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">.</span><br><span class="line">├── <span class="keyword">A</span></span><br><span class="line">│   ├── <span class="keyword">A</span></span><br><span class="line">│   │   ├── <span class="keyword">A</span></span><br><span class="line">│   │   ├── B</span><br><span class="line">│   │   └── C</span><br><span class="line">│   ├── B</span><br><span class="line">│   │   └── <span class="keyword">A</span></span><br><span class="line">│   └── C</span><br><span class="line">│       └── <span class="keyword">A</span></span><br><span class="line">├── B</span><br><span class="line">│   ├── <span class="keyword">A</span></span><br><span class="line">│   └── B</span><br><span class="line">└── C</span><br><span class="line">    ├── <span class="keyword">A</span></span><br><span class="line">    └── B</span><br><span class="line">        └── <span class="keyword">A</span></span><br></pre></td></tr></table></figure><p>then you should get the following directory structure after renaming:</p><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">.</span><br><span class="line">├── <span class="number">00</span>-A</span><br><span class="line">│   ├── <span class="number">00</span>-A</span><br><span class="line">│   │   ├── <span class="number">00</span>-A</span><br><span class="line">│   │   ├── <span class="number">01</span>-B</span><br><span class="line">│   │   └── <span class="number">02</span>-C</span><br><span class="line">│   ├── <span class="number">01</span>-B</span><br><span class="line">│   │   └── <span class="number">00</span>-A</span><br><span class="line">│   └── <span class="number">02</span>-C</span><br><span class="line">│       └── <span class="number">00</span>-A</span><br><span class="line">├── <span class="number">01</span>-B</span><br><span class="line">│   ├── <span class="number">00</span>-A</span><br><span class="line">│   └── <span class="number">01</span>-B</span><br><span class="line">└── <span class="number">02</span>-C</span><br><span class="line">    ├── <span class="number">00</span>-A</span><br><span class="line">    └── <span class="number">01</span>-B</span><br><span class="line">        └── <span class="number">00</span>-A</span><br></pre></td></tr></table></figure><ul><li>The original directories can be found in <code>weekly_tasks/original_dirs</code>.</li><li>The root directory (i.e. <code>original_dirs</code>) should not be renamed.</li><li>You can use <code>tree</code> command to display the directory structure as shown above.</li><li>An example result can be found in <code>weekly_tasks/renamed_dirs</code>.<br><strong>Hint:</strong> use <code>os.listdir</code>, <code>os.rename</code>, <code>str.format</code>, <code>sorted</code>, <code>yield</code>.</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;This is one of the chapter in &lt;a href=&quot;https://lulab.gitbooks.io/teaching/content/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Bioinformatics basic course in Tsinghua University&lt;/a&gt;. You may also find it &lt;a href=&quot;https://lulab.gitbooks.io/teaching/content/appendix/python_tutorial.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The related &lt;a href=&quot;https://github.com/lulab/teaching_book/blob/master/appendix/python_tutorial.ipynb&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;jupyter file&lt;/a&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="teaching" scheme="https://www.cmwonderland.com/blog/categories/teaching/"/>
    
    
      <category term="machine learning" scheme="https://www.cmwonderland.com/blog/tags/machine-learning/"/>
    
      <category term="python" scheme="https://www.cmwonderland.com/blog/tags/python/"/>
    
      <category term="bioinformatics" scheme="https://www.cmwonderland.com/blog/tags/bioinformatics/"/>
    
      <category term="teaching" scheme="https://www.cmwonderland.com/blog/tags/teaching/"/>
    
      <category term="TA" scheme="https://www.cmwonderland.com/blog/tags/TA/"/>
    
  </entry>
  
  <entry>
    <title>QUIZ identification of cancer biomarker from exRNA-seq data</title>
    <link href="https://www.cmwonderland.com/blog/2018/10/06/32_quiz_exrna_tutorial/"/>
    <id>https://www.cmwonderland.com/blog/2018/10/06/32_quiz_exrna_tutorial/</id>
    <published>2018-10-06T11:01:19.000Z</published>
    <updated>2018-10-10T05:01:23.264Z</updated>
    
    <content type="html"><![CDATA[<p>This is one of the two course quizzes instruction of <a href="https://lulab.gitbooks.io/teaching/content/" target="_blank" rel="noopener">Bioinformatics basic course in Tsinghua University</a>. You may also find it <a href="https://lulab.gitbooks.io/teaching/content/quiz/quiz_exrna/quiz_exrna_tutorial.html" target="_blank" rel="noopener">here</a></p><p>The related <a href="https://github.com/lulab/teaching_book/blob/master/quiz/quiz_exrna/quiz_exrna_tutorial.ipynb" target="_blank" rel="noopener">jupyter file</a></p><a id="more"></a><p>请在<a href="https://cloud.tsinghua.edu.cn/f/3f4fc999720d45f198ca/" target="_blank" rel="noopener">quiz_exrna_tutorial_shared</a>下载相关文件，并下载该<a href="https://cloud.tsinghua.edu.cn/f/ae9a9d63d1db435ab6e2/" target="_blank" rel="noopener">文件夹</a>下的内容，打开<code>quiz_exrna_tutorial.ipynb</code>文件阅读详细的<strong>Quiz指南</strong>。</p><h2 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a>背景介绍</h2><p>（adapt from Young Lee）</p><p>在多种体液中，如血清、唾液以及尿液等，可以检测到一类非侵入性细胞外 RNA (extracellular RNA, exRNA)。诸如环状RNA (circular RNA)等这类具有空间结构的 RNA 分子，能够在血浆中稳定存在。这些从细胞分泌出的 exRNA 通常由微囊泡 (microvesicles)、外泌体(exosome) 包裹，或者与 RBP 密切结合形成 RNP 复合体。因为这些分子由于具备类细胞膜结构和蛋白质的保护，加上某些 RNA 具有特定的结构，exRNA 在多种体液 (血清、唾液、尿液等) 中可以抵抗体液中 RNase 的降解，从而稳定存在。exRNA 包括的类型很多，例如 miRNA，Y RNA, circRNA，lncRNA 等，每种又有不同的加工、剪切和修饰产物，这种多样性为更 好的临床检验带来了新的期望。这些 exRNA 可以成为一类有效的生物标志物，服务于人体健康状况检测和疾病的诊断，如癌症的早期诊断、肿瘤生长状况监测、以及预后辅助诊断。</p><p>本Quiz依托于Lulab现有的一些研究结果，希望读者通过生物信息学方法，尝试使用一些机器学习方法，发现和研究与癌症发生发展相关的新型体液胞外RNA (extracellular RNA，exRNA)生物标志物，并应用于几种国内高致死癌症的早期诊断和预后辅助治疗。我们将在癌症病人体液 (如血液)中的游离、微囊泡、外泌体、RNP 等不同组分中发现和鉴定标志癌症发生发展的新型 exRNA，构建模型，最终建立一个具有更高精准度和重复性的无创检验癌症（尤其是早期癌症）的方法。</p><h2 id="编程工具介绍"><a href="#编程工具介绍" class="headerlink" title="编程工具介绍"></a>编程工具介绍</h2><p>大作业需要使用python完成，推荐读者使用python3。我们需要一些python的工具包来实现部分功能。推荐使用包管理软件Anaconda来预装一些必需的包以及安装其他需要的包。另外强烈建议使用jupyter notebook进行代码编辑、运行和调试。具体使用方法请参考教程<a href="https://lulab.gitbooks.io/teaching/content/part-iii.-machine-learning-basics/python_tutorial.html" target="_blank" rel="noopener">Anaconda 和 jupyter</a>相关指南。<br>如果本地缺少下列可能需要的包，请使用<code>pip</code>或者<code>conda</code>进行安装。如:</p><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pip <span class="keyword">install</span> tqdm</span><br><span class="line">conda <span class="keyword">install</span> sklearn</span><br></pre></td></tr></table></figure><p>本作业的部分内容可能会涉及到R，推荐读者使用<a href="https://www.rstudio.com/" target="_blank" rel="noopener">Rstudio</a>，也可以在jupyter notebook中安装R kernel</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#导入必需的库</span></span><br><span class="line"><span class="keyword">import</span> gc, argparse, sys, os, errno</span><br><span class="line">%pylab inline</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> PCA</span><br><span class="line"><span class="keyword">from</span> sklearn.manifold <span class="keyword">import</span> TSNE</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> NearestNeighbors</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> LinearSVC</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> roc_auc_score, accuracy_score, get_scorer</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler, RobustScaler, MinMaxScaler, MaxAbsScaler</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> GridSearchCV</span><br><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> RFE, RFECV</span><br><span class="line"><span class="keyword">from</span> sklearn.utils.class_weight <span class="keyword">import</span> compute_sample_weight</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> KFold, StratifiedKFold, ShuffleSplit, LeaveOneOut, \</span><br><span class="line">    RepeatedKFold, RepeatedStratifiedKFold, LeaveOneOut, StratifiedShuffleSplit</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> roc_curve, auc</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm_notebook <span class="keyword">as</span> tqdm</span><br><span class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> pearsonr</span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line">warnings.filterwarnings(<span class="string">'ignore'</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#绘图设置</span></span><br><span class="line">styles = [<span class="string">"white"</span>,<span class="string">"dark"</span>,<span class="string">'whitegrid'</span>,<span class="string">"darkgrid"</span>]</span><br><span class="line">contexts = [<span class="string">'paper'</span>,<span class="string">'talk'</span>,<span class="string">'poster'</span>,<span class="string">'notebook'</span>]</span><br><span class="line">sns.set_context(contexts[<span class="number">1</span>])</span><br><span class="line">sns.set_style(styles[<span class="number">2</span>])</span><br><span class="line">tableau20 = np.array([(<span class="number">31</span>, <span class="number">119</span>, <span class="number">180</span>), (<span class="number">174</span>, <span class="number">199</span>, <span class="number">232</span>), (<span class="number">255</span>, <span class="number">127</span>, <span class="number">14</span>), (<span class="number">255</span>, <span class="number">187</span>, <span class="number">120</span>),  </span><br><span class="line">             (<span class="number">44</span>, <span class="number">160</span>, <span class="number">44</span>), (<span class="number">152</span>, <span class="number">223</span>, <span class="number">138</span>), (<span class="number">214</span>, <span class="number">39</span>, <span class="number">40</span>), (<span class="number">255</span>, <span class="number">152</span>, <span class="number">150</span>),  </span><br><span class="line">             (<span class="number">148</span>, <span class="number">103</span>, <span class="number">189</span>), (<span class="number">197</span>, <span class="number">176</span>, <span class="number">213</span>), (<span class="number">140</span>, <span class="number">86</span>, <span class="number">75</span>), (<span class="number">196</span>, <span class="number">156</span>, <span class="number">148</span>),  </span><br><span class="line">             (<span class="number">227</span>, <span class="number">119</span>, <span class="number">194</span>), (<span class="number">247</span>, <span class="number">182</span>, <span class="number">210</span>), (<span class="number">127</span>, <span class="number">127</span>, <span class="number">127</span>), (<span class="number">199</span>, <span class="number">199</span>, <span class="number">199</span>),  </span><br><span class="line">             (<span class="number">188</span>, <span class="number">189</span>, <span class="number">34</span>), (<span class="number">219</span>, <span class="number">219</span>, <span class="number">141</span>), (<span class="number">23</span>, <span class="number">190</span>, <span class="number">207</span>), (<span class="number">158</span>, <span class="number">218</span>, <span class="number">229</span>)])/<span class="number">255.</span></span><br></pre></td></tr></table></figure><h2 id="数据介绍"><a href="#数据介绍" class="headerlink" title="数据介绍"></a>数据介绍</h2><p>为了减轻工作负担，读者不需要从mapping开始工作，我们为读者准备好了五套处理好的expression matrix，读者在此基础上完成后续的工作。</p><h3 id="expression-matrix"><a href="#expression-matrix" class="headerlink" title="expression matrix"></a>expression matrix</h3><p>expression matrix共有五套，来自每一行为一个feature，每一列为一个样本。其中<em>hcc</em>的expression matrix的feature分别为full length，peak以及两轮peak calling选出的peak数据。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">scirepount = pd.read_table(<span class="string">'data/expression_matrix/GSE71008.txt'</span>)</span><br><span class="line">hcc_full_count = pd.read_table(<span class="string">'data/expression_matrix/transcripts_exrna.txt'</span>)</span><br><span class="line">hcc_peak_count = pd.read_table(<span class="string">'data/expression_matrix/piranha_peaks.txt'</span>)</span><br><span class="line">hcc_peak_iter_count = pd.read_table(<span class="string">'data/expression_matrix/piranha_peaks_iterative.txt'</span>)</span><br><span class="line">exorbase = pd.read_table(<span class="string">'data/expression_matrix/exoRBase.txt'</span>)</span><br><span class="line">scirepount.head()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scirepount.shape, hcc_full_count.shape, hcc_peak_count.shape, hcc_peak_iter_count.shape, exorbase.shape</span><br></pre></td></tr></table></figure><pre><code>((3460, 193), (143666, 62), (1727, 64), (3061, 82), (111131, 86))</code></pre><h3 id="sample-labels"><a href="#sample-labels" class="headerlink" title="sample labels"></a>sample labels</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">exo_samplenames = pd.read_table(<span class="string">'data/labels/exoRBase.txt'</span>,header=<span class="keyword">None</span>)</span><br><span class="line">scirep_samplenames = pd.read_table(<span class="string">'data/labels/GSE71008.txt'</span>,delimiter=<span class="string">','</span> , header=<span class="keyword">None</span>)</span><br><span class="line">hcc_samplenamess = pd.read_table(<span class="string">'data/labels/hccfull.txt'</span>, header=<span class="keyword">None</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hcc_samplenamess.head()</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>0</th>      <th>1</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>17402567-B</td>      <td>stage_A</td>    </tr>    <tr>      <th>1</th>      <td>249136-B</td>      <td>stage_A</td>    </tr>    <tr>      <th>2</th>      <td>385247-B</td>      <td>stage_A</td>    </tr>    <tr>      <th>3</th>      <td>497411-B</td>      <td>stage_A</td>    </tr>    <tr>      <th>4</th>      <td>498221-B</td>      <td>stage_A</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">np.unique(scirep_samplenames[<span class="number">1</span>],return_counts=<span class="keyword">True</span>)</span><br><span class="line">np.unique(exo_samplenames[<span class="number">1</span>],return_counts=<span class="keyword">True</span>)</span><br></pre></td></tr></table></figure><h3 id="other-annotations"><a href="#other-annotations" class="headerlink" title="other annotations"></a>other annotations</h3><h4 id="gene-annotation"><a href="#gene-annotation" class="headerlink" title="gene annotation"></a>gene annotation</h4><p>可以通过feature的transcript id找到feature的transcript_nama, gene_type等信息</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">geneannotation = pd.read_table(<span class="string">'data/transcript_anno.txt'</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">geneannotation.head()</span><br></pre></td></tr></table></figure><h4 id="batch信息"><a href="#batch信息" class="headerlink" title="batch信息"></a>batch信息</h4><p>batch信息记录了对不同样本采取的不同实验条件，包括处理时间，处理材料的规格差异等，可能会造成同类样本的较大差异，称为batch effect。</p><p>对于exoRBase数据，每一种癌症样本均来自不同的实验室，因此其batch与样本类别重合。对于scirep数据和hcc数据，batch信息如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scirepbatch = pd.read_excel(<span class="string">'data/other_annotations/scirep_batch.xlsx'</span>)</span><br><span class="line">hccbatch = pd.read_csv(<span class="string">'data/other_annotations/hcc_batch.csv'</span>,delimiter=<span class="string">'\t'</span>)</span><br></pre></td></tr></table></figure><h3 id="RNA-type-统计信息"><a href="#RNA-type-统计信息" class="headerlink" title="RNA type 统计信息"></a>RNA type 统计信息</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hccrnastats = pd.read_csv(<span class="string">'data/other_annotations/hcc_rna_stats.csv'</span>,index_col=<span class="number">0</span>)</span><br><span class="line">exornastats = pd.read_csv(<span class="string">'data/other_annotations/exorbase_rna_stats.csv'</span>,index_col=<span class="number">0</span>)</span><br><span class="line">scireprnastats = pd.read_csv(<span class="string">'data/other_annotations/scirep_rna_stats.csv'</span>,index_col=<span class="number">0</span>)</span><br></pre></td></tr></table></figure><h2 id="Quiz具体要求"><a href="#Quiz具体要求" class="headerlink" title="Quiz具体要求"></a>Quiz具体要求</h2><p>请读者使用我们提供的五套数据，以下工作：</p><ul><li>完成<strong>数据分析</strong>工作</li><li>完成<strong>特征选择和特征筛除工作</strong>并汇报挑选出的feature。</li><li>完成<strong>模型拟合</strong>并汇报效果。</li><li>提交一份<strong>工作报告</strong>，中英文不限，同时提交<strong>源代码</strong>。</li><li>选择性完成加分项内容。</li></ul><h3 id="基本统计分析"><a href="#基本统计分析" class="headerlink" title="基本统计分析"></a>基本统计分析</h3><ul><li>统计一套数据中不同RNA type在不同样本的counts分布，hcc和scirep测到的主要是小RNA，exoRBase测到的主要是长RNA，观察分布能否得到这样的结论。</li><li>统计某套数据中某种类型的RNA在不同样本中的counts数量，可以分析一些希望重点关注的RNA类型，如lncRNA等。</li><li>对exoRBase和scirep数据做基本的quality control，通过counts或者PCA中明显离群点去除部分样本。参考<a href="#sampleqc"><em>sample QC</em></a>部分</li><li>统计expression matrix中counts数量排在top 20的feature的占比，分析过高的占比可能对scaling造成的影响。参考<a href="#topk"><em>top k feature</em></a>部分</li></ul><h3 id="稳健的特征选择方法"><a href="#稳健的特征选择方法" class="headerlink" title="稳健的特征选择方法"></a>稳健的特征选择方法</h3><ul><li>我们希望读者设计一个稳健的特征选择方法，完成以下几种情况下的feature selection，给出针对每套数据，每种分类条件所挑选的feature。<ul><li>hcc(full length, peak, peak iterative)<ul><li>HCC vs Normal</li><li>Stage A vs Normal</li></ul></li><li>exoRBase<ul><li>HCC vs Normal</li><li>PAAD vs Normal</li></ul></li><li>Scirep<ul><li>CRC vs Normal</li></ul></li></ul></li></ul><p>为了帮助读者确立思路，我们给出一个如下的<strong>示例性流程</strong>，以HCC peak数据为例</p><ul><li>Normalize domain coverage by total coverage of all domains (CPM), Normalize Top20 and others separately. </li><li>Scale each feature (log CPM) independently (using z-scores, min-max, robust normalization)</li><li>Run a classifier (random forest, logistic regression, linear SVM) to select features based on feature importance. Optimize hyper-parameters by 3-fold cross-validation.</li><li><strong>Optionally</strong>, use a recursive feature elimination(RFE).</li><li>Do resampling runs to select robust features:<ul><li>shuffle and split dataset and repeat feature selection for 100 times(shuffle split)</li><li>Or randomly test 1 sample in each run (leave one out).</li></ul></li><li>Select features that are recurrently selected across resampling runs (&gt;50%)</li><li>Refit the classifier on selected features</li></ul><p>以上步骤会挑出在<strong>resampling runs</strong>中出现频数超过总轮数一半的特征。其中第一步分别对top20 feature和其他feature做normalization，可以避免top20 feature对整体分布的影响，第二步读者可以尝试不同的对<strong>feature</strong>进行normalization的策略。第三步读者可以尝试不同的机器学习模型，并且在第四步选择是否使用<strong>RFE</strong>来逐步筛除feature。第五步是挑选稳健feature的关键，可以采取random split和leave one out两种方法，选择重复出现的稳健的feature。</p><p>读者可以设计自己的稳健的特征选择方法，请注意必须要体现出自己的方法的稳健性。</p><h3 id="模型效果分析"><a href="#模型效果分析" class="headerlink" title="模型效果分析"></a>模型效果分析</h3><ul><li>绘制挑选出的feature counts（经过适当的scale）的clustermap，用颜色块表示class。请参考<a href="#visfeature"><em>特征选择结果可视化</em></a>。</li><li>绘制二分类模型的ROC曲线，请注意本问题ROC曲线的特殊之处，具体细节请参考<a href="#roc"><em>用选出的feature进行分类并绘制ROC曲线</em></a>。</li><li>对比hcc数据的full length与peak在挑选出的feature以及分类的结果（ROC曲线）的差异，思考为什么会使用peak数据。</li></ul><h3 id="加分内容"><a href="#加分内容" class="headerlink" title="加分内容"></a>加分内容</h3><p>我们为有余力的读者设置了更多的挑战，完成相应的工作会有一定的加分</p><h4 id="更多模型效果分析-20’"><a href="#更多模型效果分析-20’" class="headerlink" title="更多模型效果分析 (20’)"></a>更多模型效果分析 (20’)</h4><ul><li>尝试减少feature数量（如1-10个feature），分析模型AUROC和ROC曲线。(5’)</li><li>针对不同数据中的同一种疾病，如exoRBase和HCC数据中的同一种疾病HCC，比较挑出的feature的异同。(5’)</li><li>比较挑出的feature，参考<a href="#comparefeature"><em>比较挑出的feature</em></a>部分。(10’)<ul><li>不同模型、不同数据挑出的feature的异同，可以使用Venn图、heatmap图等表示。</li><li>分析feature的鲁棒性，分析不同的条件设置（如模型超参数，scale方案，交叉验证方法）下被挑出的feature。</li></ul></li></ul><h4 id="预处理（30’）"><a href="#预处理（30’）" class="headerlink" title="预处理（30’）"></a>预处理（30’）</h4><p>此部分预处理数据不要求读者将处理后的数据再做整个的feature selection流程，只需要使用PCA/t-SNE可视化效果，并且使用我们提供的alignment score量化不同的scale方法的效果。以下问题只要求在<strong>hcc_peak数据和scirep数据</strong>上尝试即可。参考<a href="#preprocessing"><em>预处理部分教程</em></a></p><ul><li>尝试不同的scale方法（对样本），请参考<a href="#scalemethod"><em>不同的scale策略</em></a>部分<ul><li>使用内参基因对样本做normalization。(5’)</li><li>去掉piRNA，miRNA后再做normalization。(5’)</li><li>SCnorm, TMM等方法做normalization（需使用R）(10’)</li></ul></li><li>去除batch effect（需使用R） (10’)<br>尝试使用RUVs, combat等R package去除batch effect，并分析去除效果。</li></ul><h4 id="解释选出的feature（5’）"><a href="#解释选出的feature（5’）" class="headerlink" title="解释选出的feature（5’）"></a>解释选出的feature（5’）</h4><p>通过查阅文献，阐释挑选出的feature的生物学意义，尤其是研究所挑选出的feature是否被其他文献报道在相关癌症检测中起到作用。</p><h2 id="补充知识（选读）"><a href="#补充知识（选读）" class="headerlink" title="补充知识（选读）"></a>补充知识（选读）</h2><h3 id="通过alignment-score量化PCA和t-SNE可视化结果"><a href="#通过alignment-score量化PCA和t-SNE可视化结果" class="headerlink" title="通过alignment score量化PCA和t-SNE可视化结果"></a>通过alignment score量化PCA和t-SNE可视化结果</h3><p>PCA和t-SNE可以直观的看到样本目前的聚集程度，但是无法量化，尤其是不容易做比较，我们提供以下的两个函数<em>alignment_socre</em> &amp; <em>knn_score</em>分别量化二分类和多分类样本的聚集程度。数值越接近1说明同类样本越聚集。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">alignment_score</span><span class="params">(X, y, K=<span class="number">10</span>)</span>:</span></span><br><span class="line">    N = X.shape[<span class="number">0</span>]</span><br><span class="line">    nn = NearestNeighbors(K)</span><br><span class="line">    nn.fit(X)</span><br><span class="line">    distances, indices = nn.kneighbors(X, K + <span class="number">1</span>)</span><br><span class="line">    neighbor_classes = np.take(y, indices[:, <span class="number">1</span>:])</span><br><span class="line">    same_class_fractions = np.sum(neighbor_classes == y[:, np.newaxis], axis=<span class="number">1</span>)</span><br><span class="line">    score = <span class="number">1.0</span> - (np.mean(same_class_fractions) - K/N)/(K - K/N)</span><br><span class="line">    <span class="keyword">print</span> (same_class_fractions.shape,np.mean(same_class_fractions),K/N,neighbor_classes)</span><br><span class="line">    <span class="keyword">return</span> score</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">knn_score</span><span class="params">(X, y, K=<span class="number">10</span>)</span>:</span></span><br><span class="line">    N = X.shape[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">assert</span> K &lt; N</span><br><span class="line">    nn = NearestNeighbors(K)</span><br><span class="line">    nn.fit(X)</span><br><span class="line">    </span><br><span class="line">    distances, indices = nn.kneighbors(X, K + <span class="number">1</span>)</span><br><span class="line">    neighbor_classes = np.take(y, indices[:, <span class="number">1</span>:])</span><br><span class="line">    same_class_fractions = np.sum(neighbor_classes == y[:, np.newaxis], axis=<span class="number">1</span>)</span><br><span class="line">    </span><br><span class="line">    classes, counts = np.unique(y, return_counts=<span class="keyword">True</span>)</span><br><span class="line">    classes = np.argmax(y.reshape((<span class="number">-1</span>, <span class="number">1</span>)) == classes.reshape((<span class="number">1</span>, <span class="number">-1</span>)), axis=<span class="number">1</span>)</span><br><span class="line">    counts = np.take(counts, classes)</span><br><span class="line">    mean_r = K/(N - <span class="number">1</span>)*counts</span><br><span class="line">    max_r = np.minimum(K, counts)</span><br><span class="line">    <span class="comment">#print (same_class_fractions.shape,mean_r.shape,max_r.shape)</span></span><br><span class="line">    <span class="comment">#scores = (np.mean(same_class_fractions) - mean_r)/(max_r - mean_r)</span></span><br><span class="line">    scores = (same_class_fractions - mean_r)/(max_r - mean_r)</span><br><span class="line">    <span class="comment">#print(scores)</span></span><br><span class="line">    <span class="keyword">return</span> scores.mean()</span><br></pre></td></tr></table></figure><p>如下图所示，可以通过<em>knn_score</em>计算出以batch信息所谓label时scirep数据的alignment score。0.27996表示不同batch的分离程度比较差，基本混合在一起</p><p><img src="http://i1.fuimg.com/640680/ba37a834da15e1ee.png" alt="Markdown"></p><h3 id="基本统计"><a href="#基本统计" class="headerlink" title="基本统计"></a>基本统计</h3><h4 id="统计一套数据中不同RNA-type在不同样本的counts"><a href="#统计一套数据中不同RNA-type在不同样本的counts" class="headerlink" title="统计一套数据中不同RNA type在不同样本的counts"></a>统计一套数据中不同RNA type在不同样本的counts</h4><p><img src="http://i1.fuimg.com/640680/4eb6fea01e086051.png" alt="Markdown"></p><h4 id="统计某套数据中某种类型的RNA在不同样本中的counts数量。"><a href="#统计某套数据中某种类型的RNA在不同样本中的counts数量。" class="headerlink" title="统计某套数据中某种类型的RNA在不同样本中的counts数量。"></a>统计某套数据中某种类型的RNA在不同样本中的counts数量。</h4><p><img src="http://i1.fuimg.com/640680/1878901d4f1fc902.png" alt="Markdown"></p><h4 id="分析每个样本不同RNA所占的比例"><a href="#分析每个样本不同RNA所占的比例" class="headerlink" title="分析每个样本不同RNA所占的比例"></a>分析每个样本不同RNA所占的比例</h4><p><img src="http://i1.fuimg.com/640680/e8766d1d4eee4269.png" alt="Markdown"></p><p><img src="http://i1.fuimg.com/640680/fb6337ad852d4cd9.png" alt="Markdown"></p><h4 id="sample-QC"><a href="#sample-QC" class="headerlink" title="sample QC"></a>sample QC</h4><h5 id="QC-by-counts"><a href="#QC-by-counts" class="headerlink" title="QC by counts"></a>QC by counts</h5><p><img src="http://i1.fuimg.com/640680/1ee5270502206085.png" alt="Markdown"></p><h5 id="QC-by-PCA"><a href="#QC-by-PCA" class="headerlink" title="QC by PCA"></a>QC by PCA</h5><p><img src="http://i1.fuimg.com/640680/d3a6bbc7066c9c9b.jpg" alt="Markdown"></p><h4 id="top-k-feature"><a href="#top-k-feature" class="headerlink" title="top k feature"></a>top k feature</h4><p><img src="http://i1.fuimg.com/640680/938a85448344eab0.png" alt="Markdown"></p><h3 id="可视化结果"><a href="#可视化结果" class="headerlink" title="可视化结果"></a>可视化结果</h3><h4 id="特征选择结果可视化"><a href="#特征选择结果可视化" class="headerlink" title="特征选择结果可视化"></a>特征选择结果可视化</h4><p>使用seaborn的clustermap功能，将挑选出的feature的counts（做过合适的scale）绘制heatmap图并聚类，上方的颜色表示类别，可见同一类被很好的聚在了一起。</p><p><img src="http://i1.fuimg.com/640680/7f79f56b8863e3b1.png" alt="Markdown"></p><h4 id="用选出的feature进行分类并绘制ROC曲线"><a href="#用选出的feature进行分类并绘制ROC曲线" class="headerlink" title="用选出的feature进行分类并绘制ROC曲线"></a>用选出的feature进行分类并绘制ROC曲线</h4><p>请特别注意，这里的ROC曲线有其特殊之处。针对我们样本很少的问题，我们不能专门划分出一部分测试集供测试和绘制曲线。我们使用两种方式划分数据集：</p><ul><li>leave one out, 即每轮随机选择一个样本作为validation set，其他样本作为训练集，对validation set进行预测，最终保证每个样本恰好作为validation set一次。</li><li><p>shuffle split, 即每轮随机选择一些样本作为validation set，其他样本作为训练集，对validation set进行预测，最终每个样本可能在不同轮中一共被预测数次。</p></li><li><p>这样，对于leave one out方法，我们恰好可以将所有样本预测一遍，并绘制出ROC曲线，如下图所示。</p></li><li><p>而对于shuffle split方法，每个样本被预测多次，没法放在一起绘制ROC曲线，但是其每轮都可以单独画一条ROC曲线，下面的图片展示的即为“将各条曲线综合起来”的情况，我们使用阴影区域表示每个点的均值的置信区间。</p></li></ul><p><img src="http://i1.fuimg.com/640680/ae9e7f15b21fd387.png" alt="Markdown"></p><p><img src="http://i1.fuimg.com/640680/6698e9b7c214e49e.png" alt="Markdown"></p><h3 id="比较挑出的feature"><a href="#比较挑出的feature" class="headerlink" title="比较挑出的feature"></a>比较挑出的feature</h3><h4 id="比较不同的模型和参数挑出的feature的差异"><a href="#比较不同的模型和参数挑出的feature的差异" class="headerlink" title="比较不同的模型和参数挑出的feature的差异"></a>比较不同的模型和参数挑出的feature的差异</h4><p>图中有颜色的色块儿表示在该参数条件下被选中的feature，可以发现线性模型挑出的feature更相似，而random forest在不同参数设置下挑出的feature比较稳定。</p><p><img src="http://i1.fuimg.com/640680/1bb2387bf3fa532b.png" alt="Markdown"></p><h4 id="查看feature的鲁棒性"><a href="#查看feature的鲁棒性" class="headerlink" title="查看feature的鲁棒性"></a>查看feature的鲁棒性</h4><p>每一列是一轮测试，可以发现大多数feature在每轮测试中都被挑中，证明这些feature具有很强的鲁棒性，我们可以设置一个阈值，选取在超过50%的轮数中都出现的feature作为最终选择的feature。</p><p><img src="http://i1.fuimg.com/640680/89a22dce74aa130a.png" alt="Markdown"></p><h4 id="利用Venn图分析feature的重合"><a href="#利用Venn图分析feature的重合" class="headerlink" title="利用Venn图分析feature的重合"></a>利用Venn图分析feature的重合</h4><p>这里利用Venn图分析了HCC三种类型的数据（full length, peak, peak_iterative）的重合情况，每一个子图是一个模型。</p><p><img src="http://i1.fuimg.com/640680/88788932223f6d72.png" alt="Markdown"></p><h3 id="预处理部分教程"><a href="#预处理部分教程" class="headerlink" title="预处理部分教程"></a>预处理部分教程</h3><ul><li><a href="https://youngleebbs.gitbook.io/bioinfo-training/part-ii/4.-qc-and-normalization" target="_blank" rel="noopener">normalization</a></li><li><a href="https://youngleebbs.gitbook.io/bioinfo-training/part-ii/5.-imputation-and-confounders" target="_blank" rel="noopener">deal with confounders</a></li></ul><h4 id="不同的scale策略"><a href="#不同的scale策略" class="headerlink" title="不同的scale策略"></a>不同的scale策略</h4><h5 id="不同scale策略比较"><a href="#不同scale策略比较" class="headerlink" title="不同scale策略比较"></a>不同scale策略比较</h5><ul><li>使用CPM(counts per million)</li><li>或者使用可能的内参基因：’MIR1228’, ‘MIR16-1’, ‘MIR16-2’, ‘MIR21’, ‘MIR23A’, ‘MIR23B’, ‘MIR23C’,<pre><code> &#39;MIR451A&#39;, &#39;MIR15A&#39;, &#39;MIR15B&#39;进行scale。</code></pre></li><li>去除piRNA和miRNA后使用CPM(counts per million)</li></ul><p><img src="http://i1.fuimg.com/640680/36fc02c704c83c0a.png" alt="Markdown"></p><h5 id="内参基因的选择"><a href="#内参基因的选择" class="headerlink" title="内参基因的选择"></a>内参基因的选择</h5><p>我们可以绘制density plot或者violin plot来分析不同内参基因的变异系数，选择变异系数小的，比较稳定的miRNA作为内参。可以看到MIR1228, MIR15B的变异系数较大，不够稳定，不应该作为内参</p><p><img src="http://i1.fuimg.com/640680/35fcf6c9629d5d12.png" alt="Markdown"></p><p><img src="http://i1.fuimg.com/640680/5cd256a6b7e8e922.png" alt="Markdown"></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;This is one of the two course quizzes instruction of &lt;a href=&quot;https://lulab.gitbooks.io/teaching/content/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Bioinformatics basic course in Tsinghua University&lt;/a&gt;. You may also find it &lt;a href=&quot;https://lulab.gitbooks.io/teaching/content/quiz/quiz_exrna/quiz_exrna_tutorial.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The related &lt;a href=&quot;https://github.com/lulab/teaching_book/blob/master/quiz/quiz_exrna/quiz_exrna_tutorial.ipynb&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;jupyter file&lt;/a&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="school work" scheme="https://www.cmwonderland.com/blog/categories/school-work/"/>
    
    
      <category term="machine learning" scheme="https://www.cmwonderland.com/blog/tags/machine-learning/"/>
    
      <category term="python" scheme="https://www.cmwonderland.com/blog/tags/python/"/>
    
      <category term="bioinformatics" scheme="https://www.cmwonderland.com/blog/tags/bioinformatics/"/>
    
      <category term="teaching" scheme="https://www.cmwonderland.com/blog/tags/teaching/"/>
    
      <category term="TA" scheme="https://www.cmwonderland.com/blog/tags/TA/"/>
    
  </entry>
  
  <entry>
    <title>Machine Learning Basics Tutorial</title>
    <link href="https://www.cmwonderland.com/blog/2018/10/05/56_machine-learning-basics/"/>
    <id>https://www.cmwonderland.com/blog/2018/10/05/56_machine-learning-basics/</id>
    <published>2018-10-05T02:03:19.000Z</published>
    <updated>2018-10-10T05:02:32.062Z</updated>
    
    <content type="html"><![CDATA[<p>This is one of the chapter in <a href="https://lulab.gitbooks.io/teaching/content/" target="_blank" rel="noopener">Bioinformatics basic course in Tsinghua University</a>. You may also find it <a href="https://lulab.gitbooks.io/teaching/content/part-iii.-machine-learning-basics/1.simple-machine-learning-basics.html" target="_blank" rel="noopener">here</a></p><p>The related <a href="https://github.com/lulab/teaching_book/blob/master/part-iii.-machine-learning-basics/1.simple-machine-learning-basics.ipynb" target="_blank" rel="noopener">jupyter file</a></p><a id="more"></a><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>Machine learning studies how to learn patterns from data and predict characteristics of unknown data.</p><p>According whether the predicted variable is known, machine learning generally fall into two categories:<br>supervised learning and unsupervised learning.</p><p>In supervised learning, the model takes features and class labels<br>or targer values as input to build the model. If the target variable (the variable to predict) is a<br>categorical (e.g. positive/negative), the problem is called classification. If the target variable is<br>continuous (e.g. height), the problem is called regression. Most supervised learning problems fall into<br>these two categories, however, combination of continous output and categorical output or structured output<br>are also possible.</p><p>In unsupervised learning, the target variables are not specified. The objective is to identify internal<br>structures (clusters) of the data. After model fitting, we can assign new samples to clusters or generate<br>samples with similar distribution as the original data. Unsupervised learning are also useful as<br>a data preprocessing step prior to supervised learning.</p><h2 id="Import-data"><a href="#Import-data" class="headerlink" title="Import data"></a>Import data</h2><p>Datasets for machine learning can be loaded from a variety of souces.<br>Tabular data can be loaded through the <a href="https://pandas.pydata.org" target="_blank" rel="noopener"><em>pandas</em></a> package in various formats:</p><div class="table-container"><table><thead><tr><th>Format Type</th><th>Data Description</th><th>Reader</th><th>Writer</th></tr></thead><tbody><tr><td>text</td><td>CSV</td><td><a href="https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html" target="_blank" rel="noopener">pandas.read_csv</a></td><td><a href="https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.to_csv.html" target="_blank" rel="noopener">pandas.to_csv</a></td></tr><tr><td>text</td><td>JSON</td><td><a href="https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_json.html" target="_blank" rel="noopener">pandas.read_json</a></td><td><a href="https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.to_json.html" target="_blank" rel="noopener">pandas.to_json</a></td></tr><tr><td>text</td><td>HTML</td><td><a href="https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_html.html" target="_blank" rel="noopener">pandas.read_html</a></td><td><a href="https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.to_html.html" target="_blank" rel="noopener">pandas.to_html</a></td></tr><tr><td>text</td><td>Local clipboard</td><td><a href="https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_clipboard.html" target="_blank" rel="noopener">pandas.read_clipboard</a></td><td><a href="https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.to_clipboard.html" target="_blank" rel="noopener">pandas.to_clipboard</a></td></tr><tr><td>binary</td><td>MS Excel</td><td><a href="https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_excel.html" target="_blank" rel="noopener">pandas.read_excel</a></td><td><a href="https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.to_excel.html" target="_blank" rel="noopener">pandas.to_excel</a></td></tr><tr><td>binary</td><td>HDF5 Format</td><td><a href="https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_hdf.html" target="_blank" rel="noopener">pandas.read_hdf</a></td><td><a href="https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.to_hdf.html" target="_blank" rel="noopener">pandas.to_hdf</a></td></tr></tbody></table></div><p>You can refer to <a href="https://pandas.pydata.org/pandas-docs/stable/io.html" target="_blank" rel="noopener">Pandas IO Tools</a><br>for more usage of data importing using <em>pandas</em>.</p><p>For large datasets, it is recommended to use binary formats such as <em>HDF5</em> and <em>NPZ</em> for more efficient reading and writing and also reducing disk usage.</p><p>HDF5 format can be read to or write from numpy arrays conveniently using the <a href="http://docs.h5py.org/en/stable/" target="_blank" rel="noopener">h5py</a> package:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> h5py</span><br><span class="line"><span class="comment"># read data assuming that datasets 'X' and 'y' exists in HDF5 file input_file</span></span><br><span class="line"><span class="keyword">with</span> h5py.File(input_file, <span class="string">'r'</span>) <span class="keyword">as</span> f:</span><br><span class="line">    X = f[<span class="string">'X'</span>][:]</span><br><span class="line">    y = f[<span class="string">'y'</span>][:]</span><br><span class="line"><span class="comment"># write data to HDF5 file output_file</span></span><br><span class="line"><span class="comment"># X and y are numpy arrays</span></span><br><span class="line"><span class="keyword">with</span> h5py.File(output_file, <span class="string">'w'</span>) <span class="keyword">as</span> f:</span><br><span class="line">    f.create_dataset(<span class="string">'X'</span>, data=X)</span><br><span class="line">    f.create_dataset(<span class="string">'y'</span>, data=y)</span><br></pre></td></tr></table></figure><p><em>NPZ</em> format is <a href="https://docs.scipy.org/doc/numpy/reference/routines.io.html" target="_blank" rel="noopener">native format</a> for numpy. <em>NPZ/NPY</em> format can be read from file using <a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.load.html#numpy.load" target="_blank" rel="noopener">numpy.load</a> and<br>write to file using <a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.save.html#numpy.save" target="_blank" rel="noopener">numpy.save</a><br>or <a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.savez.html#numpy.savez" target="_blank" rel="noopener">numpy.savez</a>.</p><h2 id="Import-required-Python-packages"><a href="#Import-required-Python-packages" class="headerlink" title="Import required Python packages"></a>Import required Python packages</h2><p>Documentation for required Python packages:</p><ul><li><a href="https://docs.scipy.org/doc/numpy/" target="_blank" rel="noopener">numpy</a>: arrays</li><li><a href="https://pandas.pydata.org/" target="_blank" rel="noopener">pandas</a>: data IO, DataFrame</li><li><a href="https://imbalanced-learn.readthedocs.io/en/stable" target="_blank" rel="noopener">imbalanced-learn</a>: deal with class imbalance</li><li><a href="http://scikit-learn.org/" target="_blank" rel="noopener">scikit-learn</a>: machine learning</li><li><a href="https://www.statsmodels.org/" target="_blank" rel="noopener">statsmodels</a>: statistical functions</li><li><a href="https://matplotlib.org/" target="_blank" rel="noopener">matplotlib</a>: plotting</li><li><a href="https://matplotlib.org/" target="_blank" rel="noopener">seaborn</a>: high-level plotting based on <em>matplotlib</em></li><li><a href="https://jupyter.org/" target="_blank" rel="noopener">jupyter</a>: Python notebook</li><li><a href="https://rasbt.github.io/mlxtend" target="_blank" rel="noopener">mlxtend</a>: Extension of scikit-learn</li><li><a href="https://graphviz.readthedocs.io/en/stable/" target="_blank" rel="noopener">graphviz</a>: Python binding for Graphviz graph drawing software</li><li><a href="http://docs.wand-py.org/en/0.4.4/" target="_blank" rel="noopener">wand</a>: ImageMagick (image processing tool) binding for Python</li></ul><p>For Jupyter Notebook users, run the following magic command to display images inline.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># This is a magic funtion in IPython/Jupyter that import many functions and modules</span></span><br><span class="line"><span class="comment"># from matplotlib, numpy, scipy, which is roughly equivalent to:</span></span><br><span class="line"><span class="comment"># </span></span><br><span class="line"><span class="comment"># import numpy as np</span></span><br><span class="line"><span class="comment"># import numpy.ma as ma</span></span><br><span class="line"><span class="comment"># import matplotlib as mpl</span></span><br><span class="line"><span class="comment"># from matplotlib import cbook, mlab, pyplot as plt</span></span><br><span class="line"><span class="comment"># from matplotlib.pyplot import *</span></span><br><span class="line"><span class="comment"># from numpy import *</span></span><br><span class="line"><span class="comment"># from numpy.fft import *</span></span><br><span class="line"><span class="comment"># from numpy.random import *</span></span><br><span class="line"><span class="comment"># from numpy.linalg import *</span></span><br><span class="line">%pylab inline</span><br></pre></td></tr></table></figure><pre><code>Populating the interactive namespace from numpy and matplotlib</code></pre><p>If you run Python/IPython interactively or in a script, please run the following code instead.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pylab <span class="keyword">import</span> *</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> defaultdict</span><br><span class="line"><span class="comment"># For data importing</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="comment"># For machine learning</span></span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> make_classification, make_regression, make_circles, make_moons, make_gaussian_quantiles</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> KMeans</span><br><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> SVC, LinearSVC</span><br><span class="line"><span class="keyword">from</span> sklearn.gaussian_process <span class="keyword">import</span> GaussianProcessClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> PCA</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> KFold, train_test_split, GridSearchCV, cross_val_score</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score, roc_auc_score, f1_score, recall_score, precision_score, \</span><br><span class="line">    roc_curve, precision_recall_curve, average_precision_score, matthews_corrcoef, confusion_matrix</span><br><span class="line"><span class="keyword">from</span> statsmodels.robust.scale <span class="keyword">import</span> mad</span><br><span class="line"><span class="comment"># For plotting</span></span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line">sns.set()</span><br><span class="line">sns.set_style(<span class="string">'whitegrid'</span>)</span><br><span class="line"><span class="keyword">from</span> matplotlib.colors <span class="keyword">import</span> to_hex</span><br></pre></td></tr></table></figure><h2 id="Initialize-random-seed"><a href="#Initialize-random-seed" class="headerlink" title="Initialize random seed"></a>Initialize random seed</h2><p>We fix the random seed of numpy in this tutorial to make the results reproducible.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">random_state = np.random.RandomState(<span class="number">1289237</span>)</span><br></pre></td></tr></table></figure><h2 id="Generate-datasets"><a href="#Generate-datasets" class="headerlink" title="Generate datasets"></a>Generate datasets</h2><p>You can start with simple datasets that is easy to understand and visualize before handling realistic datasets.<br><em>scikit-learn</em> provides many functions (<a href="http://scikit-learn.org/stable/modules/classes.html#module-sklearn.datasets" target="_blank" rel="noopener">sklearn.datasets</a>) for generating datasets easily.</p><h3 id="Classification-dataset"><a href="#Classification-dataset" class="headerlink" title="Classification dataset"></a>Classification dataset</h3><p>For example, <a href="http://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html#sklearn.datasets.make_classification" target="_blank" rel="noopener">sklearn.datasets.make_classification</a> generates samples from a mixture of Gaussian distributions with parameters to specify the number of classes,<br>number of features, number of classes, etc. The following example generate a two-class classification dataset of 1000 samples with 2 features for visualization. Samples are generated from two independent 2D Gaussian distributions. This dataset is suitable for linear classifier.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">X, y = make_classification(n_samples=<span class="number">1000</span>, n_classes=<span class="number">2</span>, n_features=<span class="number">2</span>,</span><br><span class="line">                           n_informative=<span class="number">2</span>, n_redundant=<span class="number">0</span>, n_clusters_per_class=<span class="number">1</span>,</span><br><span class="line">                           random_state=random_state, class_sep=<span class="number">0.9</span>)</span><br><span class="line">fig, ax = plt.subplots(figsize=(<span class="number">7</span>, <span class="number">7</span>))</span><br><span class="line"><span class="keyword">for</span> label <span class="keyword">in</span> np.unique(y):</span><br><span class="line">    ax.scatter(X[y == label, <span class="number">0</span>], X[y == label, <span class="number">1</span>], s=<span class="number">10</span>, label=str(label))</span><br><span class="line">ax.legend(title=<span class="string">'Class'</span>)</span><br></pre></td></tr></table></figure><p><img src="http://i1.fuimg.com/640680/d09e1bae36643858.png" alt="Markdown"></p><h3 id="Regression-dataset"><a href="#Regression-dataset" class="headerlink" title="Regression dataset"></a>Regression dataset</h3><p>You can also use <a href="http://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_regression.html" target="_blank" rel="noopener">make_regression</a> to generate a simple regression dataset.<br>The following dataset consists of 1000 samples with 1 feature and 1 response variable. A Gaussian noise 10 is added to each response variable.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">X, y = make_regression(n_samples=<span class="number">1000</span>, n_features=<span class="number">1</span>, n_informative=<span class="number">1</span>, noise=<span class="number">10</span>, random_state=random_state)</span><br><span class="line">fig, ax = plt.subplots(figsize=(<span class="number">7</span>, <span class="number">7</span>))</span><br><span class="line">ax.scatter(X[:, <span class="number">0</span>], y, s=<span class="number">5</span>, label=str(label))</span><br><span class="line">ax.set_xlabel(<span class="string">'X'</span>)</span><br><span class="line">ax.set_ylabel(<span class="string">'y'</span>)</span><br></pre></td></tr></table></figure><p><img src="http://i1.fuimg.com/640680/5f2d9d3ef2c4ed55.png" alt="Markdown"></p><h3 id="Specialized-datasets"><a href="#Specialized-datasets" class="headerlink" title="Specialized datasets"></a>Specialized datasets</h3><p><em>scikit-learn</em> also provides sample generators for specialized classification/regression/clustering problems, e.g.<br><a href="http://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_circles.html" target="_blank" rel="noopener">make_circles</a>,<br><a href="http://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_moons.html" target="_blank" rel="noopener">make_moons</a>,<br><a href="http://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_gaussian_quantiles.html" target="_blank" rel="noopener">make_gaussian_quantiles</a>.<br>These datasets can be used to demonstrate cases where simple classifier or clustering algorithms don’t work but<br>non-linear and more complicated algorithms work better.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">fig, axes = plt.subplots(<span class="number">1</span>, <span class="number">3</span>, figsize=(<span class="number">16</span>, <span class="number">5</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i, f <span class="keyword">in</span> enumerate((make_circles, make_moons, make_gaussian_quantiles)):</span><br><span class="line">    <span class="keyword">if</span> f == make_gaussian_quantiles:</span><br><span class="line">        X, y = f(n_samples=<span class="number">1000</span>, random_state=random_state)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        X, y = f(n_samples=<span class="number">1000</span>, noise=<span class="number">0.03</span>,</span><br><span class="line">                 random_state=random_state)</span><br><span class="line">    <span class="keyword">for</span> label <span class="keyword">in</span> np.unique(y):</span><br><span class="line">        axes[i].scatter(X[y == label, <span class="number">0</span>], X[y == label, <span class="number">1</span>], s=<span class="number">5</span>, label=str(label))</span><br><span class="line">    axes[i].legend(title=<span class="string">'Class'</span>)</span><br><span class="line">    axes[i].set_title(f.__name__)</span><br></pre></td></tr></table></figure><p><img src="http://i1.fuimg.com/640680/dba0499f4483b826.png" alt="Markdown"></p><h3 id="The-digits-dataset"><a href="#The-digits-dataset" class="headerlink" title="The digits dataset"></a>The <em>digits</em> dataset</h3><p><em>scikit-learn</em> also includes some commonly used public datasets that is useful for exploring machine learning algorithms in the package. For example, the <em>digits</em> dataset is a small handwriting image dataset of 10 digits.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_digits</span><br><span class="line"></span><br><span class="line">X, y = load_digits(return_X_y=<span class="keyword">True</span>)</span><br><span class="line">fig, ax = plt.subplots(figsize=(<span class="number">10</span>, <span class="number">11</span>))</span><br><span class="line">data = np.swapaxes(X[:<span class="number">16</span>].reshape((<span class="number">-1</span>, <span class="number">8</span>, <span class="number">8</span>)), <span class="number">0</span>, <span class="number">1</span>).reshape((<span class="number">8</span>, <span class="number">-1</span>))</span><br><span class="line"><span class="keyword">with</span> plt.rc_context(&#123;<span class="string">'axes.grid'</span>: <span class="keyword">False</span>&#125;):</span><br><span class="line">    ax.imshow(data, cmap=<span class="string">'Greys'</span>)</span><br><span class="line">ax.set_axis_off()</span><br></pre></td></tr></table></figure><p><img src="http://i1.fuimg.com/640680/2a3087cba4cad1de.png" alt="Markdown"></p><h3 id="Dataset-used-in-this-tutorial"><a href="#Dataset-used-in-this-tutorial" class="headerlink" title="Dataset used in this tutorial"></a>Dataset used in this tutorial</h3><p>We use <em>sklearn.datasets.make_classification</em> to generate a dataset with 2 features</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">X, y = make_classification(n_samples=<span class="number">1000</span>, n_classes=<span class="number">2</span>, n_features=<span class="number">4</span>,</span><br><span class="line">                           n_informative=<span class="number">2</span>, n_redundant=<span class="number">0</span>, n_clusters_per_class=<span class="number">1</span>,</span><br><span class="line">                           class_sep=<span class="number">0.9</span>, random_state=random_state)</span><br></pre></td></tr></table></figure><h2 id="Single-feature-analysis"><a href="#Single-feature-analysis" class="headerlink" title="Single feature analysis"></a>Single feature analysis</h2><h3 id="Analyze-the-separability-of-classes-using-individual-features"><a href="#Analyze-the-separability-of-classes-using-individual-features" class="headerlink" title="Analyze the separability of classes using individual features"></a>Analyze the separability of classes using individual features</h3><p>Plot the distribution of feature values of each feature. A good feature should separate the two class well.<br>The following plot shows that each individual feature can largely separate the two classes, though not perfectly.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">fig, axes = plt.subplots(<span class="number">1</span>, X.shape[<span class="number">1</span>], figsize=(<span class="number">15</span>, <span class="number">4</span>))</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(X.shape[<span class="number">1</span>]):</span><br><span class="line">    <span class="keyword">for</span> label <span class="keyword">in</span> (<span class="number">0</span>, <span class="number">1</span>):</span><br><span class="line">        sns.kdeplot(X[y == label, i], label=str(label), ax=axes[i])</span><br><span class="line">    axes[i].legend(title=<span class="string">'class'</span>)</span><br><span class="line">    axes[i].set_xlabel(<span class="string">'Feature x[&#123;&#125;]'</span>.format(i))</span><br><span class="line">    axes[i].set_ylabel(<span class="string">'Density'</span>)</span><br></pre></td></tr></table></figure><p><img src="http://i1.fuimg.com/640680/1e71af3fee869e60.png" alt="Markdown"></p><h3 id="Feature-correlation-analysis"><a href="#Feature-correlation-analysis" class="headerlink" title="Feature correlation analysis"></a>Feature correlation analysis</h3><p>Sometimes highly correlated features may be detrimental to model performance and feature selection.<br>A redundant feature does not provide more information, but introduces extra parameters to the model to make<br>the model prone to overfitting. For feature selection, the model may assign a small weight to each redundant features<br>too many redundant features may dilute the contribution of individual features. Although the impact of<br>redundant features on model performance depends on the machine learning algorithm used,<br>it is a good practice to identify these features and remove/merge redundant features.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">data = pd.DataFrame(X, columns=[<span class="string">'x[&#123;&#125;]'</span>.format(i) <span class="keyword">for</span> i <span class="keyword">in</span> range(X.shape[<span class="number">1</span>])])</span><br><span class="line">data.loc[:, <span class="string">'classes'</span>] = y.astype(<span class="string">'U'</span>)</span><br><span class="line">g = sns.PairGrid(data, hue=<span class="string">'classes'</span>, vars=[<span class="string">'x[&#123;&#125;]'</span>.format(i) <span class="keyword">for</span> i <span class="keyword">in</span> range(X.shape[<span class="number">1</span>])])</span><br><span class="line">g.map_offdiag(plt.scatter, s=<span class="number">3</span>)</span><br><span class="line">g.map_diag(sns.kdeplot)</span><br><span class="line">g.add_legend()</span><br></pre></td></tr></table></figure><p><img src="http://i1.fuimg.com/640680/507c87a5d099b80e.png" alt="Markdown"></p><h2 id="PCA-analysis"><a href="#PCA-analysis" class="headerlink" title="PCA analysis"></a>PCA analysis</h2><p>A dataset with more than 3 features cannot be visualized directly. We can use dimension reduction<br>to embed the data on a 2D or 3D space. A dimension reduction algorithm maps data points in high dimension to low<br>dimension while preserve distance in their original space as well as possible.</p><p>Principal Component Analysis (PCA) is the most common algorithm for dimension reduction.<br>It maps data to a new space by linear combination of original features such that new features are linearly<br>independent and the total variance is maximized.</p><p>If samples can be separated well in a PCA plot, a linear classifier also works well. Otherwise,<br>a non-linear classifier may improve classification performance.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">X_scaled = StandardScaler().fit_transform(X)</span><br><span class="line">pca = PCA()</span><br><span class="line">X_pca = pca.fit_transform(X)</span><br><span class="line">fig, axes = plt.subplots(<span class="number">1</span>, <span class="number">2</span>, figsize=(<span class="number">15</span>, <span class="number">8</span>))</span><br><span class="line">axes[<span class="number">0</span>].plot(np.arange(<span class="number">0.5</span>, X.shape[<span class="number">1</span>] + <span class="number">0.5</span>), pca.explained_variance_ratio_, marker=<span class="string">'o'</span>)</span><br><span class="line">axes[<span class="number">0</span>].set_xticks(np.arange(<span class="number">0.5</span>, X.shape[<span class="number">1</span>] + <span class="number">0.5</span>))</span><br><span class="line">axes[<span class="number">0</span>].set_xticklabels(np.arange(<span class="number">1</span>, X.shape[<span class="number">1</span>] + <span class="number">1</span>))</span><br><span class="line">axes[<span class="number">0</span>].set_xlabel(<span class="string">'PC rank'</span>)</span><br><span class="line">axes[<span class="number">0</span>].set_ylabel(<span class="string">'Explained variance ratio'</span>)</span><br><span class="line">axes[<span class="number">0</span>].set_ylim(<span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">axes[<span class="number">0</span>].set_xlim(<span class="number">0</span>, X.shape[<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> label <span class="keyword">in</span> np.unique(y):</span><br><span class="line">    axes[<span class="number">1</span>].scatter(X_pca[y == label, <span class="number">0</span>], X_pca[y == label, <span class="number">1</span>], label=label, s=<span class="number">10</span>)</span><br><span class="line">axes[<span class="number">1</span>].set_xlabel(<span class="string">'PC1 (&#123;:.02f&#125;%)'</span>.format(pca.explained_variance_ratio_[<span class="number">0</span>]*<span class="number">100</span>))</span><br><span class="line">axes[<span class="number">1</span>].set_ylabel(<span class="string">'PC2 (&#123;:.02f&#125;%)'</span>.format(pca.explained_variance_ratio_[<span class="number">1</span>]*<span class="number">100</span>))</span><br></pre></td></tr></table></figure><p><img src="http://i1.fuimg.com/640680/4872a27f6929443d.png" alt="Markdown"></p><h2 id="Data-scaling"><a href="#Data-scaling" class="headerlink" title="Data scaling"></a>Data scaling</h2><p>For most machine learning algorithms, it is recommended to scale the features to a common small scale.<br>Features of large or small scale increase the risk of numerical instability and also make the loss function<br>harder to optimize. Feature selection based on fitted coefficients of a linear model assumes that the input<br>features are in the same scale. Performance and convergence speed of gradient-based algorithms<br>such as neural networks are largely degraded if the data is not properly scaled.<br>Decision tree and random forest, however,<br>are less sensitive to data scale because they use rule-based criteria.</p><p>Common data scaling methods include standard/z-score scaling, min-max scaling, robust scaling and abs-max scaling.</p><p>Standard/z-score scaling first shift features to their centers(mean) and then divide by their standard deviation.<br>This method is suitable for most continous features of approximately Gaussian distribution.</p><script type="math/tex; mode=display">\text{zscore}(x_{ij}^{'}) = \frac{x_{ij} - \mu _{ij}}{\sigma _i}</script><p>Min-max scaling method scales data into range [0, 1].<br>This method is suitable for data concentrated within a range and preserves zero values for sparse data.<br>Min-max scaling is also sensitive to outliers in the data. Try removing outliers or clip data into<br>a range before scaling.</p><script type="math/tex; mode=display">\text{min_max}(x_{ij}^{'}) = \frac{x_{ij} - \text{min}_k \mathbf{x}_{ik}}{\text{max}_k x_{ik} - \text{min}_k x_{ik}}</script><p>Max-abs scaling method is similar to min-max scaling, but scales data into range [-1, 1].<br>It does not shift/center the data and thus preserves signs (positive/negative) of features.<br>Like min-max, max-abs is sensitive to outliers.</p><script type="math/tex; mode=display">\text{max_abs}(x_{ij}^{'}) = \frac{x_{ij}}{\text{max}_k \vert x_{ik} \vert}</script><p>Robust scaling method use robust statistics (median, interquartile range) instead of mean and standard deviation.<br>Median and IQR are less sensitive to outliers.<br>For features with large numbers of outliers or largely deviates from normal distribution,<br>robust scaling is recommended.</p><script type="math/tex; mode=display">\text{robust_scale}(x_{ij}^{'}) = \frac{x_{ij} - \text{median}_k x_{ik}}{Q_{0.75}(\mathbf{x}_i) - Q_{0.25}(\mathbf{x}_i)}</script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">x = random_state.normal(<span class="number">10</span>, <span class="number">2</span>, size=<span class="number">1000</span>)</span><br><span class="line">fig, ax = plt.subplots(figsize=(<span class="number">8</span>, <span class="number">6</span>))</span><br><span class="line">sns.distplot(x, ax=ax)</span><br><span class="line">sns.distplot(np.ravel(StandardScaler().fit_transform(x.reshape((<span class="number">-1</span>, <span class="number">1</span>)))), ax=ax)</span><br></pre></td></tr></table></figure><p><img src="http://i1.fuimg.com/640680/6496c7878223c8e0.png" alt="Markdown"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Generate features with different distribution</span></span><br><span class="line">x = np.zeros((<span class="number">1000</span>, <span class="number">4</span>))</span><br><span class="line">x[:, <span class="number">0</span>] = random_state.normal(<span class="number">10</span>, <span class="number">2</span>, size=x.shape[<span class="number">0</span>])</span><br><span class="line">x[:, <span class="number">1</span>] = random_state.gamma(shape=<span class="number">3</span>, scale=<span class="number">4</span>, size=x.shape[<span class="number">0</span>])</span><br><span class="line">x[:, <span class="number">2</span>] = random_state.poisson(<span class="number">5</span>, size=x.shape[<span class="number">0</span>])</span><br><span class="line">x[:, <span class="number">3</span>] = random_state.uniform(<span class="number">-3</span>, <span class="number">6</span>, size=x.shape[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler, MinMaxScaler, MaxAbsScaler, RobustScaler</span><br><span class="line">scalers = &#123;</span><br><span class="line">    <span class="string">'Standard'</span>: StandardScaler(),</span><br><span class="line">    <span class="string">'MinMax'</span>: MinMaxScaler(),</span><br><span class="line">    <span class="string">'MaxAbs'</span>: MaxAbsScaler(),</span><br><span class="line">    <span class="string">'Robust'</span>: RobustScaler()</span><br><span class="line">&#125;</span><br><span class="line">fig, axes = plt.subplots(<span class="number">5</span>, x.shape[<span class="number">1</span>], figsize=(<span class="number">16</span>, <span class="number">20</span>))</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(x.shape[<span class="number">1</span>]):</span><br><span class="line">    sns.distplot(x[:, i], ax=axes[<span class="number">0</span>, i])</span><br><span class="line">    axes[<span class="number">0</span>, i].set_title(<span class="string">'Original feature &#123;&#125;'</span>.format(i + <span class="number">1</span>))</span><br><span class="line"><span class="keyword">for</span> j, scaler_name <span class="keyword">in</span> enumerate(scalers.keys()):</span><br><span class="line">    x_scaled = scalers[scaler_name].fit_transform(x)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(x.shape[<span class="number">1</span>]):</span><br><span class="line">        sns.distplot(x_scaled[:, i], ax=axes[j + <span class="number">1</span>, i])</span><br><span class="line">        axes[j + <span class="number">1</span>, i].set_title(<span class="string">'&#123;&#125; for feature &#123;&#125;'</span>.format(scaler_name, i + <span class="number">1</span>))</span><br></pre></td></tr></table></figure><p><img src="http://i1.fuimg.com/640680/b1dcf9d78e4a221f.png" alt="Markdown"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">X = StandardScaler().fit_transform(X)</span><br></pre></td></tr></table></figure><h2 id="Split-data-into-training-and-test-set"><a href="#Split-data-into-training-and-test-set" class="headerlink" title="Split data into training and test set"></a>Split data into training and test set</h2><p>We should split the dataset into a training and test set to evaluate model performance.<br>During model training, the model overfits to the data to some extent, and so model performance<br>on the training set is generally biases and higher than on the test set. The overfitting issue<br>can be resolved by adding more independent samples to the dataset. The difference of training<br>and test performance decreases with the increase of sample size.</p><p>Here, we use <a href="http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html" target="_blank" rel="noopener">train_test_split</a><br>to randomly set 80% of the samples as training set and 20% as test set.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.2</span>, random_state=random_state)</span><br><span class="line">print(<span class="string">'number of training samples: &#123;&#125;, test samples: &#123;&#125;'</span>.format(X_train.shape[<span class="number">0</span>], X_test.shape[<span class="number">0</span>]))</span><br></pre></td></tr></table></figure><pre><code>number of training samples: 800, test samples: 200</code></pre><h2 id="Train-the-model"><a href="#Train-the-model" class="headerlink" title="Train the model"></a>Train the model</h2><p>During model training, the parameters of the model is adjusted to minimize a loss function.</p><h3 id="Logistic-regression"><a href="#Logistic-regression" class="headerlink" title="Logistic regression"></a>Logistic regression</h3><p>Logistic regression is a linear model for classification. It first forms linear combination of input features<br>and then map the combined value to class probability between 0 and 1 through a non-linear sigmoid function.<br>During model training, the weights of the model are adjusted such that the cross-entropy between model prediction<br>and true labels is minimized.</p><script type="math/tex; mode=display">p(y_i | \mathbf{x}_i) = \frac{1}{1 + \text{exp} \left( \sum_{j=1}^M x_{ij} w_{j} + b \right)}</script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model = LogisticRegression()</span><br><span class="line">_ = model.fit(X_train, y_train)</span><br></pre></td></tr></table></figure><h2 id="Model-inspection"><a href="#Model-inspection" class="headerlink" title="Model inspection"></a>Model inspection</h2><h3 id="Feature-importance"><a href="#Feature-importance" class="headerlink" title="Feature importance"></a>Feature importance</h3><p>For linear models (e.g. Logistic regression, linear regression, linear SVM), feature importance<br>is usually defined as the square of coefficients:</p><script type="math/tex; mode=display">\text{FeatureImportance}_j = w_{j}^2</script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">fig, ax = plt.subplots(figsize=(<span class="number">4</span>, <span class="number">4</span>))</span><br><span class="line">feature_importance = np.square(np.ravel(model.coef_))</span><br><span class="line">ax.bar(np.arange(<span class="number">1</span>, X.shape[<span class="number">1</span>] + <span class="number">1</span>).astype(<span class="string">'U'</span>), feature_importance)</span><br><span class="line">ax.set_xlabel(<span class="string">'Feature'</span>)</span><br><span class="line">_ = ax.set_ylabel(<span class="string">'Feature importance'</span>)</span><br></pre></td></tr></table></figure><p><img src="http://i1.fuimg.com/640680/1504d9deddec2451.png" alt="Markdown"></p><h3 id="Decision-boundary"><a href="#Decision-boundary" class="headerlink" title="Decision boundary"></a>Decision boundary</h3><p>We can inspect decision boundaries of a model by predict class labels on a 2D grid of sample points.<br>You can see that the decision boundary of Logistic regression is a straight line while other classifiers<br>create non-linear and irregular decision boundaries.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">X_grid, Y_grid = np.mgrid[<span class="number">-5</span>:<span class="number">5</span>:<span class="number">0.1</span>, <span class="number">-5</span>:<span class="number">5</span>:<span class="number">0.1</span>]</span><br><span class="line">fig, axes = plt.subplots(<span class="number">2</span>, <span class="number">3</span>, figsize=(<span class="number">15</span>, <span class="number">10</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> matplotlib.colors <span class="keyword">import</span> ListedColormap</span><br><span class="line">cmap = sns.diverging_palette(<span class="number">252</span>, <span class="number">17</span>, n=<span class="number">2</span>)</span><br><span class="line">cmap = ListedColormap(cmap)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Use top 2 features</span></span><br><span class="line">selected_features = np.argsort(-feature_importance)[:<span class="number">2</span>]</span><br><span class="line"><span class="keyword">for</span> n, model_class <span class="keyword">in</span> enumerate((LogisticRegression, SVC,</span><br><span class="line">                                 DecisionTreeClassifier, KNeighborsClassifier,</span><br><span class="line">                                 GaussianProcessClassifier, RandomForestClassifier)):</span><br><span class="line">    i, j = n//<span class="number">3</span>, n%<span class="number">3</span></span><br><span class="line">    model_n = model_class()</span><br><span class="line">    model_n.fit(X_train[:, selected_features], y_train)</span><br><span class="line">    labels_grid = model_n.predict(np.column_stack([np.ravel(X_grid), np.ravel(Y_grid)]))</span><br><span class="line">    </span><br><span class="line">    axes[i, j].pcolor(X_grid, Y_grid, labels_grid.reshape(X_grid.shape), </span><br><span class="line">                          cmap=cmap, linewidth=<span class="number">0</span>, edgecolor=<span class="string">'face'</span>, alpha=<span class="number">0.3</span>)</span><br><span class="line">    axes[i, j].set_title(model_class.__name__)</span><br><span class="line">    <span class="keyword">for</span> label <span class="keyword">in</span> np.unique(y):</span><br><span class="line">        axes[i, j].scatter(X_train[y_train == label, selected_features[<span class="number">0</span>]],</span><br><span class="line">                           X_train[y_train == label, selected_features[<span class="number">1</span>]],</span><br><span class="line">                           s=<span class="number">3</span>, label=str(label))</span><br><span class="line">    axes[i, j].legend(title=<span class="string">'class'</span>)</span><br></pre></td></tr></table></figure><p><img src="http://i1.fuimg.com/640680/6b9145218cefa02b.png" alt="Markdown"></p><h2 id="Evaluate-the-model"><a href="#Evaluate-the-model" class="headerlink" title="Evaluate the model"></a>Evaluate the model</h2><h3 id="Predict-labels-on-the-test-dataset"><a href="#Predict-labels-on-the-test-dataset" class="headerlink" title="Predict labels on the test dataset"></a>Predict labels on the test dataset</h3><p>To evaluate performance of the model, we use the <em>predict</em> method of the estimator<br>to predict class labels of test data. This will return an integer array indicating class labels.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">y_pred = model.predict(X_test)</span><br></pre></td></tr></table></figure><h3 id="Confusion-matrix"><a href="#Confusion-matrix" class="headerlink" title="Confusion matrix"></a>Confusion matrix</h3><p>The most common way to evaluate classification performance is to construct a<br><a href="https://en.wikipedia.org/wiki/Confusion_matrix" target="_blank" rel="noopener">confusion matrix</a>.</p><p>A confusion matrix summarizes the number of correctly or wrongly predicted samples and is usually<br>made up of four entries:</p><div class="table-container"><table><thead><tr><th>Predicted</th><th>Negative</th><th>Positive</th></tr></thead><tbody><tr><td><strong>True</strong></td><td></td><td></td></tr><tr><td><strong>Negative</strong></td><td>True Negative (TN)</td><td>False Negative (FN)</td></tr><tr><td><strong>Positive</strong></td><td>False Positive (FP)</td><td>True Positive (TP)</td></tr></tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">pd.DataFrame(confusion_matrix(y_test, y_pred), </span><br><span class="line">             columns=pd.Series([<span class="string">'Negative'</span>, <span class="string">'Positive'</span>], name=<span class="string">'Predicted'</span>),</span><br><span class="line">             index=pd.Series([<span class="string">'Negative'</span>, <span class="string">'Positive'</span>], name=<span class="string">'True'</span>))</span><br></pre></td></tr></table></figure><div><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th>Predicted</th>      <th>Negative</th>      <th>Positive</th>    </tr>    <tr>      <th>True</th>      <th></th>      <th></th>    </tr>  </thead>  <tbody>    <tr>      <th>Negative</th>      <td>81</td>      <td>8</td>    </tr>    <tr>      <th>Positive</th>      <td>27</td>      <td>84</td>    </tr>  </tbody></table></div><h3 id="Evaluation-metrics-for-classification"><a href="#Evaluation-metrics-for-classification" class="headerlink" title="Evaluation metrics for classification"></a>Evaluation metrics for classification</h3><p>A variety of metrics can be calculate from entries in the confusion matrix.</p><p>Accuracy (0 ~ 1) summarizes both positive and negative predictions, but is biased if the classes are imbalanced:</p><script type="math/tex; mode=display">\text{Accuracy} = \frac{TP + TN}{TP + TN + FP + FN}</script><p>Recall/sensitivity (0 ~ 1) summarizes how well the model finds out positive samples:</p><script type="math/tex; mode=display">\text{Recall/Sensitivity} = \frac{TP}{TP + FN}</script><p>Precision/positive predictive value (0 ~ 1) summarizes how well the model finds out negative samples:</p><script type="math/tex; mode=display">\text{Precision/Positive Predictive Value} = \frac{TP}{TP + FP}</script><p>F1 score (0 ~ 1) balances between positive predictive value (PPV) and true positive rate (TPR) and is more suitable for<br>imbalanced dataset:</p><script type="math/tex; mode=display">\text{F1 score} = 2 \frac{PPV \cdot TPR}{PPV + TPR}</script><p>Matthews correlation coefficient (MCC) (-1 ~ 1) is another metric that balances between recall and precision:</p><script type="math/tex; mode=display">\text{MCC} = \frac{TP \times TN - FP \times FN}{(TP + FN)(TP + FP)(TN + FP)(TN + FN)}</script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">scorers = &#123;<span class="string">'accuracy'</span>: accuracy_score,</span><br><span class="line">           <span class="string">'recall'</span>: recall_score,</span><br><span class="line">           <span class="string">'precision'</span>: precision_score,</span><br><span class="line">           <span class="string">'f1'</span>: f1_score,</span><br><span class="line">           <span class="string">'mcc'</span>: matthews_corrcoef</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">for</span> metric <span class="keyword">in</span> scorers.keys():</span><br><span class="line">    print(<span class="string">'&#123;&#125; = &#123;&#125;'</span>.format(metric, scorers[metric](y_test, y_pred)))</span><br></pre></td></tr></table></figure><pre><code>accuracy = 0.825recall = 0.7567567567567568precision = 0.9130434782608695f1 = 0.8275862068965518mcc = 0.6649535460625479</code></pre><h3 id="Predict-class-probability"><a href="#Predict-class-probability" class="headerlink" title="Predict class probability"></a>Predict class probability</h3><p>Many classifiers first predict a continous value for each sample indicating confidence/probability of the prediction<br>and then choose a fixed cutoff (e.g. 0.5 for probability values) to convert the continous values to binary labels.<br>We can get the raw prediction values through the <em>predict_proba</em> method.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">y_score = model.predict_proba(X_test)</span><br></pre></td></tr></table></figure><h3 id="ROC-curve-and-precision-recall-curve"><a href="#ROC-curve-and-precision-recall-curve" class="headerlink" title="ROC curve and precision-recall curve"></a>ROC curve and precision-recall curve</h3><p>Sometimes a single fixed cutoff is insufficient to evaluate model performance.<br>Receiver Operating Characterisic (ROC) curve and Precision-Recall curve are useful tools to inspect the<br>model performance with different cutoffs. ROC curve and precision-recall curve are also less sensitive<br>to class imbalance.<br>Compared to ROC curve, precision-recall curve are more suitable for extremely imbalanced datasets.</p><p>The area under the ROC curve (AUROC) or average precision (AP) is a single value<br>that summarizes average model performance under different cutoffs and are very commonly used to report<br>classification performance.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">fig, axes = plt.subplots(<span class="number">1</span>, <span class="number">2</span>, figsize=(<span class="number">14</span>, <span class="number">7</span>))</span><br><span class="line"><span class="comment"># ROC curve</span></span><br><span class="line">fpr, tpr, thresholds = roc_curve(y_test, y_score[:, <span class="number">1</span>])</span><br><span class="line">ax = axes[<span class="number">0</span>]</span><br><span class="line">ax.plot(fpr, tpr, label=<span class="string">'ROAUC = &#123;:.4f&#125;'</span>.format(roc_auc_score(y_test, y_score[:, <span class="number">1</span>])))</span><br><span class="line">ax.plot([<span class="number">0</span>, <span class="number">1</span>], [<span class="number">0</span>, <span class="number">1</span>], linestyle=<span class="string">'dashed'</span>)</span><br><span class="line">ax.set_xlabel(<span class="string">'False positive rate'</span>)</span><br><span class="line">ax.set_ylabel(<span class="string">'True positive rate'</span>)</span><br><span class="line">ax.set_title(<span class="string">'ROC curve'</span>)</span><br><span class="line">ax.legend()</span><br><span class="line"><span class="comment"># predision-recall curve</span></span><br><span class="line">precision, recall, thresholds = precision_recall_curve(y_test, y_score[:, <span class="number">1</span>])</span><br><span class="line">ax = axes[<span class="number">1</span>]</span><br><span class="line">ax.plot(precision, recall, label=<span class="string">'AP = &#123;:.4f&#125;'</span>.format(average_precision_score(y_test, y_score[:, <span class="number">1</span>])))</span><br><span class="line">ax.plot([<span class="number">0</span>, <span class="number">1</span>], [<span class="number">1</span>, <span class="number">0</span>], linestyle=<span class="string">'dashed'</span>)</span><br><span class="line">ax.set_xlabel(<span class="string">'Precision'</span>)</span><br><span class="line">ax.set_ylabel(<span class="string">'Recall'</span>)</span><br><span class="line">ax.set_title(<span class="string">'Precision-recall curve'</span>)</span><br><span class="line">ax.legend()</span><br></pre></td></tr></table></figure><p><img src="http://i1.fuimg.com/640680/5be83055f202d1bd.png" alt="Markdown"></p><h2 id="Cross-validation"><a href="#Cross-validation" class="headerlink" title="Cross-validation"></a>Cross-validation</h2><p>For very large datasets, a single split of the dataset into a training set and a test set is sufficient<br>to evaluate the model performance. However, for small dataset, the test samples represent only a small<br>proportion of samples in future predictions. The model performance evaluated on the test samples varies<br>greatly between resamplings of the dataset.</p><h3 id="K-fold-cross-validation"><a href="#K-fold-cross-validation" class="headerlink" title="K-fold cross-validation"></a>K-fold cross-validation</h3><p>Cross-validation is a commonly used technique for model evaluation on small dataset.<br>In <strong>k-fold cross-validation</strong>, the dataset is evenly divided into <em>k</em> partitions(folds).<br>In each round of validation, the model is tested on one parition and trained on remaining <em>(k-1)/k</em><br>partitions. K-fold cross-validation ensures that there is no overlap between training and test samples<br>but can have overlaps between rounds. Each sample is set as test sample for exactly once.<br>Finally, the average performance is calculated across <em>k</em> rounds.</p><p><em>scikit-learn</em> provides [many functions for splitting datasets]<br>(<a href="http://scikit-learn.org/stable/modules/classes.html#module-sklearn.model_selection" target="_blank" rel="noopener">http://scikit-learn.org/stable/modules/classes.html#module-sklearn.model_selection</a>).</p><p>Here, we use <a href="http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html" target="_blank" rel="noopener">KFold</a><br>to create 10-fold cross-validation datasets. 5 and 10 are commonly used values for <em>k</em>.<br>Use 10-fold cross-validation if the sample size and computation burden permits.</p><p>The following code illustrates how <em>KFold</em> splits the dataset.<br>Black boxes indicates test samples in each round.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">n_splits = <span class="number">10</span></span><br><span class="line"></span><br><span class="line">kfold = KFold(n_splits=n_splits, random_state=random_state)</span><br><span class="line">is_train = np.zeros((n_splits, X.shape[<span class="number">0</span>]), dtype=np.bool)</span><br><span class="line"><span class="keyword">for</span> i, (train_index, test_index) <span class="keyword">in</span> enumerate(kfold.split(X, y)):</span><br><span class="line">    is_train[i, train_index] = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">fig, ax = plt.subplots(figsize=(<span class="number">15</span>, <span class="number">3</span>))</span><br><span class="line">ax.pcolormesh(is_train)</span><br><span class="line">ax.set_yticks(np.arange(n_splits) + <span class="number">0.5</span>)</span><br><span class="line">ax.set_yticklabels(np.arange(n_splits) + <span class="number">1</span>)</span><br><span class="line">ax.set_ylabel(<span class="string">'Round'</span>)</span><br><span class="line">ax.set_xlabel(<span class="string">'Sample'</span>)</span><br></pre></td></tr></table></figure><p><img src="http://i1.fuimg.com/640680/ac7db08435dee99a.png" alt="Markdown"></p><p>Then we train the model on each training set and predict labels and scores on the whole dataset.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">predictions = np.zeros((n_splits, X.shape[<span class="number">0</span>]), dtype=np.int32)</span><br><span class="line">predicted_scores = np.zeros((n_splits, X.shape[<span class="number">0</span>]))</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(n_splits):</span><br><span class="line">    model.fit(X[is_train[i]], y[is_train[i]])</span><br><span class="line">    predictions[i] = model.predict(X)</span><br><span class="line">    predicted_scores[i] = model.predict_proba(X)[:, <span class="number">1</span>]</span><br></pre></td></tr></table></figure><h3 id="Collect-evaluation-metrics"><a href="#Collect-evaluation-metrics" class="headerlink" title="Collect evaluation metrics"></a>Collect evaluation metrics</h3><p>Next, we evaluates the model using K-fold cross-validation.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">cv_metrics = pd.DataFrame(np.zeros((n_splits*<span class="number">2</span>, len(scorers) + <span class="number">2</span>)),</span><br><span class="line">                          columns=list(scorers.keys()) + [<span class="string">'roc_auc'</span>, <span class="string">'average_precision'</span>])</span><br><span class="line">cv_metrics.loc[:, <span class="string">'dataset'</span>] = np.empty(n_splits*<span class="number">2</span>, dtype=<span class="string">'U'</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(n_splits):</span><br><span class="line">    <span class="keyword">for</span> metric <span class="keyword">in</span> scorers.keys():</span><br><span class="line">        cv_metrics.loc[i*<span class="number">2</span> + <span class="number">0</span>, metric] = scorers[metric](y[is_train[i]], predictions[i, is_train[i]])</span><br><span class="line">        cv_metrics.loc[i*<span class="number">2</span> + <span class="number">1</span>, metric] = scorers[metric](y[~is_train[i]], predictions[i, ~is_train[i]])</span><br><span class="line">    cv_metrics.loc[i*<span class="number">2</span> + <span class="number">0</span>, <span class="string">'roc_auc'</span>] = roc_auc_score(y[is_train[i]], predicted_scores[i, is_train[i]])</span><br><span class="line">    cv_metrics.loc[i*<span class="number">2</span> + <span class="number">1</span>, <span class="string">'roc_auc'</span>] = roc_auc_score(y[~is_train[i]], predicted_scores[i, ~is_train[i]])</span><br><span class="line">    cv_metrics.loc[i*<span class="number">2</span> + <span class="number">0</span>, <span class="string">'average_precision'</span>] = average_precision_score(y[is_train[i]], </span><br><span class="line">                                                                           predicted_scores[i, is_train[i]])</span><br><span class="line">    cv_metrics.loc[i*<span class="number">2</span> + <span class="number">1</span>, <span class="string">'average_precision'</span>] = average_precision_score(y[~is_train[i]], </span><br><span class="line">                                                                           predicted_scores[i, ~is_train[i]])</span><br><span class="line">    cv_metrics.loc[i*<span class="number">2</span> + <span class="number">0</span>, <span class="string">'dataset'</span>] = <span class="string">'train'</span></span><br><span class="line">    cv_metrics.loc[i*<span class="number">2</span> + <span class="number">1</span>, <span class="string">'dataset'</span>] = <span class="string">'test'</span></span><br><span class="line"></span><br><span class="line">cv_metrics.head()</span><br></pre></td></tr></table></figure><div><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>accuracy</th>      <th>recall</th>      <th>precision</th>      <th>f1</th>      <th>mcc</th>      <th>roc_auc</th>      <th>average_precision</th>      <th>dataset</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>0.832222</td>      <td>0.797386</td>      <td>0.863208</td>      <td>0.828992</td>      <td>0.666847</td>      <td>0.908640</td>      <td>0.931433</td>      <td>train</td>    </tr>    <tr>      <th>1</th>      <td>0.810000</td>      <td>0.809524</td>      <td>0.755556</td>      <td>0.781609</td>      <td>0.614965</td>      <td>0.882184</td>      <td>0.844361</td>      <td>test</td>    </tr>    <tr>      <th>2</th>      <td>0.818889</td>      <td>0.781737</td>      <td>0.843750</td>      <td>0.811561</td>      <td>0.639439</td>      <td>0.898143</td>      <td>0.915890</td>      <td>train</td>    </tr>    <tr>      <th>3</th>      <td>0.900000</td>      <td>0.961538</td>      <td>0.862069</td>      <td>0.909091</td>      <td>0.804601</td>      <td>0.985176</td>      <td>0.988980</td>      <td>test</td>    </tr>    <tr>      <th>4</th>      <td>0.828889</td>      <td>0.796909</td>      <td>0.853428</td>      <td>0.824201</td>      <td>0.659380</td>      <td>0.905196</td>      <td>0.924640</td>      <td>train</td>    </tr>  </tbody></table></div><h3 id="Summarize-evaluate-metrics"><a href="#Summarize-evaluate-metrics" class="headerlink" title="Summarize evaluate metrics"></a>Summarize evaluate metrics</h3><p>Take average of model performance across cross-validation runs:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cv_metrics_mean = cv_metrics.groupby(<span class="string">'dataset'</span>).mean()</span><br><span class="line">cv_metrics_mean</span><br></pre></td></tr></table></figure><div><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>accuracy</th>      <th>recall</th>      <th>precision</th>      <th>f1</th>      <th>mcc</th>      <th>roc_auc</th>      <th>average_precision</th>    </tr>    <tr>      <th>dataset</th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>    </tr>  </thead>  <tbody>    <tr>      <th>test</th>      <td>0.831000</td>      <td>0.794919</td>      <td>0.861380</td>      <td>0.823425</td>      <td>0.667898</td>      <td>0.903903</td>      <td>0.921943</td>    </tr>    <tr>      <th>train</th>      <td>0.833778</td>      <td>0.795302</td>      <td>0.862274</td>      <td>0.827428</td>      <td>0.669625</td>      <td>0.906041</td>      <td>0.924631</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">fig, ax = plt.subplots(figsize=(<span class="number">10</span>, <span class="number">5</span>))</span><br><span class="line">plot_data = pd.melt(cv_metrics, id_vars=[<span class="string">'dataset'</span>], var_name=<span class="string">'metric'</span>, value_name=<span class="string">'value'</span>)</span><br><span class="line">sns.stripplot(x=<span class="string">'metric'</span>, y=<span class="string">'value'</span>, hue=<span class="string">'dataset'</span>, </span><br><span class="line">              dodge=<span class="keyword">True</span>, jitter=<span class="keyword">True</span>, data=plot_data, size=<span class="number">4</span>, ax=ax)</span><br><span class="line"><span class="comment">#sns.pointplot(x='metric', y='value', hue='dataset', data=plot_data, markers="d", </span></span><br><span class="line"><span class="comment">#              join=False, ci=None, ax=ax, dodge=True, palette='dark')</span></span><br><span class="line">ax.set_title(<span class="string">'Model performance using 10-fold cross-validation'</span>)</span><br></pre></td></tr></table></figure><p><img src="http://i1.fuimg.com/640680/1b9d375bb6fba070.png" alt="Markdown"></p><h3 id="ROC-and-PR-curves"><a href="#ROC-and-PR-curves" class="headerlink" title="ROC and PR curves"></a>ROC and PR curves</h3><p>For each cross-validation run, compute an ROC/PR curve.<br>Then plot the mean and confidence intervals across cross-validation runs.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> interp</span><br><span class="line"></span><br><span class="line">fig, axes = plt.subplots(<span class="number">1</span>, <span class="number">2</span>, figsize=(<span class="number">14</span>, <span class="number">7</span>))</span><br><span class="line"><span class="comment"># ROC curve</span></span><br><span class="line">ax = axes[<span class="number">0</span>]</span><br><span class="line">all_fprs = np.linspace(<span class="number">0</span>, <span class="number">1</span>, <span class="number">100</span>)</span><br><span class="line">roc_curves = np.zeros((n_splits, len(all_fprs), <span class="number">2</span>))</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(n_splits):</span><br><span class="line">    fpr, tpr, thresholds = roc_curve(y[~is_train[i]], predicted_scores[i, ~is_train[i]])</span><br><span class="line">    roc_curves[i, :, <span class="number">0</span>] = all_fprs</span><br><span class="line">    roc_curves[i, :, <span class="number">1</span>] = interp(all_fprs, fpr, tpr)</span><br><span class="line">roc_curves = pd.DataFrame(roc_curves.reshape((<span class="number">-1</span>, <span class="number">2</span>)), columns=[<span class="string">'fpr'</span>, <span class="string">'tpr'</span>])</span><br><span class="line">sns.lineplot(x=<span class="string">'fpr'</span>, y=<span class="string">'tpr'</span>, data=roc_curves, ci=<span class="string">'sd'</span>, ax=ax,</span><br><span class="line">             label=<span class="string">'Test AUC = &#123;:.4f&#125;'</span>.format(cv_metrics_mean.loc[<span class="string">'test'</span>, <span class="string">'roc_auc'</span>]))</span><br><span class="line"><span class="comment">#ax.plot(fpr, tpr, label='ROAUC = &#123;:.4f&#125;'.format(roc_auc_score(y_test, y_score[:, 1])))</span></span><br><span class="line"><span class="comment">#ax.plot([0, 1], [0, 1], linestyle='dashed')</span></span><br><span class="line">ax.set_xlabel(<span class="string">'False positive rate'</span>)</span><br><span class="line">ax.set_ylabel(<span class="string">'True positive rate'</span>)</span><br><span class="line">ax.plot([<span class="number">0</span>, <span class="number">1</span>], [<span class="number">0</span>, <span class="number">1</span>], linestyle=<span class="string">'dashed'</span>, color=<span class="string">'gray'</span>)</span><br><span class="line">ax.set_title(<span class="string">'ROC curve'</span>)</span><br><span class="line">ax.legend()</span><br><span class="line"></span><br><span class="line"><span class="comment"># predision-recall curve</span></span><br><span class="line">ax = axes[<span class="number">1</span>]</span><br><span class="line">all_precs = np.linspace(<span class="number">0</span>, <span class="number">1</span>, <span class="number">100</span>)</span><br><span class="line">pr_curves = np.zeros((n_splits, len(all_precs), <span class="number">2</span>))</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(n_splits):</span><br><span class="line">    fpr, tpr, thresholds = precision_recall_curve(y[~is_train[i]], predicted_scores[i, ~is_train[i]])</span><br><span class="line">    pr_curves[i, :, <span class="number">0</span>] = all_precs</span><br><span class="line">    pr_curves[i, :, <span class="number">1</span>] = interp(all_precs, fpr, tpr)</span><br><span class="line">pr_curves = pd.DataFrame(pr_curves.reshape((<span class="number">-1</span>, <span class="number">2</span>)), columns=[<span class="string">'precision'</span>, <span class="string">'recall'</span>])</span><br><span class="line">sns.lineplot(x=<span class="string">'precision'</span>, y=<span class="string">'recall'</span>, data=pr_curves, ci=<span class="string">'sd'</span>, ax=ax,</span><br><span class="line">             label=<span class="string">'Test AP = &#123;:.4f&#125;'</span>.format(cv_metrics_mean.loc[<span class="string">'test'</span>, <span class="string">'average_precision'</span>]))</span><br><span class="line"></span><br><span class="line">ax.set_xlabel(<span class="string">'Precision'</span>)</span><br><span class="line">ax.set_ylabel(<span class="string">'Recall'</span>)</span><br><span class="line">ax.plot([<span class="number">0</span>, <span class="number">1</span>], [<span class="number">1</span>, <span class="number">0</span>], linestyle=<span class="string">'dashed'</span>, color=<span class="string">'gray'</span>)</span><br><span class="line">ax.set_title(<span class="string">'Precision-recall curve'</span>)</span><br><span class="line">ax.legend()</span><br></pre></td></tr></table></figure><p><img src="http://i1.fuimg.com/640680/9d2ae29ab7890051.png" alt="Markdown"></p><h2 id="Homework"><a href="#Homework" class="headerlink" title="Homework"></a>Homework</h2><ol><li><p>Understand and run all code in this tutorial using Jupyter. You can generate different types of dataset or use a real dataset.</p></li><li><p>Try different classifiers (SVC, random forest, logistic regression, KNN) and compare model performance.</p></li><li><p>Try different K’s in K-fold cross-validation and compare mean and variance of model performance.</p></li><li><p>Try different class ratios and compare model performance.</p></li></ol><h2 id="Further-reading"><a href="#Further-reading" class="headerlink" title="Further reading"></a>Further reading</h2><h3 id="Books"><a href="#Books" class="headerlink" title="Books"></a>Books</h3><ol><li>Trevor Hastie, Robert Tibshirani, Jerome Friedman. (2009). The Elements of Statistical Learning. </li><li>Christopher Bishop. (2006). Pattern Recognition and Machine Learning.</li><li>Kevin P. Murphy. (2012). Machine Learning A Probabilisitic Perspective.</li><li>Sergios Theodoridis. (2009). Pattern Recognition.</li></ol><h3 id="Class-imbalance"><a href="#Class-imbalance" class="headerlink" title="Class imbalance"></a>Class imbalance</h3><ol><li>He, H., and Garcia, E.A. (2009). Learning from Imbalanced Data. IEEE Transactions on Knowledge and Data Engineering 21, 1263–1284.</li><li>Batista, G.E.A.P.A., Prati, R.C., and Monard, M.C. (2004). A Study of the Behavior of Several Methods for Balancing Machine Learning Training Data. SIGKDD Explor. Newsl. 6, 20–29.</li><li>Chawla, N.V., Bowyer, K.W., Hall, L.O., and Kegelmeyer, W.P. (2002). SMOTE: Synthetic Minority Over-sampling Technique. J. Artif. Int. Res. 16, 321–357.</li></ol><h3 id="Machine-learning-in-R"><a href="#Machine-learning-in-R" class="headerlink" title="Machine learning in R"></a>Machine learning in R</h3><p>The <em>caret</em> package (a tutorial in GitBook): <a href="http://topepo.github.io/caret" target="_blank" rel="noopener">http://topepo.github.io/caret</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;This is one of the chapter in &lt;a href=&quot;https://lulab.gitbooks.io/teaching/content/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Bioinformatics basic course in Tsinghua University&lt;/a&gt;. You may also find it &lt;a href=&quot;https://lulab.gitbooks.io/teaching/content/part-iii.-machine-learning-basics/1.simple-machine-learning-basics.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The related &lt;a href=&quot;https://github.com/lulab/teaching_book/blob/master/part-iii.-machine-learning-basics/1.simple-machine-learning-basics.ipynb&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;jupyter file&lt;/a&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="machine learning" scheme="https://www.cmwonderland.com/blog/categories/machine-learning/"/>
    
    
      <category term="machine learning" scheme="https://www.cmwonderland.com/blog/tags/machine-learning/"/>
    
      <category term="python" scheme="https://www.cmwonderland.com/blog/tags/python/"/>
    
      <category term="bioinformatics" scheme="https://www.cmwonderland.com/blog/tags/bioinformatics/"/>
    
      <category term="teaching" scheme="https://www.cmwonderland.com/blog/tags/teaching/"/>
    
      <category term="TA" scheme="https://www.cmwonderland.com/blog/tags/TA/"/>
    
  </entry>
  
  <entry>
    <title>Teaching Book</title>
    <link href="https://www.cmwonderland.com/blog/2018/09/30/93_gitbook_book/"/>
    <id>https://www.cmwonderland.com/blog/2018/09/30/93_gitbook_book/</id>
    <published>2018-09-30T11:47:25.000Z</published>
    <updated>2018-10-10T05:02:40.212Z</updated>
    
    <content type="html"><![CDATA[<p>I have written something about bioinformatics skills as part of two books. The <a href="https://legacy.gitbook.com/book/lulab/teaching/details" target="_blank" rel="noopener">basic teaching book</a> is used to teach undergraduate students in <em>Bioinformatics Basic</em> course. I am a teaching assistant of this course this semester. The <a href="https://lulab.gitbook.io/training/" target="_blank" rel="noopener">advanced teaching book</a> is used to teach graduate student and some senior undergraduate students. </p><p>I have spent many time written several chapters of the books. For Basic teaching book I contributed more than 1/3 of the book.</p><a id="more"></a><h1 id="Basic-teaching-book"><a href="#Basic-teaching-book" class="headerlink" title="Basic teaching book"></a>Basic teaching book</h1><p>pdf???<br>网址<br>各章链接<br>github</p><h2 id="getting-started-docker"><a href="#getting-started-docker" class="headerlink" title="getting started docker"></a>getting started docker</h2><h2 id="linux"><a href="#linux" class="headerlink" title="linux"></a>linux</h2><h2 id="python"><a href="#python" class="headerlink" title="python"></a>python</h2><h2 id="machine-learning-basics"><a href="#machine-learning-basics" class="headerlink" title="machine learning basics"></a>machine learning basics</h2><h2 id="quiz"><a href="#quiz" class="headerlink" title="quiz"></a>quiz</h2><p>based on projects</p><h3 id="eMaize"><a href="#eMaize" class="headerlink" title="eMaize"></a>eMaize</h3><h3 id="exRNA"><a href="#exRNA" class="headerlink" title="exRNA"></a>exRNA</h3><h1 id="Advanced-teaching-book"><a href="#Advanced-teaching-book" class="headerlink" title="Advanced teaching book"></a>Advanced teaching book</h1><h2 id="mapping"><a href="#mapping" class="headerlink" title="mapping"></a>mapping</h2><h2 id="deep-learning"><a href="#deep-learning" class="headerlink" title="deep learning"></a>deep learning</h2>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;I have written something about bioinformatics skills as part of two books. The &lt;a href=&quot;https://legacy.gitbook.com/book/lulab/teaching/details&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;basic teaching book&lt;/a&gt; is used to teach undergraduate students in &lt;em&gt;Bioinformatics Basic&lt;/em&gt; course. I am a teaching assistant of this course this semester. The &lt;a href=&quot;https://lulab.gitbook.io/training/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;advanced teaching book&lt;/a&gt; is used to teach graduate student and some senior undergraduate students. &lt;/p&gt;
&lt;p&gt;I have spent many time written several chapters of the books. For Basic teaching book I contributed more than 1/3 of the book.&lt;/p&gt;
    
    </summary>
    
      <category term="book" scheme="https://www.cmwonderland.com/blog/categories/book/"/>
    
    
      <category term="life" scheme="https://www.cmwonderland.com/blog/tags/life/"/>
    
      <category term="book" scheme="https://www.cmwonderland.com/blog/tags/book/"/>
    
      <category term="techniques" scheme="https://www.cmwonderland.com/blog/tags/techniques/"/>
    
      <category term="teaching" scheme="https://www.cmwonderland.com/blog/tags/teaching/"/>
    
  </entry>
  
  <entry>
    <title>ECCV 2018 paper reading</title>
    <link href="https://www.cmwonderland.com/blog/2018/09/26/38_ECCV_2018/"/>
    <id>https://www.cmwonderland.com/blog/2018/09/26/38_ECCV_2018/</id>
    <published>2018-09-26T13:23:55.000Z</published>
    <updated>2018-10-10T05:01:42.012Z</updated>
    
    <content type="html"><![CDATA[<p>I mainly focus on semantic segmentation and potentially related papers.</p><a id="more"></a><h1 id="semantic-segmentation"><a href="#semantic-segmentation" class="headerlink" title="semantic segmentation"></a>semantic segmentation</h1><ul><li><p>A Dataset for Lane Instance Segmentation in Urban Environments<br>a dataset paper</p></li><li><p>BiSeNet: Bilateral Segmentation Network for Real-time Semantic Segmentation<br><em>spatial path &amp; context path to solve real time segmentation</em></p></li><li><p>ICNet for Real-Time Semantic Segmentation on High-Resolution Images<br>solve <em>real time segmentation</em></p></li><li><p>Multi-Scale Context Intertwining for Semantic Segmentation<br>a novel scheme for aggregating features from diﬀerent scales, which we refer to as MultiScale Context Intertwining (MSCI).<br>merge pairs of feature maps <em>in a bidirectional and recurrent fashion</em>, via connections between two LSTM chains. By training the parameters of the LSTM units on the segmentation task, the above approach learns how to extract powerful and eﬀective features for pixellevel semantic segmentation, which are then combined hierarchically.</p></li><li><p>Eﬃcient Semantic Scene Completion Network with Spatial Group Convolution<br>Spatial Group Convolution (SGC) for <em>accelerating the computation of 3D dense prediction</em> tasks. SGC is orthogonal to group convolution, <em>which works on spatial dimensions</em> rather than feature channel dimension. It divides input voxels into diﬀerent groups, then conducts 3D sparse convolution on these separated groups.</p></li><li><p>Adaptive Afﬁnity Fields for Semantic Segmentation<br>propose the concept of Adaptive Afﬁnity Fields (AAF) to capture and match the semantic relations between neighbouring pixels in the label space</p></li><li><p>Encoder-Decoder with Atrous Separable Convolution for Semantic Image Segmentation<br>Spatial pyramid pooling module or encode-decoder structure<br>Encoder-Decoder with Atrous Convolution<br>Depthwise separable convolution:<br>DeepLabv3 as encoder<br><a href="https: //github.com/tensorflow/models/tree/master/research/deeplab" target="_blank" rel="noopener">implementation</a></p></li><li><p>MVTec D2S: Densely Segmented Supermarket Dataset<br>a dataset paper<br>a novel benchmark for instance-aware semantic segmentation in an industrial domain, It contains 21 000 high-resolution images with pixel-wise labels of all object instances.  The objects comprise groceries and everyday products from 60 categories.</p></li><li><p>Predicting Future Instance Segmentation by Forecasting Convolutional Features</p></li><li><p>ESPNet: Efﬁcient Spatial Pyramid of Dilated Convolutions for Semantic Segmentation<br>for semantic segmentation of high resolution images under resource constraints. ESPNet is based on a new convolutional module, efﬁcient spatial pyramid (ESP), which is efﬁcient in terms of computation, memory, and power.</p></li><li><p>Penalizing Top Performers: Conservative Loss for Semantic Segmentation Adaptation<br>a novel loss function, i.e., Conservative Loss, which penalizes the extreme good and bad cases while encouraging the moderate examples. More speciﬁcally, it enables the network to learn features that are discriminative by gradient descent and are invariant to the change of domains via gradient ascend method.</p></li><li><p>Aﬃnity Derivation and Graph Merge for Instance Segmentation<br>In our scheme, we use two neural networks with similar structures. One predicts the pixel level semantic score and the other is designed to derive pixel aﬃnities. Regarding pixels as the vertexes and aﬃnities as edges, we then propose a simple yet eﬀective graph merge algorithm to cluster pixels into instances.</p></li><li><p>ExFuse: Enhancing Feature Fusion for Semantic Segmentation<br>In this paper, we ﬁrst point out that a simple fusion of low-level and high-level features could be less eﬀective because of the gap in semantic levels and spatial resolution. We ﬁnd that introducing semantic information into low-level features and high-resolution details into high-level features is more eﬀective for the later fusion. Based on this observation, we propose a new framework, named ExFuse, to bridge the gap between low-level and high-level features thus signiﬁcantly improve the segmentation quality by 4.0% in total.</p></li><li><p>Deep Clustering for Unsupervised Learning of Visual Features<br>a clustering method that jointly learns the parameters of a neural network and the cluster assignments of the resulting features. DeepCluster iteratively groups the features with a standard clustering algorithm, kmeans, and uses the subsequent assignments as supervision to update the weights of the network.</p></li><li><p>Bidirectional Feature Pyramid Network with Recurrent Attention Residual Modules for Shadow Detection<br>recurrent attention residual (RAR) module to combine the contexts in two adjacent CNN layers and learn an attention map to select a residual and then reﬁne the context features. Second, we develop a bidirectional feature pyramid network (BFPN) to aggregate shadow contexts spanned across diﬀerent CNN layers by deploying two series of RAR modules in the network to iteratively combine and reﬁne context features: one series to reﬁne context features from deep to shallow layers, and another series from shallow to deep layers<br>better suppress false detections and enhance shadow details at the same time.</p></li><li><p>Multi-scale Residual Network for Image Super-Resolution<br>a novel multiscale residual network (MSRN) to fully exploit the image features, which outperform most of the state-of-the-art methods. Based on the residual block, we introduce convolution kernels of diﬀerent sizes to adaptively detect the image features in diﬀerent scales. Meanwhile, we let these features interact with each other to get the most eﬃcacious image information, we call this structure Multi-scale Residual Block (MSRB). Furthermore, the outputs of each MSRB are used as the hierarchical features for global feature fusion.</p></li></ul><ul><li>Predicting Future Instance Segmentation by Forecasting Convolutional Features<br>For video next frame prediction</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;I mainly focus on semantic segmentation and potentially related papers.&lt;/p&gt;
    
    </summary>
    
      <category term="machine learning" scheme="https://www.cmwonderland.com/blog/categories/machine-learning/"/>
    
    
      <category term="deep learning" scheme="https://www.cmwonderland.com/blog/tags/deep-learning/"/>
    
      <category term="techniques" scheme="https://www.cmwonderland.com/blog/tags/techniques/"/>
    
      <category term="paper reading" scheme="https://www.cmwonderland.com/blog/tags/paper-reading/"/>
    
  </entry>
  
  <entry>
    <title>Deep Learning in Medical Image</title>
    <link href="https://www.cmwonderland.com/blog/2018/08/16/95_medical_image_project/"/>
    <id>https://www.cmwonderland.com/blog/2018/08/16/95_medical_image_project/</id>
    <published>2018-08-16T11:03:19.000Z</published>
    <updated>2018-10-11T11:26:34.939Z</updated>
    
    <content type="html"><![CDATA[<p>I always have a strong interests in applying deep learning models to medical images analysis. I have two projects related to medical image analysis using deep learning. During the projects I tried to experience the whole pipeline: </p><ul><li>collect data from hospitals and open source database</li><li>clean data and organize information</li><li>learn experience from doctors, develop models and consider about its reliability.</li></ul><p>As a student from life science background with machine learning and deep learning skills, I have a broader mind to think about medical image problems from different views. From my perspectives, deep learning aided medical image analysis will soon have a wide range of application. </p><h1 id="Work-Summary"><a href="#Work-Summary" class="headerlink" title="Work Summary"></a>Work Summary</h1><h2 id="X-ray-image-for-heart-disease-analysis"><a href="#X-ray-image-for-heart-disease-analysis" class="headerlink" title="X-ray image for heart disease analysis"></a>X-ray image for heart disease analysis</h2><div class="row">    <embed src="https://arxiv.org/pdf/1808.08277.pdf" width="100%" height="550" type="application/pdf"></div><h2 id="CT-images-for-lung-disease-analysis"><a href="#CT-images-for-lung-disease-analysis" class="headerlink" title="CT images for lung disease analysis"></a>CT images for lung disease analysis</h2><div class="row"><iframe src="https://drive.google.com/file/d/1L6WLM41eIwzIi1NB6x8X6UrChYFtH_2u/preview" style="width:100%; height:550px"></iframe></div><p>We propose some change to analyze the image. For example we propose to use U-net to segment heart mask first. Force the classification model to pay more attention to heart region to make the model more reliable.</p><p>For segmentation task, it is suggested to use DICE coefficient. However, it is really hard to use DICE loss to optimize model. We make some changes to DICE loss to restrict the predicted region.</p><div class="row"><iframe src="https://drive.google.com/file/d/1VE2Ni3iAJLEtiMks2WmuT-uqamUaqxt-/preview" style="width:100%; height:550px"></iframe></div><h1 id="codes"><a href="#codes" class="headerlink" title="codes"></a>codes</h1><p><a href="https://github.com/james20141606/Summer_Intern" target="_blank" rel="noopener">3D deep learning model for lung disease CT images</a><br><a href="https://github.com/james20141606/CardiacAI" target="_blank" rel="noopener">X-ray heart disease image classification</a></p><h1 id="related"><a href="#related" class="headerlink" title="related:"></a>related:</h1><ul><li>X-ray image for heart disease analysis is under the instruction of <a href="http://www.cs.tsinghua.edu.cn/publish/cs/4616/2013/20130423133349415867263/20130423133349415867263_.html" target="_blank" rel="noopener">Hongliang Yu</a> in a student research training program. With fundings of $20,000</li><li>X-ray image for heart disease analysis also wins second prize in <strong>The First National College Students’ Brain Computation and Application Competition</strong>.</li><li>CT image analysis is under the construction of <a href="http://www.au.tsinghua.edu.cn/publish/au/1714/2011/20110323105408606814635/20110323105408606814635_.html" target="_blank" rel="noopener">Professor Xuegong Zhang</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;I always have a strong interests in applying deep learning models to medical images analysis. I have two projects related to medical imag
      
    
    </summary>
    
      <category term="projects" scheme="https://www.cmwonderland.com/blog/categories/projects/"/>
    
    
      <category term="project" scheme="https://www.cmwonderland.com/blog/tags/project/"/>
    
      <category term="deep learning" scheme="https://www.cmwonderland.com/blog/tags/deep-learning/"/>
    
      <category term="computer vision" scheme="https://www.cmwonderland.com/blog/tags/computer-vision/"/>
    
      <category term="research" scheme="https://www.cmwonderland.com/blog/tags/research/"/>
    
      <category term="medical image" scheme="https://www.cmwonderland.com/blog/tags/medical-image/"/>
    
  </entry>
  
  <entry>
    <title>Synaptic Partner and Cluster Project</title>
    <link href="https://www.cmwonderland.com/blog/2018/07/14/97_summerintern_Synaptic_Partner_and_Cluster_Project/"/>
    <id>https://www.cmwonderland.com/blog/2018/07/14/97_summerintern_Synaptic_Partner_and_Cluster_Project/</id>
    <published>2018-07-14T15:58:06.000Z</published>
    <updated>2018-10-11T08:36:56.065Z</updated>
    
    <content type="html"><![CDATA[<p>It is part of my computational task during my summer intern in <a href="https://lichtmanlab.fas.harvard.edu/" target="_blank" rel="noopener">Lichtman Lab</a> and <a href="https://vcg.seas.harvard.edu/people" target="_blank" rel="noopener">Hanspiter Lab</a>.</p><p>It is part of the big synapse project. Also the challenge 3 of <a href="https://cremi.org" target="_blank" rel="noopener">CREMI</a></p><p>For <strong>whole work summary</strong> please <a href="https://www.cmwonderland.com/blog/2018/09/12/100_summer_intern/">see here</a></p><div class="row"><iframe src="https://drive.google.com/file/d/1XyEPj9r7p8VNk5nLlLIPNhZjuDHu2KTY/preview" style="width:100%; height:550px"></iframe></div><p>Also I finished another NMJ project during summer intern in <a href="https://lichtmanlab.fas.harvard.edu/" target="_blank" rel="noopener">Lichtman Lab</a> </p><h1 id="Codes"><a href="#Codes" class="headerlink" title="Codes"></a>Codes</h1><ul><li><a href="https://github.com/james20141606/Summer_Intern/tree/master/synapse_prediction" target="_blank" rel="noopener">Summer_Intern/synaptic_partner at master · james20141606/Summer_Intern · GitHub</a></li><li><a href="https://github.com/james20141606/EM-network" target="_blank" rel="noopener">Synapse polarity</a></li><li><a href="https://github.com/james20141606/Summer_Intern/tree/master/synapse_cluster" target="_blank" rel="noopener">Summer_Intern/synapse_cluster at master · james20141606/Summer_Intern · GitHub</a></li></ul><a id="more"></a><h1 id="weekly-report"><a href="#weekly-report" class="headerlink" title="weekly report"></a>weekly report</h1><h2 id="First"><a href="#First" class="headerlink" title="First"></a>First</h2><div class="row"><iframe src="https://drive.google.com/file/d/1bmWX9M1aTgOw7YB9xrnUNynWfxuoa_Rz/preview" style="width:100%; height:550px"></iframe></div><h2 id="Second"><a href="#Second" class="headerlink" title="Second"></a>Second</h2><div class="row"><iframe src="https://drive.google.com/file/d/1OOaFajkLcwQBEf1XQuEIYqFAkl9psPrt/preview" style="width:100%; height:550px"></iframe></div><h2 id="Third"><a href="#Third" class="headerlink" title="Third"></a>Third</h2><div class="row"><iframe src="https://drive.google.com/file/d/1We4g3Ltd2gqzmICoLtKFKsL-2zP2BVeV/preview" style="width:100%; height:550px"></iframe></div><h2 id="Fourth"><a href="#Fourth" class="headerlink" title="Fourth"></a>Fourth</h2><div class="row"><iframe src="https://drive.google.com/file/d/19zhoBM6GP94a-bNj7bFIZdExC0x6yw_2/preview" style="width:100%; height:550px"></iframe></div><hr><h1 id="first-two-weeks"><a href="#first-two-weeks" class="headerlink" title="first two weeks"></a>first two weeks</h1><h2 id="creteria"><a href="#creteria" class="headerlink" title="creteria"></a>creteria</h2><p>I try to understand the task3, I read through metrics provided by CREMI website, and find the data processing and evaluation scripts provided by Cremi organization.<br><a href="https://github.com/cremi/cremi_python/blob/master/cremi/evaluation/synaptic_partners.py" target="_blank" rel="noopener">cremi_python/synaptic_partners.py at master · cremi/cremi_python · GitHub</a>. </p><p>They made it very hard to use their pipeline to store and process data. Since we have our own pipeline, I only use the core function about evaluation. By rewriting the scripts I understand how to calculate F-score, it is harder to fully understand the criteria since it needs many steps to calculate, so it is essential to read the original scripts.</p><p>I have summarized the metrics and show it to zudi and donglai.</p><p><img src="http://i2.tiimg.com/640680/ad617dc9489cb429.png" alt="Markdown"></p><p>This means we need the location data and neuron_id for wrong partner evaluation</p><h3 id="steps-to-calculate-F-score"><a href="#steps-to-calculate-F-score" class="headerlink" title="steps to calculate F-score"></a>steps to calculate F-score</h3><ul><li>cost_matrix :<ul><li>pre_post_locations get pre and post location，may consider offset shift       get rec and gt location</li><li>pre_post_labels  get pre and post segmentation( GT neuron_id) as rec_labels  segmentation[pre]  return the pixel value of a certain coordinates for further comparison of wrong partners for further comparison of wrong partners</li><li>create cost matrix，find the bigger one of rec and gt location as matrix size  init value is  2*matching_threshold</li><li>use cost function to calculate, for every rec and gt pair, input rec_locations[i], gt_locations[j], rec_labels[i], gt_labels[j], matching_threshold</li><li>in cost function, set max_cost = 2*matching_threshold，fisrt if labels1 != labels2(rec_labels[i], gt_labels[j]), from pre_post_labels we can know rec and gt comes from different segmentation(neuron).return max_cost</li><li>cost function continue, use np.linalg.norm to calculate pre and post L2 distance, if any of it is larger than thres, return max_cost. Else return average of pre and post. i.e. if  wrong partner (rec and gt not in same seg),  or FP: succeed thres</li><li>if none of them happens, return average of pre and post</li><li>return to cost_matrix, if distance less than thres, add potential pair count by 1, through loop, cost_matrix is filled with numbers, but the loop traverse rec_locations，gt_locations, positions not traverseed is max_cost</li></ul></li><li>match using Hungarian method<blockquote><p>All detected pairs that have both annotations inside the matching areas of a ground truth pair are considered potential matches. Of all potential matches, we find true matches by solving an assignment problem minimizing the Euclidean distance. Unmatched detected pairs are considered FP, unmatched ground truth pairs FN. The final score is the F1-score of the FPs and FNs.</p><ul><li>use linear_sum_assignment(costs - np.amax(costs) - 1)  np.amax(costs) almost is max_cost(2*matching_threshold)<ul><li>scpiy的linear<em>sum_assignment <strong>solves assign problems</strong>, which is one of the tricky part in this criteria.<br>let X be a boolean matrix where X[i,j] =1 if row i is assigned to column j. Then the optimal assignment has cost $$min \sum_i \sum_j C</em>{ij}X_{ij}$$, it finds the minimum Euclidean distance in all potential pairs. So we can submit all locations in a random way, it doesn’t matter.<ul><li>retain the assigned pairs by distance less than threshold</li></ul></li></ul></li></ul></blockquote></li><li>unmatched in rec = FP，all pairs detected by models subtracted by cost matrix’s pairs are FP</li><li>unmatched in gt = FN，all GT pairs subtracted by cost matrix’s pairs are FN</li><li>all ground truth elements - FN = TP</li><li>Then we can calculate fscore, precision, recall, fp, fn, filtered_matches</li></ul><h2 id="Study-others’-methods"><a href="#Study-others’-methods" class="headerlink" title="Study others’ methods"></a>Study others’ methods</h2><h4 id="1st-place"><a href="#1st-place" class="headerlink" title="1st place"></a>1st place</h4><p>Last month Funkey put a paper <strong>Synaptic partner prediction from point annotations in insect brains</strong> it is the  top in leaderboard method. They combined synapse detection and partner identification into one steps. They train a 3D Unet，directly predict directed edges formed by voxels. Balance computational resource and coverage of synaptic partner. Then calculate score of all edges from one segment to another segment. Threshold and certify candidate synapse，for candidate synapse, calculate the mass center of all related edges, getting coordinates of synapse’s pre and post.</p><ul><li>3D U-Net architecture to directly identify pairs of voxels that are pre- and postsynaptic to each other</li><li>formulate the problem of synaptic partner identiﬁcation as a classiﬁcation problem on long-range edges between voxels to encode <strong>both the presence of a synaptic pair and its direction</strong>. This formulation allows us to <strong>directly learn from synaptic point annotations</strong> instead of more expensive voxel-based synaptic cleft or vesicle annotations.</li><li>The proposed representation also allows us to learn from synaptic point annotations only, since we do not rely on labeled synaptic features, such as synaptic clefts or vesicle clouds.</li></ul><p>From fig 1we can have a connectome matrix, actually it is what the evaluation scripts do(they are written by funkey group too.)</p><h4 id="2nd-place-by-previous-postdoc-in-Hanspeter-group"><a href="#2nd-place-by-previous-postdoc-in-Hanspeter-group" class="headerlink" title="2nd place by previous postdoc in Hanspeter group"></a>2nd place by previous postdoc in Hanspeter group</h4><p>Use 3D convolutional neural network for two steps.<br>3D U-net+3D CNN, Use 3D U-net to learn labels by formulate a function, then prune it by 3D CNN<br><a href="https://www.dropbox.com/s/vug579prnxt454n/miccai18syn.pdf?dl=0" target="_blank" rel="noopener">https://www.dropbox.com/s/vug579prnxt454n/miccai18syn.pdf?dl=0</a><br>学习代码<a href="https://github.com/paragt/EMSynConn" target="_blank" rel="noopener">GitHub - paragt/EMSynConn: One algorithm to detect synaptic location AND connectivity, both dyadic and polyadic, in Electron Microscopy volume.</a></p><h4 id="4th-place-FN-is-good"><a href="#4th-place-FN-is-good" class="headerlink" title="4th place, FN is good"></a>4th place, FN is good</h4><p>Use Asymmetric Unet<br><a href="https://github.com/nicholasturner1/Synaptor" target="_blank" rel="noopener">GitHub - nicholasturner1/Synaptor: Processing voxelwise Convolutional Network output trained to predict synaptic clefts for connectomics</a></p><h2 id="Cluster"><a href="#Cluster" class="headerlink" title="Cluster"></a>Cluster</h2><p>I did some data visualization for cerebellum and CREMI data which will be used in clustering work. Also implement some computer vision algorithm for feature extraction.<a href="https://github.com/james20141606/Summer_Intern/blob/master/synapse_cluster/jupyter/visualize_cerebellum_sample.ipynb" target="_blank" rel="noopener">visualize cerebellum</a></p><p>I am considering to use deep learning based clustering methods, to do feature selection and clustering simultaneously. Also it is essential to consider model interpretability. </p><p>Resources: <a href="http://elektronn.org/" target="_blank" rel="noopener">ELEKTRONN - Convolutional Neural Network Toolkit in Python. Fast GPU acceleration and easy usage.</a> is used for generate skeletons using deep learning.</p><hr><p> Week 3<br>The main focus of week 3 is on NMJ labeling and synapse prediction project. So the progress of clustering and synaptic partner project is not much.</p><h2 id="cluster"><a href="#cluster" class="headerlink" title="cluster"></a>cluster</h2><p>I have further considered <strong>clustering</strong>  project. Since we will have a huge amount of data to cluster, it is a natural thought to use deep learning based clustering method, which I have mentioned last time. After discussion with donglai and zudi, they also agree we can use a (variational) auto-encoder to cluster and analyze the synapse. If have time, I may try 3D VAE to cluster the synapse, but it need some preprocessing work. We may at first align and rotate the 2D image for better results.</p><p>I have read some papers including<br><a href="https://arxiv.org/pdf/1610.07584.pdf" target="_blank" rel="noopener">Learning a Probabilistic Latent Space of Object Shapes via 3D Generative-Adversarial Modeling</a><br><a href="https://arxiv.org/pdf/1801.07648.pdf" target="_blank" rel="noopener">Clustering with Deep Learning:Taxonomy and New Methods</a></p><p>Which I thought will be useful</p><h2 id="synaptic-partner"><a href="#synaptic-partner" class="headerlink" title="synaptic partner"></a>synaptic partner</h2><p>I have read and summarized some paper and codes last week on synaptic partner project. This week zudi and I discuss about previous work’s strategy. We have decided that I read and study the synaptic partner codes written by a previous postdoc. </p><p>Now the codes is incomplete in github, later we may get the complete codes. The codes isn’t in a very good structure, and task 3 is harder and more complex than synapse prediction, so it will take me some time to fully understand the codes and make more improvements on it.</p><hr><h1 id="Week-4"><a href="#Week-4" class="headerlink" title="Week 4"></a>Week 4</h1><h2 id="synaptic-partner-1"><a href="#synaptic-partner-1" class="headerlink" title="synaptic partner"></a>synaptic partner</h2><p>This week we mainly focus on task 3, synaptic partner prediction, this is a new and more challenging task for us. Previously we never try to predict synaptic partner, so we have to understand this task and process the raw data to get the train label.</p><h3 id="Align-and-process-location-to-create-training-labels"><a href="#Align-and-process-location-to-create-training-labels" class="headerlink" title="Align and process location to create training labels"></a>Align and process location to create training labels</h3><p>I study and understand the synaptic partner’s identification criterion and process the location value in the same alignment steps with raw and clefts image.</p><ul><li>extract location and pre-post id, put these points in a volume</li><li>align the volume, padding and deal with bad slices using same strategy </li></ul><p>location is only point id, we can shift the point by first draw the point in zero array and then extract location. Each point use pre and post id to trace back. The premise is location and clefts matches, I have checked it.</p><p><img src="http://i1.fuimg.com/640680/db4521d532057170.png" alt="Markdown"></p><p><img src="http://i1.fuimg.com/640680/239c484ca9b1ab55.png" alt="Markdown"></p><p>Codes:</p><ul><li>alignment matlab script<br><a href="https://github.com/james20141606/Summer_Intern/blob/master/synaptic_partner/bin/T_align.m" target="_blank" rel="noopener">Summer_Intern/T_align.m at master · james20141606/Summer_Intern · GitHub</a><br>This script can align raw, clefts and location and reverse them</li><li>jupyter<br>Deal with pre and post processing of locations array.<br><a href="https://github.com/james20141606/Summer_Intern/blob/master/synaptic_partner/jupyter/cremi_shift.ipynb" target="_blank" rel="noopener">Summer_Intern/cremi_shift.ipynb at master · james20141606/Summer_Intern · GitHub</a></li></ul><p><strong>visualize shift results</strong></p><p><img src="http://i1.fuimg.com/640680/c6241b5b0bf7630b.png" alt="Markdown"></p><p>I also find that in A, B, C three volumes, the partner numbers differ a lot:432, 1324, 2276<br>But clefts numbers are similar:123, 131, 165</p><p>The align work needs many patience, I did it over ten times to ensure it is 100 percent right. The axis, scatter and imshow tradition and many steps process made it easy to make mistakes. At last I found that it is best to dilate the points in location array and visualize it using imshow uniformly to check the alignment.</p><h3 id="Synaptic-partner-identification-model"><a href="#Synaptic-partner-identification-model" class="headerlink" title="Synaptic partner identification model"></a>Synaptic partner identification model</h3><p>The model can be derived from synapse identification model. We also use 3D U-net and add some changes. We study Funke’s previous work, it has some strengths and drawbacks.</p><p>For example, they use 14 vectors to represent all possible partner vectors. And the model predict a 14 channel one-hot vector. But this methods deliberately overfits on CREMI datasets. Since we would like to develop a model to predict synaptic partners on JWR datasets, we should use a more generalized methods. But the searching space will increase a lot.</p><ul><li>dilate location point<br>for each points(so it can specify location)</li><li>Generate 4 channel output (binary, Z, Y, X)<br>binary for <strong>localization</strong>, and Z, Y, X for vector <strong>orientation</strong><br>We will use cosine loss to evaluate orientation<br>So this can be considered as a multi task training</li><li>use branched model to predict two parts<br>Output mask and vector separately.<br>A very natural thought is we can design the model further to multiply the binary channel to the orientation part as <strong>Attention mechanism</strong>, the two branched models can share weights. I use a similar architecture in another project and it works well</li></ul><p>It is hard to both predict orientation and length. So maybe we can do post-processing work: we only predict orientation, and calculate the distance from pre synapse to clefts, and add the distance to produce post synapse location.</p><h3 id="Hacking-toufiq’s-codes"><a href="#Hacking-toufiq’s-codes" class="headerlink" title="Hacking toufiq’s codes:"></a>Hacking toufiq’s codes:</h3><p>I also try to study and understand Toufiq’s work. I found Toufiq and Lee has done a lot on task 3 and related synapse work. They have some valuable work and codes to be recovered. So I try to find something useful to use. </p><p>They have a github  repo which has many useful codes for synapses. It even has codes for finding seeds etc. <a href="https://github.com/microns-ariadne/pipeline_engine/" target="_blank" rel="noopener">GitHub - microns-ariadne/pipeline_engine: reconstruction pipeline</a></p><p>Prediction of pre and post and segmentation(pre and post is self-labeled and segmentation is predicted) and clefts(ground truth in original dataset)</p><p><img src="http://i1.fuimg.com/640680/44ce375316d09d8a.png" alt="Markdown"></p><p>use binary dilation for gt-syn<br>Use segment_vesicle_style function</p><h2 id="Synapse-cluster"><a href="#Synapse-cluster" class="headerlink" title="Synapse cluster"></a>Synapse cluster</h2><p>Help siyan with 3D skeleton. Direct 3D skeleton isn’t very good since the distance of sections (30/40 nm) is a little long. Direct interpolation or dilation also works badly.</p><p>So I try a ICP and KNN algorithm to maximize matching of two 2D contours and find the nearest neighbor of each point in two neighbor contour. This idea originate from calculating the volume size of a 3D object. After finding each points neighbor, we can do linear interpolation to create another 9 sections for better 3D skeleton.  </p><p>Codes:<br><a href="https://github.com/james20141606/Summer_Intern/blob/master/synapse_cluster/jupyter/ICP_KNN.ipynb" target="_blank" rel="noopener">Summer_Intern/ICP_KNN.ipynb at master · james20141606/Summer_Intern · GitHub</a></p><hr><h1 id="Week-5-amp-6"><a href="#Week-5-amp-6" class="headerlink" title="Week 5 &amp; 6"></a>Week 5 &amp; 6</h1><h2 id="Cluster-1"><a href="#Cluster-1" class="headerlink" title="Cluster"></a>Cluster</h2><p>Use auto encoder to reconstruct synapse and cluster the latent variable. Generate missing slides, intensity, rotation, elastic to force auto-encoder learn</p><p>I also find a paper by FAIR:  Deep Clustering for Unsupervised Learning of Visual Features <a href="https://arxiv.org/pdf/1807.05520v1.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1807.05520v1.pdf</a>, it proposed an end-to-end method using  deep learning for clustering. They test it on  ImageNet and outperforms the current model. Maybe it is also useful in our datasets too.</p><h2 id="Synaptic-partner"><a href="#Synaptic-partner" class="headerlink" title="Synaptic partner"></a>Synaptic partner</h2><h3 id="Run-and-test-a-model-to-predict-synapse-and-synaptic-partner-simultaneously"><a href="#Run-and-test-a-model-to-predict-synapse-and-synaptic-partner-simultaneously" class="headerlink" title="Run and test a model to predict synapse and synaptic partner simultaneously"></a>Run and test a model to predict synapse and synaptic partner simultaneously</h3><p>I try to understand toufiq’s paper <a href="https://arxiv.org/pdf/1807.02739.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1807.02739.pdf</a> Detecting Synapse Location &amp; Connectivity by Signed Proximity Estimation and Pruning with Deep Nets. And rebuild the model using Keras. So we can have two different kinds of models to solve the <strong>synaptic partner problems</strong>. One is discussed before, and the other is toufiq’s model. We will compare this two model and take the advantages of two models to get better performance on CREMI.</p><p>I  rewrite and modify toufiq’s model using our data and understand his solutions about synaptic partner problems.<br>I apply multiple changes to the model.</p><ul><li>Change keras backend from theano to tensorflow and modify the corresponding codes.</li><li>Change depraceted function and update codes.</li><li>Change merge to concatenate, update model, conv3D </li></ul><p>The model looks like this:</p><p><img src="http://i4.fuimg.com/640680/14407c5eb5a7dc2e.png" alt="Markdown"></p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">THEANO_FLAGS=device=cuda<span class="variable">$1</span>,floatX=float32,dnn.enabled=True,dnn.library_path=<span class="regexp">/n/</span>home05<span class="regexp">/paragt/</span>cuda<span class="regexp">/lib64,dnn.include_path=/</span>n<span class="regexp">/home05/</span>paragt<span class="regexp">/cuda/i</span>nclude python -u  bin<span class="regexp">/vertebrate/</span>pixel<span class="regexp">/unet_3d_valid_unnorm_leaky_f24.py --trial=kasthuri_synapse_polarity_full_linear_leaky_f24_316_32 --imagedir=/</span>n<span class="regexp">/coxfs01/</span>paragt<span class="regexp">/test_submit/</span>ecs_synapse_polarity_full<span class="regexp">/grayscale_maps2_ac4/</span>  --gtname=<span class="regexp">/n/</span>coxfs01<span class="regexp">/paragt/</span>test_submit<span class="regexp">/ecs_synapse_polarity_full/</span>ac4_syn_polarity_both_corrected.h5 --ft=<span class="number">0</span></span><br></pre></td></tr></table></figure><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">module <span class="keyword">load</span> cuda/<span class="number">9.0</span>-fasrc01</span><br><span class="line"><span class="keyword">module</span> <span class="keyword">load</span> cudnn/<span class="number">7.0</span><span class="number">.3</span>-fasrc02</span><br><span class="line"><span class="keyword">module</span> <span class="keyword">load</span> Anaconda</span><br><span class="line"><span class="keyword">source</span> ~/anaconda2/<span class="keyword">bin</span>/<span class="keyword">activate</span> kears_theano</span><br><span class="line"></span><br><span class="line">THEANO_FLAGS=device=cuda,floatX=float32,dnn.enabled=<span class="literal">True</span> python -u test_pixelwise.py <span class="comment">--imagedir test_data/grayscale_maps_half/ --savename test_data/jwr_pixelwise_polarity.h5 --modelname models/3D_unet_jwr_synapse_polarity_half_linear_leaky_f24_316_32_100000.json --weightname models/3D_unet_jwr_synapse_polarity_half_linear_leaky_f24_316_32_100000_weights.h5</span></span><br></pre></td></tr></table></figure><p><img src="http://i4.fuimg.com/640680/2a531757ef1d035b.png" alt="Markdown"></p><h3 id="post-processing"><a href="#post-processing" class="headerlink" title="post processing"></a>post processing</h3><p>Toufiq has many post processing methods and it will be useful to process our prediction. So I study his codes and implement them.</p><p>dilate gt-syn to have bigger region</p><p><img src="http://i4.fuimg.com/640680/9cd40ceb9e49ebe8.png" alt="Markdown"></p><p><img src="http://i4.fuimg.com/640680/cb94994ad0869007.png" alt="Markdown"></p><p>some functions in<br><a href="https://github.com/microns-ariadne/pipeline_engine" target="_blank" rel="noopener">https://github.com/microns-ariadne/pipeline_engine</a></p><ul><li>segment_vesicle_style<br>Segment according to the “Vesicle” algorithm  See<br><a href="http://arxiv.org/abs/1403.3724" target="_blank" rel="noopener">http://arxiv.org/abs/1403.3724</a><br>VESICLE: Volumetric Evaluation of  Synaptic Interfaces using Computer Vision at Large Scale</li></ul><p>Volumetric Evaluation of Synaptic Interfaces using Computer vision at Large Scale<br>Segment according to the “Vesicle” algorithm</p><p><img src="http://i4.fuimg.com/640680/abd068c68b9d05f6.png" alt="Markdown"></p><p>It seems the algorithm  <strong>segment_vesicle_style</strong> do some post processing to <strong>smooth the results</strong></p><ul><li>match_synapses_by_overlap(gt_syn_np, syn_seg)<br>Determine the <strong>best ground truth synapse for a detected synapse by overlap</strong>,  <strong>gt_syn_np</strong>: dilated gt synapse, <strong>syn_seg</strong>: post processed prediction<br>Return two vectors. <ul><li>The first vector is the matching label in d for each gt label (with zero for “not a match”). </li><li>The second vector is the matching label in gt for each detected label.</li></ul></li></ul><p>interactively show blend of EM and dilated prediction</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">def draw_synseg(idx):</span><br><span class="line">    fig,<span class="attribute">ax</span>=plt.subplots(1,figsize=(8,8))</span><br><span class="line">    pylab.imshow(img[idx], <span class="attribute">cmap</span>=<span class="string">'gray'</span>)</span><br><span class="line">    pylab.imshow(gt_syn_np[idx], <span class="attribute">cmap</span>=<span class="string">'tab20'</span>, <span class="attribute">alpha</span>=.3)</span><br><span class="line">    pylab.colorbar()</span><br><span class="line">    pylab.show()</span><br><span class="line">interact(draw_synseg, idx=(0, 144))</span><br></pre></td></tr></table></figure><p>Dilated GT</p><p><img src="http://i4.fuimg.com/640680/78d027d947270dee.png" alt="Markdown"></p><p>post processed prediction</p><p><img src="http://i4.fuimg.com/640680/1f61c116cc41a292.png" alt="Markdown"></p><hr><p>Last three weeks<br>Week 7,8,9 (10)</p><p>Continue to improve synaptic partners model. It first uses a 3D U-net  to generates candidate synaptic connections from voxel-wise predictions of signed proximities. A second 3D CNN then prunes the set of candidates to produce the final detection of cleft and polar. </p><p>The U-net first generates candidate with many false positives</p><p><img src="http://i1.fuimg.com/640680/1da2e8575a992b08.png" alt="Markdown"></p><p>Then the 3D CNN uses EM image, predicted candidate and segmentation to classify if a candidate is a syanpse or not.</p><p><img src="http://i1.fuimg.com/640680/2216275efd0ce764.png" alt="Markdown"></p><hr><h4 id="use-bin-vertebrate-pixel-test-py-to-generate-candidate"><a href="#use-bin-vertebrate-pixel-test-py-to-generate-candidate" class="headerlink" title="use bin/vertebrate/pixel/test.py to generate candidate"></a>use bin/vertebrate/pixel/test.py to generate candidate</h4><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">THEANO_FLAGS=device=cuda<span class="variable">$1</span>,floatX=float32,dnn.enabled=True,dnn.library_path=<span class="regexp">/n/</span>home05<span class="regexp">/paragt/</span>cuda<span class="regexp">/lib64,dnn.include_path=/</span>n<span class="regexp">/home05/</span>paragt<span class="regexp">/cuda/i</span>nclude python -u bin<span class="regexp">/vertebrate/</span>pixel<span class="regexp">/test.py --imagedir  vol3_pngspad/</span> --savename jwrprediction<span class="regexp">/jwr_pixelwise_polarity_vol3.h5 --modelname models/</span><span class="number">3</span>D_unet_jwr_synapse_polarity_half_linear_leaky_f24_316_32_100000.json --weightname models<span class="regexp">/3D_unet_jwr_synapse_polarity_half_linear_leaky_f24_316_32_100000_weights.h5</span></span><br></pre></td></tr></table></figure><p>test_pixel_wise.py 是bin/vertebrate/pixel/test.py</p><ul><li>imagedir  /n/coxfs01/xupeng/projects/EMSynConn-master/vol3_image</li><li>imagedir   /zudi_data/jwr-test/grayscale_maps_half/image_00105.png</li><li>savename </li><li>modelname   JWR_annotation/trained_models/Toufiq/keras1/3D_unet_jwr_synapse_polarity_half_linear_leaky_f24_316_32_100000.json</li><li>weightname  JWR_annotation/trained_models/Toufiq/keras1/3D_unet_jwr_synapse_polarity_half_linear_leaky_f24_316_32_100000_weights.h5</li></ul><p>Must keep the following parameters, so we should do padding on jwr data.</p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">patchSize</span> = <span class="number">316</span></span><br><span class="line"><span class="attr">patchSize_out</span> = <span class="number">228</span></span><br><span class="line"><span class="attr">patchZ</span> = <span class="number">32</span></span><br><span class="line"><span class="attr">patchZ_out</span> = <span class="number">4</span></span><br></pre></td></tr></table></figure><h4 id="8-28-CNN"><a href="#8-28-CNN" class="headerlink" title="8.28 CNN"></a>8.28 CNN</h4><h5 id="Step1"><a href="#Step1" class="headerlink" title="Step1"></a>Step1</h5><p>Test.py in <strong>bin/candidate/pixel/test.py</strong></p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/bin/bash</span></span><br><span class="line"><span class="comment"># add all other SBATCH directives here...</span></span><br><span class="line"><span class="comment">#SBATCH -p seas_dgx1 </span></span><br><span class="line"><span class="comment">#SBATCH --gres=gpu:1</span></span><br><span class="line"><span class="comment">#SBATCH -n 1 # Number of cores</span></span><br><span class="line"><span class="comment">#SBATCH -N 1 # Ensure that all cores are on one machine                        </span></span><br><span class="line"><span class="comment">#SBATCH --mem=60000</span></span><br><span class="line"><span class="comment">#SBATCH -t 3-0:00:00</span></span><br><span class="line"><span class="comment">#SBATCH -o jwr_candidate_prune.log</span></span><br><span class="line"></span><br><span class="line"><span class="attribute">pred_thd_start</span>=-0.5</span><br><span class="line"><span class="attribute">iteration_start</span>=21500</span><br><span class="line"><span class="keyword">for</span> ((<span class="attribute">imultiple</span>=0;imultiple&lt;20;imultiple++));</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">    <span class="attribute">iteration1</span>=`echo <span class="variable">$iteration_start</span> + 500*<span class="variable">$imultiple</span> | bc -l`</span><br><span class="line"><span class="attribute">model_name</span>=kasthuri_val_seg_trial_0.3_o100_leaky_f24_160_16_122K_unbiased/syn_prune_kasthuri_val_seg_trial_0.3_o100_leaky_f24_160_16_122K_unbiased_$&#123;iteration1&#125;.json</span><br><span class="line">    <span class="attribute">weightname</span>=kasthuri_val_seg_trial_0.3_o100_leaky_f24_160_16_122K_unbiased/sys_prune_kasthuri_val_seg_trial_0.3_o100_leaky_f24_160_16_122K_unbiased_$&#123;iteration1&#125;_weights.h5</span><br><span class="line">    echo model <span class="variable">$model_name</span></span><br><span class="line">    echo weight <span class="variable">$weightname</span></span><br><span class="line">    echo threshold <span class="variable">$pred_thd</span></span><br><span class="line">    <span class="attribute">THEANO_FLAGS</span>=device=cuda,floatX=float32,dnn.enabled=True python -u test.py  <span class="attribute">--trial</span>=jwrdata_candidate_prune <span class="attribute">--datadir</span>=kasthuri_test_files <span class="attribute">--imagedir</span>=grayscale_maps2_cropped <span class="attribute">--predname</span>=ac3_synapse-polarity_full_linear_leaky_f24_316_32_122500.h5 --syn_gtname ac3_syn_groundtruth_cropped.h5  <span class="attribute">--segname</span>=ac3-seg_m.h5 --seg_gtname ac3_seg_groundtruth_cropped.h5  <span class="attribute">--inputSize_xy</span>=160 <span class="attribute">--inputSize_z</span>=16 --modelname <span class="variable">$model_name</span>  --weightname <span class="variable">$weightname</span>  --cleft_label</span><br><span class="line"></span><br><span class="line">done</span><br><span class="line">exit 0;</span><br></pre></td></tr></table></figure><hr><h5 id="Step2"><a href="#Step2" class="headerlink" title="Step2"></a>Step2</h5><p>First generate proposals</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/bin/bash</span></span><br><span class="line"><span class="comment"># add all other SBATCH directives here...</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#SBATCH -p cox</span></span><br><span class="line"><span class="comment">#SBATCH -n 1 # Number of cores</span></span><br><span class="line"><span class="comment">#SBATCH -N 1 # Ensure that all cores are on one machine                        </span></span><br><span class="line"><span class="comment">#SBATCH --mem=60000</span></span><br><span class="line"><span class="comment">#SBATCH -t 3-00:00:00</span></span><br><span class="line"><span class="comment">#SBATCH -o ecs_synapse_multiclass_f24_316_32_%j.log</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">iter=<span class="number">150000</span></span><br><span class="line">python generate_proposals.py  --trial test_seg_trial_0.<span class="number">3</span>_o100_leaky_f24_160_16 --datadir test_files --imagedir grayscale_maps2_tst4x6x6 --predname test_ecs_synapse_polarity_full_margin_linear_leaky_f24_316_32_196000-cropped.h5  --syn_gtname ecs-syn-tst-groundtruth-polarity.h5  --segname result_ecs-<span class="number">4</span>x6x6-<span class="number">100</span>K-<span class="number">40000</span>-itr3-thd0.<span class="number">1</span>_xml_m.h5  --seg_gtname seg_groundtruth0.h5  --inputSize_xy=<span class="number">160</span> --inputSize_z=<span class="number">16</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">exit</span> <span class="number">0</span>;</span><br></pre></td></tr></table></figure><h5 id="Step3"><a href="#Step3" class="headerlink" title="Step3"></a>Step3</h5><p><strong>submit_test_dgx_kasthuri.sh</strong>  test.py  do prediction</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/bin/bash</span></span><br><span class="line"><span class="comment"># add all other SBATCH directives here...</span></span><br><span class="line"><span class="comment">#SBATCH -p seas_dgx1 </span></span><br><span class="line"><span class="comment">#SBATCH --gres=gpu:1</span></span><br><span class="line"><span class="comment">#SBATCH -n 1 # Number of cores</span></span><br><span class="line"><span class="comment">#SBATCH -N 1 # Ensure that all cores are on one machine                        </span></span><br><span class="line"><span class="comment">#SBATCH --mem=60000</span></span><br><span class="line"><span class="comment">#SBATCH -t 3-0:00:00</span></span><br><span class="line"><span class="comment">#SBATCH -o ecs_test_316_32_%j.log</span></span><br><span class="line">source ~/anaconda2/bin/activate kears_theano</span><br><span class="line"></span><br><span class="line"><span class="attribute">pred_thd_start</span>=-0.5</span><br><span class="line"><span class="attribute">iteration_start</span>=21500</span><br><span class="line"><span class="keyword">for</span> ((<span class="attribute">imultiple</span>=0;imultiple&lt;20;imultiple++));</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">    <span class="attribute">iteration1</span>=`echo <span class="variable">$iteration_start</span> + 500*<span class="variable">$imultiple</span> | bc -l`</span><br><span class="line"><span class="attribute">model_name</span>=kasthuri_val_seg_trial_0.3_o100_leaky_f24_160_16_122K_unbiased/syn_prune_kasthuri_val_seg_trial_0.3_o100_leaky_f24_160_16_122K_unbiased_$&#123;iteration1&#125;.json</span><br><span class="line">    <span class="attribute">weightname</span>=kasthuri_val_seg_trial_0.3_o100_leaky_f24_160_16_122K_unbiased/sys_prune_kasthuri_val_seg_trial_0.3_o100_leaky_f24_160_16_122K_unbiased_$&#123;iteration1&#125;_weights.h5</span><br><span class="line">    echo model <span class="variable">$model_name</span></span><br><span class="line">    echo weight <span class="variable">$weightname</span></span><br><span class="line">    echo threshold <span class="variable">$pred_thd</span></span><br><span class="line">    <span class="attribute">THEANO_FLAGS</span>=device=cuda,floatX=float32,dnn.enabled=True python -u test.py  <span class="attribute">--trial</span>=kasthuri_test_seg_trial_0.3_o100_leaky_f24_160_16_122K <span class="attribute">--datadir</span>=kasthuri_test_files <span class="attribute">--imagedir</span>=grayscale_maps2_cropped <span class="attribute">--predname</span>=ac3_synapse-polarity_full_linear_leaky_f24_316_32_122500.h5 --syn_gtname ac3_syn_groundtruth_cropped.h5  <span class="attribute">--segname</span>=ac3-seg_m.h5 --seg_gtname ac3_seg_groundtruth_cropped.h5  <span class="attribute">--inputSize_xy</span>=160 <span class="attribute">--inputSize_z</span>=16 --modelname <span class="variable">$model_name</span>  --weightname <span class="variable">$weightname</span>  --cleft_label</span><br><span class="line"></span><br><span class="line">done</span><br><span class="line">exit 0;</span><br></pre></td></tr></table></figure><p><strong>run_unet_06_f24_kasthuri.sh</strong>  train a unet_3d_valid_unnorm_leaky_f24 model</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">THEANO_FLAGS=device=gpu<span class="variable">$1</span>,floatX=float32,dnn.enabled=True,dnn.library_path=<span class="regexp">/n/</span>home05<span class="regexp">/paragt/</span>cuda<span class="regexp">/lib64,dnn.include_path=/</span>n<span class="regexp">/home05/</span>paragt<span class="regexp">/cuda/i</span>nclude python -u  unet_3d_valid_unnorm_leaky_f24.py --trial=kasthuri_synapse_polarity_full_linear_leaky_f24_316_32 --imagedir=<span class="regexp">/n/</span>coxfs01<span class="regexp">/paragt/</span>test_submit<span class="regexp">/ecs_synapse_polarity_full/g</span>rayscale_maps2_ac4<span class="regexp">/  --gtname=/</span>n<span class="regexp">/coxfs01/</span>paragt<span class="regexp">/test_submit/</span>ecs_synapse_polarity_full<span class="regexp">/ac4_syn_polarity_both_corrected.h5</span></span><br></pre></td></tr></table></figure><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">pred_thd_start</span>=-0.5</span><br><span class="line"><span class="attribute">iteration_start</span>=21500</span><br><span class="line"><span class="keyword">for</span> ((<span class="attribute">imultiple</span>=0;imultiple&lt;20;imultiple++));</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">    <span class="attribute">iteration1</span>=`echo <span class="variable">$iteration_start</span> + 500*<span class="variable">$imultiple</span> | bc -l`</span><br><span class="line"><span class="attribute">model_name</span>=kasthuri_val_seg_trial_0.3_o100_leaky_f24_160_16_122K_unbiased/syn_prune_kasthuri_val_seg_trial_0.3_o100_leaky_f24_160_16_122K_unbiased_$&#123;iteration1&#125;.json</span><br><span class="line">    <span class="attribute">weightname</span>=kasthuri_val_seg_trial_0.3_o100_leaky_f24_160_16_122K_unbiased/sys_prune_kasthuri_val_seg_trial_0.3_o100_leaky_f24_160_16_122K_unbiased_$&#123;iteration1&#125;_weights.h5</span><br><span class="line">    echo model <span class="variable">$model_name</span></span><br><span class="line">    echo weight <span class="variable">$weightname</span></span><br><span class="line">    echo threshold <span class="variable">$pred_thd</span></span><br><span class="line">done</span><br></pre></td></tr></table></figure><p>We compare the model with SynEM on Kasthuri data. The model makes better prediction.</p><p><img src="http://i1.fuimg.com/640680/8b04e56610dffdea.png" alt="Markdown"></p><p>We will also test another model, Resnet+U-net, originated from task2 and it has many improvements in this summer.<br>It includes dilation CNN, batch normalization for multi-GPU, squeeze-and-excitation block. For polarity prediction, now the pixel can be either background, pre-synapse or post-synapse, so we can adapt the model to 3 channel  output. And we can change the loss function to MSE.</p><p><img src="http://i1.fuimg.com/640680/e80d496181dafa1e.png" alt="Markdown"></p><p>It has better generalization than what Funke’s group’s model since they over fit the CREMI dataset. It performs well on JWR data.</p><p>I will apply our model to predict synEM data. Thus we both test synEM model on our data and test our model on their data, this will give us enough result to compare our model.</p><p>SynEM data has four channels, using different size of synapse. We only use the small polarity for post synapse and large for pre synapse.<br>[image:F10F22C4-AAA4-4868-B496-BF7DB0A73A97-385-0000D376F35FA1C0/屏幕快照 2018-09-04 下午5.27.40.png]</p><p><code>env create -f bin/synapse_pytorch/envs/py3_pytorch.yml</code></p><p><code>source activate py3_pytorch</code></p><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">source activate py3_pytorch</span><br><span class="line">CUDA_VISIBLE_DEVICES=<span class="number">0</span> python3 -u bin/synapse_pytorch/train_sync_polarity.py -t /n/coxfs01/xupeng/projects/synapse/data/synEM/synEM_train_data/ -dn raw/synEM_train_raw_000.h5 -ln label_new/synEM_train_label_new_channel_000.h5 -o outputs/<span class="number">9.6</span>_single -lr <span class="number">1e-03</span> --volume-total <span class="number">1600000</span> --volume-save <span class="number">100000</span> -mi <span class="number">8</span>,<span class="number">160</span>,<span class="number">160</span> -g <span class="number">1</span> -c <span class="number">1</span> -b <span class="number">1</span></span><br></pre></td></tr></table></figure><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">source activate py3_pytorch</span><br><span class="line">CUDA_VISIBLE_DEVICES=<span class="number">0</span> python3 -u bin/synapse_pytorch/train_sync_polarity.py -t data/synEM/synEM/synEM_train_data/ -dn raw/synEM_train_raw_000.h5 -ln label_new/synEM_train_label_new_channel_000.h5 -o outputs/<span class="number">9.6</span>_single -lr <span class="number">1e-03</span> --volume-total <span class="number">1600000</span> --volume-save <span class="number">100000</span> -mi <span class="number">8</span>,<span class="number">160</span>,<span class="number">160</span> -g <span class="number">1</span> -c <span class="number">1</span> -b <span class="number">1</span></span><br></pre></td></tr></table></figure><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">source activate py3_pytorch</span><br><span class="line">CUDA_VISIBLE_DEVICES=<span class="number">0</span> python3 -u bin/synapse_pytorch/train_sync_polarity.py -t /n/coxfs01/zudilin/research/data/JWR/syn_vol1/ -dn im.h5 -ln jwr_syn_polarity.h5 -o outputs/<span class="number">9.10</span>_single -lr <span class="number">1e-03</span> --volume-total <span class="number">1600000</span> --volume-save <span class="number">100000</span> -mi <span class="number">8</span>,<span class="number">160</span>,<span class="number">160</span> -g <span class="number">1</span> -c <span class="number">1</span> -b <span class="number">1</span></span><br></pre></td></tr></table></figure><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">source activate py3_pytorch</span><br><span class="line">CUDA_VISIBLE_DEVICES=<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span> python3 -u bin/synapse_pytorch/train_sync_polarity.py -t /n/coxfs01/xupeng/projects/synapse/data/synEM/synEM_train_data/ -dn raw/synEM_train_raw_000.h5@raw/synEM_train_raw_001.h5@raw/synEM_train_raw_002.h5 -ln label_new/synEM_train_label_new_channel_000.h5@label_new/synEM_train_label_new_channel_001.h5@label_new/synEM_train_label_new_channel_002.h5 -o outputs/<span class="number">9.6</span> -lr <span class="number">1e-03</span> --volume-total <span class="number">1600000</span> --volume-save <span class="number">100000</span> -mi <span class="number">8</span>,<span class="number">160</span>,<span class="number">160</span> -g <span class="number">3</span> -c <span class="number">3</span> -b <span class="number">3</span></span><br></pre></td></tr></table></figure><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/bin/bash</span></span><br><span class="line"><span class="comment"># add all other SBATCH directives here...</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#SBATCH -p cox</span></span><br><span class="line"><span class="comment">#SBATCH --gres=gpu:8</span></span><br><span class="line"><span class="comment">#SBATCH --constraint=titanx</span></span><br><span class="line"><span class="comment">#SBATCH -n 8 # Number of cores</span></span><br><span class="line"><span class="comment">#SBATCH -N 1 # Ensure that all cores are on one machine</span></span><br><span class="line"><span class="comment">#SBATCH --mem=50000</span></span><br><span class="line"><span class="comment">#SBATCH -t 5-00:00:00</span></span><br><span class="line"><span class="comment">#SBATCH -o logs/train_%j.log</span></span><br><span class="line"></span><br><span class="line">module load cuda</span><br><span class="line">source activate py3_pytorch</span><br><span class="line"></span><br><span class="line">CUDA_VISIBLE_DEVICES=<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span> python3 -u bin<span class="regexp">/synapse_pytorch/</span>train_sync_polarity.py -t <span class="regexp">/n/</span>coxfs01<span class="regexp">/xupeng/</span>projects<span class="regexp">/synapse/</span>data<span class="regexp">/synEM/</span>synEM_train_data<span class="regexp">/ -dn raw/</span>synEM_train_raw_000.h5@raw<span class="regexp">/synEM_train_raw_001.h5@raw/</span>synEM_train_raw_002.h5@raw<span class="regexp">/synEM_train_raw_003.h5@raw/</span>synEM_train_raw_004.h5@raw<span class="regexp">/synEM_train_raw_005.h5@raw/</span>synEM_train_raw_006.h5@raw<span class="regexp">/synEM_train_raw_007.h5@raw/</span>synEM_train_raw_008.h5@raw<span class="regexp">/synEM_train_raw_009.h5 -ln label_new/</span>synEM_train_label_new_channel_000.h5@label_new<span class="regexp">/synEM_train_label_new_channel_001.h5@label_new/</span>synEM_train_label_new_channel_002.h5@label_new<span class="regexp">/synEM_train_label_new_channel_003.h5@label_new/</span>synEM_train_label_new_channel_004.h5@label_new<span class="regexp">/synEM_train_label_new_channel_005.h5@label_new/</span>synEM_train_label_new_channel_006.h5@label_new<span class="regexp">/synEM_train_label_new_channel_007.h5@label_new/</span>synEM_train_label_new_channel_008.h5@label_new<span class="regexp">/synEM_train_label_new_channel_009.h5 -o outputs/</span><span class="number">9.5</span>_10_volumes -lr <span class="number">1</span>e-<span class="number">03</span> --volume-total <span class="number">1600000</span> --volume-save <span class="number">100000</span> -mi <span class="number">8</span>,<span class="number">160</span>,<span class="number">160</span> -g <span class="number">8</span> -c <span class="number">8</span> -b <span class="number">32</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># end of program</span></span><br><span class="line"><span class="keyword">exit</span> <span class="number">0</span>;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;It is part of my computational task during my summer intern in &lt;a href=&quot;https://lichtmanlab.fas.harvard.edu/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Lichtman Lab&lt;/a&gt; and &lt;a href=&quot;https://vcg.seas.harvard.edu/people&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Hanspiter Lab&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;It is part of the big synapse project. Also the challenge 3 of &lt;a href=&quot;https://cremi.org&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;CREMI&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;For &lt;strong&gt;whole work summary&lt;/strong&gt; please &lt;a href=&quot;https://www.cmwonderland.com/blog/2018/09/12/100_summer_intern/&quot;&gt;see here&lt;/a&gt;&lt;/p&gt;


	&lt;div class=&quot;row&quot;&gt;
		&lt;iframe src=&quot;https://drive.google.com/file/d/1XyEPj9r7p8VNk5nLlLIPNhZjuDHu2KTY/preview&quot; style=&quot;width:100%; height:550px&quot;&gt;&lt;/iframe&gt;
	&lt;/div&gt;



&lt;p&gt;Also I finished another NMJ project during summer intern in &lt;a href=&quot;https://lichtmanlab.fas.harvard.edu/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Lichtman Lab&lt;/a&gt; &lt;/p&gt;
&lt;h1 id=&quot;Codes&quot;&gt;&lt;a href=&quot;#Codes&quot; class=&quot;headerlink&quot; title=&quot;Codes&quot;&gt;&lt;/a&gt;Codes&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/james20141606/Summer_Intern/tree/master/synapse_prediction&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Summer_Intern/synaptic_partner at master · james20141606/Summer_Intern · GitHub&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/james20141606/EM-network&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Synapse polarity&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/james20141606/Summer_Intern/tree/master/synapse_cluster&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Summer_Intern/synapse_cluster at master · james20141606/Summer_Intern · GitHub&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="projects" scheme="https://www.cmwonderland.com/blog/categories/projects/"/>
    
    
      <category term="project" scheme="https://www.cmwonderland.com/blog/tags/project/"/>
    
      <category term="neural science" scheme="https://www.cmwonderland.com/blog/tags/neural-science/"/>
    
      <category term="summer intern" scheme="https://www.cmwonderland.com/blog/tags/summer-intern/"/>
    
      <category term="connectomics" scheme="https://www.cmwonderland.com/blog/tags/connectomics/"/>
    
      <category term="computational neural science" scheme="https://www.cmwonderland.com/blog/tags/computational-neural-science/"/>
    
      <category term="deep learning" scheme="https://www.cmwonderland.com/blog/tags/deep-learning/"/>
    
      <category term="computer vision" scheme="https://www.cmwonderland.com/blog/tags/computer-vision/"/>
    
      <category term="Jeff Lichtman" scheme="https://www.cmwonderland.com/blog/tags/Jeff-Lichtman/"/>
    
  </entry>
  
  <entry>
    <title>Synapse Prediction Project</title>
    <link href="https://www.cmwonderland.com/blog/2018/07/14/98_summerintern_Synapse_Prediction/"/>
    <id>https://www.cmwonderland.com/blog/2018/07/14/98_summerintern_Synapse_Prediction/</id>
    <published>2018-07-14T14:50:06.000Z</published>
    <updated>2018-10-11T08:32:01.211Z</updated>
    
    <content type="html"><![CDATA[<p>It is part of my computational task during my summer intern in <a href="https://lichtmanlab.fas.harvard.edu/" target="_blank" rel="noopener">Lichtman Lab</a> and <a href="https://vcg.seas.harvard.edu/people" target="_blank" rel="noopener">Hanspiter Lab</a>.</p><p>It is part of the big synapse project. Also the challenge 2 of <a href="https://cremi.org" target="_blank" rel="noopener">CREMI</a></p><p>We now rank <strong>No.1</strong> in the <a href="https://cremi.org" target="_blank" rel="noopener">CREMI contest</a>. And we will submit a paper to CVPR this November.</p><p>For <strong>whole work summary</strong> please <a href="https://www.cmwonderland.com/blog/2018/09/12/100_summer_intern/">see here</a></p><div class="row"><iframe src="https://drive.google.com/file/d/1XyEPj9r7p8VNk5nLlLIPNhZjuDHu2KTY/preview" style="width:100%; height:550px"></iframe></div><p>Also I finished another NMJ project during summer intern in <a href="https://lichtmanlab.fas.harvard.edu/" target="_blank" rel="noopener">Lichtman Lab</a> </p><h1 id="Codes"><a href="#Codes" class="headerlink" title="Codes"></a>Codes</h1><ul><li><a href="https://github.com/james20141606/Summer_Intern/tree/master/synapse_prediction" target="_blank" rel="noopener">Summer_Intern/synaptic_partner at master · james20141606/Summer_Intern · GitHub</a></li><li><a href="https://github.com/james20141606/EM-network" target="_blank" rel="noopener">Synapse polarity</a></li></ul><a id="more"></a><h1 id="weekly-report"><a href="#weekly-report" class="headerlink" title="weekly report"></a>weekly report</h1><h2 id="First"><a href="#First" class="headerlink" title="First"></a>First</h2><div class="row"><iframe src="https://drive.google.com/file/d/1bmWX9M1aTgOw7YB9xrnUNynWfxuoa_Rz/preview" style="width:100%; height:550px"></iframe></div><h2 id="Second"><a href="#Second" class="headerlink" title="Second"></a>Second</h2><div class="row"><iframe src="https://drive.google.com/file/d/1OOaFajkLcwQBEf1XQuEIYqFAkl9psPrt/preview" style="width:100%; height:550px"></iframe></div><h2 id="Third"><a href="#Third" class="headerlink" title="Third"></a>Third</h2><div class="row"><iframe src="https://drive.google.com/file/d/1We4g3Ltd2gqzmICoLtKFKsL-2zP2BVeV/preview" style="width:100%; height:550px"></iframe></div><h2 id="Fourth"><a href="#Fourth" class="headerlink" title="Fourth"></a>Fourth</h2><div class="row"><iframe src="https://drive.google.com/file/d/19zhoBM6GP94a-bNj7bFIZdExC0x6yw_2/preview" style="width:100%; height:550px"></iframe></div><hr><h1 id="First-two-weeks"><a href="#First-two-weeks" class="headerlink" title="First two weeks"></a>First two weeks</h1><h2 id="summarize-and-rewrite-some-data-augmentation-repo"><a href="#summarize-and-rewrite-some-data-augmentation-repo" class="headerlink" title="summarize and rewrite some data augmentation repo"></a>summarize and rewrite some data augmentation repo</h2><p>The three main repos are gunpowder from funke lab, EM-data, EM-seglib from Sebastian lab.</p><p>Gunpowder is quite complicated since it includes a whole pipeline of data preprocessing. It defines some batch provider and batch filter at first, making it harder to understand the data augmentation steps in the middle. Since it is written in python2 and designed for caffe, I rewrite and summarize, compare the gunpowder’s four augmentation methods with Sebastian’s codes.</p><p>Funke said in his paper about CREMI challenge 2 that data augmentation is the most important steps in the whole pipeline. I rewrite the four kinds of data augmentation methods combining Funkey and Sebastian’s codes.<br><a href="https://github.com/james20141606/Summer_Intern/blob/master/synapse_prediction/jupyter/gunpowder.ipynb" target="_blank" rel="noopener">gunpowder</a><br><a href="https://github.com/james20141606/Summer_Intern/blob/master/synapse_prediction/jupyter/gunpowder_cremi.ipynb" target="_blank" rel="noopener">gunpowder on cremi</a></p><ul><li>simple augmentation</li><li>intensity augment</li><li>ElasticAugment</li><li>DefectAugment</li></ul><h2 id="simple-augmentation"><a href="#simple-augmentation" class="headerlink" title="simple augmentation"></a>simple augmentation</h2><p>class gunpowder.SimpleAugment(mirror_only=None, transpose_only=None)<br>Randomly mirror and transpose all Arrays and Points in a batch.</p><p>simple augment can be achieved by EM-segLib/em_segLib/transform.py!<br>in this repo, only transpose_only_xy=True is used!</p><h2 id="intensity-augment"><a href="#intensity-augment" class="headerlink" title="intensity augment"></a>intensity augment</h2><p>class gunpowder.IntensityAugment(array, scale_min, scale_max, shift_min, shift_max, z_section_wise=False)<br>Randomly scale and shift the values of an intensity array.</p><ul><li>array (ArrayKey) – The intensity array to modify.</li><li>scale_min (float) –</li><li>scale_max (float) –</li><li>shift_min (float) –</li><li>shift_max (float) –<br>The min and max of the uniformly randomly drawn scaling and shifting values for the intensity augmentation. Intensities are changed as:</li></ul><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">a</span> = <span class="selector-tag">a</span>.mean() + (a-<span class="selector-tag">a</span>.mean())*scale + shift</span><br></pre></td></tr></table></figure><ul><li>z_section_wise (bool) – Perform the augmentation z-section wise. Requires 3D arrays and assumes that z is the first dimension.</li></ul><h3 id="Randomly-scale-and-shift-the-values-of-an-intensity-array，"><a href="#Randomly-scale-and-shift-the-values-of-an-intensity-array，" class="headerlink" title="Randomly scale and shift the values of an intensity array，"></a>Randomly scale and shift the values of an intensity array，</h3><ul><li>can do z axis sections augmentation，first dim should be z</li><li>normalized array desired</li><li>set scale and shift’s biggest and smallest value</li></ul><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">np<span class="selector-class">.random</span><span class="selector-class">.uniform</span>(low=self<span class="selector-class">.shift_min</span>, high=self.shift_max))</span><br></pre></td></tr></table></figure><p>Return scale and shift value</p><ul><li>for each array: a.mean() + (a-a.mean())*scale + shift</li><li>np.clip(0,1)</li></ul><h3 id="similar-implementation"><a href="#similar-implementation" class="headerlink" title="similar implementation!"></a>similar implementation!</h3><ul><li>scale is similar to DataProvider/python/data_augmentation.py class GreyAugment(DataAugment)!</li><li>DataProvider/python/data_augmentation.py class GreyAugment(DataAugment)<strong>may be better</strong>：</li></ul><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">img</span> *= <span class="number">1</span> + (np<span class="selector-class">.random</span><span class="selector-class">.rand</span>() - <span class="number">0.5</span>)*self.CONTRAST_FACTOR</span><br><span class="line"><span class="selector-tag">img</span> += (np<span class="selector-class">.random</span><span class="selector-class">.rand</span>() - <span class="number">0.5</span>)*self.BRIGHTNESS_FACTOR</span><br><span class="line"><span class="selector-tag">img</span> = np.<span class="attribute">clip</span>(img, <span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line"><span class="selector-tag">img</span> **= <span class="number">2.0</span>**(np<span class="selector-class">.random</span><span class="selector-class">.rand</span>()*<span class="number">2</span> - <span class="number">1</span>)</span><br></pre></td></tr></table></figure><ul><li>it borrows from (<a href="http://elektronn.org/).ELEKTRONN" target="_blank" rel="noopener">http://elektronn.org/).ELEKTRONN</a> is used for 2D/3D large scale image. Also used for segmentation</li></ul><h2 id="ElasticAugment"><a href="#ElasticAugment" class="headerlink" title="ElasticAugment"></a>ElasticAugment</h2><p>The author used ElasticAugment([4,40,40], [0,2,2], [0,math.pi/2.0], prob_slip=0.05,prob_shift=0.05,max_misalign=25)</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">class gunpowder.ElasticAugment(control_point_spacing, jitter_sigma, rotation_interval, <span class="attribute">prob_slip</span>=0, <span class="attribute">prob_shift</span>=0, <span class="attribute">max_misalign</span>=0, <span class="attribute">subsample</span>=1)</span><br></pre></td></tr></table></figure><ul><li>reshape array data into (channels,) + spatial dims</li><li>first  <strong>create_identity_transformation</strong><ul><li>create_identity_transformation from funkey another repo augment，create_identity_transformation, channel change to three , use np.meshgrid increase two channels</li></ul></li><li>if sum(jitter_sigma) &gt; 0: <strong>create_elastic_transformation</strong></li><li><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">augment.create_elastic_transformation(</span><br><span class="line">                    target_shape,</span><br><span class="line">                    self<span class="selector-class">.control_point_spacing</span>,</span><br><span class="line">                    self<span class="selector-class">.jitter_sigma</span>,</span><br><span class="line">                    subsample=self.subsample)</span><br></pre></td></tr></table></figure></li><li><p>first get control_point_offsets，the interpolation to upscale，generate 3 channel images</p></li><li><p>then by rotation_interval [0,math.pi/2.0], rotation_start = rotation_interval[0], rotation_max_amount = rotation_interval[1] - rotation_interval[0]</p><p>  rotation = random.random()*self.rotation_max_amount + self.rotation_start(less than 90)</p></li></ul><p>If rotation&gt;0,do <strong>create_rotation_transformation</strong></p><ul><li>then if prob_slip + prob_shift &gt; 0，做<strong>__misalign(transformation)</strong></li></ul><p>According to thres to do randomly shift by section</p><ul><li><p>at last if subsample &gt;1 before elastic augmentation do subsampling to speed up elasticaugment after augmentation then do upscale</p><p>  Instead of creating an elastic transformation on the full<br>  resolution, create one subsampled by the given factor, and linearly<br>  interpolate to obtain the full resolution transformation. This can<br>  significantly speed up this node, at the expense of having visible<br>  piecewise linear deformations for large factors. Usually, a factor<br>  of 4 can savely by used without noticable changes. However, the<br>  default is 1 (i.e., no subsampling).</p></li></ul><h2 id="DefectAugment"><a href="#DefectAugment" class="headerlink" title="DefectAugment"></a>DefectAugment</h2><p>class gunpowder.DefectAugment(intensities, prob_missing=0.05, prob_low_contrast=0.05, prob_artifact=0.0, prob_deform=0.0, contrast_scale=0.1, artifact_source=None, artifacts=None, artifacts_mask=None, deformation_strength=20, axis=0)[source]</p><p>Augment intensity arrays section-wise with artifacts like missing sections, low-contrast sections, by blending in artifacts drawn from a separate source, or by deforming a section.</p><ul><li>intensities (ArrayKey) – The key of the array of intensities to modify.</li><li>prob_missing (float) –</li><li>prob_low_contrast (float) –</li><li>prob_artifact (float) –</li><li>prob_deform (float) – Probabilities of having a missing section, low-contrast section, an artifact (see param artifact_source) or a deformed slice. The sum should not exceed 1. Values in missing sections will be set to 0.<br>contrast_scale (float, optional) – By how much to scale the intensities for a low-contrast section, used if prob_low_contrast &gt; 0.</li><li><p>(class (artifact_source) – BatchProvider, optional):A gunpowder batch provider that delivers intensities (via ArrayKey artifacts) and an alpha mask (via ArrayKey artifacts_mask), used if prob_artifact &gt; 0.</p></li><li><p>artifacts (ArrayKey, optional) – The key to query artifact_source for to get the intensities of the artifacts.</p></li><li>artifacts_mask (ArrayKey, optional) – The key to query artifact_source for to get the alpha mask of the artifacts to blend them with intensities.</li><li>deformation_strength (int, optional) – Strength of the slice deformation in voxels, used if prob_deform &gt; 0. The deformation models a fold by shifting the section contents towards a randomly oriented line in the section. The line itself will be drawn with a value of 0.</li><li>axis (int, optional) – Along which axis sections are cut.</li></ul><p>From a special artifect source read data and defectaugment</p><figure class="highlight lisp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">artifact_source = (</span><br><span class="line">        Hdf5Source(</span><br><span class="line">            'sample_ABC_padded_20160501.defects.hdf',</span><br><span class="line">            datasets = &#123;</span><br><span class="line">                ArrayKeys.RAW: 'defect_sections/raw',</span><br><span class="line">                ArrayKeys.ALPHA_MASK: 'defect_sections/mask',</span><br><span class="line">            &#125;</span><br><span class="line">        ) +</span><br><span class="line">        RandomLocation(<span class="name">min_masked=0</span>.<span class="number">05</span>, mask_array_key=ArrayKeys.ALPHA_MASK) +</span><br><span class="line">        Normalize() +</span><br><span class="line">        IntensityAugment(<span class="number">0.9</span>, <span class="number">1.1</span>, <span class="number">-0.1</span>, <span class="number">0.1</span>, z_section_wise=True) +</span><br><span class="line">        ElasticAugment([<span class="number">4</span>,<span class="number">40</span>,<span class="number">40</span>], [<span class="number">0</span>,<span class="number">2</span>,<span class="number">2</span>], [<span class="number">0</span>,math.pi/2.<span class="number">0</span>]) +</span><br><span class="line">        SimpleAugment(<span class="name">transpose_only_xy=True</span>)</span><br><span class="line">    )</span><br></pre></td></tr></table></figure><ul><li><p>threshold：</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">DefectAugment(</span><br><span class="line">            <span class="attribute">prob_missing</span>=0.03,</span><br><span class="line">            <span class="attribute">prob_low_contrast</span>=0.01,</span><br><span class="line">            <span class="attribute">prob_artifact</span>=0.03,</span><br><span class="line">            <span class="attribute">artifact_source</span>=artifact_source,</span><br><span class="line">            <span class="attribute">contrast_scale</span>=0.1)</span><br></pre></td></tr></table></figure></li><li><p>get missing，low_contrast, artifact, deform value    prob_missing_threshold = self.prob_missing   (0.03=0.03)<br>  prob_low_contrast_threshold = prob_missing_threshold + self.prob_low_contrast  (0.04=0.03+0.01)<br>  prob_artifact_threshold = prob_low_contrast_threshold + self.prob_artifact    (0.07=0.03+0.04)<br>  prob_deform_slice = prob_artifact_threshold + self.prob_deform   (0.07=0.07+0)</p></li><li>for each slice，generate 0-1 random value r，if：<ul><li>r &lt; prob_missing_threshold:  ‘zero_out’<ul><li>do nothing</li></ul></li><li>elif r &lt; prob_low_contrast_threshold:  ‘lower_contrast’<ul><li>mean = section.mean(), section -= mean, section *= self.contrast_scale, section += mean</li></ul></li><li>elif r &lt; prob_artifact_threshold:’artifact’<ul><li>raw.data[section_selector] = section<em>(1.0 - artifact_alpha) + artifact_raw</em>artifact_alpha</li><li>artifact_alpha, artifact_raw from artifact_source’s mask and raw， equals to a <strong>Alpha Blending</strong></li></ul></li><li>elif r &lt; prob_deform_slice: ‘deformed_slice’ if deformed slice, needs bigger upstream roi for deformed slice</li></ul></li></ul><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">section = raw.data[section_selector].squeeze()</span><br><span class="line">interpolation = 3 if self.spec[self.intensities].interpolatable <span class="keyword">else</span> 0</span><br><span class="line">flow_x, flow_y, line_mask = self.deform_slice_transformations[c]</span><br><span class="line">shape = section.shape</span><br><span class="line"><span class="comment">#做双线性插值</span></span><br><span class="line">section = map_coordinates(</span><br><span class="line">    section, (flow_y, flow_x), mode='constant', order=interpolation</span><br><span class="line">).reshape(shape)</span><br><span class="line">section = np.clip(section, 0., 1.)</span><br><span class="line">section[line_mask] = 0</span><br><span class="line">raw.data[section_selector] = section</span><br></pre></td></tr></table></figure><p><strong>cremi exapmle</strong><br><a href="https://github.com/funkey/gunpowder/tree/master/examples/cremi" target="_blank" rel="noopener">gunpowder/examples/cremi at master · funkey/gunpowder · GitHub</a></p><p>docker has problems (MALIS, pycaffe)<br>Install docker on server <a href="https://docs.docker.com/install/linux/docker-ce/ubuntu/#install-from-a-package" target="_blank" rel="noopener">Get Docker CE for Ubuntu | Docker Documentation</a></p><figure class="highlight applescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">docker pull funkey/gunpowder</span><br><span class="line"></span><br><span class="line">sudo docker images</span><br><span class="line">sudo docker <span class="built_in">run</span> -i -t <span class="comment">--name=chen ubuntu:latest</span></span><br><span class="line"><span class="keyword">exit</span>  </span><br><span class="line">docker start <span class="built_in">id</span> / <span class="built_in">name</span></span><br><span class="line">docker attach <span class="built_in">id</span> /<span class="built_in">name</span></span><br></pre></td></tr></table></figure><p>Encounter problems with installing nvidia docker and docker run.</p><p>Seems we should try to rewrite some codes to incorporate directly without the bothering of docker, python2, caffe, malis and other settings.</p><h3 id="resources"><a href="#resources" class="headerlink" title="resources"></a>resources</h3><p><a href="https://github.com/donglaiw/em-data" target="_blank" rel="noopener">GitHub - donglaiw/EM-data: dataset loader</a><br><a href="https://github.com/torms3/DataProvider/tree/refactoring/python/dataprovider" target="_blank" rel="noopener">DataProvider/python/dataprovider at refactoring · torms3/DataProvider · GitHub</a><br><a href="https://arxiv.org/abs/1706.00120" target="_blank" rel="noopener">1706.00120 Superhuman Accuracy on the SNEMI3D Connectomics Challenge</a> Sebastian group</p><p>Then I incorporate the data augmentation methods into synapse prediction model for further use.<br><a href="https://github.com/james20141606/Summer_Intern/blob/master/synapse_prediction/jupyter/augment_cremi.ipynb" target="_blank" rel="noopener">augmentation on cremi</a></p><h3 id="Model-test-and-redesign"><a href="#Model-test-and-redesign" class="headerlink" title="Model test and redesign"></a>Model test and redesign</h3><p>I tried zudi’s synapse prediction model using 3D U-net, since it is based on pytorch, I spent some time to read the pytorch documentation. We have discussed about the model improvement issue and I have tried to use other architecture for better prediction results.<br><a href="https://github.com/james20141606/Summer_Intern/blob/master/synapse_prediction/jupyter/pytorch_synapse.ipynb" target="_blank" rel="noopener">synapse prediction model</a><br><a href="https://github.com/james20141606/Summer_Intern/blob/master/synapse_prediction/jupyter/syn_pytorch_add_dink.ipynb" target="_blank" rel="noopener">improvement on U net</a></p><p>I can try a lot fine tune and redesign about U-net and 3D U-net, maybe from kaggle top solutions and github. </p><hr><h1 id="Week-3"><a href="#Week-3" class="headerlink" title="Week 3"></a>Week 3</h1><p>In week 3, apart from NMJ project, I concentrate mainly on synapse prediction project and make many progress. Since zudi has come back, it is more efficient to discuss and collaborate, we have done a lot this week.</p><h2 id="short-term-plan"><a href="#short-term-plan" class="headerlink" title="short term plan"></a>short term plan</h2><p>Our short term plan is adding all the new tricks (dilation CNN block from Deepglobe’s Dlink-net, DICE_BCE combined loss, all the data augmentation methods) to the model. We train the whole model for three days on all A, B, C samples. And fine tune it later for one day. Then we submit the result to see if it is better.</p><p>In my consideration, the previous model <strong>has a not very little gap with the state-of-art one</strong>. About one fold error score. So it is a lot for us to do. <strong>I have used dilation CNN, combined Loss, and some very useful data augmentation methods</strong> which take me many days to accomplish(All admit that proper augmentation is one of the most import procedure to achieve better results.) So this week I have read many other people’s good paper, project summary and codes in similar tasks( <strong>the dilation CNN, DICE_BCE loss and data augmentation all originate from this.</strong>) I believe there are more to implement. The state-of-art model and pipeline looks really good, so I think I should use more strategy to improve our results.</p><h2 id="Model-improvement-and-training"><a href="#Model-improvement-and-training" class="headerlink" title="Model improvement and training"></a>Model improvement and training</h2><h3 id="settings-and-training"><a href="#settings-and-training" class="headerlink" title="settings and training"></a>settings and training</h3><p> Since I have done several deep learning and machine learning projects(Emaize, CardiacAI, 3D CT images, Deepshape), I am quite familiar with linux, python deep learning environment and all extra settings( jupyter, TensorboardX etc). I can be quite efficient in running the previous model designed by zudi.</p><h4 id="training-settings"><a href="#training-settings" class="headerlink" title="training settings"></a>training settings</h4><h5 id="create-envs"><a href="#create-envs" class="headerlink" title="create envs"></a>create envs</h5><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">conda env <span class="keyword">create</span> -f <span class="keyword">bin</span>/synapse_pytorch/envs/py3_pytorch.yml</span><br><span class="line"><span class="keyword">source</span> <span class="keyword">activate</span> py3_pytorch</span><br><span class="line"><span class="keyword">source</span> deactivate</span><br><span class="line"><span class="keyword">alias</span> act=<span class="string">'source activate py3_pytorch'</span></span><br><span class="line"><span class="keyword">alias</span> deact=<span class="string">'source deactivate'</span></span><br><span class="line">virtualenv venv</span><br></pre></td></tr></table></figure><h5 id="training-parameter-setting"><a href="#training-parameter-setting" class="headerlink" title="training parameter setting"></a>training parameter setting</h5><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">CUDA_VISIBLE_DEVICES=<span class="number">0</span>,<span class="number">1</span> python3 -u bin/synapse_pytorch/train<span class="selector-class">.py</span> -t data/cremi/ -dn images/im_A_v2_200.h5@images/im_B_v2_200.h5@images/im_C_v2_200<span class="selector-class">.h5</span> -ln gt-syn/syn_A_v2_200.h5@gt-syn/syn_B_v2_200.h5@gt-syn/syn_C_v2_200<span class="selector-class">.h5</span> -o outputs/cremi0719mixloss -lr <span class="number">0.001</span> --volume-total <span class="number">400000</span> --volume-save <span class="number">20000</span> -mi <span class="number">24</span>,<span class="number">256</span>,<span class="number">256</span> -g <span class="number">2</span> -c <span class="number">6</span> -<span class="selector-tag">b</span> <span class="number">2</span> -l mix</span><br><span class="line"><span class="selector-id">#b</span>:<span class="number">6</span>  try to keep gpu and batch size same</span><br></pre></td></tr></table></figure><h5 id="Tensorboard-monitor-setting"><a href="#Tensorboard-monitor-setting" class="headerlink" title="Tensorboard monitor setting"></a>Tensorboard monitor setting</h5><p>it is a real time monitoring</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#http://140.247.107.75:6006</span></span><br><span class="line"><span class="comment">#set locale to solve locale unsupported locale #setting problems</span></span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">LANGUAGE</span>=en_US.UTF-8</span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">LANG</span>=en_US.UTF-8</span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">LC_ALL</span>=en_US.UTF-8</span><br><span class="line"><span class="comment">#tensorboard monitor dir at: synapse/runs/outputs</span></span><br><span class="line">tensorboard --logdir cremi0719</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"><span class="built_in">kill</span> jupyter and release port</span></span><br><span class="line">ps aux | grep -i notebook</span><br></pre></td></tr></table></figure><h3 id="network-visualization"><a href="#network-visualization" class="headerlink" title="network visualization"></a>network visualization</h3><p>I visualize our current model, it is a very big one.</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line"><span class="keyword">from</span> torch.autograd import Variable</span><br><span class="line"><span class="keyword">from</span> torchviz import make_dot</span><br><span class="line">model = res_unet()</span><br><span class="line">model = model.<span class="keyword">to</span>(device)</span><br><span class="line">x = Variable(torch.randn(1,1,24, 256,256))#change 12 <span class="keyword">to</span> the channel number of<span class="built_in"> network </span>input</span><br><span class="line">y = model(x)</span><br><span class="line">g = make_dot(y)</span><br><span class="line">g.view()</span><br></pre></td></tr></table></figure><p><strong>Current model:</strong></p><p><img src="http://i2.tiimg.com/640680/aac9181df1496b48.png" alt="Markdown"></p><p>Scripts: <a href="https://github.com/james20141606/Summer_Intern/blob/master/synapse_prediction/jupyter/pytorch_synapse.ipynb" target="_blank" rel="noopener">Summer_Intern/pytorch_synapse.ipynb at master · james20141606/Summer_Intern · GitHub</a></p><h3 id="model-structure-and-loss-function-improvement"><a href="#model-structure-and-loss-function-improvement" class="headerlink" title="model structure and loss function improvement"></a>model structure and loss function improvement</h3><p>I read D-LinkNet: LinkNet with Pretrained Encoder and Dilated Convolution for High Resolution Satellite Imagery Road Extraction and other winners in some challenges and implement more model structure and loss function design.</p><h5 id="dilated-CNN-block"><a href="#dilated-CNN-block" class="headerlink" title="dilated CNN block"></a>dilated CNN block</h5><p>It can further enlarge the visual area of the model, which is helpful to learn more information efficiently. The dilation is adaptive according the the layer depth. The maximum is 8, we may change it smaller later.</p><h5 id="loss-function"><a href="#loss-function" class="headerlink" title="loss function"></a>loss function</h5><p>I read Deepglobe challenge’s solution and change the loss function to <strong>DICE + BCE</strong> like this:<br>P: predict result, GT: ground truth, N: batch size</p><script type="math/tex; mode=display">L = 1 - \frac{2 \times \sum_{i=1}^N  |P_i \cap GT_i  | }{\sum_{i=1}^N  (P_i + GT_i)} + \sum_{i=1}^N BCELoss(P_i,  GT_i)</script><p>It added a DICE part to previous BCE loss function, which is better since it is common to use DICE as loss function for U-net, the combined loss function is also used in some challenges winner.</p><p>loss function implementation:<br><a href="https://github.com/james20141606/Summer_Intern/blob/master/synapse_prediction/bin/loss.py" target="_blank" rel="noopener">Summer_Intern/loss.py at master · james20141606/Summer_Intern · GitHub</a><br><a href="https://github.com/james20141606/Summer_Intern/blob/master/synapse_prediction/jupyter/loss_dlink_net.ipynb" target="_blank" rel="noopener">Summer_Intern/loss_dlink_net.ipynb at master · james20141606/Summer_Intern · GitHub</a></p><figure class="highlight stata"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> dice_bce_loss(nn.Module):</span><br><span class="line">    def __init__(self, batch=True):</span><br><span class="line">        super(dice_bce_loss, self).__init__()</span><br><span class="line">        self.batch = batch</span><br><span class="line">        self.bce_loss = WeightedBCELoss()</span><br><span class="line"></span><br><span class="line">    def soft_dice_coeff(self, <span class="keyword">input</span>, target):</span><br><span class="line">        <span class="keyword">smooth</span> = 0.0  # may change</span><br><span class="line">        <span class="keyword">if</span> self.batch:</span><br><span class="line">            i = torch.<span class="built_in">sum</span>(target)</span><br><span class="line">            j = torch.<span class="built_in">sum</span>(<span class="keyword">input</span>)</span><br><span class="line">            intersection = torch.<span class="built_in">sum</span>(target * <span class="keyword">input</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            i = target.<span class="built_in">sum</span>(1).<span class="built_in">sum</span>(1).<span class="built_in">sum</span>(1)</span><br><span class="line">            j = <span class="keyword">input</span>.<span class="built_in">sum</span>(1).<span class="built_in">sum</span>(1).<span class="built_in">sum</span>(1)</span><br><span class="line">            intersection = (target * <span class="keyword">input</span>).<span class="built_in">sum</span>(1).<span class="built_in">sum</span>(1).<span class="built_in">sum</span>(1)</span><br><span class="line">        <span class="keyword">score</span> = (2. * intersection + <span class="keyword">smooth</span>) / (i + j + <span class="keyword">smooth</span>)</span><br><span class="line">        #<span class="keyword">score</span> = (intersection + <span class="keyword">smooth</span>) / (i + j - intersection + <span class="keyword">smooth</span>)#iou</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">score</span>.<span class="keyword">mean</span>()</span><br><span class="line"></span><br><span class="line">    def soft_dice_loss(self, <span class="keyword">input</span>, target):</span><br><span class="line">        loss = 1 - self.soft_dice_coeff(<span class="keyword">input</span>, target)</span><br><span class="line">        <span class="keyword">return</span> loss</span><br><span class="line"></span><br><span class="line">    def __call__(self, <span class="keyword">input</span>, target, weight):</span><br><span class="line">        a = self.bce_loss(<span class="keyword">input</span>, target, weight)</span><br><span class="line">        b = self.soft_dice_loss(<span class="keyword">input</span>, target)</span><br><span class="line">        <span class="keyword">return</span> a + b</span><br></pre></td></tr></table></figure><p>I use TensorboardX to monitor the training procedure. I monitor the combined loss, DICE loss and BCE loss simultaneously. To my relief, the loss function decrease not only because BCE decrease, the DICE loss also decrease. Since 1- DICE reflect the overlap ratio of predicted and ground truth area, it means our model learns well.</p><p><strong>Train loss:</strong><br><img src="http://i4.fuimg.com/640680/03763aade56aca61.png" alt="Markdown"><br><strong>BCE loss:</strong><br><img src="http://i4.fuimg.com/640680/a3694f6e59e4a242.png" alt="Markdown"><br><strong>DICE loss:</strong><br><img src="http://i4.fuimg.com/640680/163718480760fffd.png" alt="Markdown"></p><p>We should do further improvement on loss function, BCE is divided by batch size, so we may do the same with DICE.</p><p>We think BCE punishes FN since we set a weight to punish it. And we think DICE is punishing FP since the remained are mainly FP, and we think it is good: our strategy is remove FN at first, then we can prune FP using some methods. So DICE loss may become one of our methods.</p><p><strong>We can also balance the FP, FN by adjusting DICE and BCE’s weight. It is essential for us to decrease FP since it is the main gap between the state of art model. We retain so many FP in predicting.</strong></p><h2 id="Data-augmentation"><a href="#Data-augmentation" class="headerlink" title="Data augmentation"></a>Data augmentation</h2><p><strong>I spent many time on this part because I believe it is the most important part besides the model, also this part may determine which pipeline is better between many good models.</strong></p><p>Last week we have discussed a lot about augmentation’s details. This week I rewrite several of them, and learned many different augmentation methods from many sources( mature pipeline, API, challenge winner and papers) I compare their results by rewrite their codes and visualize the results. Some of the codes  I read are hard to understand(like gunpowder) since it contain a whole pipeline’s complex manipulation. </p><p><strong>I have applied several of them and implement them in training and testing pipeline.</strong></p><p>The codes for final use is: <a href="https://github.com/james20141606/Summer_Intern/blob/master/synapse_prediction/bin/augmentation.py" target="_blank" rel="noopener">Summer_Intern/augmentation.py at master · james20141606/Summer_Intern · GitHub</a><br>And the implementation and visualization codes:<br><a href="https://github.com/james20141606/Summer_Intern/blob/master/synapse_prediction/jupyter/cremi_augmentation_implementation.ipynb" target="_blank" rel="noopener">Summer_Intern/cremi_augmentation_implementation.ipynb at master · james20141606/Summer_Intern · GitHub</a><br><a href="https://github.com/james20141606/Summer_Intern/blob/master/synapse_prediction/jupyter/augment_cremi.ipynb" target="_blank" rel="noopener">Summer_Intern/augment_cremi.ipynb at master · james20141606/Summer_Intern · GitHub</a></p><h3 id="training"><a href="#training" class="headerlink" title="training"></a>training</h3><p>I do transformation on image and mask at the same time. For simple augmentation it is simple, for elastic transformation, I use random seed to reproduce, and binarize mask data to 0, 1 again. For intensity augmentation  I don’t do any transformation on mask. For defect transformation, there are many to notice, including random seed to reproduce and binarize. </p><p>I do many visualization to benchmark every augmentation</p><h5 id="train"><a href="#train" class="headerlink" title="train"></a>train</h5><h4 id="simple-augmentation-1"><a href="#simple-augmentation-1" class="headerlink" title="simple augmentation"></a>simple augmentation</h4><p>Do X, Y, Z mirror and transpose, so in total there are 16 methods. Produce a list to generate four 0, 1 random int to decide do or not do these four methods. Do same transformation on image and mask.</p><p>Usage:  simpleaug_train_produce()<br><img src="http://i1.fuimg.com/640680/b230e7beb1ffb4fd.png" alt="Markdown"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># produce 16 binary arr</span></span><br><span class="line">binaryarr = np.zeros([<span class="number">16</span>, <span class="number">4</span>]).astype(<span class="string">'int'</span>)</span><br><span class="line"><span class="keyword">for</span> t <span class="keyword">in</span> range(<span class="number">16</span>):</span><br><span class="line">    binaryarr[t] = np.concatenate((np.repeat(<span class="number">0</span>, <span class="number">4</span>-len(bin(t)[<span class="number">2</span>:])), np.array(</span><br><span class="line">        [bin(t)[<span class="number">2</span>:][i] <span class="keyword">for</span> i <span class="keyword">in</span> range(len(bin(t)[<span class="number">2</span>:]))]).astype(<span class="string">'int'</span>)))</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">augmentsimple</span><span class="params">(data, rule)</span>:</span></span><br><span class="line">    <span class="keyword">assert</span> np.size(rule) == <span class="number">4</span> <span class="keyword">and</span> data.ndim == <span class="number">3</span></span><br><span class="line">    <span class="comment"># z reflection.</span></span><br><span class="line">    <span class="keyword">if</span> rule[<span class="number">0</span>]:</span><br><span class="line">        data = data[::<span class="number">-1</span>, :, :]</span><br><span class="line">    <span class="comment"># x reflection.</span></span><br><span class="line">    <span class="keyword">if</span> rule[<span class="number">1</span>]:</span><br><span class="line">        data = data[:, :, ::<span class="number">-1</span>]</span><br><span class="line">    <span class="comment"># y reflection.</span></span><br><span class="line">    <span class="keyword">if</span> rule[<span class="number">2</span>]:</span><br><span class="line">        data = data[:, ::<span class="number">-1</span>, :]</span><br><span class="line">    <span class="comment"># Transpose in xy.</span></span><br><span class="line">    <span class="keyword">if</span> rule[<span class="number">3</span>]:</span><br><span class="line">        data = data.transpose(<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> data</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">produce_simple_16_sample</span><span class="params">(imgs, imgshape)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    imgs: 24*256*256 -&gt; 16*24*256*256</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    <span class="keyword">assert</span> imgs.ndim == <span class="number">3</span></span><br><span class="line">    augmentsimplearr = np.ndarray(</span><br><span class="line">        [<span class="number">16</span>, imgshape[<span class="number">0</span>], imgshape[<span class="number">1</span>], imgshape[<span class="number">2</span>]])</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">16</span>):</span><br><span class="line">        augmentsimplearr[i] = augmentsimple(imgs, binaryarr[i])</span><br><span class="line">    <span class="keyword">return</span> augmentsimplearr</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">produce_simple_train_sample</span><span class="params">(imgs, rule)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    imgs: 24*256*256 -&gt; 16*24*256*256</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    <span class="keyword">assert</span> imgs.ndim == <span class="number">3</span></span><br><span class="line">    <span class="keyword">return</span> augmentsimple(imgs, rule)</span><br></pre></td></tr></table></figure><h4 id="intensity-augmentation"><a href="#intensity-augmentation" class="headerlink" title="intensity augmentation"></a>intensity augmentation</h4><p>Usage: IntensityAugment()</p><p>Use <strong>mix</strong> mode for random choose 2D or 3D intensity augmentation. I do not transform mask because there is only pixel shift. </p><p><img src="http://i1.fuimg.com/640680/8f09339677f17d82.png" alt="Markdown"></p><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">IntensityAugment</span>():</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(<span class="keyword">self</span>,  mode=<span class="string">'mix'</span>, skip_ratio=<span class="number">0</span>.<span class="number">3</span>, CONTRAST_FACTOR=<span class="number">0</span>.<span class="number">3</span>, BRIGHTNESS_FACTOR=<span class="number">0</span>.<span class="number">3</span>)</span></span><span class="symbol">:</span></span><br><span class="line">        <span class="string">""</span><span class="string">"</span></span><br><span class="line"><span class="string">        Initialize parameters.</span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            mode: 2D, 3D, or mix</span></span><br><span class="line"><span class="string">        "</span><span class="string">""</span></span><br><span class="line">        assert mode == <span class="string">'3D'</span> <span class="keyword">or</span> mode == <span class="string">'2D'</span> <span class="keyword">or</span> mode == <span class="string">'mix'</span></span><br><span class="line">        <span class="keyword">self</span>.mode = mode</span><br><span class="line">        <span class="keyword">self</span>.ratio = skip_ratio</span><br><span class="line">        <span class="keyword">self</span>.CONTRAST_FACTOR = CONTRAST_FACTOR</span><br><span class="line">        <span class="keyword">self</span>.BRIGHTNESS_FACTOR = BRIGHTNESS_FACTOR</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">augment</span><span class="params">(<span class="keyword">self</span>, imgs)</span></span><span class="symbol">:</span></span><br><span class="line">        skiprand = np.random.rand()</span><br><span class="line">        <span class="keyword">if</span> skiprand &gt; <span class="keyword">self</span>.<span class="symbol">ratio:</span></span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">self</span>.mode == <span class="string">'mix'</span><span class="symbol">:</span></span><br><span class="line">                threshold = <span class="number">1</span>-(<span class="number">1</span>-<span class="keyword">self</span>.ratio)/<span class="number">2</span></span><br><span class="line">                mode<span class="number">_</span> = <span class="string">'3D'</span> <span class="keyword">if</span> skiprand &gt; threshold <span class="keyword">else</span> <span class="string">'2D'</span> </span><br><span class="line">            <span class="symbol">else:</span></span><br><span class="line">                mode<span class="number">_</span> = <span class="keyword">self</span>.mode</span><br><span class="line">            <span class="keyword">if</span> mode<span class="number">_</span> == <span class="string">'2D'</span><span class="symbol">:</span></span><br><span class="line">                imgs = <span class="keyword">self</span>.augment2D(imgs)</span><br><span class="line">            elif mode<span class="number">_</span> == <span class="string">'3D'</span><span class="symbol">:</span></span><br><span class="line">                imgs = <span class="keyword">self</span>.augment3D(imgs)</span><br><span class="line">            <span class="keyword">return</span> imgs</span><br><span class="line">        <span class="symbol">else:</span></span><br><span class="line">            <span class="keyword">return</span> imgs</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">augment2D</span><span class="params">(<span class="keyword">self</span>, imgs)</span></span><span class="symbol">:</span></span><br><span class="line">        <span class="keyword">for</span> z <span class="keyword">in</span> range(imgs.shape[-<span class="number">3</span>])<span class="symbol">:</span></span><br><span class="line">            img = imgs[z, <span class="symbol">:</span>, <span class="symbol">:</span>]</span><br><span class="line">            img *= <span class="number">1</span> + (np.random.rand() - <span class="number">0</span>.<span class="number">5</span>)*<span class="keyword">self</span>.CONTRAST_FACTOR</span><br><span class="line">            img += (np.random.rand() - <span class="number">0</span>.<span class="number">5</span>)*<span class="keyword">self</span>.BRIGHTNESS_FACTOR</span><br><span class="line">            img = np.clip(img, <span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">            img **= <span class="number">2.0</span>**(np.random.rand()*<span class="number">2</span> - <span class="number">1</span>)</span><br><span class="line">            imgs[z, <span class="symbol">:</span>, <span class="symbol">:</span>] = img</span><br><span class="line">        <span class="keyword">return</span> imgs</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">augment3D</span><span class="params">(<span class="keyword">self</span>, imgs)</span></span><span class="symbol">:</span></span><br><span class="line">        imgs *= <span class="number">1</span> + (np.random.rand() - <span class="number">0</span>.<span class="number">5</span>)*<span class="keyword">self</span>.CONTRAST_FACTOR</span><br><span class="line">        imgs += (np.random.rand() - <span class="number">0</span>.<span class="number">5</span>)*<span class="keyword">self</span>.BRIGHTNESS_FACTOR</span><br><span class="line">        imgs = np.clip(imgs, <span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">        imgs **= <span class="number">2.0</span>**(np.random.rand()*<span class="number">2</span> - <span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> imgs</span><br></pre></td></tr></table></figure><h4 id="elastic-augmentation"><a href="#elastic-augmentation" class="headerlink" title="elastic augmentation"></a>elastic augmentation</h4><p>Usage: apply_elastic_transform(img, mask)<br>I compare gunpowder and this <a href="https://www.kaggle.com/bguberfain/elastic-transform-for-data-augmentation" target="_blank" rel="noopener">Elastic Transform for Data Augmentation | Kaggle</a> one, after comparison, it seems gunpowder version elastic has more functions, if we do not use rotate, it is fine.<br>The output range of create_transformation is 0-width, we can normalize the results. And I use random seed to reproduce on images and masks</p><p><img src="http://i1.fuimg.com/640680/b57e8e884c754591.png" alt="Markdown"></p><figure class="highlight maxima"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br></pre></td><td class="code"><pre><span class="line">def create_identity_transformation(shape, <span class="built_in">subsample</span>=<span class="number">1</span>):</span><br><span class="line">    dims = len(shape)</span><br><span class="line">    subsample_shape = tuple(<span class="built_in">max</span>(<span class="number">1</span>, int(s/<span class="built_in">subsample</span>)) <span class="keyword">for</span> s <span class="keyword">in</span> shape)</span><br><span class="line">    step_width = tuple(<span class="built_in">float</span>(shape[d]-<span class="number">1</span>)/(subsample_shape[d]-<span class="number">1</span>)</span><br><span class="line">                       <span class="keyword">if</span> subsample_shape[d] &gt; <span class="number">1</span> <span class="keyword">else</span> <span class="number">1</span> <span class="keyword">for</span> d <span class="keyword">in</span> <span class="built_in">range</span>(dims))</span><br><span class="line">    axis_ranges = (</span><br><span class="line">        <span class="built_in">np</span>.arange(subsample_shape[d], dtype=<span class="built_in">np</span>.float32)*step_width[d]</span><br><span class="line">        <span class="keyword">for</span> d <span class="keyword">in</span> <span class="built_in">range</span>(dims)</span><br><span class="line">    )</span><br><span class="line">    <span class="built_in">return</span> <span class="built_in">np</span>.<span class="built_in">array</span>(<span class="built_in">np</span>.meshgrid(*axis_ranges, indexing='ij'), dtype=<span class="built_in">np</span>.float32)</span><br><span class="line"></span><br><span class="line">def upscale_transformation(transformation, output_shape, interpolate_order=<span class="number">1</span>):</span><br><span class="line">    input_shape = transformation.shape[<span class="number">1</span>:]</span><br><span class="line">    dims = len(output_shape)</span><br><span class="line">    <span class="built_in">scale</span> = tuple(<span class="built_in">float</span>(s)/c <span class="keyword">for</span> s, c <span class="keyword">in</span> zip(output_shape, input_shape))</span><br><span class="line">    scaled = <span class="built_in">np</span>.zeros((dims,)+output_shape, dtype=<span class="built_in">np</span>.float32)</span><br><span class="line">    <span class="keyword">for</span> d <span class="keyword">in</span> <span class="built_in">range</span>(dims):</span><br><span class="line">        zoom(transformation[d], zoom=<span class="built_in">scale</span>,</span><br><span class="line">             output=scaled[d], order=interpolate_order)</span><br><span class="line">    <span class="built_in">return</span> scaled</span><br><span class="line"></span><br><span class="line">def create_elastic_transformation(shape, control_point_spacing=<span class="number">100</span>, jitter_sigma=<span class="number">10.0</span>, <span class="built_in">subsample</span>=<span class="number">1</span>):</span><br><span class="line">    dims = len(shape)</span><br><span class="line">    subsample_shape = tuple(<span class="built_in">max</span>(<span class="number">1</span>, int(s/<span class="built_in">subsample</span>)) <span class="keyword">for</span> s <span class="keyword">in</span> shape)</span><br><span class="line">    try:</span><br><span class="line">        spacing = tuple((d <span class="keyword">for</span> d <span class="keyword">in</span> control_point_spacing))</span><br><span class="line">    except:</span><br><span class="line">        spacing = (control_point_spacing,)*dims</span><br><span class="line">    try:</span><br><span class="line">        sigmas = [s <span class="keyword">for</span> s <span class="keyword">in</span> jitter_sigma]</span><br><span class="line">    except:</span><br><span class="line">        sigmas = [jitter_sigma]*dims</span><br><span class="line">    control_points = tuple(</span><br><span class="line">        <span class="built_in">max</span>(<span class="number">1</span>, int(<span class="built_in">round</span>(<span class="built_in">float</span>(shape[d])/spacing[d])))</span><br><span class="line">        <span class="keyword">for</span> d <span class="keyword">in</span> <span class="built_in">range</span>(len(shape))</span><br><span class="line">    )</span><br><span class="line">    control_point_offsets = <span class="built_in">np</span>.zeros(</span><br><span class="line">        (dims,) + control_points, dtype=<span class="built_in">np</span>.float32)</span><br><span class="line">    <span class="keyword">for</span> d <span class="keyword">in</span> <span class="built_in">range</span>(dims):</span><br><span class="line">        <span class="keyword">if</span> sigmas[d] &gt; <span class="number">0</span>:</span><br><span class="line">            control_point_offsets[d] = <span class="built_in">np</span>.<span class="built_in">random</span>.normal(</span><br><span class="line">                <span class="built_in">scale</span>=sigmas[d], size=control_points)</span><br><span class="line">    <span class="built_in">return</span> upscale_transformation(control_point_offsets, subsample_shape, interpolate_order=<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def rotate(point, angle):</span><br><span class="line">    res = <span class="built_in">np</span>.<span class="built_in">array</span>(point)</span><br><span class="line">    res[<span class="number">0</span>] = math.<span class="built_in">sin</span>(angle)*point[<span class="number">1</span>] + math.<span class="built_in">cos</span>(angle)*point[<span class="number">0</span>]</span><br><span class="line">    res[<span class="number">1</span>] = -math.<span class="built_in">sin</span>(angle)*point[<span class="number">0</span>] + math.<span class="built_in">cos</span>(angle)*point[<span class="number">1</span>]</span><br><span class="line">    <span class="built_in">return</span> res</span><br><span class="line"></span><br><span class="line">def create_rotation_transformation(shape, angle, <span class="built_in">subsample</span>=<span class="number">1</span>):</span><br><span class="line">    dims = len(shape)</span><br><span class="line">    subsample_shape = tuple(<span class="built_in">max</span>(<span class="number">1</span>, int(s/<span class="built_in">subsample</span>)) <span class="keyword">for</span> s <span class="keyword">in</span> shape)</span><br><span class="line">    control_points = (<span class="number">2</span>,)*dims</span><br><span class="line">    control_point_scaling_factor = tuple(<span class="built_in">float</span>(s-<span class="number">1</span>) <span class="keyword">for</span> s <span class="keyword">in</span> shape)</span><br><span class="line">    <span class="built_in">center</span> = <span class="built_in">np</span>.<span class="built_in">array</span>([<span class="number">0.5</span>*(d-<span class="number">1</span>) <span class="keyword">for</span> d <span class="keyword">in</span> shape])</span><br><span class="line">    control_point_offsets = <span class="built_in">np</span>.zeros(</span><br><span class="line">        (dims,) + control_points, dtype=<span class="built_in">np</span>.float32)</span><br><span class="line">    <span class="keyword">for</span> control_point <span class="keyword">in</span> <span class="built_in">np</span>.ndindex(control_points):</span><br><span class="line"></span><br><span class="line">        point = <span class="built_in">np</span>.<span class="built_in">array</span>(control_point)*control_point_scaling_factor</span><br><span class="line">        center_offset = <span class="built_in">np</span>.<span class="built_in">array</span>(</span><br><span class="line">            [p-c <span class="keyword">for</span> c, p <span class="keyword">in</span> zip(<span class="built_in">center</span>, point)], dtype=<span class="built_in">np</span>.float32)</span><br><span class="line">        rotated_offset = <span class="built_in">np</span>.<span class="built_in">array</span>(center_offset)</span><br><span class="line">        rotated_offset[-<span class="number">2</span>:] = rotate(center_offset[-<span class="number">2</span>:], angle)</span><br><span class="line">        displacement = rotated_offset - center_offset</span><br><span class="line">        control_point_offsets[(slice(None),) + control_point] += displacement</span><br><span class="line"></span><br><span class="line">    <span class="built_in">return</span> upscale_transformation(control_point_offsets, subsample_shape)</span><br><span class="line"></span><br><span class="line">def random_offset(max_misalign):</span><br><span class="line">    <span class="built_in">return</span> Coordinate((<span class="number">0</span>,) + tuple(max_misalign - <span class="built_in">random</span>.randint(<span class="number">0</span>, <span class="number">2</span>*int(max_misalign)) <span class="keyword">for</span> d <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>)))</span><br><span class="line"></span><br><span class="line">def misalign(transformation, prob_slip, prob_shift, max_misalign):</span><br><span class="line">    num_sections = transformation[<span class="number">0</span>].shape[<span class="number">0</span>]</span><br><span class="line">    <span class="built_in">print</span> (num_sections)</span><br><span class="line">    shifts = [Coordinate((<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>))]*num_sections</span><br><span class="line">    <span class="keyword">for</span> z <span class="keyword">in</span> <span class="built_in">range</span>(num_sections):</span><br><span class="line">        r = <span class="built_in">random</span>.<span class="built_in">random</span>()</span><br><span class="line">        <span class="keyword">if</span> r &lt;= prob_slip:</span><br><span class="line">            shifts[z] = random_offset(max_misalign)</span><br><span class="line">        elif r &lt;= prob_slip + prob_shift:</span><br><span class="line">            offset = random_offset(max_misalign)</span><br><span class="line">            <span class="keyword">for</span> zp <span class="keyword">in</span> <span class="built_in">range</span>(z, num_sections):</span><br><span class="line">                shifts[zp] += offset</span><br><span class="line">                #<span class="built_in">print</span> ('shiftzp '+str(shifts[zp]))</span><br><span class="line">    <span class="keyword">for</span> z <span class="keyword">in</span> <span class="built_in">range</span>(num_sections):</span><br><span class="line">        transformation[<span class="number">1</span>][z, :, :] += shifts[z][<span class="number">1</span>]</span><br><span class="line">        transformation[<span class="number">2</span>][z, :, :] += shifts[z][<span class="number">2</span>]</span><br><span class="line">    <span class="built_in">return</span> transformation</span><br><span class="line">class ElasticAugment():</span><br><span class="line">    def __init__(</span><br><span class="line">            self,</span><br><span class="line">            control_point_spacing,</span><br><span class="line">            jitter_sigma,</span><br><span class="line">            rotation_interval,</span><br><span class="line">            prob_slip=<span class="number">0</span>,</span><br><span class="line">            prob_shift=<span class="number">0</span>,</span><br><span class="line">            max_misalign=<span class="number">0</span>,</span><br><span class="line">            <span class="built_in">subsample</span>=<span class="number">1</span>):</span><br><span class="line">        self.control_point_spacing = control_point_spacing</span><br><span class="line">        self.jitter_sigma = jitter_sigma</span><br><span class="line">        self.rotation_start = rotation_interval[<span class="number">0</span>]</span><br><span class="line">        self.rotation_max_amount = rotation_interval[<span class="number">1</span>] - rotation_interval[<span class="number">0</span>]</span><br><span class="line">        self.prob_slip = prob_slip</span><br><span class="line">        self.prob_shift = prob_shift</span><br><span class="line">        self.max_misalign = max_misalign</span><br><span class="line">        self.<span class="built_in">subsample</span> = <span class="built_in">subsample</span></span><br><span class="line">    def create_transformation(self, target_shape):</span><br><span class="line">        transformation = create_identity_transformation(</span><br><span class="line">            target_shape,</span><br><span class="line">            <span class="built_in">subsample</span>=self.<span class="built_in">subsample</span>)</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">sum</span>(self.jitter_sigma) &gt; <span class="number">0</span>:</span><br><span class="line">            transformation += create_elastic_transformation(</span><br><span class="line">                target_shape,</span><br><span class="line">                self.control_point_spacing,</span><br><span class="line">                self.jitter_sigma,</span><br><span class="line">                <span class="built_in">subsample</span>=self.<span class="built_in">subsample</span>)</span><br><span class="line">        rotation = <span class="built_in">random</span>.<span class="built_in">random</span>()*self.rotation_max_amount + self.rotation_start</span><br><span class="line">        <span class="keyword">if</span> rotation != <span class="number">0</span>:</span><br><span class="line">            transformation += create_rotation_transformation(</span><br><span class="line">                target_shape,</span><br><span class="line">                rotation,</span><br><span class="line">                <span class="built_in">subsample</span>=self.<span class="built_in">subsample</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.<span class="built_in">subsample</span> &gt; <span class="number">1</span>:</span><br><span class="line">            transformation = upscale_transformation(</span><br><span class="line">                transformation,</span><br><span class="line">                target_shape)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.prob_slip + self.prob_shift &gt; <span class="number">0</span>:</span><br><span class="line">            misalign(transformation, self.prob_slip,</span><br><span class="line">                     self.prob_shift, self.max_misalign)</span><br><span class="line">        <span class="built_in">return</span> transformation</span><br><span class="line">def apply_transformation(<span class="built_in">image</span>, transformation, interpolate=True, outside_value=<span class="number">0</span>, output=None):</span><br><span class="line"></span><br><span class="line">    # <span class="built_in">print</span>(<span class="string">"Applying transformation..."</span>)</span><br><span class="line">    order = <span class="number">1</span> <span class="keyword">if</span> interpolate == True <span class="keyword">else</span> <span class="number">0</span></span><br><span class="line">    output = <span class="built_in">image</span>.dtype <span class="keyword">if</span> output <span class="built_in">is</span> None <span class="keyword">else</span> output</span><br><span class="line">    <span class="built_in">return</span> map_coordinates(<span class="built_in">image</span>, transformation, output=output, order=order, mode='<span class="built_in">constant</span>', cval=outside_value)</span><br><span class="line"></span><br><span class="line">def apply_elastic_transform(img, mask):</span><br><span class="line">    assert img.shape[<span class="number">1</span>] == img.shape[<span class="number">2</span>]</span><br><span class="line">    img *= img.shape[<span class="number">1</span>]</span><br><span class="line">    <span class="built_in">transform</span> = ElasticAugment([<span class="number">4</span>, <span class="number">40</span>, <span class="number">40</span>], [<span class="number">0</span>, <span class="number">2</span>, <span class="number">2</span>], [<span class="number">0</span>, <span class="number">0</span>], prob_slip=<span class="number">0.05</span>,</span><br><span class="line">                               prob_shift=<span class="number">0.05</span>, max_misalign=<span class="number">25</span>).create_transformation([img.shape[<span class="number">0</span>], img.shape[<span class="number">1</span>], img.shape[<span class="number">2</span>]])</span><br><span class="line">    img_transform = apply_transformation(img,</span><br><span class="line">                                         <span class="built_in">transform</span>,</span><br><span class="line">                                         interpolate=False,</span><br><span class="line">                                         outside_value=img.dtype.type(-<span class="number">1</span>),</span><br><span class="line">                                         output=<span class="built_in">np</span>.zeros(img.shape, dtype=<span class="built_in">np</span>.float32))</span><br><span class="line">    seg_transform = apply_transformation(mask,</span><br><span class="line">                                         <span class="built_in">transform</span>,</span><br><span class="line">                                         interpolate=False,</span><br><span class="line">                                         outside_value=mask.dtype.type(-<span class="number">1</span>),</span><br><span class="line">                                         output=<span class="built_in">np</span>.zeros(mask.shape, dtype=<span class="built_in">np</span>.float32))(<span class="built_in">np</span>.<span class="built_in">unique</span>(seg_transform.ravel()),<span class="built_in">np</span>.<span class="built_in">unique</span>(<span class="built_in">transform</span>.ravel()))</span><br><span class="line">    seg_transform[seg_transform &gt; <span class="number">0</span>] = <span class="number">1</span></span><br><span class="line">    seg_transform[seg_transform != <span class="number">1</span>] = <span class="number">0</span></span><br><span class="line">    <span class="built_in">return</span> img_transform/img_transform.shape[<span class="number">1</span>], seg_transform</span><br></pre></td></tr></table></figure><h4 id="defect-augmentation"><a href="#defect-augmentation" class="headerlink" title="defect augmentation"></a>defect augmentation</h4><p>Usage: transformedimgs, transformedmasks = apply_deform(testdatraw/256.,testdatseg,0,20,0.08)</p><p><img src="http://i1.fuimg.com/640680/3dfea030bf017168.png" alt="Markdown"></p><p>I use gunpowder’s defect, the block region used to be zero, but I change it to zero for better batch normalization results. I use random seed to reproduce images and masks. The block size and missing section’s ratio can change. </p><figure class="highlight maxima"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line">def prepare_deform_slice(slice_shape, deformation_strength, <span class="built_in">iterations</span>, randomseed):</span><br><span class="line">    <span class="built_in">np</span>.<span class="built_in">random</span>.seed(randomseed)</span><br><span class="line">    grow_by = <span class="number">2</span> * deformation_strength</span><br><span class="line">    shape = (slice_shape[<span class="number">0</span>] + grow_by, slice_shape[<span class="number">1</span>] + grow_by)</span><br><span class="line">    fixed_x = <span class="built_in">np</span>.<span class="built_in">random</span>.<span class="built_in">random</span>() &lt; .<span class="number">5</span></span><br><span class="line">    <span class="keyword">if</span> fixed_x:</span><br><span class="line">        x0, y0 = <span class="number">0</span>, <span class="built_in">np</span>.<span class="built_in">random</span>.randint(<span class="number">1</span>, shape[<span class="number">1</span>] - <span class="number">2</span>)</span><br><span class="line">        x1, y1 = shape[<span class="number">0</span>] - <span class="number">1</span>, <span class="built_in">np</span>.<span class="built_in">random</span>.randint(<span class="number">1</span>, shape[<span class="number">1</span>] - <span class="number">2</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        x0, y0 = <span class="built_in">np</span>.<span class="built_in">random</span>.randint(<span class="number">1</span>, shape[<span class="number">0</span>] - <span class="number">2</span>), <span class="number">0</span></span><br><span class="line">        x1, y1 = <span class="built_in">np</span>.<span class="built_in">random</span>.randint(<span class="number">1</span>, shape[<span class="number">0</span>] - <span class="number">2</span>), shape[<span class="number">1</span>] - <span class="number">1</span></span><br><span class="line">    line_mask = <span class="built_in">np</span>.zeros(shape, dtype='bool')</span><br><span class="line">    rr, cc = line(x0, y0, x1, y1)</span><br><span class="line">    line_mask[rr, cc] = <span class="number">1</span></span><br><span class="line">    line_vector = <span class="built_in">np</span>.<span class="built_in">array</span>([x1 - x0, y1 - y0], dtype='float32')</span><br><span class="line">    line_vector /= <span class="built_in">np</span>.linalg.norm(line_vector)</span><br><span class="line">    normal_vector = <span class="built_in">np</span>.zeros_like(line_vector)</span><br><span class="line">    normal_vector[<span class="number">0</span>] = - line_vector[<span class="number">1</span>]</span><br><span class="line">    normal_vector[<span class="number">1</span>] = line_vector[<span class="number">0</span>]</span><br><span class="line">    x, y = <span class="built_in">np</span>.meshgrid(<span class="built_in">np</span>.arange(shape[<span class="number">1</span>]), <span class="built_in">np</span>.arange(shape[<span class="number">0</span>]))</span><br><span class="line">    flow_x, flow_y = <span class="built_in">np</span>.zeros(shape), <span class="built_in">np</span>.zeros(shape)</span><br><span class="line">    <span class="built_in">components</span>, n_components = <span class="built_in">label</span>(<span class="built_in">np</span>.logical_not(line_mask).<span class="built_in">view</span>('uint8'))</span><br><span class="line">    assert n_components == <span class="number">2</span>, <span class="string">"%i"</span> <span class="symbol">%</span> n_components</span><br><span class="line">    neg_val = <span class="built_in">components</span>[<span class="number">0</span>, <span class="number">0</span>] <span class="keyword">if</span> fixed_x <span class="keyword">else</span> <span class="built_in">components</span>[-<span class="number">1</span>, -<span class="number">1</span>]</span><br><span class="line">    pos_val = <span class="built_in">components</span>[-<span class="number">1</span>, -<span class="number">1</span>] <span class="keyword">if</span> fixed_x <span class="keyword">else</span> <span class="built_in">components</span>[<span class="number">0</span>, <span class="number">0</span>]</span><br><span class="line">    flow_x[<span class="built_in">components</span> == pos_val] = deformation_strength * normal_vector[<span class="number">1</span>]</span><br><span class="line">    flow_y[<span class="built_in">components</span> == pos_val] = deformation_strength * normal_vector[<span class="number">0</span>]</span><br><span class="line">    flow_x[<span class="built_in">components</span> == neg_val] = - deformation_strength * normal_vector[<span class="number">1</span>]</span><br><span class="line">    flow_y[<span class="built_in">components</span> == neg_val] = - deformation_strength * normal_vector[<span class="number">0</span>]</span><br><span class="line">    flow_x, flow_y = (x + flow_x).reshape(-<span class="number">1</span>, <span class="number">1</span>), (y + flow_y).reshape(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">    line_mask = binary_dilation(line_mask, <span class="built_in">iterations</span>=<span class="built_in">iterations</span>)  # default=<span class="number">10</span></span><br><span class="line">    <span class="built_in">return</span> flow_x, flow_y, line_mask</span><br><span class="line"></span><br><span class="line">def deform_2d(image2d, deformation_strength, <span class="built_in">iterations</span>, randomseed):</span><br><span class="line">    flow_x, flow_y, line_mask = prepare_deform_slice(</span><br><span class="line">        image2d.shape, deformation_strength, <span class="built_in">iterations</span>, randomseed)</span><br><span class="line">    section = image2d.squeeze()</span><br><span class="line">    <span class="built_in">mean</span> = section.<span class="built_in">mean</span>()</span><br><span class="line">    shape = section.shape</span><br><span class="line">    #interpolation=<span class="number">3</span></span><br><span class="line">    section = map_coordinates(section, (flow_y, flow_x), mode='<span class="built_in">constant</span>', order=<span class="number">3</span>).reshape(int(flow_x.shape[<span class="number">0</span>]**<span class="number">0.5</span>), int(flow_x.shape[<span class="number">0</span>]**<span class="number">0.5</span>))</span><br><span class="line">    section = <span class="built_in">np</span>.clip(section, <span class="number">0</span>., <span class="number">1</span>.)</span><br><span class="line">    section[line_mask] = <span class="built_in">mean</span></span><br><span class="line">    <span class="built_in">return</span> section</span><br><span class="line"></span><br><span class="line">def apply_deform(imgs, masks, deformation_strength=<span class="number">0</span>, <span class="built_in">iterations</span>=<span class="number">20</span>, deform_ratio=<span class="number">0.08</span>):</span><br><span class="line">    transformedimgs, transformedmasks = &#123;&#125;, &#123;&#125;</span><br><span class="line">    sectionsnum = imgs.shape[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(sectionsnum):</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">random</span>.<span class="built_in">random</span>() &lt;= deform_ratio:</span><br><span class="line">            randomseed = <span class="built_in">np</span>.<span class="built_in">random</span>.randint(<span class="number">1000000</span>)</span><br><span class="line">            transformedimgs[i] = deform_2d(</span><br><span class="line">                imgs[i], deformation_strength, <span class="built_in">iterations</span>, randomseed)</span><br><span class="line">            transformedmasks[i] = deform_2d(</span><br><span class="line">                masks[i], deformation_strength, <span class="built_in">iterations</span>, randomseed)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            transformedimgs[i] = imgs[i]</span><br><span class="line">            transformedmasks[i] = masks[i]</span><br><span class="line">    <span class="built_in">return</span> transformedimgs, transformedmasks</span><br></pre></td></tr></table></figure><h3 id="test"><a href="#test" class="headerlink" title="test"></a>test</h3><p>For each sample in test, I will produce 16 transformed images and reverse the predicted masks later.</p><p>Usage: simpleaug_test_produce()</p><p>Usage: simpleaug_test_reverse()</p><p>In test, it is common to only use 16 kinds <strong>simple augmentation</strong></p><p>For X Y Z axis mirro and xy transpose, in all $2^4 = 16$ images produced.</p><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">simpleaug_test_produce</span>():</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(<span class="keyword">self</span>, model_io_size=[<span class="number">24</span>, <span class="number">256</span>, <span class="number">256</span>])</span></span><span class="symbol">:</span></span><br><span class="line">        <span class="keyword">self</span>.model_io_size = model_io_size</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__call__</span><span class="params">(<span class="keyword">self</span>, imgs)</span></span><span class="symbol">:</span></span><br><span class="line">        <span class="keyword">return</span> produce_simple_16_sample(imgs, <span class="keyword">self</span>.model_io_size)</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">simpleaug_train_produce</span>():</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(<span class="keyword">self</span>, model_io_size=[<span class="number">24</span>, <span class="number">256</span>, <span class="number">256</span>])</span></span><span class="symbol">:</span></span><br><span class="line">        <span class="keyword">self</span>.rule = np.random.randint(<span class="number">2</span>, size=<span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__call__</span><span class="params">(<span class="keyword">self</span>, imgs, mask)</span></span><span class="symbol">:</span></span><br><span class="line">        <span class="comment">#print (self.rule)</span></span><br><span class="line">        imgs_aug = produce_simple_train_sample(imgs, <span class="keyword">self</span>.rule)</span><br><span class="line">        mask_aug = produce_simple_train_sample(mask, <span class="keyword">self</span>.rule)</span><br><span class="line">        <span class="keyword">return</span> imgs_aug, mask_aug</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">simpleaug_test_reverse</span>():</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(<span class="keyword">self</span>, model_io_size=[<span class="number">24</span>, <span class="number">256</span>, <span class="number">256</span>])</span></span><span class="symbol">:</span></span><br><span class="line">        <span class="keyword">self</span>.model_io_size = model_io_size</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">augmentsimplereverse</span><span class="params">(<span class="keyword">self</span>,data, rule)</span></span><span class="symbol">:</span></span><br><span class="line">        assert np.size(rule) == <span class="number">4</span> <span class="keyword">and</span> data.ndim == <span class="number">3</span></span><br><span class="line">        <span class="comment"># z reflection.</span></span><br><span class="line">        <span class="keyword">if</span> rule[<span class="number">3</span>]<span class="symbol">:</span></span><br><span class="line">            data = data.transpose(<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">        <span class="keyword">if</span> rule[<span class="number">2</span>]<span class="symbol">:</span></span><br><span class="line">            data = data[<span class="symbol">:</span>, <span class="symbol">:</span><span class="symbol">:-</span><span class="number">1</span>, <span class="symbol">:</span>]</span><br><span class="line">        <span class="keyword">if</span> rule[<span class="number">1</span>]<span class="symbol">:</span></span><br><span class="line">            data = data[<span class="symbol">:</span>, <span class="symbol">:</span>, <span class="symbol">:</span><span class="symbol">:-</span><span class="number">1</span>]</span><br><span class="line">        <span class="keyword">if</span> rule[<span class="number">0</span>]<span class="symbol">:</span></span><br><span class="line">            data = data[<span class="symbol">:</span><span class="symbol">:-</span><span class="number">1</span>, <span class="symbol">:</span>, <span class="symbol">:</span>]</span><br><span class="line">        <span class="keyword">return</span> data</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">reverse_and_mean</span><span class="params">(<span class="keyword">self</span>,imgs, imgshape)</span></span><span class="symbol">:</span></span><br><span class="line">        <span class="string">''</span><span class="string">'</span></span><br><span class="line"><span class="string">        imgs: 16*24*256*256 -&gt;24*256*256</span></span><br><span class="line"><span class="string">        '</span><span class="string">''</span></span><br><span class="line">        assert imgs.ndim == <span class="number">4</span></span><br><span class="line">        reversedsimplearr = np.ndarray(</span><br><span class="line">            [<span class="number">16</span>, imgshape[<span class="number">0</span>], imgshape[<span class="number">1</span>], imgshape[<span class="number">2</span>]])</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">16</span>)<span class="symbol">:</span></span><br><span class="line">            reversedsimplearr[i] = <span class="keyword">self</span>.augmentsimplereverse(imgs[i], binaryarr[i])</span><br><span class="line">        <span class="keyword">return</span> np.mean(reversedsimplearr, axis=<span class="number">0</span>)</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__call__</span><span class="params">(<span class="keyword">self</span>, imgs)</span></span><span class="symbol">:</span></span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">self</span>.reverse_and_mean(imgs, <span class="keyword">self</span>.model_io_size)</span><br></pre></td></tr></table></figure><h3 id="further-useful-augmentation"><a href="#further-useful-augmentation" class="headerlink" title="further useful augmentation"></a>further useful augmentation</h3><p>I have found many other augmentations in many sources. Since our main aim now is to get a better result in a short time. I will see if the augmentation strategy is enough. If not, I will implement them later. If the augmentation is good enough, we can do more on task 3 later. Since the model is really hard to train and see the results(may take a week for the feedback), time is really precious, and we can’t test one method at one time.</p><p>I have tried some here <a href="https://github.com/james20141606/Summer_Intern/blob/master/synapse_prediction/jupyter/further_aug_imgaug.ipynb" target="_blank" rel="noopener">Summer_Intern/further_aug_imgaug.ipynb at master · james20141606/Summer_Intern · GitHub</a>, but I will decide what to do first next week.</p><ul><li>2018 annual datascience bowl top1: segment cells<br><a href="https://www.leiphone.com/news/201804/qfus8zALhZLoA8Ai.html" target="_blank" rel="noopener">https://www.leiphone.com/news/201804/qfus8zALhZLoA8Ai.html</a><br>There are many data augmentation methods:<br><a href="https://github.com/selimsef/dsb2018_topcoders/blob/7a87c07e1fb8e090186a3914a1443469f5107962/albu/src/augmentations/transforms.py" target="_blank" rel="noopener">https://github.com/selimsef/dsb2018_topcoders/blob/7a87c07e1fb8e090186a3914a1443469f5107962/albu/src/augmentations/transforms.py</a><br>It seems clear and they used an augmentation API imgaug<br><a href="http://imgaug.readthedocs.io/en/latest/" target="_blank" rel="noopener">imgaug</a><br>Apart from gunpowder’s method, there are a lot to use!</li><li>random zoom, rotate, flip</li><li>contrast and brightness</li><li>heavy geometric transform:  Elastic Transform, Perspective Transform, Piecewise Affine transforms, Pincushion Distortion</li><li>contrast limited adaptive histogram equalization (CLAHE) ，Sharpen，Emboss</li><li>Gaussian noise</li><li>Blur、Median Blur、Motion Blur</li><li>HSV</li><li>rearrange channel</li><li>repeat of cell nuclear</li></ul><h2 id="future-work"><a href="#future-work" class="headerlink" title="future work"></a>future work</h2><h3 id="compare-with-other-work-and-thoughs"><a href="#compare-with-other-work-and-thoughs" class="headerlink" title="compare with other work and thoughs"></a>compare with other work and thoughs</h3><ul><li>For randomly chosen sample, we use pixel ratio to determine if one sample is used to train, Funke use probability,  we can think which is better.</li><li>Funke use regression whereas  we use binary classification, it is simple to change to regression, but we should compare our loss function and strategy at first. For example, Funke’s STED loss may not be good.</li><li>Funke use auxiliary loss for better prune, but we have visualize the result and find the proposed synapse matchh the membrane well, so it may not be necessary. </li></ul><h3 id="future-plan"><a href="#future-plan" class="headerlink" title="future plan"></a>future plan</h3><p>As mentioned above, I believe there are more to implement. The state-of-art model and pipeline looks really good, so I think I should use more strategy to improve our results.</p><ul><li>read and consider V-net’s structure. V-Net: Fully Convolutional Neural Networks for Volumetric Medical Image Segmentation<br><a href="http://mattmacy.io/vnet.pytorch/" target="_blank" rel="noopener">vnet.pytorch</a><br><a href="https://github.com/mattmacy/vnet.pytorch" target="_blank" rel="noopener">GitHub - mattmacy/vnet.pytorch: A PyTorch implementation for V-Net: Fully Convolutional Neural Networks for Volumetric Medical Image Segmentation</a><br><a href="https://github.com/mattmacy/torchbiomed" target="_blank" rel="noopener">GitHub - mattmacy/torchbiomed: Datasets, Transforms and Utilities specific to Biomedical Imaging</a></li><li>if submitted result has a big difference with Funke’s, I may try to reproduce their work.</li><li>read task 3 complete codes apart from  <a href="https://github.com/paragt/EMSynConn" target="_blank" rel="noopener">GitHub - paragt/EMSynConn: One algorithm to detect synaptic location AND connectivity, both dyadic and polyadic, in Electron Microscopy volume.</a></li><li>how to fine tune, apart from learning rate adjustment, we should consider some prune work. For example, the paper <strong>Stacked U-Nets with Multi-Output for Road Extraction</strong>:<blockquote><p>postprocessing: Various post-processing techniques for road extraction have been proposed in the literature, e.g., centerline extraction using structured SVM or Markov random ﬁeld, handling noisy data using a special CNN, recovering lines by sampling junction-points, and bridging road gaps by heuristic search. Here we develope a novel post processing technique by linking broken roads through shortest path search with decreasing conﬁdence thresholds. More speciﬁcally, we ﬁrst convert the raster road prediction image to vector format so we can bridge gaps and trim spurious roads, then we render a raster image from road vectors and merge it with the original prediction because the challenge needs raster images for IoU calculation.</p></blockquote></li><li>examine results carefully to understand the difference between FP and TP, gain biological intuition from it for better model design. For example the  density of membrane and vesicle</li></ul><hr><h1 id="Week-4"><a href="#Week-4" class="headerlink" title="Week 4"></a>Week 4</h1><p>This week I mainly focus on synaptic partner prediction and NMJ pipeline, and wait for our current models’ result on CREMI synapse prediction challenge.</p><h2 id="Loss-adjustment"><a href="#Loss-adjustment" class="headerlink" title="Loss adjustment"></a>Loss adjustment</h2><p>Last week we add DICE loss and this week we change BCE loss to Focal loss. It is adaptive to better consider weights.</p><p>P: predict result, GT: ground truth, N: batch size</p><script type="math/tex; mode=display">L = 1 - \frac{2 \times \sum_{i=1}^N  |P_i \cap GT_i  | }{\sum_{i=1}^N  (P_i + GT_i)} + \sum_{i=1}^N FocalLoss(P_i,  GT_i)</script><p><img src="http://i4.fuimg.com/640680/52858efa5d322afa.png" alt="Markdown"></p><script type="math/tex; mode=display">FocalLoss(pt) = -{(1 - p_t)}^\gamma log(p_t)</script><p><img src="http://i4.fuimg.com/640680/58f54732f92776ef.png" alt="Markdown"></p><h2 id="Augmentation-improvement"><a href="#Augmentation-improvement" class="headerlink" title="Augmentation improvement"></a>Augmentation improvement</h2><p>This week I add and improve two augmentation methods: deform and elastic augmetation.<br><a href="https://github.com/james20141606/Summer_Intern/blob/master/synapse_prediction/jupyter/cremi_augmentation_implementation.ipynb" target="_blank" rel="noopener">Summer_Intern/cremi_augmentation_implementation.ipynb at master · james20141606/Summer_Intern · GitHub</a></p><h3 id="deformation-augmentation"><a href="#deformation-augmentation" class="headerlink" title="deformation augmentation"></a>deformation augmentation</h3><p>Remove random seeds, do not add deformation on masks.<br>Write the function to avoid deformation on adjacent sections. We wish this can force the network pay attention to 3D characteristics of the image.</p><figure class="highlight nix"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br></pre></td><td class="code"><pre><span class="line">def prepare_deform_slice(slice_shape,deformation_strength,iterations):</span><br><span class="line">    <span class="comment"># grow slice shape by 2 x deformation strength</span></span><br><span class="line">    <span class="attr">grow_by</span> = <span class="number">2</span> * deformation_strength</span><br><span class="line">    <span class="comment">#print ('sliceshape: '+str(slice_shape[0])+' growby: '+str(grow_by)+ ' strength: '+str(deformation_strength))</span></span><br><span class="line">    <span class="attr">shape</span> = (slice_shape[<span class="number">0</span>] + grow_by, slice_shape[<span class="number">1</span>] + grow_by)</span><br><span class="line">    <span class="comment"># randomly choose fixed x or fixed y with p = 1/2</span></span><br><span class="line">    <span class="attr">fixed_x</span> = np.random.random() &lt; .<span class="number">5</span></span><br><span class="line">    <span class="keyword">if</span> fixed_x:</span><br><span class="line">        x0, <span class="attr">y0</span> = <span class="number">0</span>, np.random.randint(<span class="number">1</span>, shape[<span class="number">1</span>] - <span class="number">2</span>)</span><br><span class="line">        x1, <span class="attr">y1</span> = shape[<span class="number">0</span>] - <span class="number">1</span>, np.random.randint(<span class="number">1</span>, shape[<span class="number">1</span>] - <span class="number">2</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        x0, <span class="attr">y0</span> = np.random.randint(<span class="number">1</span>, shape[<span class="number">0</span>] - <span class="number">2</span>), <span class="number">0</span></span><br><span class="line">        x1, <span class="attr">y1</span> = np.random.randint(<span class="number">1</span>, shape[<span class="number">0</span>] - <span class="number">2</span>), shape[<span class="number">1</span>] - <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">## generate the mask of the line that should be blacked out</span></span><br><span class="line">    <span class="comment">#print (shape)</span></span><br><span class="line">    <span class="attr">line_mask</span> = np.zeros(shape, <span class="attr">dtype='bool')</span></span><br><span class="line">    rr, <span class="attr">cc</span> = line(x0, y0, x1, y1)</span><br><span class="line">    line_mask[rr, cc] = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># generate vectorfield pointing towards the line to compress the image</span></span><br><span class="line">    <span class="comment"># first we get the unit vector representing the line</span></span><br><span class="line">    <span class="attr">line_vector</span> = np.array([x1 - x0, y1 - y0], <span class="attr">dtype='float32')</span></span><br><span class="line">    line_vector /= np.linalg.norm(line_vector)</span><br><span class="line">    <span class="comment"># next, we generate the normal to the line</span></span><br><span class="line">    <span class="attr">normal_vector</span> = np.zeros_like(line_vector)</span><br><span class="line">    normal_vector[<span class="number">0</span>] = - line_vector[<span class="number">1</span>]</span><br><span class="line">    normal_vector[<span class="number">1</span>] = line_vector[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># make meshgrid</span></span><br><span class="line">    x, <span class="attr">y</span> = np.meshgrid(np.arange(shape[<span class="number">1</span>]), np.arange(shape[<span class="number">0</span>]))</span><br><span class="line">    <span class="comment"># generate the vector field</span></span><br><span class="line">    flow_x, <span class="attr">flow_y</span> = np.zeros(shape), np.zeros(shape)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># find the 2 components where coordinates are bigger / smaller than the line</span></span><br><span class="line">    <span class="comment"># to apply normal vector in the correct direction</span></span><br><span class="line">    components, <span class="attr">n_components</span> = label(np.logical_not(line_mask).view('uint8'))</span><br><span class="line">    <span class="keyword">assert</span> <span class="attr">n_components</span> == <span class="number">2</span>, <span class="string">"%i"</span> % n_components</span><br><span class="line">    <span class="attr">neg_val</span> = components[<span class="number">0</span>, <span class="number">0</span>] <span class="keyword">if</span> fixed_x <span class="keyword">else</span> components[-<span class="number">1</span>, -<span class="number">1</span>]</span><br><span class="line">    <span class="attr">pos_val</span> = components[-<span class="number">1</span>, -<span class="number">1</span>] <span class="keyword">if</span> fixed_x <span class="keyword">else</span> components[<span class="number">0</span>, <span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    flow_x[<span class="attr">components</span> == pos_val] = deformation_strength * normal_vector[<span class="number">1</span>]</span><br><span class="line">    flow_y[<span class="attr">components</span> == pos_val] = deformation_strength * normal_vector[<span class="number">0</span>]</span><br><span class="line">    flow_x[<span class="attr">components</span> == neg_val] = - deformation_strength * normal_vector[<span class="number">1</span>]</span><br><span class="line">    flow_y[<span class="attr">components</span> == neg_val] = - deformation_strength * normal_vector[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># generate the flow fields</span></span><br><span class="line">    flow_x, <span class="attr">flow_y</span> = (x + flow_x).reshape(-<span class="number">1</span>, <span class="number">1</span>), (y + flow_y).reshape(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># dilate the line mask</span></span><br><span class="line">    <span class="attr">line_mask</span> = binary_dilation(line_mask, <span class="attr">iterations=iterations)#default=10</span></span><br><span class="line">    </span><br><span class="line">    return flow_x, flow_y, line_mask</span><br><span class="line">def deform_2d(image2d,deformation_strength,iterations):</span><br><span class="line">    flow_x, flow_y, <span class="attr">line_mask</span> = prepare_deform_slice(image2d.shape,deformation_strength,iterations)</span><br><span class="line">    <span class="attr">section</span> = image2d.squeeze()</span><br><span class="line">    <span class="attr">mean</span> = section.mean()</span><br><span class="line">    <span class="attr">shape</span> = section.shape</span><br><span class="line">    <span class="comment">#interpolation=3</span></span><br><span class="line">    <span class="attr">section</span> = map_coordinates( section, (flow_y, flow_x), <span class="attr">mode='constant',</span> </span><br><span class="line">                                  <span class="attr">order=3).reshape(int(flow_x.shape[0]**0.5),int(flow_x.shape[0]**0.5))</span></span><br><span class="line">    <span class="attr">section</span> = np.clip(section, <span class="number">0</span>., <span class="number">1</span>.)</span><br><span class="line">    section[line_mask] = mean</span><br><span class="line">    return section </span><br><span class="line">def apply_deform(imgs,<span class="attr">deformation_strength=0,iterations=50,deform_ratio=0.25):</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    imgs :3D</span></span><br><span class="line"><span class="string">    ''</span>'</span><br><span class="line">    <span class="attr">transformedimgs=</span> np.copy(imgs)</span><br><span class="line">    <span class="attr">sectionsnum</span> = imgs.shape[<span class="number">0</span>]</span><br><span class="line">    <span class="attr">i</span> =<span class="number">0</span></span><br><span class="line">    while i &lt;sectionsnum:</span><br><span class="line">        <span class="keyword">if</span> random.random() &lt;= deform_ratio:</span><br><span class="line">            transformedimgs[i] = deform_2d(imgs[i],deformation_strength,iterations)</span><br><span class="line">            i +=<span class="number">2</span></span><br><span class="line">        i +=<span class="number">1</span></span><br><span class="line">    return transformedimgs</span><br></pre></td></tr></table></figure><p><img src="http://i4.fuimg.com/640680/2be847081da6e223.png" alt="Markdown"></p><h3 id="elastic-augmentation-1"><a href="#elastic-augmentation-1" class="headerlink" title="elastic augmentation"></a>elastic augmentation</h3><figure class="highlight fortran"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">from scipy.ndimage.interpolation <span class="keyword">import</span> map_coordinates</span><br><span class="line">from scipy.ndimage.filters <span class="keyword">import</span> gaussian_filter</span><br><span class="line"></span><br><span class="line">def elastic_transform(image, alpha, sigma, random_state=<span class="keyword">None</span>):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> random_state is <span class="keyword">None</span>:</span><br><span class="line">        random_state = np.random.RandomState(<span class="keyword">None</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        random_state = np.random.RandomState(random_state)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">shape</span> = image.<span class="built_in">shape</span></span><br><span class="line">    dx = gaussian_filter((random_state.rand(*<span class="built_in">shape</span>) * <span class="number">2</span> - <span class="number">1</span>), sigma) * alpha</span><br><span class="line">    dy = gaussian_filter((random_state.rand(*<span class="built_in">shape</span>) * <span class="number">2</span> - <span class="number">1</span>), sigma) * alpha</span><br><span class="line">    dz = np.zeros_like(dx)</span><br><span class="line"></span><br><span class="line">    x, y, z = np.meshgrid(np.arange(<span class="built_in">shape</span>[<span class="number">1</span>]), np.arange(<span class="built_in">shape</span>[<span class="number">0</span>]), np.arange(<span class="built_in">shape</span>[<span class="number">2</span>]))</span><br><span class="line">    indices = np.<span class="built_in">reshape</span>(y+dy, (-<span class="number">1</span>, <span class="number">1</span>)), np.<span class="built_in">reshape</span>(x+dx, (-<span class="number">1</span>, <span class="number">1</span>)), np.<span class="built_in">reshape</span>(z, (-<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> map_coordinates(image, indices, order=<span class="number">1</span>, mode=<span class="string">'reflect'</span>).<span class="built_in">reshape</span>(<span class="built_in">shape</span>)</span><br><span class="line">def apply_elastic(img,mask):</span><br><span class="line">    <span class="built_in">random_seed</span> = np.random.randint(<span class="number">1000000</span>)</span><br><span class="line">    elasticedraw = elastic_transform(img, img.<span class="built_in">shape</span>[<span class="number">1</span>] * <span class="number">2</span>, img.<span class="built_in">shape</span>[<span class="number">1</span>] * <span class="number">0.07</span>, <span class="built_in">random_seed</span>)</span><br><span class="line">    elasticedseg = elastic_transform(mask, img.<span class="built_in">shape</span>[<span class="number">1</span>] * <span class="number">2</span>, img.<span class="built_in">shape</span>[<span class="number">1</span>] * <span class="number">0.07</span>, <span class="built_in">random_seed</span>)</span><br><span class="line">    <span class="keyword">return</span> elasticedraw, elasticedseg</span><br></pre></td></tr></table></figure><p>elastic augmentation is important and should be treated very carefully. I use the idea in Best Practices for Convolutional Neural Networks applied to Visual Document Analysis.</p><p>The main methods are Gaussian filter and interpolation. There is a version of elastic augmentation using affine transformation, I test it but the effect is hard to control.</p><p>So I use Gaussian filter and interpolation for gentle elastic transformation. Then normalize to 0-1, binarize label and make sure the transformation is same in images and masks.</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="title">apply_elastic</span><span class="params">(img,mask)</span></span></span><br></pre></td></tr></table></figure><p><img src="http://i4.fuimg.com/640680/64061355143fac3a.png" alt="Markdown"></p><h2 id="task2-reverse-predicting"><a href="#task2-reverse-predicting" class="headerlink" title="task2 reverse predicting"></a>task2 reverse predicting</h2><p>I have use alignment and padding and shift scripts to process the raw data and it should be reversed after prediction. I test the codes to make sure it works.</p><p>Codes: <a href="https://github.com/james20141606/Summer_Intern/blob/master/synapse_prediction/bin/T_align.m" target="_blank" rel="noopener">Summer_Intern/T_align.m at master · james20141606/Summer_Intern · GitHub</a></p><hr><h1 id="Week-5-amp-6"><a href="#Week-5-amp-6" class="headerlink" title="Week 5 &amp; 6"></a>Week 5 &amp; 6</h1><h2 id="align-location-volume"><a href="#align-location-volume" class="headerlink" title="align location volume"></a>align location volume</h2><p>I align the annotation about pre and post synaptic partners location for later training and analyze three volumes pre and post’s section distance</p><p>It seems that the volume C annotation has some apparent outliers, it is impossible that the two partners have such a big distance, so I removed the outlier with distance more than 300.</p><p><img src="http://i4.fuimg.com/640680/5271eb263cb9e565.png" alt="Markdown"></p><p><img src="http://i4.fuimg.com/640680/a41fb440d8d1c617.png" alt="Markdown"></p><p><img src="http://i4.fuimg.com/640680/132ddef47af261fc.png" alt="Markdown"></p><p>The final process include two more changes: do not use good slice replace bad slice<br>And remove partners with distance more than 300. Now the three volumes have 217,634,722 synaptic partners.</p><h3 id="data-augmentation"><a href="#data-augmentation" class="headerlink" title="data augmentation"></a>data augmentation</h3><p>For elastic transformation, it is weird to use gaussian filter and then warp, but it is good to use warp first and then do gaussian filter.</p><ol><li>elastic: smoothed random motion field=random vector+gaussian filter</li><li>warping: random global affine matrix</li></ol><p><img src="http://i4.fuimg.com/640680/208732c8803ea2b3.png" alt="Markdown"></p><p><img src="http://i4.fuimg.com/640680/206cd5295b80d561.png" alt="Markdown"></p><h2 id="loss-function-and-new-design"><a href="#loss-function-and-new-design" class="headerlink" title="loss function and new design"></a>loss function and new design</h2><ul><li>Intensity  influence the result severely, besides decreasing contrast and brightness,<br><a href="http://cs231n.stanford.edu/reports/2017/pdfs/300.pdf" target="_blank" rel="noopener">http://cs231n.stanford.edu/reports/2017/pdfs/300.pdf</a></li><li>we can also try group normalization and multi GPU batch normalization.<br>32 channel, 8 groups, each 4 channels</li><li>distance transform to assign weight for negative class, similar with tanh(D/S)</li><li>multi resolution and multi task learning<br><strong>Multi task!</strong> is using multiple loss on different resolution level and add these lossed together. It is a kind of like attention. But the combined losses are not very precise to control different levels.<br>We may also consider MULTI -SCALE DENSE NETWORKS FOR RESOURCE E FFICIENT IMAGE CLASSIFICATION, it can output results on different resolution levels and are better than resnet based models.</li></ul><h3 id="Loss"><a href="#Loss" class="headerlink" title="Loss"></a>Loss</h3><p>DICE loss are hard to convergence.<br>I formulate some equations to change the DICE loss, and also implement some other DICE loss adjustment.</p><p><img src="http://i4.fuimg.com/640680/ceea6995778ee50a.png" alt="Markdown"></p><p><img src="http://i4.fuimg.com/640680/b793b22de5ed6051.png" alt="Markdown"></p><h5 id="generalized-DICE-loss"><a href="#generalized-DICE-loss" class="headerlink" title="generalized DICE loss"></a>generalized DICE loss</h5><p>Change DICE denominator to square. So that the points having different distance from GT have different  derivative.</p><p><img src="http://i4.fuimg.com/640680/d196b3bb76ababaa.png" alt="Markdown"></p><p>change denomi<img src="http://i4.fuimg.com/640680/cbdbb1c2f4192ada.png" alt="Markdown"></p><p><strong>Using this formulation we do not need to assign weights to samples of different classes to establish the right balance between foreground and background voxels,</strong> and we obtain results that we experimentally observed are much better than the ones computed through the same network trained optimising a multinomial logistic loss with sample re-weighting</p><p><strong>DICE Loss</strong><br>consider negative？<br><img src="http://i4.fuimg.com/640680/14a4604e6910d2ef.png" alt="Markdown"></p><p><strong>sensitivity-specificity</strong><br><img src="http://i4.fuimg.com/640680/45a62036466fb811.png" alt="Markdown"></p><p><strong>weighted dice</strong><br><img src="http://i4.fuimg.com/640680/7597c15cb6c70bd5.png" alt="Markdown"></p><p><img src="http://i4.fuimg.com/640680/0fefcfc0276481ba.png" alt="Markdown"></p><p>still based only on pairwise comparisons of probabilities associated with the same label and don’t take into account <strong>inter-class relationships.</strong></p><h2 id="reverse-prediction-and-deal-with-cracks"><a href="#reverse-prediction-and-deal-with-cracks" class="headerlink" title="reverse prediction and deal with cracks"></a>reverse prediction and deal with cracks</h2><p>For CREMI contest, we do several preprocessing, like align the dataset, and deal with two specific sections with cracks( it is very important, because the crack will severely influence the result.)</p><p>I will realign the predicted result to the original one and submit the prediction. And I will deal with two sections with cracks separately.</p><h4 id="对那两层做crack-align"><a href="#对那两层做crack-align" class="headerlink" title="对那两层做crack align"></a>对那两层做crack align</h4><ul><li><p>[ ] 脚本 align_new</p></li><li><p>detect crack region and split the picture into two regions</p></li></ul><p><img src="http://i4.fuimg.com/640680/b88ca29cc508e738.png" alt="Markdown"></p><ul><li>align the two parts with neighbor sections. Use warp to align. The crack will look bigger.</li></ul><p><img src="http://i4.fuimg.com/640680/d898e30f03ec6e90.png" alt="Markdown"></p><ul><li>do interpolation, using optical flow</li></ul><p><img src="http://i4.fuimg.com/640680/a077144bab1af22e.png" alt="Markdown"></p><p>Reverse the predicted crack section back:</p><ul><li>delete interpolation region</li><li>find connected region and extract them</li><li>reverse warp the two parts</li><li><figure class="highlight lisp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">imwarp(<span class="name">im</span>, affine2d(<span class="name">tmp</span>(:,:,<span class="number">2</span>)),'FillValues',<span class="number">0</span>,'OutputView',imref2d(<span class="name">sz</span>))<span class="comment">;</span></span><br><span class="line">tform = affine2d([<span class="number">2</span> <span class="number">0.33</span> <span class="number">0</span><span class="comment">; 0 1 0; 0 0 1])</span></span><br></pre></td></tr></table></figure></li></ul><p>For reverse warp, we can use invert function<br><a href="https://www.mathworks.com/help/images/ref/affine2d.invert.html" target="_blank" rel="noopener">Invert geometric transformation - MATLAB invert</a></p><ul><li>add the two parts</li><li>get the reversed images and test if it is right.</li></ul><p><img src="http://i4.fuimg.com/640680/1f07ed5887f5112b.png" alt="Markdown"></p><p>it’s good enough to transform synapse prediction result, no synapse will be on the border<br>So we do not need the padding work</p><h4 id="for-predicted-data"><a href="#for-predicted-data" class="headerlink" title="for predicted data:"></a>for predicted data:</h4><ul><li>[ ] Use <a href="http://140.247.107.75:8889/notebooks/projects/synapse/jupyter/realign_crack.ipynb" target="_blank" rel="noopener">Jupyter Notebook</a> to get connected components from em<br>And apply invert on them to get reversed version</li></ul><h3 id="8-6-reverse-all-predictions"><a href="#8-6-reverse-all-predictions" class="headerlink" title="8.6 reverse all predictions"></a>8.6 reverse all predictions</h3><p>A+ B+ C+ reverse prediction<br>Test if the algorithm is right!</p><h4 id="use-gt-syn-transformed，and-reverse，check-if-it-is-the-same-with-the-original-one"><a href="#use-gt-syn-transformed，and-reverse，check-if-it-is-the-same-with-the-original-one" class="headerlink" title="use gt-syn transformed，and reverse，check if it is the same with the original one"></a>use gt-syn transformed，and reverse，check if it is the same with the original one</h4><ul><li>input: gt-syn/syn</li><li>output: reverse/syn<br>Check if output=images/volumes/labels/clefts</li></ul><p><strong>Rewrite the reverse alignment code</strong><br>after a long time, it finally works, with the help of donglai. It seems it is really hard to reverse back to the original align.</p><ul><li>The forward strategy looks like:<br>Read alignment shift distance, cumsum to get continuous shift, get each section’s shift. Have a very big tmp arr, put the small original arr in it. Get a bigger ROI to have the  medium one</li></ul><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">syn_o=<span class="built_in">zeros</span>([<span class="number">1250</span>+sum(ww([<span class="number">1</span>,<span class="number">3</span>])),<span class="number">1250</span>+sum(ww([<span class="number">2</span>,<span class="number">4</span>])),<span class="number">153</span>],<span class="string">'uint16'</span>);</span><br><span class="line"><span class="keyword">for</span> <span class="built_in">i</span>=<span class="number">1</span>:<span class="number">125</span></span><br><span class="line">pd = <span class="built_in">round</span>(pp(<span class="built_in">i</span>+<span class="number">14</span>,:)); </span><br><span class="line">tmp = <span class="built_in">zeros</span>(<span class="number">3075</span>+ph,<span class="number">3075</span>);</span><br><span class="line"></span><br><span class="line">tmp(<span class="number">912</span>:<span class="number">911</span>+<span class="number">1250</span>,<span class="number">912</span>:<span class="number">911</span>+<span class="number">1250</span>) = syn(:,:,<span class="built_in">i</span>);</span><br><span class="line">syn_o(:,:,<span class="built_in">i</span>+<span class="number">14</span>) = tmp((<span class="number">912</span>+pd(<span class="number">1</span>)-ww(<span class="number">1</span>)):(<span class="number">911</span>+pd(<span class="number">1</span>)+<span class="number">1250</span>+ww(<span class="number">3</span>)),...</span><br><span class="line">            (<span class="number">912</span>+pd(<span class="number">2</span>)-ww(<span class="number">2</span>)):(<span class="number">911</span>+pd(<span class="number">2</span>)+<span class="number">1250</span>+ww(<span class="number">4</span>))); </span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure><ul><li>The reverse strategy looks like:<br>Read alignment shift distance, cumsum to get continuous shift, get each section’s shift. Have a very big tmp arr, put the predicted region(medium size) in it. Get a small, original ROI to have the  original one<br><strong>through test there is no problem!</strong></li></ul><h4 id="A-in-15-and-48-layer-from-one-not-zero-do-reverse-crack"><a href="#A-in-15-and-48-layer-from-one-not-zero-do-reverse-crack" class="headerlink" title="A+: in 15 and 48 layer(from one, not zero), do reverse crack!"></a>A+: in 15 and 48 layer(from one, not zero), do reverse crack!</h4><p>It is 14 and 47 section of predicted A+ syn<br>data/prediction/im015_reverse0.png, data/prediction/im048_reverse0.png</p><p><img src="http://i4.fuimg.com/640680/24b6323ecbacadcb.png" alt="Markdown"></p><hr><h1 id="Last-three-weeks"><a href="#Last-three-weeks" class="headerlink" title="Last three weeks"></a>Last three weeks</h1><p>Week 7,8,9 (10)</p><h2 id="8-13"><a href="#8-13" class="headerlink" title="8.13"></a>8.13</h2><p>We add squeeze and excitation block to our model. It further improves our performance on CREMI contest. We achieve 2nd place by the end of August. This architecture also works for synapse polarity prediction task.<br><img src="http://i1.fuimg.com/640680/1b36249fa6f56a59.png" alt="Markdown"></p><p><img src="http://i1.fuimg.com/640680/3d5fe582cfbd9d77.png" alt="Markdown"></p><h4 id="8-29"><a href="#8-29" class="headerlink" title="8.29"></a>8.29</h4><p>Reverse back a new version</p><ul><li>Get ROI, delete interpolation region</li><li>inverse warp</li><li>get reverse0<br>-merge</li><li>Put back to predicted A+ and reverse A+</li><li><code>/n/coxfs01/xupeng/projects/synapse/data/reverse</code></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;It is part of my computational task during my summer intern in &lt;a href=&quot;https://lichtmanlab.fas.harvard.edu/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Lichtman Lab&lt;/a&gt; and &lt;a href=&quot;https://vcg.seas.harvard.edu/people&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Hanspiter Lab&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;It is part of the big synapse project. Also the challenge 2 of &lt;a href=&quot;https://cremi.org&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;CREMI&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;We now rank &lt;strong&gt;No.1&lt;/strong&gt; in the &lt;a href=&quot;https://cremi.org&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;CREMI contest&lt;/a&gt;. And we will submit a paper to CVPR this November.&lt;/p&gt;
&lt;p&gt;For &lt;strong&gt;whole work summary&lt;/strong&gt; please &lt;a href=&quot;https://www.cmwonderland.com/blog/2018/09/12/100_summer_intern/&quot;&gt;see here&lt;/a&gt;&lt;/p&gt;


	&lt;div class=&quot;row&quot;&gt;
		&lt;iframe src=&quot;https://drive.google.com/file/d/1XyEPj9r7p8VNk5nLlLIPNhZjuDHu2KTY/preview&quot; style=&quot;width:100%; height:550px&quot;&gt;&lt;/iframe&gt;
	&lt;/div&gt;



&lt;p&gt;Also I finished another NMJ project during summer intern in &lt;a href=&quot;https://lichtmanlab.fas.harvard.edu/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Lichtman Lab&lt;/a&gt; &lt;/p&gt;
&lt;h1 id=&quot;Codes&quot;&gt;&lt;a href=&quot;#Codes&quot; class=&quot;headerlink&quot; title=&quot;Codes&quot;&gt;&lt;/a&gt;Codes&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/james20141606/Summer_Intern/tree/master/synapse_prediction&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Summer_Intern/synaptic_partner at master · james20141606/Summer_Intern · GitHub&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/james20141606/EM-network&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Synapse polarity&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="projects" scheme="https://www.cmwonderland.com/blog/categories/projects/"/>
    
    
      <category term="project" scheme="https://www.cmwonderland.com/blog/tags/project/"/>
    
      <category term="neural science" scheme="https://www.cmwonderland.com/blog/tags/neural-science/"/>
    
      <category term="summer intern" scheme="https://www.cmwonderland.com/blog/tags/summer-intern/"/>
    
      <category term="connectomics" scheme="https://www.cmwonderland.com/blog/tags/connectomics/"/>
    
      <category term="computational neural science" scheme="https://www.cmwonderland.com/blog/tags/computational-neural-science/"/>
    
      <category term="deep learning" scheme="https://www.cmwonderland.com/blog/tags/deep-learning/"/>
    
      <category term="computer vision" scheme="https://www.cmwonderland.com/blog/tags/computer-vision/"/>
    
      <category term="Jeff Lichtman" scheme="https://www.cmwonderland.com/blog/tags/Jeff-Lichtman/"/>
    
  </entry>
  
  <entry>
    <title>NMJ Project</title>
    <link href="https://www.cmwonderland.com/blog/2018/07/14/99_summerintern_NMJ/"/>
    <id>https://www.cmwonderland.com/blog/2018/07/14/99_summerintern_NMJ/</id>
    <published>2018-07-14T12:35:19.000Z</published>
    <updated>2018-10-11T08:37:00.670Z</updated>
    
    <content type="html"><![CDATA[<p>It is my detailed progress of <strong>Neural Muscular Junction project</strong> during my summer intern in <a href="https://lichtmanlab.fas.harvard.edu/" target="_blank" rel="noopener">Jeff Lichtman Lab</a>. With the generous help of Jeff, I complete NMJ tracing and segmentation work.</p><p>The <strong>codes related</strong> are here:<br><a href="https://github.com/james20141606/Summer_Intern" target="_blank" rel="noopener">Main codes</a><br><a href="https://github.com/james20141606/NMJ_automatic_pipeline" target="_blank" rel="noopener">Automatic pipeline</a></p><p>For <strong>whole work summary</strong> please <a href="https://www.cmwonderland.com/blog/2018/09/12/100_summer_intern/">see here</a></p><div class="row"><iframe src="https://drive.google.com/file/d/1XyEPj9r7p8VNk5nLlLIPNhZjuDHu2KTY/preview" style="width:100%; height:550px"></iframe></div><p>Also I finished another synapse prediction and synaptic polarity prediction work during summer intern in <a href="https://vcg.seas.harvard.edu/people" target="_blank" rel="noopener">Hanspiter Lab</a></p><a id="more"></a><h1 id="weekly-report"><a href="#weekly-report" class="headerlink" title="weekly report"></a>weekly report</h1><h2 id="First"><a href="#First" class="headerlink" title="First"></a>First</h2><div class="row"><iframe src="https://drive.google.com/file/d/1bmWX9M1aTgOw7YB9xrnUNynWfxuoa_Rz/preview" style="width:100%; height:550px"></iframe></div><h2 id="Second"><a href="#Second" class="headerlink" title="Second"></a>Second</h2><div class="row"><iframe src="https://drive.google.com/file/d/1OOaFajkLcwQBEf1XQuEIYqFAkl9psPrt/preview" style="width:100%; height:550px"></iframe></div><h2 id="Third"><a href="#Third" class="headerlink" title="Third"></a>Third</h2><div class="row"><iframe src="https://drive.google.com/file/d/1We4g3Ltd2gqzmICoLtKFKsL-2zP2BVeV/preview" style="width:100%; height:550px"></iframe></div><h2 id="Fourth"><a href="#Fourth" class="headerlink" title="Fourth"></a>Fourth</h2><div class="row"><iframe src="https://drive.google.com/file/d/19zhoBM6GP94a-bNj7bFIZdExC0x6yw_2/preview" style="width:100%; height:550px"></iframe></div><hr><h1 id="First-two-weeks"><a href="#First-two-weeks" class="headerlink" title="First two weeks"></a>First two weeks</h1><p>Since the new data is still to be processed, I spent several days doing dense segmentation work both for study and future training. </p><p>I have done 25 sections dense segmentation in W12-W14 for 4 days(7.5-7.8), it includes dense segmentation of Axons, Schwann cell, and Schwann cell nucleus. </p><p>I have written codes to use python to visualize animation of the 25 segments <img src="http://i2.tiimg.com/640680/674ef868297b66d0.gif" alt="Markdown">. Since the computational  work use more python codes know, I also shared my animating code with others.<br><a href="https://github.com/james20141606/Summer_Intern/blob/master/NMJ/jupyter/plot_segment.ipynb" target="_blank" rel="noopener">plot segment script</a></p><p>Core codes to plot animation in python</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">defdef  transform_rgbtransfor (img):</span><br><span class="line">    num = np.unique(img.reshape(<span class="number">-1</span>,<span class="number">3</span>),axis=<span class="number">0</span>).shape[<span class="number">0</span>]</span><br><span class="line">    <span class="comment">#print (num)</span></span><br><span class="line">    <span class="comment">#rgbarr = np.ndarray([num*3])</span></span><br><span class="line">    <span class="comment">#for i in range(num*3):</span></span><br><span class="line">      <span class="comment">#  rgbarr[i] = np.random.uniform(0,1)</span></span><br><span class="line">    <span class="comment">#rgbarr = rgbarr.reshape(-1,3)</span></span><br><span class="line">    image = np.zeros([img.shape[<span class="number">0</span>]*img.shape[<span class="number">1</span>],<span class="number">3</span>])</span><br><span class="line">    sumimg = np.sum(img.reshape(<span class="number">-1</span>,<span class="number">3</span>),axis=<span class="number">1</span>)</span><br><span class="line">    uniqueind = np.unique(img.reshape(<span class="number">-1</span>,<span class="number">3</span>),axis=<span class="number">0</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> np.arange(<span class="number">0</span>,num<span class="number">-1</span>):</span><br><span class="line">        image[sumimg==<span class="number">3</span>*(uniqueind[i][<span class="number">0</span>]+<span class="number">1</span>)] = colorsgallery[i]</span><br><span class="line">    <span class="comment">#print (sumimg.shape)</span></span><br><span class="line">    image[sumimg==<span class="number">0</span>] = [<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>]</span><br><span class="line">    <span class="keyword">return</span> image.reshape(img.shape[<span class="number">0</span>],img.shape[<span class="number">1</span>],<span class="number">3</span>)</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> matplotlib.animation <span class="keyword">as</span> animation</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> rc</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">animations</span><span class="params">(opt=<span class="string">'show'</span>,type=<span class="string">'gif'</span>)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    opt: show/save</span></span><br><span class="line"><span class="string">    type:gif/mp4</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    imagelist = [transform_rgb(imagedata[i][<span class="number">100</span>:<span class="number">900</span>,<span class="number">100</span>:<span class="number">900</span>]) <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">26</span>)]</span><br><span class="line">    fig,ax=plt.subplots(<span class="number">1</span>,figsize=(<span class="number">16</span>,<span class="number">12</span>)) </span><br><span class="line">    im =ax.imshow(imagelist[<span class="number">0</span>])</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">updatefig</span><span class="params">(j)</span>:</span></span><br><span class="line">        im.set_array(imagelist[j])</span><br><span class="line">        <span class="keyword">return</span> [im]</span><br><span class="line">    anim = animation.FuncAnimation(fig, updatefig, frames=range(<span class="number">26</span>), </span><br><span class="line">                                  interval=<span class="number">100</span>, blit=<span class="keyword">True</span>)</span><br><span class="line">    <span class="keyword">if</span> opt==<span class="string">'show'</span>:</span><br><span class="line">        <span class="keyword">return</span> anim</span><br><span class="line">    <span class="keyword">elif</span> opt==<span class="string">'save'</span>:</span><br><span class="line">        <span class="keyword">if</span> type==<span class="string">'mp4'</span>:</span><br><span class="line">            Writer = animation.writers[<span class="string">'ffmpeg'</span>]</span><br><span class="line">            writer1 = Writer(fps=<span class="number">10</span>)</span><br><span class="line">            anim.save(<span class="string">'animation.'</span>+type, writer=writer1,dpi=<span class="number">1000</span>)</span><br><span class="line">        <span class="keyword">elif</span> type==<span class="string">'gif'</span>:</span><br><span class="line">            <span class="comment">#Writer = animation.writers['imagemagick']</span></span><br><span class="line">            anim.save(<span class="string">'animation.'</span>+type, writer=<span class="string">'imagemagick'</span>, fps=<span class="number">10</span>)</span><br></pre></td></tr></table></figure><p>I also read several articles Marco and Yaron recommened, including previous NMJ work, some segmentation and Connectome processing pipeline papers.</p><h2 id="Future-work"><a href="#Future-work" class="headerlink" title="Future work"></a>Future work</h2><p>We also discuss a lot about the future plan of the project. Since it is more challenging than other tasks, it seems we are a little slow in progress. We have worked with Marco to find a way to label the ROI and use a script to extract coordinates of the bounding box. We have labeled one mask, later we will test Adi’s align results and generate more.</p><ul><li>Manually create ROI region for bundles and NMJ for alignment</li><li>Do segmentation and \textbf{statistical analysis} work on some NMJs(concerning our limited staying time, it seems there isn’t enough time to wait for all NMJs’ alignment and segmentation results to analyze)</li></ul><hr><h1 id="Week-3"><a href="#Week-3" class="headerlink" title="Week 3"></a>Week 3</h1><h2 id="mask-and-seeding"><a href="#mask-and-seeding" class="headerlink" title="mask and seeding"></a>mask and seeding</h2><p>This week we have worked out a plan on alignment and seeding.</p><p>We use a mind map to record tree’s nodes to visualize our progress. The mask was sent to Adi for aligning. The alignment results seem very good.</p><p>I have seeded three masks Adi sent back, <strong>for about 900 sections mainly in bundle area.</strong></p><p>I also wrote python script <a href="https://github.com/james20141606/Summer_Intern/blob/master/NMJ/jupyter/plot_segment.ipynb" target="_blank" rel="noopener">Summer_Intern/plot_segment.ipynb at master · james20141606/Summer_Intern · GitHub</a> for further analysis. Since I am proficient in using python for visualization, statistical analysis and machine learning, I wrote some python scripts to read seeding result, visualize them and plot them in 3D and animation. It will be better to have more statistical analysis when I collect more seeding data.<br><img src="http://i1.fuimg.com/640680/45e727fc31a9b0dc.png" alt="Markdown"></p><h2 id="discussion-on-mask"><a href="#discussion-on-mask" class="headerlink" title="discussion on mask"></a>discussion on mask</h2><p>When we put masks on ROI, we found many branches even in bundle area, two branches from one stem may encounter and form a closed loop. We are worried if it will be a problem when we merge all masks together. After discussing with Adi and Daniel, we understand that the spatial structure’s change isn’t a big problem.</p><hr><p>Week 4</p><h2 id="My-thought-about-how-the-whole-project"><a href="#My-thought-about-how-the-whole-project" class="headerlink" title="My thought about how the whole project"></a>My thought about how the whole project</h2><p>This week I continue to seed on Mask3, and then I do a lot of exploration on how to do the NMJ project automatically.</p><p>I have understood how big and challenging this project is, it requires so many manually labeling work than we can’t finish all the masking and seeding and segmentation and reconstruction work in two months. We know that it took KK and Marco several months to finish part of the bundle parts. But the remaining parts are more complex to seed, segment and it contains maybe 200 masks with approximately 50,000 sections. It is hard to estimate how long it will take to finish the whole project</p><p>However, as I am getting more familiar with this project, I am trying to build a more automatically pipeline for seeding, predicting membrane and segmentation. If it works, the project may move faster when we are here and after we leave:)</p><h3 id="Seeding-on-Mask3"><a href="#Seeding-on-Mask3" class="headerlink" title="Seeding on Mask3"></a>Seeding on Mask3</h3><p>I felt that seeding on mask3 is much more complex than previous bundle seeding, the axon travels very fast and I should look up and down to look for one axon, it takes much more time to trace the branch than the main bundle.</p><h2 id="Automatic-pipeline"><a href="#Automatic-pipeline" class="headerlink" title="Automatic pipeline"></a>Automatic pipeline</h2><p><strong>We would like to build up a more automatic pipeline before we leave and test the whole pipeline on several masks to see if they can be merged and reconstructed.</strong></p><p>We would like to build up the whole pipeline, prepare all the codes and model for prediction and processing and write down the protocol.</p><p>The complete pipeline should contain:<br><strong>Generating Masks —&gt; Seeding —&gt; Predict Membrane —&gt; Expand Seeds —&gt; Merge different Masks</strong></p><p>Previously we do seeding manually and then predict membrane, but the remaining masks have so many sections, I would like to do the seeding work more automatically too.</p><h3 id="Predict-Membrane"><a href="#Predict-Membrane" class="headerlink" title="Predict Membrane"></a>Predict Membrane</h3><p>The automatically prediction parts must include membrane prediction, because it is “easier” to predict since the raw image already have the membrane.</p><h3 id="Automatically-seeding"><a href="#Automatically-seeding" class="headerlink" title="Automatically seeding"></a>Automatically seeding</h3><p>The traditional way is to manually put seeds on each axon, but we have approximately 50,000 sections if all masks are generated, it is so time-consuming to manually put seeds. I will <strong>generate seeds by distance transformation from membrane</strong></p><p>Then the seeds must be indexed to track each seed is from which axon, so we will manually put seeds  per 100 sections, then do <strong>Hungarian matching.</strong></p><h3 id="segmentation"><a href="#segmentation" class="headerlink" title="segmentation"></a>segmentation</h3><p>Expand the seed to generate segments</p><h3 id="Merge-masks"><a href="#Merge-masks" class="headerlink" title="Merge masks"></a>Merge masks</h3><p>We are thinking about linear interpolation to merge anchor sections for loop problems. We will discuss it more with Daniel and Yaron after the segmentation</p><h2 id="Algorithm"><a href="#Algorithm" class="headerlink" title="Algorithm"></a>Algorithm</h2><p>The related codes are here:<br><a href="https://github.com/james20141606/membrane_prediction" target="_blank" rel="noopener">GitHub - james20141606/membrane_prediction: Use 3D U-net to predict membrane predition</a></p><h3 id="Predict-Membrane-1"><a href="#Predict-Membrane-1" class="headerlink" title="Predict Membrane"></a>Predict Membrane</h3><p>I will use a 3D U-net model to use contours extracted from dense segmentation sections. Use 50 sections for training, then predict more, proofread predicted sections to generate more training samples. <strong>The iterative training and predicting method will make the model more precise.</strong></p><p>The model’s weight is adaptive to the pixels ratio, I can do fine tune on the model iteratively. So the model will be more precise and requires fewer proofreading. Last week I do many augmentation works, it is also useful to generate more training images since I only have 50 sections for training now.</p><p><strong>How to fine tune:</strong><br>If we want better result, we can manually label several sections on each mask and retrain the model on each mask.</p><p>For membrane prediction, since we do not consider affinity, we can also consider 2D U-net, it contains much less parameters and easier to train.</p><h3 id="Automatically-seeding-1"><a href="#Automatically-seeding-1" class="headerlink" title="Automatically seeding"></a>Automatically seeding</h3><ul><li><strong>Distance transformation</strong> to generate seeds from membrane</li><li><strong>Hungarian matching</strong> to label each seeds for different axons. Manually label one section’ s seed and do Hungarian matching for the next 100 sections.</li></ul><h3 id="Watershed"><a href="#Watershed" class="headerlink" title="Watershed"></a>Watershed</h3><p>Use watershed to expand seeds and generate segments</p><h3 id="Useful-resources"><a href="#Useful-resources" class="headerlink" title="Useful resources"></a>Useful resources</h3><p><a href="https://github.com/tdedecko/hungarian-algorithm/blob/master/hungarian.py#L6" target="_blank" rel="noopener">hungarian-algorithm/hungarian.py at master · tdedecko/hungarian-algorithm · GitHub</a><br><a href="https://github.com/hrldcpr/hungarian" target="_blank" rel="noopener">GitHub - hrldcpr/hungarian: Hungarian / Munkres’ algorithm for the linear assignment problem, in Python</a></p><p><a href="https://github.com/microns-ariadne/pipeline_engine/tree/cf100202997d3c848a21de441e15deb9f975042d/ariadne_microns_pipeline/tasks" target="_blank" rel="noopener">pipeline_engine/ariadne_microns_pipeline/tasks at cf100202997d3c848a21de441e15deb9f975042d · microns-ariadne/pipeline_engine · GitHub</a></p><p>Other possible algorithm:</p><ul><li>seeding<br>Use EM data to predict seeds, train seeding prediction network, using affinity because the axon travels fast. Sebastian’s group has some work. But I think it is imprecise compared to membrane prediction—distance transformation algorithm</li></ul><blockquote><p>Convolutional Networks Can Learn to Generate Affinity<br>Graphs for Image Segmentation<br>Maximin affinity learning of image segmentation</p></blockquote><p><a href="https://github.com/jiwoon-ahn/psa" target="_blank" rel="noopener">GitHub - jiwoon-ahn/psa: Learning Pixel-level Semantic Affinity with Image-level Supervision for Weakly Supervised Semantic Segmentation, CVPR 2018</a></p><h2 id="Work-on-membrane-prediction"><a href="#Work-on-membrane-prediction" class="headerlink" title="Work on membrane prediction"></a>Work on membrane prediction</h2><h3 id="Prepare-ground-truth-training-set"><a href="#Prepare-ground-truth-training-set" class="headerlink" title="Prepare ground truth training set"></a>Prepare ground truth training set</h3><p>I have started on membrane prediction pipeline after discussion with zudi, yaron and others. I would like to use previously label siyan and I have done in first two weeks to save time. We have done dense segmentation on 51 sections, I wrote a python script</p><p>Codes: <a href="https://github.com/james20141606/Summer_Intern/blob/master/NMJ/jupyter/extract_membrane_gt.ipynb" target="_blank" rel="noopener">Summer_Intern/extract_membrane_gt.ipynb at master · james20141606/Summer_Intern · GitHub</a></p><p> to extract the needed EM image and contours of the membrane in the following steps:</p><ul><li>export segmentation and EM ROI from VAST</li><li>read in python, converting id array to RGB array for visualization</li></ul><p><img src="http://i2.tiimg.com/640680/8b18f43f830a2eb7.png" alt="Markdown"></p><ul><li>find bounding box of each segmentation and EM image</li></ul><figure class="highlight maxima"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">def find_bounding(data):</span><br><span class="line">    xmin = <span class="built_in">np</span>.<span class="built_in">sort</span>(<span class="built_in">np</span>.where(data[:,:,<span class="number">0</span>]!=<span class="number">0</span>)[<span class="number">0</span>])[<span class="number">0</span>]</span><br><span class="line">    xmax = <span class="built_in">np</span>.<span class="built_in">sort</span>(<span class="built_in">np</span>.where(data[:,:,<span class="number">0</span>]!=<span class="number">0</span>)[<span class="number">0</span>])[-<span class="number">1</span>]</span><br><span class="line">    ymin = <span class="built_in">np</span>.<span class="built_in">sort</span>(<span class="built_in">np</span>.where(data[:,:,<span class="number">0</span>]!=<span class="number">0</span>)[<span class="number">1</span>])[<span class="number">0</span>]</span><br><span class="line">    ymax = <span class="built_in">np</span>.<span class="built_in">sort</span>(<span class="built_in">np</span>.where(data[:,:,<span class="number">0</span>]!=<span class="number">0</span>)[<span class="number">1</span>])[-<span class="number">1</span>]</span><br><span class="line">    <span class="built_in">return</span> xmin, xmax, ymin, ymax</span><br><span class="line"><span class="built_in">row</span> = <span class="number">26</span></span><br><span class="line">fig,ax=plt.subplots(<span class="built_in">row</span>,<span class="number">2</span>,figsize=(<span class="number">16</span>,<span class="number">6</span>*<span class="built_in">row</span>))</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">row</span>):</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>):</span><br><span class="line">        xmin, xmax, ymin, ymax = find_bounding(segdata[i*<span class="number">2</span>+j])</span><br><span class="line">        ax[i,j].imshow(transform_rgb(segdata[i*<span class="number">2</span>+j][(xmin-<span class="number">10</span>): (xmax+<span class="number">10</span>), (ymin-<span class="number">10</span>): (ymax+<span class="number">10</span>)]))</span><br></pre></td></tr></table></figure><ul><li>remove Schwann cell to concentrate on axons</li></ul><p>First it has some problems</p><p><img src="http://i2.tiimg.com/640680/2a5303ed7c054769.png" alt="Markdown"></p><p>Then I separately plot and find the black wrong region is 25 and 38</p><p>After correction:</p><p><img src="http://i2.tiimg.com/640680/96c7c89bc409d6ba.png" alt="Markdown"></p><ul><li>convert the segment array to binary mask</li></ul><p><img src="http://i2.tiimg.com/640680/070eef826c0612ae.png" alt="Markdown"></p><ul><li>Make sure each mask and EM data are in same bounding box</li></ul><p><img src="http://i2.tiimg.com/640680/2b1b68b735d93e29.png" alt="Markdown"></p><ul><li>Generate contours as training set label<br>opencv’s findcontour function is not suitable for same grayscale image, so I use erode and dilation<figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">open = cv2.erode(grayimg, None, iterations = 4)</span><br><span class="line">open1 = cv2.dilate(open, None, iterations = 3)</span><br><span class="line">imshow(open1-open)</span><br></pre></td></tr></table></figure></li></ul><p><img src="http://i2.tiimg.com/640680/c9d99655bdaf9cac.png" alt="Markdown"></p><ul><li>Padding for same image size<br>Do reflection padding on each image to generate images with same size.</li></ul><p><img src="http://i2.tiimg.com/640680/06d9ead45f4caa9a.png" alt="Markdown"></p><p>The margin is the reflection of the original image<br>Store in HDF5</p><ul><li>Save image and label as HDF5<br>EM data as training set’s image and contour as label</li></ul><p>Save as uint8   (51, 530, 835)</p><h3 id="Train-membrane-prediction-model"><a href="#Train-membrane-prediction-model" class="headerlink" title="Train membrane prediction model"></a>Train membrane prediction model</h3><p>Input image and label are the 51 bundle sections.</p><p><strong>Train model args:</strong><br>Run on two machines: one with one gpu and another with 4 gpus</p><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">CUDA_VISIBLE_DEVICES=<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span> python3 -u bin/train.py -t data/train_set/ -dn em_51 -ln mask_51 -o outputs/nmj0729mixloss -lr <span class="number">0.001</span> --volume-total <span class="number">40000</span> --volume-save <span class="number">2000</span> -mi <span class="number">4</span>,<span class="number">256</span>,<span class="number">256</span> -g <span class="number">1</span> -c <span class="number">12</span> -b <span class="number">4</span> -lt <span class="number">4</span> -ac <span class="number">2</span></span><br><span class="line"></span><br><span class="line">CUDA_VISIBLE_DEVICES=<span class="number">0</span> python3 -u bin/train.py -t data/train_set/ -dn em_51 -ln mask_51 -o outputs/nmj0729mixloss -lr <span class="number">0.001</span> --volume-total <span class="number">40000</span> --volume-save <span class="number">2000</span> -mi <span class="number">4</span>,<span class="number">256</span>,<span class="number">256</span> -g <span class="number">1</span> -c <span class="number">6</span> -b <span class="number">1</span> -lt <span class="number">4</span> -ac <span class="number">2</span></span><br><span class="line"></span><br><span class="line">#-lt <span class="number">4</span> focal and dice loss</span><br></pre></td></tr></table></figure><p>References:</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">CUDA_VISIBLE_DEVICES=<span class="number">0</span>,<span class="number">1</span> python3 -u bin/synapse_pytorch/train<span class="selector-class">.py</span> -t data/cremi/ -dn images/im_A_v2_200.h5@images/im_B_v2_200.h5@images/im_C_v2_200<span class="selector-class">.h5</span> -ln gt-syn/syn_A_v2_200.h5@gt-syn/syn_B_v2_200.h5@gt-syn/syn_C_v2_200<span class="selector-class">.h5</span> -o outputs/cremi0719mixloss -lr <span class="number">0.001</span> --volume-total <span class="number">400000</span> --volume-save <span class="number">20000</span> -mi <span class="number">24</span>,<span class="number">256</span>,<span class="number">256</span> -g <span class="number">2</span> -c <span class="number">6</span> -<span class="selector-tag">b</span> <span class="number">2</span> -l mix</span><br><span class="line"><span class="selector-id">#b</span>:<span class="number">6</span>  try to keep gpu and batch size same</span><br></pre></td></tr></table></figure><p>The hp003 memory is small, also train on hpc</p><h4 id="Check-loss"><a href="#Check-loss" class="headerlink" title="Check loss"></a>Check loss</h4><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensorboard <span class="attribute">--logdir</span>=outputs/nmj0729mixloss</span><br></pre></td></tr></table></figure><p>Monitor loss and test on new EM image. If is good, train it longer with more GPUs</p><p>Train loss( DICE + Focal loss)</p><p><img src="http://i2.tiimg.com/640680/68a5d5858d2eca5f.png" alt="Markdown"></p><p>Focal loss</p><p><img src="http://i2.tiimg.com/640680/14e81611ee917fa6.png" alt="Markdown"></p><p>Dice loss</p><p><img src="http://i2.tiimg.com/640680/20dac5fc8da5ae1f.png" alt="Markdown"></p><p>It seems that the combined loss and both focal and dice loss decrease well.</p><h4 id="real-time-monitoring-predicted-result"><a href="#real-time-monitoring-predicted-result" class="headerlink" title="real time monitoring predicted result"></a>real time monitoring predicted result</h4><p>Use TensorboardX to monitor predicted results:</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">if i % <span class="number">20</span> == <span class="number">0</span>:</span><br><span class="line">            <span class="comment">#draw image every 20 batches</span></span><br><span class="line">            writer.add_image(<span class="string">'EM image '</span>+str(i),</span><br><span class="line">                             torchvision.utils.make_grid(<span class="keyword">volume</span><span class="bash">), i)</span></span><br><span class="line"><span class="bash">            writer.add_image(<span class="string">'GT image '</span>+str(i), torchvision.utils.make_grid(label), i)</span></span><br><span class="line"><span class="bash">            writer.add_image(<span class="string">'predict image '</span>+str(i), torchvision.utils.make_grid(output), i)</span></span><br></pre></td></tr></table></figure><p>This will allow me to see the improvement of model’s performance more clearly.</p><p>EM in 3680th batches</p><p><img src="http://i2.tiimg.com/640680/6ba0407959138c82.png" alt="Markdown"></p><p>Ground truth in 3680th batches</p><p><img src="http://i2.tiimg.com/640680/83ebcf388707f0a6.png" alt="Markdown"></p><p>Predicted in 3680th batches</p><p><img src="http://i2.tiimg.com/640680/f618886ef775eb3c.png" alt="Markdown"></p><p>Then I will predict new EM image which is preprocessed by the previous steps. Then do proofreading on the predicted membrane. Then do distance transformation to generate seeds.</p><hr><h1 id="Week-5-amp-6"><a href="#Week-5-amp-6" class="headerlink" title="Week 5 &amp; 6"></a>Week 5 &amp; 6</h1><h1 id="predict-on-EM"><a href="#predict-on-EM" class="headerlink" title="predict on EM"></a>predict on EM</h1><ul><li>prepare predict data</li><li>export mask1 em</li><li>Mip level 3, it is really important to keep the resolution same( realize it after several failures)</li><li>set to window</li><li>bad slices record, replace by the previous layer</li></ul><p><strong>Record export coordinates</strong></p><pre><code>- 0-80: 10809-20685  5448-11102- 81-144 9200-19076   4649-10303- 145-182 8193-18069  4104-9758- 183-219  7337-17213  3792-9446- 220-265 6496-16372  3584-9238- 266-292   55509-15385    3241-8895- 293-300 4590-14466   2914-8568</code></pre><p><strong>Test commands</strong><br><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CUDA_VISIBLE_DEVICES=<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span> python3 -u bin/test.py -t data/mask1/ -dn mask1_em.h5 -o outputs/mask1output -mi <span class="number">4</span>,<span class="number">256</span>,<span class="number">256</span> -g <span class="number">1</span> -m outputs/nmj0729mixloss/volume_40000.pth -c <span class="number">12</span> -b <span class="number">4</span> -ac <span class="number">2</span></span><br></pre></td></tr></table></figure></p><ul><li>see results:<br><a href="http://127.0.0.1:8889/notebooks/projects/membrane/jupyter/visualize_prediction_result.ipynb" target="_blank" rel="noopener">http://127.0.0.1:8889/notebooks/projects/membrane/jupyter/visualize_prediction_result.ipynb</a></li></ul><p>Not good, check very bad slices and deflicker<br>Try to train for a longer time</p><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">CUDA_VISIBLE_DEVICES=<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span> python3 -u bin/train.py -t data/train_set/ -dn em_51 -ln mask_51 -o outputs/nmj0731retrain -lr <span class="number">0.0005</span> --volume-total <span class="number">400000</span> --volume-save <span class="number">4000</span> -mi <span class="number">4</span>,<span class="number">256</span>,<span class="number">256</span> -g <span class="number">3</span> -c <span class="number">8</span> -b <span class="number">3</span> -lt <span class="number">4</span> -ac <span class="number">2</span></span><br><span class="line"></span><br><span class="line">CUDA_VISIBLE_DEVICES=<span class="number">0</span> python3 -u bin/train.py -t data/train_set/ -dn em_51 -ln mask_51 -o outputs/nmj0729mixloss -lr <span class="number">0.001</span> --volume-total <span class="number">40000</span> --volume-save <span class="number">2000</span> -mi <span class="number">4</span>,<span class="number">256</span>,<span class="number">256</span> -g <span class="number">1</span> -c <span class="number">6</span> -b <span class="number">1</span> -lt <span class="number">4</span> -ac <span class="number">2</span></span><br><span class="line"></span><br><span class="line">#-lt <span class="number">4</span> focal and dice loss</span><br></pre></td></tr></table></figure><p>It seems the results of membrane prediction isn’t very good. Needs many post process work. For example, one way is to use a deep learning model like U-net to predict affinity and close the membrane.</p><p><img src="http://i4.fuimg.com/640680/080f9880226ba6e5.png" alt="Markdown"></p><h4 id="preprocess"><a href="#preprocess" class="headerlink" title="preprocess"></a>preprocess</h4><p><strong>Deflickering work</strong><br>I use deflickering codes to smooth the contrast.</p><ul><li>[ ] <a href="https://github.com/donglaiw/EM-preprocess/blob/master/script/T_deflicker.py" target="_blank" rel="noopener">EM-preprocess/T_deflicker.py at master · donglaiw/EM-preprocess · GitHub</a><br>20 sec to process a volume with data size 100x1024x1024 using online version of deflickering</li></ul><p><img src="http://i4.fuimg.com/640680/493a642ca564813f.png" alt="Markdown"></p><h4 id="try-to-predict-directly-on-masks-Not-the-membrane"><a href="#try-to-predict-directly-on-masks-Not-the-membrane" class="headerlink" title="try to predict directly on masks. Not the membrane"></a>try to predict directly on masks. Not the membrane</h4><p>It may have some advantages: do not need to be precise, we can perform distance transformation on the predicted masks to get the seed. And it will be better to track and automatically assign labels using masks instead of seeds.</p><p><img src="http://i2.tiimg.com/640680/96c7c89bc409d6ba.png" alt="Markdown"></p><p>Comparison of mask and membrane:<br><img src="http://i4.fuimg.com/640680/743789aaa8f0fe9f.png" alt="Markdown"></p><h3 id="7-31-retrain-on-deflicker-data"><a href="#7-31-retrain-on-deflicker-data" class="headerlink" title="7.31 retrain on deflicker data"></a>7.31 retrain on deflicker data</h3><p>volume_168000.pth<br>data/mask1/deflicker_em.h5</p><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CUDA_VISIBLE_DEVICES=<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span> python3 -u bin/test.py -t data/mask1/ -dn deflicker_em.h5 -o outputs/mask1output8<span class="number">.01</span>deflicker -mi <span class="number">4</span>,<span class="number">256</span>,<span class="number">256</span> -g <span class="number">3</span> -m outputs/nmj0801retrain/volume_156000.pth -c <span class="number">3</span> -b <span class="number">3</span> -ac <span class="number">2</span></span><br></pre></td></tr></table></figure><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">CUDA_VISIBLE_DEVICES=<span class="number">0</span> python3 -u bin/train.py -t data/train_set/ -dn em_51 -ln mask_51 -o outputs/nmj0731debug -lr <span class="number">0.0005</span> --volume-total <span class="number">4000</span> --volume-save <span class="number">1000</span> -mi <span class="number">4</span>,<span class="number">256</span>,<span class="number">256</span> -g <span class="number">1</span> -c <span class="number">3</span> -b <span class="number">1</span> -lt <span class="number">4</span> -ac <span class="number">2</span></span><br><span class="line"></span><br><span class="line">CUDA_VISIBLE_DEVICES=<span class="number">0</span> python3 -u bin/test.py -t data/mask1/ -dn deflicker_em.h5 -o outputs/mask1outputdebug -mi <span class="number">4</span>,<span class="number">256</span>,<span class="number">256</span> -g <span class="number">1</span> -m outputs/nmj0731retrain/volume_4002.pth -c <span class="number">6</span> -b <span class="number">1</span> -ac <span class="number">2</span></span><br></pre></td></tr></table></figure><p>Model structure has problems<br>Retrain on previous model</p><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CUDA_VISIBLE_DEVICES=<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span> python3 -u bin/train.py -t data/train_set/ -dn em_51 -ln mask_51 -o outputs/nmj0801retrain -lr <span class="number">0.0001</span> --volume-total <span class="number">400000</span> --volume-save <span class="number">4000</span> -mi <span class="number">4</span>,<span class="number">256</span>,<span class="number">256</span> -g <span class="number">3</span> -c <span class="number">8</span> -b <span class="number">3</span> -lt <span class="number">4</span> -ac <span class="number">2</span> -ft True -pm outputs/nmj0731retrain/volume_200001.pth</span><br></pre></td></tr></table></figure><p>Train on segment data</p><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CUDA_VISIBLE_DEVICES=<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span> python3 -u bin/train.py -t data/train_set/ -dn em_51 -ln mask_51_ -o outputs/nmj0801segment -lr <span class="number">0.001</span> --volume-total <span class="number">400000</span> --volume-save <span class="number">4000</span> -mi <span class="number">4</span>,<span class="number">256</span>,<span class="number">256</span> -g <span class="number">3</span> -c <span class="number">8</span> -b <span class="number">3</span> -lt <span class="number">4</span> -ac <span class="number">2</span></span><br></pre></td></tr></table></figure><p>It is weird that after some training, the test results have nothing</p><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CUDA_VISIBLE_DEVICES=<span class="number">5</span> python3 -u bin/train.py -t data/train_set/ -dn em_51 -ln mask_51 -o outputs/nmj0801after -lr <span class="number">0.001</span> --volume-total <span class="number">400000</span> --volume-save <span class="number">4000</span> -mi <span class="number">4</span>,<span class="number">256</span>,<span class="number">256</span> -g <span class="number">1</span> -c <span class="number">8</span> -b <span class="number">1</span> -lt <span class="number">4</span> -ac <span class="number">2</span></span><br></pre></td></tr></table></figure><p>Add image augmentation, adjust intensity augmentation. Decrease contrast and brightness ratio, it will severely influence converge.</p><h4 id="NMJ-manually-labeling-work"><a href="#NMJ-manually-labeling-work" class="headerlink" title="NMJ manually labeling work"></a>NMJ manually labeling work</h4><p>First I start randomly from a terminal or axon. Then Jeff recommended it is better to start from axons. I use the latter method to manually label <strong>two NMJs</strong> for using one week.</p><p>At first it seems very hard to track and label NMJs. The boundary is unclear and I have little experience on labeling NMJs, it is a lot harder to label NMJs than labeling on the main bundle.</p><p>I will try to label maybe more <strong>5 NMJs</strong> to collect enough data to test the linear hypothesis: <strong>the correlation of axon caliber and terminal area.</strong> If we can prove that, we can save a lot of time: we can just dense segment on axons and calculate the corresponding terminal area. And we only need tracing on the terminals.</p><p>I will try to reslice the labeled NMJs to calculate the axon caliber. It seems VTK is a good tool to do reslice on any arbitrary orientation reslice.</p><h4 id="Add-more-data-for-automatic-pipeline"><a href="#Add-more-data-for-automatic-pipeline" class="headerlink" title="Add more data for automatic pipeline"></a>Add more data for automatic pipeline</h4><ul><li>[ ] 代码 <a href="http://140.247.107.75:8889/notebooks/projects/membrane/jupyter/extract_membrane_from_marco.ipynb" target="_blank" rel="noopener">Jupyter Notebook</a><br>I processed marco’s data for training. It is really precious, we easily increase our data from 51 images to 1440 images. It is really helpful if we have more.</li></ul><figure class="highlight delphi"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> h5py.<span class="keyword">File</span>(<span class="string">'data/train_set/marco_1435_mask'</span>) <span class="keyword">as</span> f:</span><br><span class="line">    f.create_dataset(<span class="string">'main'</span>,data= paddedmask,dtype =uint8)</span><br><span class="line"><span class="keyword">with</span> h5py.<span class="keyword">File</span>(<span class="string">'data/train_set/marco_1435_membrane'</span>) <span class="keyword">as</span> f:</span><br><span class="line">    f.create_dataset(<span class="string">'main'</span>,data= paddedmaskmem,dtype =uint8)</span><br></pre></td></tr></table></figure><p><img src="http://i4.fuimg.com/640680/8c9abba357fcb56c.png" alt="Markdown"></p><p><img src="http://i4.fuimg.com/640680/ad6c8f42a22e89f1.png" alt="Markdown"></p><p><img src="http://i4.fuimg.com/640680/db41e29e1b9c045a.png" alt="Markdown"></p><h3 id="updated-pipeline"><a href="#updated-pipeline" class="headerlink" title="updated pipeline"></a>updated pipeline</h3><ul><li>segmentation first, doesn’t need to be very precise. </li><li>Then do distance transform and find the seed. It is easy to find connected component and then do distance transform to get seeds.</li><li><p>Test distance transform and hungarian matching on marco’s data.</p></li><li><p>[ ]  代码<a href="http://140.247.107.75:8889/notebooks/projects/membrane/jupyter/extract_membrane_from_marco.ipynb" target="_blank" rel="noopener">Jupyter Notebook</a></p></li></ul><p>8.3  training</p><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">CUDA_VISIBLE_DEVICES=<span class="number">0</span> python3 -u bin/train.py -t data/train_set/marco/ -dn marco_1435_em -ln marco_1435_mask -o outputs/nmj0804segmentmarcodata -lr <span class="number">0.001</span> --volume-total <span class="number">400000</span> --volume-save <span class="number">4000</span> -mi <span class="number">4</span>,<span class="number">256</span>,<span class="number">256</span> -g <span class="number">1</span> -c <span class="number">4</span> -b <span class="number">1</span> -lt <span class="number">4</span> -ac <span class="number">2</span></span><br><span class="line"></span><br><span class="line">CUDA_VISIBLE_DEVICES=<span class="number">0</span> python3 -u bin/train.py -t data/train_set/marco/ -dn marco_1435_em -ln marco_1435_mask -o outputs/nmj0805segmentmarcodataretrain -lr <span class="number">0.001</span> --volume-total <span class="number">400000</span> --volume-save <span class="number">4000</span> -mi <span class="number">4</span>,<span class="number">256</span>,<span class="number">256</span> -g <span class="number">1</span> -c <span class="number">4</span> -b <span class="number">1</span> -lt <span class="number">4</span> -ac <span class="number">2</span> -ft True -pm outputs/nmj0805segmentmarcodataretrain/volume_4000.pth</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">CUDA_VISIBLE_DEVICES=<span class="number">0</span> python3 -u bin/test.py -t data/mask1/ -dn mask1_em.h5 -o outputs/mask1output8<span class="number">.04</span> -mi <span class="number">4</span>,<span class="number">256</span>,<span class="number">256</span> -g <span class="number">1</span> -m outputs/nmj0804segmentmarcodata/volume_108000.pth -c <span class="number">2</span> -b <span class="number">1</span> -ac <span class="number">2</span></span><br></pre></td></tr></table></figure><h4 id="resolution-matters"><a href="#resolution-matters" class="headerlink" title="resolution matters!"></a>resolution matters!</h4><p>It seems that the resolution influence the prediction. We should keep the training and test data in the same resolution!</p><p>Record test data’s export coordinates:</p><pre><code>- 0-80: 10809-20685  5448-11102- 81-144 9200-19076   4649-10303- 145-182 8193-18069  4104-9758- 183-219  7337-17213  3792-9446- 220-265 6496-16372  3584-9238- 266-292   55509-15385    3241-8895- 293-300 4590-14466   2914-8568</code></pre><p>Try <strong>mip4</strong> result</p><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CUDA_VISIBLE_DEVICES=<span class="number">0</span> python3 -u bin/test.py -t data/mask1/ -dn mask1_em_mip4.h5 -o outputs/mask1output8<span class="number">.05</span>mip4 -mi <span class="number">4</span>,<span class="number">256</span>,<span class="number">256</span> -g <span class="number">1</span> -m outputs/nmj0804segmentmarcodata/volume_108000.pth -c <span class="number">2</span> -b <span class="number">1</span> -ac <span class="number">2</span></span><br></pre></td></tr></table></figure><p><img src="http://i4.fuimg.com/640680/c8462edb973660e0.png" alt="Markdown"></p><p>Result still not good: some axons are not predicted.<br>Maybe the noise has a big influence. And the proposed region isn’t enough.  Maybe DICE loss function influence the False positive region.</p><p>Try only BCE</p><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">CUDA_VISIBLE_DEVICES=<span class="number">0</span> python3 -u bin/train.py -t data/train_set/marco/ -dn marco_1435_em -ln marco_1435_mask -o outputs/nmj0805segmentmarcodataBCE -lr <span class="number">0.001</span> --volume-total <span class="number">400000</span> --volume-save <span class="number">4000</span> -mi <span class="number">4</span>,<span class="number">256</span>,<span class="number">256</span> -g <span class="number">1</span> -c <span class="number">4</span> -b <span class="number">1</span> -lt <span class="number">1</span> -ac <span class="number">2</span></span><br><span class="line"></span><br><span class="line">CUDA_VISIBLE_DEVICES=<span class="number">0</span> python3 -u bin/test.py -t data/mask1/ -dn mask1_em_mip4.h5 -o outputs/mask1output8<span class="number">.07</span>mip4 -mi <span class="number">4</span>,<span class="number">256</span>,<span class="number">256</span> -g <span class="number">1</span> -m outputs/nmj0805segmentmarcodataBCE/volume_160000.pth -c <span class="number">2</span> -b <span class="number">1</span> -ac <span class="number">2</span></span><br><span class="line"></span><br><span class="line">#<span class="number">8.7</span> retrain</span><br><span class="line">CUDA_VISIBLE_DEVICES=<span class="number">0</span> python3 -u bin/train.py -t data/train_set/marco/ -dn marco_1435_em -ln marco_1435_mask -o outputs/nmj0807segmentmarcodataretrain -lr <span class="number">0.001</span> --volume-total <span class="number">400000</span> --volume-save <span class="number">4000</span> -mi <span class="number">4</span>,<span class="number">256</span>,<span class="number">256</span> -g <span class="number">1</span> -c <span class="number">4</span> -b <span class="number">1</span> -lt <span class="number">4</span> -ac <span class="number">2</span> -ft True -pm outputs/nmj0805segmentmarcodataBCE/volume_160000.pth</span><br></pre></td></tr></table></figure><p>Results still not good<br><img src="http://i4.fuimg.com/640680/81ada9efd84b2bb8.png" alt="Markdown"></p><h4 id="8-11-new-try"><a href="#8-11-new-try" class="headerlink" title="8.11 new try"></a>8.11 new try</h4><p>Previous computing resource isn’t enough. Only have one gpu on the machine. I use RC cluster to do the computing. It has many gpus to use. Setting some environment and softwares to computing.</p><figure class="highlight jboss-cli"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">srun <span class="params">--pty</span> -p cox -t 7-00<span class="function">:00</span> <span class="params">--mem</span> 100000 -n 8 <span class="params">--gres=gpu</span><span class="function">:4</span> <span class="string">/bin/bash</span></span><br><span class="line">srun <span class="params">--pty</span> -p cox -t 7-00<span class="function">:00</span> <span class="params">--mem</span> 200000 -n 2 <span class="params">--gres=gpu</span><span class="function">:1</span> <span class="string">/bin/bash</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#control D exit</span></span><br><span class="line"><span class="comment">#squeue/sacct check job</span></span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">!/bin/bash</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> add all other SBATCH directives here...</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">SBATCH -p cox</span></span><br><span class="line"><span class="meta">#</span><span class="bash">SBATCH --gres=gpu:4</span></span><br><span class="line"><span class="meta">#</span><span class="bash">SBATCH --constraint=titanx</span></span><br><span class="line"><span class="meta">#</span><span class="bash">SBATCH -n 8 <span class="comment"># Number of cores</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash">SBATCH -N 1 <span class="comment"># Ensure that all cores are on one machine</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash">SBATCH --mem=100000</span></span><br><span class="line"><span class="meta">#</span><span class="bash">SBATCH -t 5-00:00:00</span></span><br><span class="line"><span class="meta">#</span><span class="bash">SBATCH -o logs/train_%j.log</span></span><br><span class="line"></span><br><span class="line">module load cuda</span><br><span class="line"></span><br><span class="line">CUDA_VISIBLE_DEVICES=0,1,2,3 python3 -u bin/train.py -t data/train_set/marco/ -dn marco_1435_em -ln marco_1435_mask -o outputs/nmj08011segmentmarcodataretrain -lr 0.001 --volume-total 400000 --volume-save 4000 -mi 4,256,256 -g 4 -c 8 -b 4 -lt 4 -ac 2 -ft True -pm outputs/nmj0811membranemarcodata/volume_12000.pth</span><br><span class="line"><span class="meta">#</span><span class="bash"> end of program</span></span><br><span class="line">exit 0;</span><br></pre></td></tr></table></figure><p>Working dir on rc<br>/n/coxfs01/xupeng/projects/membrane<br>Scp -r hp003 to rc<br>Install anaconda2 and 3<br>Install pytorch(0.4.0)  keras and tensorflow<br>tensorboardX 1.2 torchvision0.2</p><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">pip <span class="keyword">install</span> keras</span><br><span class="line">pip <span class="keyword">install</span> tensorflow-gpu</span><br><span class="line">conda <span class="keyword">install</span> pytorch torchvision -c pytorch</span><br></pre></td></tr></table></figure><p>train with 4 gpus<br><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">CUDA_VISIBLE_DEVICES=<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span> python3 -u bin/train.py -t data/train_set/marco/ -dn marco_1435_em -ln marco_1435_mask -o outputs/nmj0811membranemarcodata -lr <span class="number">0.001</span> --volume-total <span class="number">400000</span> --volume-save <span class="number">4000</span> -mi <span class="number">12</span>,<span class="number">256</span>,<span class="number">256</span> -g <span class="number">4</span> -c <span class="number">8</span> -b <span class="number">4</span> -lt <span class="number">4</span> -ac <span class="number">2</span></span><br><span class="line"></span><br><span class="line">#retrain</span><br><span class="line">CUDA_VISIBLE_DEVICES=<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span> python3 -u bin/train.py -t data/train_set/marco/ -dn marco_1435_em -ln marco_1435_mask -o outputs/nmj08012segmentmarcodataretrain -lr <span class="number">0.001</span> --volume-total <span class="number">400000</span> --volume-save <span class="number">4000</span> -mi <span class="number">4</span>,<span class="number">256</span>,<span class="number">256</span> -g <span class="number">4</span> -c <span class="number">8</span> -b <span class="number">4</span> -lt <span class="number">4</span> -ac <span class="number">2</span> -ft True -pm outputs/nmj0811membranemarcodata/volume_12000.pth</span><br></pre></td></tr></table></figure></p><p><strong>Thoughts about the not perfect results:</strong></p><ul><li>Maybe 3D U-net model is too large to train, intensity has influence. </li><li>The pattern difference is large, we may use the similar one with larger weights. </li><li>We may need some more design to predict many separate regions and consider the continuity. Consider higher resolution.</li></ul><h4 id="2D-D-Linknet"><a href="#2D-D-Linknet" class="headerlink" title="2D D-Linknet"></a>2D D-Linknet</h4><p>I started to build a new deep learning model. I use 2D U-net instead of 3D to train is easier. It is different with U-net, but also effective in predicting segments.</p><p><img src="http://i4.fuimg.com/640680/87378f2e7ea1db4c.png" alt="Markdown"></p><p>D-LinkNet uses Linknet with pretrained encoder as its backbone and has additional dilated convolution layers in the center part. Linknet is an efficient semantic segmentation<br>neural network which takes the advantages of skip connections, residual blocks and encoder-decoder architecture. The original Linknet uses ResNet18 as its encoder, which is a pretty light but outperforming network. Linknet has shown high precision on several benchmarks, and it runs pretty fast.</p><p>I also use dilation CNN, Dilated convolution is a useful kernel to adjust receptive<br>fields of feature points without decreasing the resolution of feature maps. It was widely used recently.</p><p>I set the image input shape as 1024*1024, so I reprocess Marco data, export Mip level 0. Change the export ROI for better ROI and more precise resolution. Change the channels for resnet.</p><p>I will keep on modifying the model and build up the whole training pipeline including several efficient data augmentation methods. And then do test on the mask data.</p><hr><h1 id="Last-three-weeks"><a href="#Last-three-weeks" class="headerlink" title="Last three weeks"></a>Last three weeks</h1><p>Week 7,8,9 (10)</p><ul><li>mip 0， train on old model<br>Process the mip 0 data<br><a href="http://140.247.107.75:10000/notebooks/projects/membrane/jupyter/extract_membrane_from_marco_mip0.ipynb" target="_blank" rel="noopener">Jupyter Notebook</a></li><li>mip 0, multi task</li><li>mip 0, 2D D-linknet<br>This is three and one channel, for 2D Linknet</li></ul><figure class="highlight haskell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">data</span>/train_set/marco/maskfor2Dlinknet.h5</span></span><br><span class="line"><span class="class"><span class="keyword">data</span>/train_set/marco/emfor2Dlinknet.h5</span></span><br></pre></td></tr></table></figure><ul><li>prepare dataloader 512 512, random slice to get data, augmentation, weight, test dense segment</li><li>change channel to 3 and 1 after dataloader’s original process !  </li></ul><p><code>np.stack((imgs,)*3, 1)</code></p><p>Solve dataloader problem<br>Test to use synapse data loader, it has random slice, but we need  dimension right and batch more than one</p><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CUDA_VISIBLE_DEVICES=<span class="number">0</span> python3 -u bin/train.py -t data/train_set/marco/ -dn marco_1435_em -ln marco_1435_mask -o outputs/testdimension -lr <span class="number">0.001</span> --volume-total <span class="number">400000</span> --volume-save <span class="number">4000</span> -mi <span class="number">2</span>,<span class="number">512</span>,<span class="number">512</span> -g <span class="number">1</span> -c <span class="number">1</span> -b <span class="number">1</span> -lt <span class="number">4</span> -ac <span class="number">2</span></span><br></pre></td></tr></table></figure><ul><li>512*512</li><li>normalization</li><li>augmentation</li><li>test dense</li></ul><p>Train use mip0<br>1434,1112, 1734<br>This is one channel, for 3D unet, too large to train, use half? Last 800</p><figure class="highlight haskell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">data</span>/train_set/marco/coloredmaskmip0whole.h5</span></span><br><span class="line"><span class="class"><span class="keyword">data</span>/train_set/marco/emmip0whole.h5</span></span><br></pre></td></tr></table></figure><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CUDA_VISIBLE_DEVICES=<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span> python3 -u bin/train.py -t data/train_set/marco/ -dn emmip0whole_half.h5 -ln coloredmaskmip0whole_half.h5 -o outputs/nmj0813marcodatamip0 -lr <span class="number">0.001</span> --volume-total <span class="number">400000</span> --volume-save <span class="number">4000</span> -mi <span class="number">4</span>,<span class="number">256</span>,<span class="number">256</span> -g <span class="number">4</span> -c <span class="number">4</span> -b <span class="number">4</span> -lt <span class="number">4</span> -ac <span class="number">2</span></span><br></pre></td></tr></table></figure><p>On hp003 not work, memory error maybe should cut to quarter</p><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CUDA_VISIBLE_DEVICES=<span class="number">0</span> python3 -u bin/train.py -t data/train_set/marco/ -dn emmip0whole_quarter.h5 -ln coloredmaskmip0whole_quarter.h5 -o outputs/nmj0814marcodatamip0 -lr <span class="number">0.001</span> --volume-total <span class="number">400000</span> --volume-save <span class="number">1000</span> -mi <span class="number">4</span>,<span class="number">256</span>,<span class="number">256</span> -g <span class="number">1</span> -c <span class="number">4</span> -b <span class="number">1</span> -lt <span class="number">4</span> -ac <span class="number">2</span></span><br></pre></td></tr></table></figure><p>Locally smoothed networks<br>Smooth backgroud</p><p>talk about NMJ<br>Daniel and Jeff<br>Axon caliber:</p><ul><li>calculate volume and distance</li><li>or reslice it and find the minimum diameter!<br>Terminal:<br>Reslice it and paint the terminal!</li></ul><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">#<span class="number">8.14</span>  test <span class="number">4</span> gpus result</span><br><span class="line">CUDA_VISIBLE_DEVICES=<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span> python3 -u bin/test.py -t data/mask1/ -dn mask1_em_mip4.h5 -o outputs/nmj08014segmentmarcodataretrainmip4 -mi <span class="number">4</span>,<span class="number">256</span>,<span class="number">256</span> -g <span class="number">4</span> -m outputs/nmj08012segmentmarcodataretrain/volume_400000.pth -c <span class="number">4</span> -b <span class="number">4</span> -ac <span class="number">2</span></span><br></pre></td></tr></table></figure><p>not good enough, almost sure it is about resolution<br><img src="http://i2.tiimg.com/640680/89d953939c17fce1.png" alt="Markdown"></p><p><strong>sbatch_mip0_3D.sh</strong></p><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CUDA_VISIBLE_DEVICES=<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span> python3 -u bin/train.py -t data/train_set/marco/ -dn emmip0whole_half.h5 -ln coloredmaskmip0whole_half.h5 -o outputs/nmj0814marcodatamip0_half -lr <span class="number">0.001</span> --volume-total <span class="number">400000</span> --volume-save <span class="number">1000</span> -mi <span class="number">4</span>,<span class="number">256</span>,<span class="number">256</span> -g <span class="number">4</span> -c <span class="number">4</span> -b <span class="number">4</span> -lt <span class="number">4</span> -ac <span class="number">2</span></span><br></pre></td></tr></table></figure><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CUDA_VISIBLE_DEVICES=<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span> python3 -u bin/train.py -t data/train_set/marco/ -dn emmip0whole.h5 -ln coloredmaskmip0whole.h5 -o outputs/nmj0814marcodatamip0 -lr <span class="number">0.001</span> --volume-total <span class="number">400000</span> --volume-save <span class="number">1000</span> -mi <span class="number">4</span>,<span class="number">256</span>,<span class="number">256</span> -g <span class="number">4</span> -c <span class="number">4</span> -b <span class="number">4</span> -lt <span class="number">4</span> -ac <span class="number">2</span></span><br></pre></td></tr></table></figure><ul><li>outputs/nmj0814marcodatamip0</li><li>outputs/nmj0814marcodatamip0_half</li></ul><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CUDA_VISIBLE_DEVICES=<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span> python3 -u bin/test.py -t data/mask1/ -dn mask1_em_mip0_0_50.h5 -o outputs/nmj0815marcodatamip0_half -mi <span class="number">4</span>,<span class="number">256</span>,<span class="number">256</span> -g <span class="number">4</span> -m outputs/nmj0814marcodatamip0_half/volume_86000.pth -c <span class="number">4</span> -b <span class="number">4</span> -ac <span class="number">2</span></span><br></pre></td></tr></table></figure><p>logs/3D_mip0_hald_test.err</p><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CUDA_VISIBLE_DEVICES=<span class="number">0</span> python3 -u bin/test.py -t data/mask1/ -dn mask1_em_mip0_0_50.h5 -o outputs/nmj0815marcodatamip0 -mi <span class="number">4</span>,<span class="number">256</span>,<span class="number">256</span> -g <span class="number">1</span> -m outputs/nmj0814marcodatamip0/volume_99000.pth -c <span class="number">1</span> -b <span class="number">1</span> -ac <span class="number">2</span></span><br></pre></td></tr></table></figure><p>3D_mip0_whole_test.err</p><p>Conclusion:</p><p><strong>we should use 2D since the shift is too big to infer 3D information</strong></p><p>Finally the segmentation part of automatic tracing pipeline works:</p><h3 id="Automatic-Tracing-in-Bundle"><a href="#Automatic-Tracing-in-Bundle" class="headerlink" title="Automatic Tracing in Bundle"></a>Automatic Tracing in Bundle</h3><p><img src="http://i2.tiimg.com/640680/584c64fdaf11c64e.png" alt="Markdown"></p><p>This work is inspired from yaron and marco’s great work on automatically prediction membrane on bundle. And we are thinking, if we only care about tracing, maybe we can automatically trace the axon with little manual label. Since the bundle data is sparse and the shift of the z section is big, we may use a simpler yet more robust way to automaticaly trace.<br>So at first we will prepare the data, use some methods to generate more, and we will do segment prediction to get a segment and post process it, then use matching algorithm to trace each axon.</p><h4 id="Data-preparation"><a href="#Data-preparation" class="headerlink" title="Data  preparation"></a>Data  preparation</h4><ul><li><p>Extract axon segment (from Marco’s data)<br><img src="http://i2.tiimg.com/640680/9d013476a19d3dd8.png" alt="Markdown"><br><img src="http://i2.tiimg.com/640680/3c2d8c2fe9cab2e7.png" alt="Markdown"></p></li><li><p>Convert all segments to same color</p><ul><li>Training:    1200</li><li>Validation: 200<br><img src="http://i2.tiimg.com/640680/9e61c84bcda13810.png" alt="Markdown"></li></ul></li></ul><p>At first we use KK and marco’s data as training and validation sample. We convert the segment to same color as binary mask</p><h4 id="Data-Augmentation"><a href="#Data-Augmentation" class="headerlink" title="Data Augmentation"></a>Data Augmentation</h4><h3 id="Training"><a href="#Training" class="headerlink" title="Training:"></a>Training:</h3><ul><li><p>Simple augmentation: </p><ul><li>flip of x, y, (z); </li><li>90 degree rotation.<br><img src="http://i2.tiimg.com/640680/688954a7b2f85b05.png" alt="Markdown"></li></ul></li><li><p>Intensity augmentation.<br><img src="http://i2.tiimg.com/640680/d7f84ed10dc6977f.png" alt="Markdown"></p></li><li><p>Elastic augmentation<br><img src="http://i1.fuimg.com/640680/3e78d3e458b063b3.png" alt="Markdown"></p></li></ul><h5 id="Test"><a href="#Test" class="headerlink" title="Test:"></a>Test:</h5><p>Simple augmentation(16 combination)</p><p>Several augmentation methods are applied here to generate more training data, we have simple augmentation, intensity and elastic augmentation. For test part, we do all kinds of simple augmentation to get the average result<br>Although the augmentation May not have the strong biological meaning, but it is always useful to optimize the model better.</p><h4 id="Prediction-Model"><a href="#Prediction-Model" class="headerlink" title="Prediction Model"></a>Prediction Model</h4><p>We have discussed a lot about the prediction model, after a long time’s try, the 2D Dlinknet (adjustmen of U-net) finally works.</p><p>3D U-net with res block  (not very good)<br>2D D-LinkNet: encoder-decoder, res block, dilation.<br><img src="http://i2.tiimg.com/640680/70f0977b0a1fdfa5.png" alt="Markdown"></p><ul><li>Loss:<br>BCE+DICE loss(It seems remove DICE may have better result)<br><img src="http://i2.tiimg.com/640680/3b59f2842eaf0b18.png" alt="Markdown"></li></ul><p><img src="http://i2.tiimg.com/640680/713830f2720ff701.png" alt="Markdown"></p><p>Now we use a deep learning model to predict segmentation. I tried 3D U-net and 2D Link net to predict segment. It seems the 2D model is easier to train, for it has less parameters to tune and our data may have a big shift cross z-section. The model is similar to U-net, and the loss function we use is the combination of DICE loss and focal loss, which depict the overlap and difference of ground truth and prediction. The loss function decreases as training goes on.</p><p>which adopts encoderdecoder structure, dilated convolution and pretrained encoder, D-LinkNet architecture. Each blue rectangular block represents a multi-channel features map. Part A is the encoder of D-LinkNet. D-LinkNet uses ResNet34 as encoder. Part C is the decoder of D-LinkNet, it is set the same as LinkNet decoder. Original LinkNet only has Part A and Part C. D-LinkNet has an additional Part B which can enlarge the receptive field and as well as preserve the detailed spatial information. Each convolution layer is followed by a ReLU activation except the last convolution layer which use sigmoid activation.</p><p>reduces the relative loss for well-classified examples (pt &gt; .5), putting more focus on hard, misclassified examples. (we propose to reshape the loss function to down-weight easy examples and thus focus training on hard negatives. More formally, we propose to add a modulating factor (1 − pt) γ to the cross entropy loss, with tunable focusing parameter γ ≥ 0. We define the focal loss as)</p><h4 id="Prediction-Result"><a href="#Prediction-Result" class="headerlink" title="Prediction Result"></a>Prediction Result</h4><h3 id="Post-processing"><a href="#Post-processing" class="headerlink" title="Post processing:"></a>Post processing:</h3><ul><li>Bilateral filter</li><li>Erosion</li><li>Dilation</li></ul><p><img src="http://i2.tiimg.com/640680/3ccf827be716fafb.png" alt="Markdown"></p><p>I did some post processing work on prediction, using bilateral filter to remove some noise, Bilateral filter is better than gaussian filter. and use erosion and dilation to remove the potential merge of different connected region, since it is important to get sparse segment for next matching step, the dilation will make the segment smaller than the ground truth.<br>I evaluate it on validation set and the dice coefficient is acceptable since most of the region overlaps well.<br>Evaluation on Validation set</p><p><img src="http://i2.tiimg.com/640680/e24603eb94d53f89.png" alt="Markdown"></p><p><img src="http://i2.tiimg.com/640680/840d29a47250f731.png" alt="Markdown"></p><h1 id="NMJ-labeling-work"><a href="#NMJ-labeling-work" class="headerlink" title="NMJ labeling work"></a>NMJ labeling work</h1><p>Thanks to siyan and adi’s great work to align the image better, we can track and segment axons and terminals more easily. But the image quality isn’t good enough to apply automatic segmentation algorithm since it has many crack, noised and blur region. Now we have two magnitude more NMJs than six years ago,  our first ambition is to segment 13 NMJs to gain some<br>So after 1 month’s manual label we finally get the reconstruction result of 13 NMJs with 7 axons innervating them</p><p>It took us a month to reconstruct 13 NMJs, and there maybe 250 NMJs in total. So if we manually segment all NMJs, it will be at least two years effort. Which is too long to endure.<br><img src="http://i2.tiimg.com/640680/1b3e88542e0b6375.png" alt="Markdown"></p><p><img src="http://i2.tiimg.com/640680/659916b155960e05.png" alt="Markdown"></p><p><img src="http://i2.tiimg.com/640680/b064a79497b7cf37.png" alt="Markdown"></p><p><img src="http://i2.tiimg.com/640680/c5b7f35d11a3cc82.png" alt="Markdown"></p><p><img src="http://i2.tiimg.com/640680/749f5a6947ca871b.png" alt="Markdown"></p><p><img src="http://i2.tiimg.com/640680/0cc8c91faa68fc5c.png" alt="Markdown"></p><p><img src="http://i2.tiimg.com/640680/845ff7279a00f5f0.png" alt="Markdown"></p><p><img src="http://i2.tiimg.com/640680/7b9b3d2b77f9f277.png" alt="Markdown"></p><p>We would like to take advantage of what we have done here to do the work more quickily elsewhere. For example, since we really care about how much territory each axon has in each neural muscular junction. Does the incoming axon provides us any hints about that, that is to say, if we look at something like diameter of the incoming axon, can we get the information of  territory each axon has in NMJ. </p><p>For example, if the caliber of the axon and the contact area is propotional, we don’t need to reconstruct all of the junctions. That’s why we want to test if there is a correlation between diameter and contact area. So we need to quantify two things, one is axonal diameter, for each axon innervating each muscle fiber, to be more accurate, I extract 5 points to calculate diamter. and another one is the contact area.</p><p>Quantification of <strong>axonal diameter</strong></p><ul><li>5 points for each axon coming in each muscle fiber<br>Quantification of the <strong>contact area</strong></li><li>Contact area of each axon innervating each muscle fiber</li></ul><p>Firstly, for each axon, I calculate all the contact area it has with 13 muscle fibers and you can see different axons have different occupancy. The two largest have approximately 17 percent and the smallest one has less than nine percent</p><p><img src="http://i2.tiimg.com/640680/f06f7b963b5b305c.png" alt="Markdown"></p><p>Since  I have collected data for each axon coming into each muscle fiber, we can also have a look at them individually</p><p><img src="http://i2.tiimg.com/640680/59ecac8427b3a117.png" alt="Markdown"></p><p>This heatmap illustrate the diameter of each axon coming into each muscle fiber. And the white block means this axon has no contact with this muscle fiber, so I didn’t calculate it’s diameter</p><p><img src="http://i2.tiimg.com/640680/43d03374f4d2abd3.png" alt="Markdown"></p><p>This heatmap illustrate the contact area of each axon coming into each muscle fiber. And the white block means this axon has no contact with this muscle fiber, so I didn’t calculate it’s contact area</p><p>We can already have a sense that these two statistics may have some correlations by comparing these two heatmaps, by looking at these two plots together, I will gave you a scatter plot to see these correlation, although it is not perfect, but you will see a definite correlation between axonal diameter and contact area.</p><h3 id="Correlation-Test-Result"><a href="#Correlation-Test-Result" class="headerlink" title="Correlation Test Result"></a>Correlation Test Result</h3><p><img src="http://i2.tiimg.com/640680/3e61fe8864bdff61.png" alt="Markdown"></p><p>Pearson correlation coefficient:</p><script type="math/tex; mode=display">\rho_{X,Y} = \frac{cov(X,Y)}{\sigma_X \sigma_Y}</script><p>0.731 (p = 6.44×10^−12 )</p><p>Spearman correlation coefficient:  </p><script type="math/tex; mode=display">r_s = \rho_{rg_{X},rg_{Y}} = \frac{cov(g_{X},rg_{Y})}{\sigma_{rg_{X}} \sigma_{rg_{Y}} }</script><p>0.762 (p = 4.36*× 10^−12 )</p><p>Now we plot a scatter plot of all data points we collect, which are 7 axons coming into 13 muscle fibers, with some of them don’t have contact, there are more than seventy points. The x axis is axonal diameter and the y axis is contact area.  The units are microns and square microns. We have a regression line which fits the data well. Although it is not perfect. The shadow area is the confidence region of the regression.</p><p>By looking at this plot we have a sense that the axonal diameter and contact area should have a relatively linear correlation. We also use two metrics to quantify the correlation.<br>So one is pearson correlation coefficient, it is the covariance of two dataset divided by the individual standard deviation of two datasets. The range of this value is -1 to 1, the positive value means there is a positive correlation and the higher value means stronger correlation.<br>Now the pcc is 0.709 which indicates the correlation is good.<br>We also use another improved version of PCC to quantify the relative ranking correlation of the data. Which means we only focus on the relative value instead of the absolute value. It is Spearman correlation coefficient, and the result is a little higher. The good correlation means  if you get a bigger axonal diameter, it may have a relatively bigger contact area.</p><p>Apart from testing on all data together, we also test on each axon and each muscle fiber</p><h4 id="For-each-muscle"><a href="#For-each-muscle" class="headerlink" title="For each muscle"></a>For each muscle</h4><p><img src="http://i2.tiimg.com/640680/c8017110826d1fd5.png" alt="Markdown"></p><p><img src="http://i2.tiimg.com/640680/1ecfd3d4046d2dda.png" alt="Markdown"></p><p><img src="http://i2.tiimg.com/640680/a059b010a2dd1e39.png" alt="Markdown"></p><h4 id="For-each-axon"><a href="#For-each-axon" class="headerlink" title="For each axon"></a>For each axon</h4><p><img src="http://i2.tiimg.com/640680/ee09bea1b5c618d4.png" alt="Markdown"></p><p><img src="http://i2.tiimg.com/640680/5b0f66cfd920ac58.png" alt="Markdown"></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;It is my detailed progress of &lt;strong&gt;Neural Muscular Junction project&lt;/strong&gt; during my summer intern in &lt;a href=&quot;https://lichtmanlab.fas.harvard.edu/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Jeff Lichtman Lab&lt;/a&gt;. With the generous help of Jeff, I complete NMJ tracing and segmentation work.&lt;/p&gt;
&lt;p&gt;The &lt;strong&gt;codes related&lt;/strong&gt; are here:&lt;br&gt;&lt;a href=&quot;https://github.com/james20141606/Summer_Intern&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Main codes&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;https://github.com/james20141606/NMJ_automatic_pipeline&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Automatic pipeline&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;For &lt;strong&gt;whole work summary&lt;/strong&gt; please &lt;a href=&quot;https://www.cmwonderland.com/blog/2018/09/12/100_summer_intern/&quot;&gt;see here&lt;/a&gt;&lt;/p&gt;


	&lt;div class=&quot;row&quot;&gt;
		&lt;iframe src=&quot;https://drive.google.com/file/d/1XyEPj9r7p8VNk5nLlLIPNhZjuDHu2KTY/preview&quot; style=&quot;width:100%; height:550px&quot;&gt;&lt;/iframe&gt;
	&lt;/div&gt;



&lt;p&gt;Also I finished another synapse prediction and synaptic polarity prediction work during summer intern in &lt;a href=&quot;https://vcg.seas.harvard.edu/people&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Hanspiter Lab&lt;/a&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="projects" scheme="https://www.cmwonderland.com/blog/categories/projects/"/>
    
    
      <category term="project" scheme="https://www.cmwonderland.com/blog/tags/project/"/>
    
      <category term="neural science" scheme="https://www.cmwonderland.com/blog/tags/neural-science/"/>
    
      <category term="summer intern" scheme="https://www.cmwonderland.com/blog/tags/summer-intern/"/>
    
      <category term="connectomics" scheme="https://www.cmwonderland.com/blog/tags/connectomics/"/>
    
      <category term="computational neural science" scheme="https://www.cmwonderland.com/blog/tags/computational-neural-science/"/>
    
      <category term="deep learning" scheme="https://www.cmwonderland.com/blog/tags/deep-learning/"/>
    
      <category term="computer vision" scheme="https://www.cmwonderland.com/blog/tags/computer-vision/"/>
    
      <category term="Jeff Lichtman" scheme="https://www.cmwonderland.com/blog/tags/Jeff-Lichtman/"/>
    
  </entry>
  
  <entry>
    <title>Wittgenstein’s love and philosophy</title>
    <link href="https://www.cmwonderland.com/blog/2018/06/20/39_wittgenstein_bio/"/>
    <id>https://www.cmwonderland.com/blog/2018/06/20/39_wittgenstein_bio/</id>
    <published>2018-06-20T15:19:27.000Z</published>
    <updated>2018-10-10T05:01:44.388Z</updated>
    
    <content type="html"><![CDATA[<p>When I prepared my presentation about Wittgenstein, especially chapter RELUCTANT PROFESSOR, I write down some of my thoughts towards Wittgenstein, some of them is biased, because I read something which reveals the weakness and defect about him:</p><a id="more"></a><blockquote><p>To be honest, I first found Wittgenstein very mysterious and great (part of the reason is the translation of his german name sounds mysterious). But now I feel little disappointed. I see more a crazy and strange man rather than a genius. He may be a genius, but if it is because his madness and defect (I know it is wrong to say like this, but I can always have such feelings that some man is “great” just because he is strange or even mad), I don’t think it is a great thing. Also I am always confused about philosopher, they always think themselves have the right to judge everything, it is really ridiculous. So I am not happy about many of his thoughts concerning language, science and maths.</p></blockquote><p>The content which gives me the deepest impression is about the death of Francis.</p><p>By the time the second world war broke out, Skinner’s period as an apprentice had come to an end and he returned to Cambridge and he seems to have made an attempt to return to theoretical work. But<br>he knew that he was losing Wittgenstein’s love. After his return to Cambridge, he and Wittgenstein lived separately</p><p>In 1941 Francis had been taken seriously ill with polio and had been admitted into hospital. On 11 October 1941, Francis died.<br>Wittgenstein’s initial reaction was <strong>one of delicate restraint</strong>. In letters to friends telling them of Francis’s death, he managed a <strong>tone of quiet dignity.</strong> :<br>~He died without any pain or struggle entirely peacefully. I was with him. I think he has had one of the happiest lives I’ve known anyone to have, &amp; also the most peaceful death.~ </p><p>By the time of the funeral  his restraint had gone. He behaves like a <strong>‘frightened wild animal’</strong> at the ceremony, after the ceremony he refused to go to the house but  walked around town.</p><p>The reaction is very pure Wittgenstein’s style. But I don’t think Wittgenstein’s guilt over Francis was because his influence on Francis. It had to do with more about Wittgenstein himself.</p><p>I think Wittgenstein is cruel towards Francis, as he admitted:<br>~In the last 2 years of his life very often loveless and, in my heart, unfaithful to him. If he had not been so boundlessly gentle and true, I would have become totally loveless towards him.~ </p><p>I think it is a little like the normal lovers in daily life. The one who do more and contribute more always have less paid back. The other one always  do not value this sacrifice, and later regret about his/her wrongdoing. In this aspect, Wittgenstein is also a very normal person, or even more stubborn and make more mistakes concerning emotions. He is genius in thinking,  making metaphors and find out the tiniest details of world, but his genius make him innocent and vulnerable in emotion. He is not an all-rounder, like Keynes and Russell. His stubbornness and childish in emotions and love made him more vulnerable, and more sensitive to the world.</p><p>There is a very important concept about Wittgenstein’s love and philosophical ideas:  <strong>solipsism</strong></p><p>Compared with other people Wittgenstein love but not get reward, we can see the characteristics of his love: <strong>a certain indifference to the feelings of the other person.</strong> Neither Pinsent nor Marguerite nor Kirk  were in love with him seemed not to affect his love for them. Indeed, it perhaps made <strong>his love easier to give</strong>, for the relationship could be <strong>safe</strong>, in the <strong>splendid isolation of his own feelings</strong>.  But Francis acts opposite, he gave too many love to Wittgenstein, it seems that the <strong>”overlove”</strong> made Wittgenstein feel unsafe. He is a man which loves to contribute something to others but afraid of <strong>“having too many reaction and reward”</strong> It is very strange to say “I understand him”, but I can really understand part of his philosophy in love. Sometimes I also felt it is better to contribute and make others happy. But the idea to have others treat you well too. You may want the reaction, but you are more afraid and frightened about the “disappointment”, the afraid overcome your desire for intimacy. I know several friends who are great at their study and work but holds the similar ideas about love, the <strong>ambivalent</strong> about love made them vulnerable. Actually I think love is really difficult for almost everyone, it is particularly difficult for someone like Wittgenstein.</p><p>Wittgenstein’s ideas towards love is the reflect of his core value towards life and his work. We can say that most of his later work is to against the philosophical solipsism which once attracted him very much. He characterized his later work as <strong>an attempt to show the fly the way out of the fly-bottle.</strong> Here I don’t think it is a very high comment on his contribution to other people, but about himself. He is a isolated man, he is always interested in so many things, like he loves more than one person, even more than one gender. But he is also afraid if one thing or one person hurt him or let him down because he is so into them. He always reflects on himself, he is always sensitive to the environment, be careful not to be controlled by other thing and people. This kind of character made him great at criticizing the problem of previous thought about world and give him the ability to do some very creative work. But this kind of character also made him struggle at most of the time.</p><p>Its parallel is the emotional solipsism. Together with Francis the isolation was threatened, and, in the face of that threat, Wittgenstein had withdrawn. I think it is the major reason he behaves really badly towards Francis in his last few years and made him so guilty.</p><p>It shows us what a complicated man Wittgenstein was, most importantly, the author gives us the parallel comparison about his love and his work. We can have a better understanding how one man’s characteristics can deeply shape him,  especially for such a genius.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;When I prepared my presentation about Wittgenstein, especially chapter RELUCTANT PROFESSOR, I write down some of my thoughts towards Wittgenstein, some of them is biased, because I read something which reveals the weakness and defect about him:&lt;/p&gt;
    
    </summary>
    
      <category term="thoughts" scheme="https://www.cmwonderland.com/blog/categories/thoughts/"/>
    
    
      <category term="thoughts" scheme="https://www.cmwonderland.com/blog/tags/thoughts/"/>
    
      <category term="philosophy" scheme="https://www.cmwonderland.com/blog/tags/philosophy/"/>
    
      <category term="Wittgenstein" scheme="https://www.cmwonderland.com/blog/tags/Wittgenstein/"/>
    
  </entry>
  
  <entry>
    <title>记和爸爸的点点滴滴</title>
    <link href="https://www.cmwonderland.com/blog/2018/06/16/11_dad/"/>
    <id>https://www.cmwonderland.com/blog/2018/06/16/11_dad/</id>
    <published>2018-06-16T15:58:06.000Z</published>
    <updated>2018-10-10T05:00:23.078Z</updated>
    
    <content type="html"><![CDATA[<p>今天终于考完试了，也好久没有更新网站了，正好是父亲节，很想写一篇文章回忆一些记忆中细碎但是印象深刻的事。</p><p>我是个很在意各种细节的人，父亲也用一个个细节深深地影响了我，回顾我长大的每一步，每一步都有爸爸带着我向前走，我们一起经历了很多很多的事情，人们都说一个人二十岁之前的经历基本决定了他是一个什么样的人，我要感谢爸爸和妈妈让我经历的成长，让我成长为一个没有让人失望的人。</p><p>我记下了一些一下子就能想到的事情，还有太多太多细节都回荡在脑海里，如果有时间的话，应该仔细地写一写这些宝贵的回忆。</p><p><img src="http://i4.fuimg.com/640680/c81907e7cb9988e7.jpg" alt="Markdown"></p><a id="more"></a><ul><li>幼儿园</li></ul><p>我记得那时候冬天裹得像个大粽子，妈妈给我裹上一层有一层，我面对着爸爸坐在摩托上，爸爸送我去幼儿园，等着老师开门<br>小学。虽然就家离幼儿园很远，但是纵使能到的特别早，坐在第一排，后来想想这应该是我意识里要做到最好的源头，在我连记忆都保存不下来的岁月里，是爸爸妈妈帮我塑造起了这样的意识。</p><p>我记得直到后来上了小学，赶不上公交了，爸爸就骑着摩托带我一路追上，我最喜欢的就是爸爸说算了直接给你送到吧，我就反而可以提前到校门口，早点到学校总能给我一种很好的感觉，这是父母给我的良好的习惯，永远要早一点，永远不要往后拖。</p><p>我在路上总是喜欢问爸爸无穷无尽的问题，那时候应付一个小孩子多简单呀，爸爸还会教我认各种各样的车，我还记得有一次说到计算图形的面积，爸爸说，还有一个东西叫微积分，还可以计算曲线的面积，比如皮鞋鞋面的面积，我记得很清楚，那是爸爸载着我在买菜的时候说的，我惊讶极了，还有这么高级的东西，我给爸爸说，能不能暑假教会我。现在想想自己当初好天真，但是这种让我每天都对知识充满新鲜与好奇感的生活真的很美妙。</p><ul><li>小学</li></ul><p>我记得爸爸在我一年级的时候就买来奥数书和我一起钻研，这是一件让我感激至今的事情，这个行为带给我的深远影响可能远远地被低估了。我记得那些题，很难，也很有意思，比如用直线分割平面，数列找规律等等问题，有的题还要爸爸研究了答案讲给我。初一的时候郑老师给我们说，要有中招意识，这个思维方式已经很先进了，但是我觉得爸爸的思维方式更先进，让我时刻先人一步地学习，我记得我小学第一学期期末考试就考了双百分，现在想想，得益于父母的眼光，我的每一步都走的很早又很准确，这是多么幸运的事情。</p><p>我记得有一段时间我和爸爸迷上了九宫格和十六宫格，我们比赛谁能先填出来，有一天爸爸告诉我说他半夜起来还填了一会儿，我当时觉得特别有趣，和爸爸比赛做数学题在我看来是一个小男孩能够经历了最佳童年运动之一。我会经常回忆起这个片段，并且会暗下决心，设计更多有趣的挑战，亲子游戏，和我以后的孩子一起经历。虽然时代进步，可以利用的方法和工具越来越多，但是父母的亲身参与陪伴才是这些事的内核所在，如果父亲只是扔下一本奥数书，或者说，你把这十个数独题做出来，我想年幼的我会索然无味，可能就变得和我学电子琴一样了，但是爸爸通过亲身的陪伴把事情变得非常有趣，在我很小的时候就揭示出了“世界上有很多有挑战并且有趣的事情”的道理。我想如果世界上的爸爸们都能这么配着孩子做这些有趣的事情，很多孩子的人生可能会变得很不一样了。</p><p>我还特别感谢爸爸在我小学的时候带着我打篮球和羽毛球，从我使劲扔都仍不到篮筐开始，到我可以一放学就抱着球满场飞奔。我一直觉得小学的时候是我身体最好的时候，也为我中学时候储备了不错的身体，可惜这种锻炼的精神没能被自己坚持下来。那时候总是被爸爸叫着去运动，打羽毛球的时候爸爸总是会想办法调动我，我可以打的越来越远了，投的越来越远了，很可惜到了郑州之后打球的机会就非常少了，风也打，时间也少，再也没有了在老房子门前打羽毛球等着妈妈叫吃饭，还有在篮球场打球打得汗流浃背被爸爸妈妈叫回家的美好记忆了。</p><p>我还记得小学的时候有一次老师让每个人写一张速算卡，以后课间拿着背，别的同学很多是家长手抄，我自己写好公式之后，爸爸就用word敲好公式，然后彩色打印，粘在硬纸板上，我拿着比其他小朋友更精致的速算板，让我无比的自豪，其实我不需要速算卡来帮助我学速算，我每天都做速算题，做很多数学题，六年级还拿了速算比赛的第一名，但是爸爸对细节的重视，利用更好的工具做的更好的行为让我印象深刻。现在我也总是会想办法找到最好的工具，把东西做的尽量完美，这种对待事物的态度对每个人，尤其是对于小孩子的影响是巨大的。</p><p>可以说，爸爸妈妈对教育的重视和精细是我童年收到的最宝贵的礼物，</p><ul><li>小学毕业</li></ul><p>得到去郑外考试的消息，爸爸就立马决定带我去郑州考试，记得当时我还在妈妈办公室玩电脑，正在畅想六年级的暑假，文具盒都已经找不到了。我跟着爸爸做大巴到郑州站，做公交到了偏僻荒凉的西开发区，在那片有艺术气息但是荒废的独栋转车，然后找到河南工业大学，经历了一场偷偷摸摸的安排在晚上的考试，然后彻底改变了自己人生的轨迹。我在想如果是我的话，我会不会这么果决地带着自己的孩子去考试呢，很有可能我会错过一次改变我的孩子和家庭命运的机会，而父母总是在我还年幼无知，不知不觉间，帮我做了一次次无比正确的，让我感激不尽的选择。</p><p>我还记得考试一段时间之后的故事，郑外的考试数学满分一百份，英语五十，语文三十，我当时和爸爸在外面等我认识的一个家长的孩子交流做题的感觉，他应该是考遍了郑州能考的学校，我能感觉到自己信息的闭塞，但是当时题做的确实很不错，交流了一遍之后感觉自己应该都做对了，但是英语很难，觉得自己做的一般，和在南阳的考试完全不是一个难度。回到南阳之后过了很久，都一直没有消息。有一天爸爸送我去睿源上课外班，说起来还没有消息的事情，我大概觉得有点没面子，就说，反正就算考上了也不一定去上，这是大家一直说的，我太小，就算考上了也不一定要去。我记得正好到睿源的楼下了，爸爸停车看着我说，虽然是这么说，但是我很想接到打来的电话。这句话我记得非常非常深，一直到今天我都会常常想起。后来终于接到了电话，我的第一反应就是，一定要去，这是我人生的挑战和转折的起点，父亲的一句话给我带来了多少影响，我说不清楚，但是那种深藏的强烈的期望感在很多年里都在催促着我，在我悠闲的小学时光之后，一下子体会到我应该做些什么。父母的无数的行动和点滴的言语，让我在远离父母的时候从毫无想法的小学生迅速地有了很多意识和想法，这种意识比家长和老师的灌输要有用的多。</p><ul><li>初中的长路漫漫</li></ul><p>还记得初中求学的艰辛和有趣，炎热的夏天，我和爸爸从家里出发，心中充满了不舍，坐上去郑州的大巴，为了早点走，不想等下一班，我们就坐在大巴车偷偷加的小椅子上坐了一路，一路颠簸到郑州。我记得我写的对家人的想念的文章还因为感情细腻被郑老师朗读了。我一学期也就回家一两次，而爸爸妈妈却要轮流来看我，实在是非常辛苦，尤其是妈妈，要坐一天的车，晚上还要买菜做饭，周末为我洗衣服，带我继续在市里奔波上课，为了让我接受好一倍的教育，父母付出了多了好几倍的辛劳，这份付出一直是我内心深处一份非常重要的力量。</p><p>还记得好几次回家的经历，有父亲在国庆节接我到火车站坐大巴，因为买不到票了，一直等到晚上八点多，火车站上空还升起来了孔明灯，回到家已经凌晨了，妈妈还是做好了饭等着。第一个国庆我们去快到高速口的地方坐大巴，也是车非常少，我们最后坐上了一辆一路晃晃悠悠跑的相当慢的车，还在省道上走了一段。还有一年相当有趣，实在等不到车的我们突然在高速口看到一辆从郑州回南阳想挣点外快的救护车，于是我们大概七八个人都挤进去，坐着闪着等的救护车回了南阳。高中之后都是大家一起包车了，也没有太多记忆深刻的回家的记忆，但是初中的每次经历真的让我记忆格外的深刻，每次终于到了南阳的收费站，淡黄色的灯光一下子出现在眼前，那种家的气息就出现了，妈妈总是做好了可口的饭菜在等着，直到大学，已经有了很多的回家的方式，但是让我印象最深刻的依然是初中的求学经历。</p><p>高中的保送生考试，依然是和爸爸一起到了北京，然后记得后学校等成绩的那天，正好发烧了，然后爸爸那天到了郑州，然后就接到消息，被清华录取啦，这几年的艰辛的路都没有白走。记得去大学报到还是和爸爸一起，住在清华南边的宾馆，提前一天晚上逛校园，在法学院门前合照，以及因为转系的风波爸爸来北京，和学校协商，最终顺利地转了专业，每一步能走的顺心如意，真的要感谢父亲。</p><p>我记得初中有一年父亲节，我忘了是初一还是初二，我期末考试考了第一名，非常高兴，打电话给爸爸，正好是父亲节，我就说，我送你的礼物就是我考了第一名，那个时候我很骄傲，不过那个时候我能给的就只是考试的成绩，很多年了这一直是我能做的为数不多的事情。我很感谢父母给了我那么好的机会，让我一直追求我想追求的事情，让我少受到了很多束缚，让我不用想世俗的很多事情，让我做我想做的事情。</p><p>谢谢爸爸让我成长为一个更好的人，我想，等我以后当父亲了，我也要做爸爸这样的父亲。</p><p>煽情的话也不多说啦，<strong>祝爸爸父亲节快乐~</strong></p><p><img src="http://i4.fuimg.com/640680/c99b6d3389f52a7a.jpg" alt="Markdown"></p><center><font color="blue" ,font="" size="5">如果我懂得了爱，那一定是因为你</font></center><center><font color="pink" ,font="" size="5">If I Know What Love is, It is Because of You</font></center>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;今天终于考完试了，也好久没有更新网站了，正好是父亲节，很想写一篇文章回忆一些记忆中细碎但是印象深刻的事。&lt;/p&gt;
&lt;p&gt;我是个很在意各种细节的人，父亲也用一个个细节深深地影响了我，回顾我长大的每一步，每一步都有爸爸带着我向前走，我们一起经历了很多很多的事情，人们都说一个人二十岁之前的经历基本决定了他是一个什么样的人，我要感谢爸爸和妈妈让我经历的成长，让我成长为一个没有让人失望的人。&lt;/p&gt;
&lt;p&gt;我记下了一些一下子就能想到的事情，还有太多太多细节都回荡在脑海里，如果有时间的话，应该仔细地写一写这些宝贵的回忆。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://i4.fuimg.com/640680/c81907e7cb9988e7.jpg&quot; alt=&quot;Markdown&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="life" scheme="https://www.cmwonderland.com/blog/categories/life/"/>
    
    
      <category term="Life" scheme="https://www.cmwonderland.com/blog/tags/Life/"/>
    
  </entry>
  
  <entry>
    <title>Artificial Intelligence and Wittgenstein&#39;s use theory of meaning</title>
    <link href="https://www.cmwonderland.com/blog/2018/06/15/49_Artificial%20Intelligence%20and%20Wittgenstein&#39;s%20use%20theory%20of%20meaning/"/>
    <id>https://www.cmwonderland.com/blog/2018/06/15/49_Artificial Intelligence and Wittgenstein&#39;s use theory of meaning/</id>
    <published>2018-06-15T14:30:17.000Z</published>
    <updated>2018-10-10T05:02:20.128Z</updated>
    
    <content type="html"><![CDATA[<h3 id="AI’s-view"><a href="#AI’s-view" class="headerlink" title="AI’s view:"></a>AI’s view:</h3><h4 id="what-is-AI"><a href="#what-is-AI" class="headerlink" title="what is AI"></a>what is AI</h4><p>Artificial intelligence means using program to accomplish tasks human can do by simulating human’s brain. The purpose of artificial intelligence is to bypass the brain and body to achieve a full understanding of human intelligence. The idea can be traced back to <strong>Turing machine</strong> (we can already see some interesting coincidence here~ Turing has attended Wittgenstein’s class in Cambridge, though Turing holds different opinions, Wittgenstein values his ideas very much. Maybe Turing also get some inspiration during the idea conflict.)</p><a id="more"></a><p>In 1956, H. Simon and others designed the first AI program called “logical theoretician”. It can prove 38 of the first 52 theorems in “Principles of Mathematics.”</p><p>Today, AI has thrived in research, application, and education field in computer science and other disciplines. It specializes in issues such as procedural languages, methods of reasoning and problem solving, visual identification, and expert systems. The most powerful use of nowadays AI is in computer vision. </p><p>AI tries to help humans understand the human intelligence by means of symbolic operations, so it proposes under what conditions we have reason to attribute the state of mind to a purely physical system. It has made a great contribution to the development of cognitive science and the philosophy of the mind. There is a distinction between “strong AI theory” and “weak AI theory.” The weak AI theory aargues that computer programs help to understand the state of mind. This point has been widely accepted. The strong point of view claimed that the “heart” of the computer exemplifies the human psychological process. This argument is controversial. Searle argues that, unlike people, the syntactic manipulation of symbols by machines is not accompanied by a semantic understanding of the meaning of symbols.</p><h4 id="Why-Wittgenstein’s-theory-should-be-related-to-AI"><a href="#Why-Wittgenstein’s-theory-should-be-related-to-AI" class="headerlink" title="Why Wittgenstein’s theory should be related to AI"></a>Why Wittgenstein’s theory should be related to AI</h4><p>The AI discipline was formally established until the Dartmouth Conference in 1956, at that time Wittgenstein had already passed away. However, this does not mean that, from his discussion of other philosophical issues, we cannot find its philosophical inspiration for artificial intelligence, and on this basis reconstruct an artificial intelligence using Wittgenstein’s philosophy.</p><p>Artificial intelligence does not have a certain level of unity as mature disciplines such as physics and chemistry. In other words, the fundamental issues related to the basic definition of disciplines, such as what is “intelligence” “what is artificial intelligence,” and “what is the basic means of artificial intelligence”, the divergence among different AI schools is almost impossible to reconcile (until today It is far from being able to reach a consensus on how artificial intelligence can be realized. No one has a effective plan to achieve it.</p><p>One of the hopes of the public in philosophical research is that philosophy should be able to provide some kind of “integrated” solution to conflicts between discourse systems of various natural sciences (even between science and common sense). For example, philosophy of physics should provide some reconciliation solutions for conflicts between quantum mechanics and relativity; and cognitive science philosophy must provide some reconciliation solutions for conflicts between common-sense psychology and neuroscience; as for metaphysics It is necessary to provide a reconciliation program on the topic of “what is there?” and the conflict between common sense insights and scientific perspectives in the most general sense. From this point of view, facing the chaotic situation of within artificial intelligence discipline, people naturally expect philosophers to do something for them.</p><p>I think Wittgenstein’s philosophy may has closest relation to artificial intelligence and it can also give people inspiration on AI.</p><h4 id="The-pursuit-of-Unity-in-Wittgenstein’s-Philosophy"><a href="#The-pursuit-of-Unity-in-Wittgenstein’s-Philosophy" class="headerlink" title="The pursuit of Unity in Wittgenstein’s Philosophy"></a>The pursuit of Unity in Wittgenstein’s Philosophy</h4><p>Wittgenstein’s philosophy seems to have an inherent “integrated” quality, that is, its philosophy is always trying to provide a unified solution to all problems in the world. This academic style is scarce for the present situation of scattered research on AI. (actually, due to the rising of probability and statistics methods in AI, we focus less on the ideas and essence of AI, but only on techniques of math.)</p><p>This philosophical temperament was embodied in Wittgenstein’s Early work(TLP). In the “preface” of TLP, he wrote a bit arrogantly:</p><blockquote><p>“……On the other hand the truth of the thoughts that are here communicated seems to me unassailable and deﬁnitive. I therefore believe myself to have found, on all essential points, the ﬁnal solution of the problems. And if I am not mistaken in this belief, then the second thing in which the value of this work consists is that it shows how little is achieved when these problems are solved”</p></blockquote><p>The broad coverage of this book undoubtedly confirms his rhetoric. Within just over 20,000 words, Wittgenstein actually involved three topics: the metaphysical construction of the world and the metaphysical world. Linguistic representations, and the “right of being silence” for matters that cannot be characterized. These three topics basically correspond to the three steps of the “<strong>knowledge representation</strong>” task of artificial intelligence science: </p><ul><li>First, the metaphysical understanding of the object being represented; </li><li>Second, the technical means (especially the logical technical means) of knowledge representation </li><li>Third, the problem of delineation of the possibility boundary of the scope of knowledge representation (under the premise of selecting a specific representation method).</li></ul><p>From the perspective of the history of AI development, Wittgenstein ’ thought roughly corresponds to the “primary physics plan” of Hayes, who once attempted to use predicate calculus as a technical means to compile human daily physics knowledge (in contrast to scientific physics)  into axioms and set certain inference rules so that the system can automatically infer the required conclusions in the relevant context. </p><p>In other words, early Wittgenstein, like Hayes, tried to use the “once-for-all” approach to complete the task of comprehensive representation of daily knowledge on the premise of formal logic. They also assumed that in this process of knowledge representation, any <strong>particular agent</strong> that uses this knowledge is either negligible (as in Hayes) or cannot be characterized (in Wittgenstein, the “subject” merely “shows” rather than “characterizes” the boundaries of the linguistic representation). Although Wittgenstein eventually gave up the TLP system, and Hayes’s “simple physics” plan has now become part of  AI history, they share the same kind of theoretical courage to try to integrate all aspects of daily knowledge. And ambition, is what today’s AI engineers lack. Today’s AI theoreticians and engineers often abandon the interpretability of the model but pursue the increase in the accuracy of the model. This is an unavoidable but pitiable solution to solve complex problem in daily life. Nowadays AI already loses its interpretability under simple tasks. Could it become interpretable under hard tasks? Or maybe we can only solve the hard problem and produce real AI when we integrate everything again.</p><p>This kind of advocating comprehensive temperament has not disappeared in Wittgenstein’s later work Philosophical Investigations. Judging by appearance, this book is only constituted by a few scattered reviews of “philosophical sentiments”, but the “sloppyness” does not obscure its substantial comprehensiveness. In the preface of the book, he recognizes:</p><blockquote><p>“The thoughts that I publish in what follows are the precipitate of philosophical investigations which have occupied me for the last sixteen years. They concern many subjects: the concepts of meaning, of understanding, of a proposition and sentence, of logic, the foundations of mathematics, states of consciousness, and other things.……Originally it was my intention to bring all this together in a book whose form I thought of differently at different times.……After several unsuccessful attempts to weld my results together into such a whole, I realized that I should never succeed.”</p></blockquote><h4 id="Wittgenstein-uses-language-games-to-settle-everything"><a href="#Wittgenstein-uses-language-games-to-settle-everything" class="headerlink" title="Wittgenstein uses language games to settle everything"></a>Wittgenstein uses language games to settle everything</h4><p>The topics involved in the “Philosophical Investigations” are essentially related to each other, although the author has to observe the same or almost the same entity from different perspectives, and draw new sketches. </p><p>If we summarize the subject of “Philosophical Investigations” in the most succinct way with AI colors, then we might say that this book discusses  <strong>agents</strong>: Under what kind of normative constraints, in a dynamic  diachronic environment, using relevant characterization tools (especially daily language)  to perform causal interactions with the environment and other agents, and ultimately accomplish certain tasks. </p><p>Obviously, because the interactive process between the agent and the environment (using language) is very complicated, Wittgenstein had to carefully philosophize the normative conditions of the various links involved in the process. For example, his reflection on the concept of “understanding” and the concept of “consciousness” is about the agent itself; the investigation of concepts such as “logic”, “proposition”, and “meaning” is about representation of mediation; and discussion about “life “Formal”  involves the portrayal of an external environment grasped by an agent. </p><p>Wittgenstein put all these discussions together in the general framework of language games and settled them one by one. By constantly exploring new varieties of language games, he eventually turned his entire post-philosophy into an unusually open system: this system has no clear boundaries and it can  extend its jurisdiction to new virgin lands at any time.</p><p>It is really hard to put all these things together, but it seems that it is the best way to achieve real artificial intelligence. Nowadays many “naive” researchers are immersed in tuning there networks to do better at image classification、object recognition or related “simple/single task”. But it is far from the real intelligence. Recently some excellent scientists concer more about how to produce a real agent, but it is hard to use current state-of-art deep learning architecture to design a real agent. So deep learning cannot play hard games( game like GO looks hard to human, but it is more of a computational work to computer, so it can’t reflect the real intelligence level of computer).</p><h4 id="Real-time-information-processing-when-using-it"><a href="#Real-time-information-processing-when-using-it" class="headerlink" title="Real-time information processing when using it"></a>Real-time information processing when using it</h4><p>From the AI’s point of view, Philosophical Investigations surpass TLP because it no longer regards the static knowledge system as a focal point of philosophical theories, but shifts the focus to the <strong>actions of agents</strong>. Moved to the real-time processing of information. In other words, the issue of subject portrayal in the marginal position of its early philosophy has now become one of the focuses of the study. Considering the diversity of different real-time information processing tasks that different agents face, the complexity involved in Philosophical Investigations naturally will be far better than the TLP - which also partly explains why the late Wittgenstein’s philosophy is so complicated. In AI textbooks, the problem solving task also correspond to completely different problem solving techniques!  (For example, you can use Bayesian networks for reasoning, use genetic algorithms to do optimization of solution selection, use neuron networks for pattern recognition, use symbolic AI techniques for expert systems, etc.). Wittgenstein used a “language game” cover to try to put some of its most elementary neutrality on the various information processing processes. In the fragmented AI kingdom, we have seen this kind integration.</p><h4 id="Wittgenstein’s-“Factualism”-and-use-theory"><a href="#Wittgenstein’s-“Factualism”-and-use-theory" class="headerlink" title="Wittgenstein’s “Factualism” and use theory"></a>Wittgenstein’s “Factualism” and use theory</h4><p>From this point of view, Wittgenstein is indeed a different kind of alternative (or, he is an anti-analytic philosopher in analytic philosophy, and an analytical philosopher in anti-analytic philosophers). This special philosophical character mainly reflects in the atmosphere of some kind of “Factualism” by his writings.</p><p>“Factualism is referring to a philosophical style in which philosophers are to faithfully describe the known areas of humanity. In other words, they should not be as ignorant of the linguistic phenomena of everyday language as the traditional rationalist philosophers. In other words, “Factualism” must balance the “respection of  people’s existing experience” and “rethinking of the existing human experience”, and thus gradually tease out the deep formal framework from the complex human experience.</p><p>From the author’s point of view, the following paragraphs written by Vickers in Philosophical Studies fully demonstrate this practical essence of Vickers’ later philosophy—and it is in a way that makes AI experts happy:</p><blockquote><p>Think of the tools in a toolbox: there is a hammer, pliers, a saw, a screwdriver, a rule, a glue-pot, glue, nails and screws. a The functions of words are as diverse as the functions of these objects. (And in both cases there are similarities.)</p><p>Of course, what confuses us is the uniform appearance of words when we hear them in speech, or see them written or in print. For their use is not that obvious. Especially when we are doing philosophy!</p></blockquote><h5 id="This-corresponds-to-the-programming-design-level-of-programming"><a href="#This-corresponds-to-the-programming-design-level-of-programming" class="headerlink" title="This corresponds to the programming design level of programming"></a>This corresponds to the programming design level of programming</h5><p>In the language of AI, Wittgenstein actually distinguishes between the <strong>two interfaces of language operation</strong>: </p><ul><li>the usage of the terms between the words “user-friendly” is not obvious, and the traditional philosophers are also confused by its similar surface. </li><li>In a deeper “programming level”, the differences between the functional structures of the words are presented - in which each functional structure corresponds to a different input-output relationship and different input-oriented operations. </li></ul><p>Obviously, in Wittgenstein’s opinion, the real task of philosophy is to find the differences between these functional uses as marked by words—or to find real programs that allow our natural language mechanisms to flourish. This is the true ground that philosophers want to hug, or the “pragmatic facts” faced by the “Factualer”.</p><p>This position of Wittgenstein’s inspiration for today’s AI is: If an AI engineer wants to faithfully reproduce intelligent activities on the symbolic representation level, his working sample can neither be too close to the surface form of human natural language, nor too far away. </p><p>Not too close is because the surface form of natural language does not show the real mechanism of the use of words; not too far away is because the somewhat confusing “user-friendly” interface, after all is the starting point to explore the real mechanism behind it. </p><p>The recommended working procedure should be: The researcher must first observe the different functional roles played by the similar “user interface” <strong>in different use environments</strong> (ie, the input-output relationship), and then re-introduce the most likely programs. Then find the most appropriate engineering simulation method in the existing “arsenal library” of computer science. </p><p>This means that the engineering reproduction of the language operation mechanism is essentially a “top-down” construction process that use the experience of human natural language mechanisms. </p><p>At the initial stage of this construction process, that is, at the stage of qualitatively characterizing the operating mechanism of the characterization system, the reference significance of Wittgenstein’s philosophy will be most clearly demonstrated.</p><h2 id="Additional-Basic-data-mining-of-Philosophical-Investigations"><a href="#Additional-Basic-data-mining-of-Philosophical-Investigations" class="headerlink" title="Additional: Basic data mining of Philosophical Investigations"></a>Additional: Basic data mining of Philosophical Investigations</h2><p>I also spent some time analyzing the context of Philosophical Investigations using python, since it is more casual and less organized, it seems it’s hard to learn many information from it.</p><h3 id="prepare-data"><a href="#prepare-data" class="headerlink" title="prepare data"></a>prepare data</h3><figure class="highlight xl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> jieba</span><br><span class="line"><span class="keyword">import</span> os, codecs  </span><br><span class="line">from collections <span class="keyword">import</span> Counter  </span><br><span class="line"><span class="keyword">import</span> matplotlib.pylab <span class="keyword">as</span> plt</span><br><span class="line">plt.style.use(<span class="string">'ggplot'</span>)</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">with</span> codecs.open(<span class="string">'text.txt'</span>, <span class="string">'r'</span>, <span class="string">'utf8'</span>) <span class="keyword">as</span> f:  </span><br><span class="line">    txt = f.read()</span><br><span class="line">def get_words(txt):  </span><br><span class="line">    seg_list = jieba.cut(txt)  </span><br><span class="line">    c = Counter()  </span><br><span class="line">    <span class="keyword">for</span> x <span class="built_in">in</span> seg_list:  </span><br><span class="line">        <span class="keyword">if</span> len(x)&gt;<span class="number">1</span> <span class="built_in">and</span> x != <span class="string">'\r\n'</span>:  </span><br><span class="line">            c[x] += <span class="number">1</span>  </span><br><span class="line">    return c  # c.most_common(<span class="number">100</span>)</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:  </span><br><span class="line">    <span class="keyword">with</span> codecs.open(<span class="string">'text.txt'</span>, <span class="string">'r'</span>, <span class="string">'utf8'</span>) <span class="keyword">as</span> f:  </span><br><span class="line">        txt = f.read()  </span><br><span class="line">    a = get_words(txt)</span><br><span class="line">dat = a.most_common(<span class="number">1000</span>)</span><br><span class="line">countlist = np.ndarray([<span class="number">1000</span>,<span class="number">2</span>]).astype(<span class="string">'str'</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="built_in">in</span> range(<span class="number">1000</span>):</span><br><span class="line">    countlist[i][<span class="number">0</span>] = dat[i][<span class="number">0</span>]</span><br><span class="line">    countlist[i][<span class="number">1</span>] = dat[i][<span class="number">1</span>]</span><br><span class="line">wordlist = np.array(re.split(<span class="string">' |; |, |\*|\n'</span>,txt))</span><br><span class="line">select_ind = np.<span class="keyword">where</span>(np.isin(countlist[:,<span class="number">0</span>],np.array(selectwords)))[<span class="number">0</span>]</span><br><span class="line">countlist_ = []</span><br><span class="line"><span class="keyword">for</span> i <span class="built_in">in</span> range(<span class="number">1000</span>):</span><br><span class="line">    countlist_.append(countlist[i,<span class="number">0</span>]+<span class="string">': '</span>+countlist[i,<span class="number">1</span>])</span><br><span class="line">pd.DataFrame(np.array(countlist_)[:<span class="number">200</span>].reshape(<span class="number">20</span>,<span class="number">10</span>))</span><br></pre></td></tr></table></figure><h3 id="words-counts-most-frequent"><a href="#words-counts-most-frequent" class="headerlink" title="words counts, most frequent"></a>words counts, most frequent</h3><p><img src="http://i2.tiimg.com/640680/8c3c1a7d9cbd30c5.png" alt="Markdown"></p><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">count</span> = <span class="number">27</span></span><br><span class="line">fig,ax=plt.subplots(<span class="number">1</span>,figsize=(<span class="number">20</span>,<span class="number">10</span>))</span><br><span class="line">ax.bar(<span class="built_in">range</span>(<span class="built_in">count</span>),countlist[:<span class="built_in">count</span>,<span class="number">1</span>].astype(<span class="string">'int'</span>))</span><br><span class="line">ax.set_xticks(<span class="built_in">range</span>(<span class="built_in">count</span>))</span><br><span class="line">ax.set_xticklabels(countlist[:<span class="built_in">count</span>,<span class="number">0</span>])</span><br><span class="line">ax.set_title(<span class="string">'most frequent words'</span>)</span><br></pre></td></tr></table></figure><p><img src="http://i2.tiimg.com/640680/0b08dd44adeb8df9.png" alt="Markdown"></p><h3 id="most-frequent-words-with-specific-meaning"><a href="#most-frequent-words-with-specific-meaning" class="headerlink" title="most frequent words with specific meaning"></a>most frequent words with specific meaning</h3><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">count = <span class="number">50</span></span><br><span class="line">index = index_54[:count]</span><br><span class="line">fig,ax=plt.subplots(<span class="number">1</span>,figsize=(<span class="number">20</span>,<span class="number">10</span>))</span><br><span class="line">barlist = plt.bar(range(count),countlist[index,<span class="number">1</span>].astype(<span class="string">'int'</span>))</span><br><span class="line"><span class="keyword">for</span> <span class="selector-tag">i</span> <span class="keyword">in</span> np.arange(<span class="number">0</span>,<span class="number">2</span>):</span><br><span class="line">    barlist[i].set_color(<span class="string">'r'</span>)</span><br><span class="line"><span class="keyword">for</span> <span class="selector-tag">i</span> <span class="keyword">in</span> np.arange(<span class="number">2</span>,<span class="number">5</span>):</span><br><span class="line">    barlist[i].set_color(<span class="string">'b'</span>)</span><br><span class="line"><span class="keyword">for</span> <span class="selector-tag">i</span> <span class="keyword">in</span> np.arange(<span class="number">5</span>,<span class="number">12</span>):</span><br><span class="line">    barlist[i].set_color(<span class="string">'g'</span>)</span><br><span class="line"><span class="keyword">for</span> <span class="selector-tag">i</span> <span class="keyword">in</span> np.arange(<span class="number">12</span>,<span class="number">26</span>):</span><br><span class="line">    barlist[i].set_color(<span class="string">'m'</span>)</span><br><span class="line"><span class="keyword">for</span> <span class="selector-tag">i</span> <span class="keyword">in</span> np.arange(<span class="number">26</span>,count):</span><br><span class="line">    barlist[i].set_color(<span class="string">'y'</span>)</span><br><span class="line">ax.set_xticks(range(count))</span><br><span class="line">ax.set_xticklabels(countlist[index,<span class="number">0</span>],fontsize=<span class="number">15</span>)</span><br><span class="line">ax.set_title(<span class="string">'Most Frequent Words in Philosophical Investigations'</span>,fontsize=<span class="number">30</span>)</span><br><span class="line">plt.setp(ax.get_xticklabels(), rotation=<span class="number">30</span>, horizontalalignment=<span class="string">'right'</span>)</span><br><span class="line">fig.tight_layout()</span><br></pre></td></tr></table></figure><p><img src="http://i2.tiimg.com/640680/1b87903c55d89ec6.png" alt="Markdown"></p><h3 id="words-frequency-by-chapter"><a href="#words-frequency-by-chapter" class="headerlink" title="words frequency by chapter"></a>words frequency by chapter</h3><figure class="highlight prolog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">chapterind = [<span class="number">1491</span>,<span class="number">82898</span>]</span><br><span class="line">namelist = countlist[index,<span class="number">0</span>]</span><br><span class="line">def count_frequent(chap,count):</span><br><span class="line">    freqlist =[]</span><br><span class="line">    if chap &lt;<span class="number">1</span>:</span><br><span class="line">        for i in range(count):</span><br><span class="line">            freqlist.append(np.where(wordlist[chapterind[chap]:chapterind[chap+<span class="number">1</span>]] ==namelist[i])[<span class="number">0</span>].shape[<span class="number">0</span>])</span><br><span class="line">    else:</span><br><span class="line">        for i in range(count):</span><br><span class="line">            freqlist.append(np.where(wordlist[chapterind[chap]:] ==namelist[i])[<span class="number">0</span>].shape[<span class="number">0</span>])</span><br><span class="line">    return np.array(freqlist)</span><br><span class="line">freq_var = np.ndarray([<span class="number">2</span>,<span class="number">50</span>])</span><br><span class="line">for i in range(<span class="number">2</span>):</span><br><span class="line">    freq_var[i] = count_frequent(i,<span class="number">50</span>)</span><br><span class="line">freq_var[<span class="number">0</span>,:] =freq_var[<span class="number">0</span>,:]/len1</span><br><span class="line">freq_var[<span class="number">1</span>,:] =freq_var[<span class="number">1</span>,:]/len2</span><br><span class="line">fig,ax=plt.subplots(<span class="number">1</span>,figsize =(<span class="number">10</span>,<span class="number">10</span>))</span><br><span class="line">ax.matshow(np.repeat(freq_var.<span class="symbol">T</span>,<span class="number">4</span>).reshape(<span class="number">50</span>,<span class="number">-1</span>) ,cmap =<span class="string">'jet'</span>)</span><br><span class="line">ax.set_title(<span class="string">'50 Key Words Fluctuation in 2 Parts'</span>)</span><br><span class="line">ax.set_xticks(np.arange(<span class="number">0</span>,<span class="number">12</span>,<span class="number">6</span>))</span><br><span class="line">ax.set_xticklabels([<span class="string">'Part I'</span>,<span class="string">'Part II'</span>])</span><br><span class="line">ax.set_yticks(range(<span class="number">50</span>))</span><br><span class="line">ax.set_yticklabels(namelist)</span><br></pre></td></tr></table></figure><p><strong>You can see the words variation in different chapters</strong>.  Unfortunately, unlike TLP, Wittgenstein only divide his book into two parts, so we can learn very little by feature fluctuation.</p><p><img src="http://i2.tiimg.com/640680/7b056710733efb93.png" alt="Markdown"></p><h3 id="Calculate-different-words’-distances"><a href="#Calculate-different-words’-distances" class="headerlink" title="Calculate different words’ distances"></a>Calculate different words’ distances</h3><p>I also think about how to depict different words’ relationship. One easiest way I think of is calculating two words minimum distance in the book whenever they appears. <strong>For example:</strong><br><figure class="highlight nix"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">def calculate_distance(ind1,ind2):</span><br><span class="line">    <span class="attr">pos1</span> = np.where(<span class="attr">wordlist==namelist[ind1])[0]</span></span><br><span class="line">    <span class="attr">pos2</span> = np.where(<span class="attr">wordlist==namelist[ind2])[0]</span></span><br><span class="line">    num1 ,<span class="attr">num2</span> = pos1.shape[<span class="number">0</span>],pos2.shape[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">if</span> num1&gt;num2:</span><br><span class="line">        <span class="attr">small</span> = num2</span><br><span class="line">        <span class="attr">large</span> = num1</span><br><span class="line">        <span class="attr">lararr</span> = pos1</span><br><span class="line">        <span class="attr">smarr</span> = pos2</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="attr">small</span> = num1</span><br><span class="line">        <span class="attr">large</span> = num2</span><br><span class="line">        <span class="attr">lararr</span> = pos2</span><br><span class="line">        <span class="attr">smarr</span> = pos1</span><br><span class="line">    <span class="attr">disarr</span> = np.ndarray([small,large])  <span class="comment">#each line calculate the small set's ith word's and large set's every words distance</span></span><br><span class="line">    <span class="attr">arr1=</span> np.repeat(smarr,large).reshape(-<span class="number">1</span>,large)</span><br><span class="line">    <span class="attr">arr2=</span> np.repeat(lararr,small).reshape(-<span class="number">1</span>,small).T</span><br><span class="line">    <span class="attr">mindis</span> = np.min(np.abs(arr2-arr1),<span class="attr">axis=1)</span></span><br><span class="line">    return mindis</span><br><span class="line">def draw_dist_count(ind1,ind2):</span><br><span class="line">    fig,<span class="attr">ax=plt.subplots(1,figsize=(20,10))</span></span><br><span class="line">    ax.bar(range(calculate_distance(<span class="number">0</span>,<span class="number">1</span>).shape[<span class="number">0</span>]),calculate_distance(<span class="number">0</span>,<span class="number">1</span>),<span class="attr">color='g')</span></span><br><span class="line">    ax.set_title('Minimum Distance of '+namelist[ind1]+<span class="string">" and "</span>+namelist[ind2])</span><br><span class="line">draw_dist_count(<span class="number">0</span>,<span class="number">1</span>)</span><br></pre></td></tr></table></figure></p><p>It is the minimum distance of two words: <strong>picture and game</strong>, we can see at the first half of the book, the two words have closer distance, which means they have higher chance appearing together or nearby. But in the last half, the author didn’t arrange them appearing together very close.</p><p><img src="http://i4.fuimg.com/640680/dd3d1fca192d56eb.png" alt="Markdown"></p><p>We can also see one word’s distance with many other words: <strong>game and other words</strong><br><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">fig,ax=plt.subplots(<span class="number">4</span>,<span class="number">2</span>,figsize=(<span class="number">20</span>,<span class="number">20</span>))</span><br><span class="line"><span class="keyword">for</span> <span class="selector-tag">i</span> <span class="keyword">in</span> range(<span class="number">4</span>):</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">2</span>):</span><br><span class="line">        ax[<span class="selector-tag">i</span>,j].bar(range(calculate_distance(<span class="number">2</span>*i+j,<span class="number">8</span>)<span class="selector-class">.shape</span>[<span class="number">0</span>]),calculate_distance(<span class="number">2</span>*i+j,<span class="number">8</span>))</span><br><span class="line">        ax[<span class="selector-tag">i</span>,j].set_title(<span class="string">'Minimum Distance of '</span>+namelist[<span class="number">9</span>]+<span class="string">" and "</span>+namelist[<span class="number">2</span>*i+j])</span><br></pre></td></tr></table></figure></p><p><img src="http://i2.tiimg.com/640680/d444d7717b1a13d8.png" alt="Markdown"></p><p>As we can see, the word game’s appearance with other words have different patterns, for example, it is closer to word use than word picture.</p><p>We can also overview one word’s distance(relationship) with others using hist or boxplot<br><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">fig,ax=plt.subplots(<span class="number">4</span>,<span class="number">2</span>,figsize=(<span class="number">20</span>,<span class="number">20</span>))</span><br><span class="line"><span class="keyword">for</span> <span class="selector-tag">i</span> <span class="keyword">in</span> range(<span class="number">4</span>):</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">2</span>):</span><br><span class="line">        ax[<span class="selector-tag">i</span>,j].hist(calculate_distance(<span class="number">0</span>,<span class="number">1</span>+<span class="number">2</span>*i+j),bins =<span class="number">50</span>,<span class="attribute">color</span>=<span class="string">'b'</span>,alpha=<span class="number">0.4</span>)</span><br><span class="line">        ax[<span class="selector-tag">i</span>,j].set_title(<span class="string">'Minimum Distance of '</span>+namelist[<span class="number">0</span>]+<span class="string">" and "</span>+namelist[<span class="number">1</span>+<span class="number">2</span>*i+j])</span><br></pre></td></tr></table></figure></p><p><img src="http://i2.tiimg.com/640680/20c8d426b5181b6b.png" alt="Markdown"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">dist_data = &#123;&#125;</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> np.arange(<span class="number">1</span>,<span class="number">20</span>):</span><br><span class="line">    dist_data[i] = calculate_distance(<span class="number">0</span>,i)</span><br><span class="line">dataframe_dxp = pd.concat((pd.DataFrame(&#123;namelist[i]:dist_data[i]&#125;) <span class="keyword">for</span> i <span class="keyword">in</span> np.arange(<span class="number">1</span>,<span class="number">20</span>)),axis=<span class="number">1</span>)</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line">fig, ax = plt.subplots(figsize=(<span class="number">100</span>,<span class="number">20</span>))</span><br><span class="line">sns.boxplot(data =dataframe_dxp,ax=ax,boxprops=dict(alpha=<span class="number">.5</span>),color=<span class="string">'g'</span>)</span><br><span class="line">ax.set_title(<span class="string">u'Proposition and others'</span>,fontsize=<span class="number">120</span>)</span><br><span class="line">ax.set_xticks(range(<span class="number">19</span>))</span><br><span class="line">ax.set_xticklabels(namelist[<span class="number">1</span>:<span class="number">20</span>],fontsize=<span class="number">80</span>)</span><br><span class="line">plt.setp(ax.get_xticklabels(), rotation=<span class="number">30</span>, horizontalalignment=<span class="string">'right'</span>)</span><br><span class="line">fig.tight_layout()</span><br></pre></td></tr></table></figure><p><img src="http://i2.tiimg.com/640680/93eed5dd19fdd212.png" alt="Markdown"></p><p>That’s all about my basic data mining and analysis of Philosophical Investigations. It took me a some time writing codes to count and plot. I believe in the future we can use data mining, natural language processing to do analysis more automatically. What’s more, it may do some really exciting and serious study instead of my basic plotting. We may use the powerful so called “artificial intelligence” tool to mine thousands of books and materials to analyze the hidden ideas which is omitted by human due to our limitation of memorizing. Thus we can understand more about the author and the ideas behind the book. For some book as “random and complex” as this one, it may be a good tool to help us understand more by using statistics and visualization.</p>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;AI’s-view&quot;&gt;&lt;a href=&quot;#AI’s-view&quot; class=&quot;headerlink&quot; title=&quot;AI’s view:&quot;&gt;&lt;/a&gt;AI’s view:&lt;/h3&gt;&lt;h4 id=&quot;what-is-AI&quot;&gt;&lt;a href=&quot;#what-is-AI&quot; class=&quot;headerlink&quot; title=&quot;what is AI&quot;&gt;&lt;/a&gt;what is AI&lt;/h4&gt;&lt;p&gt;Artificial intelligence means using program to accomplish tasks human can do by simulating human’s brain. The purpose of artificial intelligence is to bypass the brain and body to achieve a full understanding of human intelligence. The idea can be traced back to &lt;strong&gt;Turing machine&lt;/strong&gt; (we can already see some interesting coincidence here~ Turing has attended Wittgenstein’s class in Cambridge, though Turing holds different opinions, Wittgenstein values his ideas very much. Maybe Turing also get some inspiration during the idea conflict.)&lt;/p&gt;
    
    </summary>
    
      <category term="thoughts" scheme="https://www.cmwonderland.com/blog/categories/thoughts/"/>
    
    
      <category term="thoughts" scheme="https://www.cmwonderland.com/blog/tags/thoughts/"/>
    
      <category term="philosophy" scheme="https://www.cmwonderland.com/blog/tags/philosophy/"/>
    
      <category term="Wittgenstein" scheme="https://www.cmwonderland.com/blog/tags/Wittgenstein/"/>
    
      <category term="AI" scheme="https://www.cmwonderland.com/blog/tags/AI/"/>
    
  </entry>
  
  <entry>
    <title>Linear Regression Assignment 13</title>
    <link href="https://www.cmwonderland.com/blog/2018/05/28/48_line7/"/>
    <id>https://www.cmwonderland.com/blog/2018/05/28/48_line7/</id>
    <published>2018-05-28T08:01:19.000Z</published>
    <updated>2018-10-10T05:02:08.520Z</updated>
    
    <content type="html"><![CDATA[<p>The thirteenth assignment of Linear Regression. The assignment is written in Rmarkdown, a smart syntax supported by RStudio helping with formula, plot visualization and plugin codes running.</p><a id="more"></a><blockquote><p><strong>most recommend:</strong> <a href="https://www.cmwonderland.com/linearweek13.html"><strong>click here</strong></a> for <strong>html version</strong> of assignment, you can see codes as well as plots.</p></blockquote><p>You may also find the <a href="https://github.com/james20141606/somethingmore/tree/master/linear_regression_pdf" target="_blank" rel="noopener"><strong>PDF Version</strong></a> of this assignment from github. <strong>Or if you can cross the fire wall, just see below</strong>:<br><div class="row"><iframe src="https://drive.google.com/file/d/1WibEAysXOszktnD3d1BK8bDNcS-vN6wN/preview" style="width:100%; height:550px"></iframe></div></p><h1 id="1"><a href="#1" class="headerlink" title="1"></a>1</h1><h2 id="a"><a href="#a" class="headerlink" title="a"></a>a</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">dat&lt;-read.table(&quot;CH19PR10.txt&quot;)</span><br><span class="line">names(dat)&lt;-c(&apos;y&apos;,&apos;age&apos;,&apos;gender&apos;)</span><br><span class="line">dat$age&lt;-factor(dat$age)</span><br><span class="line">dat$gender&lt;-factor(dat$gender)</span><br><span class="line">fit&lt;-aov(data=dat,y~age*gender)</span><br><span class="line">summary(fit)</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">library(&quot;ggpubr&quot;)</span><br><span class="line">ggboxplot(dat, x = &quot;age&quot;, y = &quot;y&quot;, color = &quot;gender&quot;,</span><br><span class="line">          palette = c(&quot;#00AFBB&quot;, &quot;#E7B800&quot;))</span><br></pre></td></tr></table></figure><h2 id="b"><a href="#b" class="headerlink" title="b"></a>b</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">for (i in c(1,2,3,4,5,6))&#123;</span><br><span class="line">  print (sum(fit$residuals[(6*(i-1)+1):(6*i)]))</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Yes, they sum to zero for each treatment.</p><h2 id="c"><a href="#c" class="headerlink" title="c"></a>c</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">par(mfrow=c(1,2))</span><br><span class="line">stripchart(split(resid(fit), dat$gender), method = &quot;stack&quot;,  pch = 19)</span><br><span class="line">abline(h = seq(2, 4)-0.1)</span><br><span class="line">title(&quot;Aligned Residual Dot Plot gender&quot;)</span><br><span class="line">stripchart(split(resid(fit), dat$age), method = &quot;stack&quot;,  pch = 19)</span><br><span class="line">abline(h = seq(2, 4)-0.1)</span><br><span class="line">title(&quot;Aligned Residual Dot Plot age&quot;)</span><br></pre></td></tr></table></figure><h2 id="d"><a href="#d" class="headerlink" title="d"></a>d</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">rq&lt;-c()</span><br><span class="line">for (i in c(1:36)) &#123;</span><br><span class="line">  qq&lt;-qnorm((i-3/8)/(36+1/4))</span><br><span class="line">  rq&lt;-c(rq,qq)</span><br><span class="line">&#125;</span><br><span class="line">plot(rq,sort(fit$residuals))</span><br><span class="line">abline(0,1)</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cor(rq,sort(fit$residuals))**2</span><br></pre></td></tr></table></figure><p>when n = 36 and significance value = 0.05, the Critical Values for Coefficient of Correlation between Ordered Residuals and Expected Values under Normality is 0.97. And the correlation calculated is 0.9720399. So it appears reasonable.</p><h2 id="e"><a href="#e" class="headerlink" title="e"></a>e</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">par(mfrow=c(1,2))</span><br><span class="line">arrofres = matrix(nrow = 6,ncol = 6)</span><br><span class="line">for (i in c(1,2,3,4,5,6))&#123;</span><br><span class="line">  arrofres[i,]&lt;-fit$residuals[(6*(i-1)+1):(6*i)]</span><br><span class="line">&#125;</span><br><span class="line">matplot(arrofres)</span><br><span class="line">plot(fit$residuals,type = &apos;b&apos;)</span><br></pre></td></tr></table></figure><p>residuals in each treatment’s sum is equal to zero, and it seems that the residuals has no relation with treatments.</p><h1 id="2"><a href="#2" class="headerlink" title="2"></a>2</h1><h2 id="a-1"><a href="#a-1" class="headerlink" title="a"></a>a</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">interaction.plot(dat$age,dat$gender,dat$y,type=&quot;b&quot;,col=c(&quot;red&quot;,&quot;blue&quot;),pch=c(16,18))</span><br></pre></td></tr></table></figure><p>age has larger effect and gender has small effect, since they are nearly parrallel, they have little interaction.</p><h2 id="b-1"><a href="#b-1" class="headerlink" title="b"></a>b</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">fit&lt;-aov(data=dat,y~age*gender)</span><br><span class="line">anova(fit)</span><br></pre></td></tr></table></figure><p>age, it has the largest SSR.</p><h2 id="c-1"><a href="#c-1" class="headerlink" title="c"></a>c</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">fit&lt;-aov(data=dat,y~age*gender)</span><br><span class="line">anova(fit)</span><br><span class="line">qf(0.95,2,30)</span><br><span class="line">1-pf(1.0581,2,30)</span><br></pre></td></tr></table></figure><ul><li>Hypothesis: $H<em>0 : \sigma^2</em>{\alpha\beta}&gt;0, i =1,2,3,j=1,2 $</li><li>Decision rule: Reject $H<em>0$ if $F* &gt;F</em>{0.95,2,30}$</li><li>Conclusion: Since $F∗ = \frac{MSAB}{MSE} = 1.0581$ , we do not reject $H_0$ and conclude that there<br>are no interaction effects with p = 0.3597133</li></ul><h2 id="d-1"><a href="#d-1" class="headerlink" title="d"></a>d</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">qf(0.95,2,2)</span><br><span class="line">qf(0.95,1,2)</span><br><span class="line">1-pf(66.2907,2,2)</span><br><span class="line">1-pf(2.2791,1,2)</span><br></pre></td></tr></table></figure><h3 id="i-Factor-A-age-main-effect"><a href="#i-Factor-A-age-main-effect" class="headerlink" title="i. Factor A (age) main effect"></a>i. Factor A (age) main effect</h3><ul><li>Hypothesis: $H_0 : \alpha_i = 0 vs H_a$ : at least one $\alpha_i$ is not 0, i = 1, 2, 3</li><li>Decision rule: Reject $H<em>0$ if $F∗ = MSA/MSE &gt; F</em>{0.95,2,2} = 19$</li><li>Conclusion: Since F∗ = 158.361/2.528 =62.6428 , we reject $H_0$ and conclude that there is<br>Factor A main effect for the number of coats with p =0.01486089</li></ul><h3 id="ii-Factor-B-gender-main-effect"><a href="#ii-Factor-B-gender-main-effect" class="headerlink" title="ii. Factor B (gender) main effect"></a>ii. Factor B (gender) main effect</h3><ul><li>Hypothesis: $H_0 : \beta_i = 0 vs H_a$ : at least one $\beta_i$ is not 0, i = 1, 2</li><li>Decision rule: Reject $H<em>0$ if $F∗ = MSB/MSE &gt; F</em>{0.95,1,2} = 18.51282$</li><li>Conclusion: Since F∗ = 2.2791 , we do not reject $H_0$ and conclude that there is no<br>Factor B main effect for the number of coats with p =0.2701973</li></ul><h2 id="f"><a href="#f" class="headerlink" title="f"></a>f</h2><p>Yes, age has large effect and gender has little effect, and there are no apparent interactions</p><h2 id="g"><a href="#g" class="headerlink" title="g"></a>g</h2><ul><li>single factor: age 316.7, Residuals   82.2 </li><li>two factor: age 316.7, gender    5.44, age:gender   5.06, Residuals   71.67<br>factor A age has same sum of squares, and residuals’ sum of squares in single factor ANOVA equals to all other sum of squares in two factor ANOVA except age. Yes, the degree holds the same relation.</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;The thirteenth assignment of Linear Regression. The assignment is written in Rmarkdown, a smart syntax supported by RStudio helping with formula, plot visualization and plugin codes running.&lt;/p&gt;
    
    </summary>
    
      <category term="school work" scheme="https://www.cmwonderland.com/blog/categories/school-work/"/>
    
    
      <category term="codes" scheme="https://www.cmwonderland.com/blog/tags/codes/"/>
    
      <category term="statistics" scheme="https://www.cmwonderland.com/blog/tags/statistics/"/>
    
      <category term="assignment" scheme="https://www.cmwonderland.com/blog/tags/assignment/"/>
    
      <category term="R" scheme="https://www.cmwonderland.com/blog/tags/R/"/>
    
      <category term="linear regression" scheme="https://www.cmwonderland.com/blog/tags/linear-regression/"/>
    
  </entry>
  
  <entry>
    <title>Equilibrium inspiring AI</title>
    <link href="https://www.cmwonderland.com/blog/2018/05/23/27_aboutbrain&amp;dl/"/>
    <id>https://www.cmwonderland.com/blog/2018/05/23/27_aboutbrain&amp;dl/</id>
    <published>2018-05-23T08:49:39.000Z</published>
    <updated>2018-10-10T05:01:08.758Z</updated>
    
    <content type="html"><![CDATA[<p>本文写于2016年末，作为《脑科学与人工智能》一课的作业</p><h3 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h3><p>人工智能领域自惊艳出世以来已有几十年的历史，经过长久的蛰伏和起伏，在这两年徐徐展开渐至高潮的宏伟篇章。对人工智能的探讨是一个复杂的深奥的话题，我想选择人工智能与生物接壤的一个小角度，谈谈我对智能的理解。</p><a id="more"></a><p>脑科学与人工智能有着天然的交叉，虽然很多做技术的人并不懂得古老又崭新的神经学知识。我们的大脑确实格外神秘，我们的大脑有上千亿的神经元，还要再多上几个数量级的突触。这个数量虽然远远不如广袤的宇宙中行星的个数，但也足够赋予渺小的人类畅想的资质和勇气。思考本身就是个值得思考的有趣的话题，然而这类话题往往陷入人择原理的尴尬处境。人脑是如此复杂精细的结构，以至于我们用还原论的方法研究至今还进展尚浅，甚至也弄不明白人工智能和大脑结构究竟哪个能更快地弄明白原理。因此我想稍微降低一些难度，也是受到宋老师的启发，从智能的角度思考，试图像数学家和物理学家那样，思考得更基本一些。</p><h3 id="简单与复杂"><a href="#简单与复杂" class="headerlink" title="简单与复杂"></a>简单与复杂</h3><p>智能、生命的定义是什么，是一个不止由生物学家专有的宏大的问题。薛定谔就曾经写过令生物学家折服的小册子《生命是什么》，其负熵的概念颇有新意，只是那个时候意识和智能并没有被摆到很高的位置，而如今身体其他部位问题的解惑愈发加重了人们对于智能和意识的兴趣，我甚至觉得意识和智能就是万物之源，自然真理乃至永生之匙。</p><p>一门自称为科学的学科总是试图用尽可能少的通行的原理构建体系。物理学家苦苦寻觅统一基本作用力的终极理论，生物学家却不得不一开始就面对真实世界的复杂的模型。Paul Nurse曾经评论道：要真正理解细胞系统的复杂网络，可能不得不进入一个更抽象的陌生领域，这个领域更适于进行数学分析。</p><p>自从洛伦兹在分析天气问题时搞出来一套混沌科学的想法，这套神奇又诱人的理论就格外深入人心，人们可以把简单至三体问题复杂至生物系统、经济社会等各种问题代入其中并且摊手摇头。过去我们习惯于研究生物化学中的平衡状态，但是平衡态意味着寂静和死亡，生物系统中存在着大量的非平衡态，正是在非平衡态中得以产生秩序与结构。</p><p>大脑是无可置疑的复杂系统，神经元的立体连接，不同化学物质的复杂作用让整个系统复杂得让人心碎。随着连接组学等学科的深入发展，有更多的理论工作者开始努力阐释系统的原理。我们希望系统是尽可能简洁的，纵然结果并不简洁，但是希望源头是简洁的。就像四种基本作用力和精确的宇宙常数带来的宏大的宇宙，机械决定论畅想过拉普拉斯妖这样的预言家。现在我们知道仅从物理角度是不够拼凑出真理的全部的，那么我们还需要多少尽量简单的东西呢？</p><p>简单可以产生让人炫目的复杂，比如冯诺依曼提出的元胞自动机。就是一种简单的对真实世界的模型化建构。通过简单的非线性函数的耦合，元胞自动机可以产生极端复杂的结果。比如规则为184的自动机，可以描述交通流、模拟晶体生长。规则30可以产生混沌，用来做伪随机数发生器。最强大的110，被证明具有图灵完备性，具有通用的计算能力。110也许是目前最简单的通用计算机了，可以计算自然界能够计算的复杂性的上限。Wolfram大胆地提出了新的自然定律，指出自然系统不可能产生不可计算的行为。自然界中各种过程实现的计算在复杂程度上都是本质等价的，没有比通用计算机所能进行的计算更复杂的了。</p><p>元胞自动机的规则如此简单，却能产生如此复杂的强大的结果让人振奋。如果，人脑也是这么简单就好了，或者，稍微复杂一些，但是逃不过一些简单的规则的组合，只是这些规则的非线性乃至量子性像一团薄雾蒙住了我们的眼睛，这样的迷雾我们是不怕的，人类对简洁的天然的追求总会为我们拨云见日，揭示复杂背后的简单。</p><h3 id="从简单到复杂：描述智能的临界态"><a href="#从简单到复杂：描述智能的临界态" class="headerlink" title="从简单到复杂：描述智能的临界态"></a>从简单到复杂：描述智能的临界态</h3><p>人工智能已经在很多领域取得了成就，语音、视觉、自动驾驶、语言、博弈等等领域。</p><p>但是遗憾的是每个机器学习的系统只能解决特定问题，并不像人类大脑经过简单学习学会新的东西，通用的智能似乎是计算机很难实现的。</p><p>通用的智能是否有方法进行描述？人工智能解决某个具体问题，我们总能找到一个标准去判断其好坏，比如下围棋，视觉、语音识别准确率。那么通用性的评价标准是什么呢？</p><p>在《临界：智能设计的原则》一书中有这样有趣的观点：</p><blockquote><p>把智能/人工智能定义为在任意环境中找到最优解的能力。</p></blockquote><p>这种神奇的能力，在我看来受到一些更基本的原理的影响：比如对称性，最小作用量原理和熵。比如很简单的例子：一个粒子在盒子里自由运动，一旦撞到壁游戏就结束，那么最安全的，选择最多的位置就是正中央；当单摆恰好直立时，有两种不同的摆动方向，这位它自身提供了最大的未来的可能性，虽然它本身会处于一种不稳定平衡的状态。而当系统变得复杂的时候，这种不稳定的最大化可能就很容易维持了。</p><p>比如在鸟群或者昆虫群的集体运动中，要让未来有更多的可能性，鸟群的可能性包括更多的食物和对捕食者的应对，当未来有无穷的可能性时它们仍然有办法做出响应。一个天然的想法是无限可能性=每个粒子完全随机，其实这个想法是不对的，完全随机意味着可能性的急剧降低，系统的统计学指标会趋于完全确定，而完全的有序当然也不是可能性最多的选择。只有在处于某种临界态上，群体可以维持完整的同时每个粒子个体可以感受到未来刺激，并且在整个群体中产生长程的效应，微小的扰动就可以在群体中产生剧烈的响应。这样的性质是临界态的重要特点，这样的临界态才是对应于未来可能性最大的状态，也就是智能的状态。这个例子很好理解，看一下鸟群和海洋中的鱼群是如何在空间中做出令人炫目的群体运动就可以有最直观的感受了。完全的无序和完全的有序都不是最大化未来可能的选择，真正的选择应该是自组织临界态。</p><p>未来选择最多的状态应该是处于对称状态，可以发生对称性破缺；从动力学角度看，应该停留在分叉点或者中间转变态的点。某个对称性消失，系统就可能产生转变。在临界态附近系统会表现出既不完全随机也不完全有序的状态。两个晶体的温度差距可以非常小，但是图案样式可以有非常大的变化。临界态的图像的构象上有自相似的特性，图案上有分形的结构，这是临界现象的特点。</p><h3 id="沙堆模型与森林大火"><a href="#沙堆模型与森林大火" class="headerlink" title="沙堆模型与森林大火"></a>沙堆模型与森林大火</h3><p>桌子上放着一些沙子，沙子还比较少，不断增加沙子之后沙堆的斜坡的斜率会增加，但是不会无限增加，我们从来没有见过九十度的沙堆。当沙堆的斜坡斜率小于某个值，不断加沙子就会增加斜率，而达到某个值之后，不管怎么加沙子，尽管斜率会发生一些微小的变化，但是会维持在一个临界的斜率，它不需要我们用某种智能的方法维持就会自发维持，这就是沙堆模型，这就是能让系统自动保持在临界态附近的最简单模型。</p><p>我对沙堆模型感兴趣的原因之一是我的实验室老板(2016年)汤超教授也是该模型的发现者之一。这个模型有非常非常深刻又广泛的内涵。当我们去研究简单的东西（比如沙堆）时却能发现深刻的规律的时候，我们就会不禁去想，这背后应该有什么非常有趣的规律。</p><p>沙堆模型是非平衡物理中非常简单又深刻的模型，沙堆不断流入的沙粒可以看做系统对外界能量和信息的吸收，从而使自己维持在自组织临界的状态，这个模型是具有普适的意义的。前面从简单到复杂的模型已经让我们意识到，自组织临界的维持是需要条件的，沙堆模型向我们很好的演示了这一点，而这样的思想与生命拥有的智能不谋而合：我们正是依靠摄入能量和信息来抵御熵增，避免生命走向彻底的无序。</p><p>一粒沙子也可以改变整个系统的临界态。有可能造成巨大的崩塌的，也有可能没有什么影响。接下来再放的沙子又有可能恢复系统的临界态，也就是说沙子会造成系统的崩塌，但是系统的临界态还可以保持在很小的范围内。如果沙堆还没有到达临界态上，放上一粒沙子我们就可以很确定地说沙堆不会发生崩塌，而达到临界态之后沙堆有可能发生任意规模的崩塌，这也就是我们前面说的最大未来可能性。至于发生多大规模的崩塌，几位专家很容易地统计出来，沙堆崩塌规模的大小与概率符合幂律分布。</p><p>如果在临界状态下，外界不做干预的情况下沙堆的未来是无法预知的，而非临界态时的未来是可知的，这也是我们前面说的最大化未来可能。地质学家很快发现，地震震级与发生概率也符合幂律分布，地壳的活动可能也处于自组织临界的状态，这也是地震等灾害难以预测的原因。沙堆模型也是一种特殊的元胞自动机模型，有很多相关的研究。</p><p>不但许多自然现象里蕴含着沙堆模型，更贴近生命与智能的例子里也蕴含着这样的思想。鱼群的游动受到的扰动与一条鱼的速度分布符合幂律分布，人群的合作也可以与沙堆模型类比。一个沙子扰动附近的沙子的分叉行为就符合分形产生的规则，如果有初始状态的确定，这个结构还可以不断增长，比如生物发育中三个胚层的发育。</p><p><img src="http://i1.fuimg.com/640680/e707a6c6f4ea10a4.png" alt="Markdown"></p><p>生物/智能“自发选择”的符合自组织临界的特性让人欣喜，我们可以考虑把研究生物智能问题和研究系统自组织问题融入一体，从简单的动力学和统计学角度去思考智能的特性，这无疑是很好的结果了。</p><h3 id="森林大火与大脑的临界态"><a href="#森林大火与大脑的临界态" class="headerlink" title="森林大火与大脑的临界态"></a>森林大火与大脑的临界态</h3><p>森林大火模型与沙堆模型以一些相似性。一棵树的燃烧可能造成周围格点，也就是其他树的燃烧，这与沙子掉落导致斜率超过临界值带来的崩塌是类似的。不同之处在于：沙堆可以继续放沙子，而森林大火刚刚燃烧过的地方是不能再燃烧的，这种本来就是自然的特性的东西显然与生物模型更符合！稍微考虑一下就会想到，这可以与生物的不应期对应，这在大脑的功能中是重要的。因此研究森林大火的统计性质，从某种程度上也是在研究大脑神经活动的统计性质。</p><p>何帆先生曾经写过一篇政治杂文，用森林大火的模型研究政治现象（可见这种朴素普适的想法是很容易被人接受的），他提出如果不断地掉落一些小的火种，让森林部分燃烧，这样森林虽然燃烧一部分，但是火灾规模都不大，如果平时不燃烧，那么系统有小概率产生大的火灾的时候就很糟糕了，这里面想讲的政治道理其实已经比较明显了。</p><p>森林可能不是一年四季都处于临界状态的，何帆先生先放一把火的做法就让森林不那么容易发生火灾了，这就是让系统偏离平衡态的方法。雨水很多的地方不易发生火灾，可以被称为亚临界状态，如果非常干燥极易发生火灾，可以被称为超临界状态。</p><p>超临界状态也是系统和生命常见的状态。如果崩塌中有正反馈，一个崩塌就越容易造成崩塌，就像马太效应一样。正反馈的直接效果会带来要不然不崩塌要不然剧烈崩塌的双稳态。<br>其实这个现象是非常容易发生的，在非理想情况的沙堆实验中，沙子落下时会带有一定冲击力，沙子掉下时就会造成本来不至于崩塌的地方也崩塌，也就是说沙堆会处于某种超临界的状态，这种正反馈的效果就是真实实验观察时发现了很多巨大的崩塌。</p><p>换句话说，在沙堆实验中只要给系统一些正反馈，就会使系统处于一种超临界的状态下，使系统要不不崩塌要不产生巨大崩塌，这种状态就是双稳态。因为沙堆的崩塌是连带性的，因此一个崩塌区域是连城一片的，所以真实的沙堆模型可能就没有抽象的理论中那么复杂的分形结构。</p><p>下面是针对大脑神经活动的思考。图灵曾经有过一段深受时代影响的对机器思想的论述。他从原子弹的原理受到启发，提出人类的大脑输入的想法就像反应堆外界轰击的中子，这些中子会造成我们大脑的反应，这些反应可能会逐步消失，但是过量的轰击甚至会导致反应堆解体。图灵进一步提出了不具有真正思想的动物的大脑可能的情况：动物的大脑处于亚临界状态，输入想法则回到静息状态，而人类的一部分思想处于超临界状态，给一个想法可以创造出无穷无尽的想法。图灵很自然地就提出，想让机器拥有智能，就要让机器也拥有超临界的状态。<br>然而图灵的想法有两个重大的失误，这种设想并不直接对应于神经的活动，超临界状态也并不是最好的选择。超临界状态只有两种结果：大的崩塌或者小的崩塌。如果大脑真的出现超临界状态，比如大脑大范围的神经放电，这种现象就对应于癫痫。（当然超临界状态也许会给人一些因祸得福的好处，比如近乎“疯狂”的创造力）到了八九十年代，提出沙堆模型的bak在一个神经科学会议上提出，人类的大脑应该是临界态的，虽然当时没有办法进行实验验证，但是如今我们已经有非常多的实验证明大脑确实处于临界状态。</p><p>从小尺度上，我们可以观察到与沙堆模型相似的神经雪崩，一个神经的兴奋造成周围神经的兴奋。大尺度上，类似于鸟群一样，大脑皮层在时间空间上产生长程关联，虽然是小概率但是可能发生在行为层次上，产生类似于临界慢化的现象，类似于疾病的潜伏期。</p><p>虽然实验说明在大脑一小块儿区域有临界态，切片与完整的大脑还是不一样的，如今通过对整个大脑的测量，比如功能核磁共振FMRI，来做大脑神经活动研究，如果要说明大脑整体处于临界状态，就要看大脑的神经关联是否足够长。FMRI实验证明了大脑皮层的神经活动存在长程关联，从而说明了大脑在整体上也处于临界态。如今已经有理论说明了大脑的临界性与大脑的网络结构有关。</p><p>有一些人因为看一些画面闪烁过快的电视节目发生癫痫：频率过高的输入信号就像沙堆模型中大规模的沙粒下落会导致大规模沙崩导致癫痫。而正常人在看到这些画面不会癫痫的保护机制包括输入信号频率增加后突触的活动会降低，就像发生小火变多之后森林大火的可能性减小，也就是说我们的大脑存在机制保持在临界态上不会产生崩溃。这个例子也让人联想到最近一项治疗阿尔兹海默症的突破性研究，在大量的药物治疗尝试后，科学家试着用一定频率的闪光治疗阿尔兹海默症并且取得了奇效。这让人浮想联翩，除了对某些化学物质的刺激，一定频率（40Hz）的光还对大脑产生了什么影响。现在人们已经知道大脑的临界态对大脑的意义包括信息传输、存储、计算能力的提升。</p><h3 id="大脑中的幂律分布"><a href="#大脑中的幂律分布" class="headerlink" title="大脑中的幂律分布"></a>大脑中的幂律分布</h3><p>大脑中也是存在幂律分布的，新近的研究更是进一步阐释了这一点。该研究的其中一个实验是以蒙着眼睛的小鼠作为实验对象，实验结果表明在生物大脑中可能存在一种通用的计算原理。在小鼠大脑发育的关键阶段，蒙着眼睛的小鼠的大脑中与视觉相关的大脑区域会被重新分配其它心智任务。这似乎能够证明人脑和老鼠的大脑相似，都具有可塑性，可以以一种通用计算机器（universal computing machine）的方式进行重新编程。</p><p>钱卓教授花费了十多年的时间研究连接理论（Theory of Connectivity）中，试图发现人脑灰质（grey matter）中存在的一种占据主导地位的统一计算原理</p><p>很多人都一直在思考，在智能的起源和大脑的进化上一定有一个基本的设计原理，就像是 DNA 的双螺旋结构，每一个生物都有普遍存在的遗传密码。钱卓给出了证据说明人脑可能是按照一种极其简单的数理逻辑来运作的。连接理论（Theory of Connectivity）认为一个叫做基于二次幂的置换（power-of-two-based permutation）的简单算法可以被用来解释大脑的回路，其可表示为$N = 2^i -1$</p><p>研究观察说明大脑的基本计算算法确实是通过基于二次幂的置换逻辑进行组织的。这个简单的数学逻辑可以用来解释整个进化谱（evolutionary spectrum）中的大脑计算，范围涵盖最简单的神经网络到最复杂的神经网络。这种工作是令人震撼和激动的。想一想，一项结合了神经科学，自然世界与人工神经网络的研究，把一种普适的规律就这样发现了：自然界的幂律分布，大脑的简洁又普适的运算机制，又能给深度学习很多启发，这样的发现是对神经科学的重大的冲击，对人工智能的极大地促进，对自己的更加深刻的认识。这个公式的简洁让人舒适又开心，自然界就应该是这样的：复杂又简单，简单源自于思想与原理的统一，只要原理是统一的，我们就只需要处理数学和具体条件的复杂，这样的复杂性就可以被聪明的人类掌握于手中。这就是自然、科学、数理与思想的奇妙和联系！</p><p>进一步把临界态的特征适用于大脑中，可以看到大脑的一些特点，比如长程性：大脑存在着长程的时间与空间相关，让大脑有了更高的整合特性，这也是大家关注的大脑与AI的重要区别。比如均衡性，保持整体与保持敏感的平衡，而且在做出反应后依然可以保持敏感，而不是接受一波信息之后就放松了。这种状态是稳定性与随机性的最佳的平衡。人的大脑还在有序无序之间表达出很强的适应性，一个很随机的系统很灵活但是不稳定，比如今天做这个明天做这个但是记不住，没法应用和进步；一个很稳定的大脑可以记住很多东西但是并不能互相联系（比如AI），因此一个适应性很强的大脑应该在稳定性与随机性之间。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>我相信世界应该是简洁的，我们总是希望用各种方法逼近一些尽可能简洁美好的基本真理。现在工业界的深度学习进展迅速，这是对人类发展有益的好事，但是对于科学界来说，更关键的不是盲目的冒进，而是静下心来发现原理性的东西，计算科学家希望从数学和计算的角度研究，神经科学家希望从大脑结构和功能的角度研究，我想我们应该加入更多的系统生物学和物理学、统计学的想法，把所有的这些东西都融合起来，追本溯源，也许就可拨云见日，目见真理。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文写于2016年末，作为《脑科学与人工智能》一课的作业&lt;/p&gt;
&lt;h3 id=&quot;引言&quot;&gt;&lt;a href=&quot;#引言&quot; class=&quot;headerlink&quot; title=&quot;引言&quot;&gt;&lt;/a&gt;引言&lt;/h3&gt;&lt;p&gt;人工智能领域自惊艳出世以来已有几十年的历史，经过长久的蛰伏和起伏，在这两年徐徐展开渐至高潮的宏伟篇章。对人工智能的探讨是一个复杂的深奥的话题，我想选择人工智能与生物接壤的一个小角度，谈谈我对智能的理解。&lt;/p&gt;
    
    </summary>
    
      <category term="machine learning" scheme="https://www.cmwonderland.com/blog/categories/machine-learning/"/>
    
    
      <category term="deep learning" scheme="https://www.cmwonderland.com/blog/tags/deep-learning/"/>
    
      <category term="thoughts" scheme="https://www.cmwonderland.com/blog/tags/thoughts/"/>
    
      <category term="brain" scheme="https://www.cmwonderland.com/blog/tags/brain/"/>
    
  </entry>
  
</feed>
